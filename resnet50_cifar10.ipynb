{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os, sys\n",
    "import time\n",
    "import datetime\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Softloss(nn.Module):\n",
    "    def __init__(self,T=4,loss_portion=[1,0,0]) -> None:\n",
    "        '''\n",
    "        T: temperature\n",
    "        loss_portion: KLD, cosine, mse\n",
    "        '''\n",
    "        super(Softloss,self).__init__()\n",
    "        self.T=T\n",
    "        self.portion=loss_portion\n",
    "    def forward(self,x,y):\n",
    "        soft_x=F.log_softmax(x/self.T,dim=-1)\n",
    "        soft_y=F.softmax(y/self.T,dim=-1)\n",
    "        loss=self.portion[0]*F.kl_div(soft_x,soft_y,reduction=\"batchmean\")\\\n",
    "            +self.portion[1]*F.cosine_embedding_loss(soft_x,soft_y,torch.ones(soft_x.shape[0]).to(soft_x.device))\\\n",
    "            +self.portion[2]*F.mse_loss(soft_x,soft_y)\n",
    "        return loss*self.T*self.T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# useful libraries\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "#############################################\n",
    "# your code here\n",
    "# specify preprocessing function\n",
    "transform = transforms.Compose(\n",
    "    (\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "    )\n",
    ")\n",
    "transform_train = transforms.Compose(\n",
    "    (\n",
    "    \n",
    "    transforms.RandomCrop((32,32),padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    #transforms.RandomVerticalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "    \n",
    "    #\n",
    "    #transforms.ColorJitter(0.2,0,0)\n",
    "    \n",
    "    )\n",
    ")\n",
    "\n",
    "transform_val = transform\n",
    "#############################################\n",
    "# do NOT change these\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# a few arguments, do NOT change these\n",
    "DATA_ROOT = \"./data\"\n",
    "TRAIN_BATCH_SIZE = 128\n",
    "VAL_BATCH_SIZE = 100\n",
    "\n",
    "#############################################\n",
    "# your code here\n",
    "# construct dataset\n",
    "train_set = CIFAR10(\n",
    "    root=DATA_ROOT, \n",
    "    train=True, \n",
    "    download=True,\n",
    "    transform=transform_train    # your code\n",
    ")\n",
    "\n",
    "val_set = CIFAR10(\n",
    "    root=DATA_ROOT, \n",
    "    train=False, \n",
    "    download=True,\n",
    "    transform=transform_val    # your code\n",
    ")\n",
    "\n",
    "# construct dataloader\n",
    "train_loader = DataLoader(\n",
    "    train_set, \n",
    "    batch_size=TRAIN_BATCH_SIZE,  # your code\n",
    "    shuffle=True,     # your code\n",
    "    num_workers=2\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_set, \n",
    "    batch_size=VAL_BATCH_SIZE,  # your code\n",
    "    shuffle=False,     # your code\n",
    "    num_workers=2\n",
    ")\n",
    "#############################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models\n",
    "\n",
    "def train_res50(train_loader,val_loader,INITIAL_LR = 0.1,REG = 0.0006,DECAY_EPOCHS=70, DECAY=0.1,EPOCHS=200):\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    student=torchvision.models.resnet50(num_classes=10)\n",
    "    student=student.to(device)\n",
    "    model=student\n",
    "    \n",
    "\n",
    "    # some hyperparameters\n",
    "    # total number of training epochs\n",
    "\n",
    "    # hyperparameters, do NOT change right now\n",
    "    # initial learning rate\n",
    "    \n",
    "\n",
    "    # momentum for optimizer\n",
    "    MOMENTUM = 0.9\n",
    "\n",
    "    # L2 regularization strength\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    # Add optimizer\n",
    "    optimizer = optim.SGD(student.parameters(),weight_decay=REG,lr=INITIAL_LR,momentum=MOMENTUM,nesterov=True)\n",
    "\n",
    "    # the folder where the trained model is saved\n",
    "    CHECKPOINT_FOLDER = \"./tmp_model\"\n",
    "    \n",
    "   \n",
    "    # start the training/validation process\n",
    "    # the process should take about 5 minutes on a GTX 1070-Ti\n",
    "    # if the code is written efficiently.\n",
    "    best_val_acc = 0\n",
    "    current_learning_rate = INITIAL_LR\n",
    "    \n",
    "    print(\"==> Training starts!\")\n",
    "    print(\"=\"*50)\n",
    "    for i in range(0, EPOCHS):\n",
    "        # handle the learning rate scheduler.\n",
    "        \n",
    "        if i % DECAY_EPOCHS == 0 and i != 0 :\n",
    "            current_learning_rate = current_learning_rate * DECAY\n",
    "        \n",
    "            for param_group in optimizer.param_groups:\n",
    "                param_group['lr'] = current_learning_rate\n",
    "            #print(\"Current learning rate has decayed to %f\" %current_learning_rate)\n",
    "        \n",
    "        #######################\n",
    "        # your code here\n",
    "        # switch to train mode\n",
    "        model.train()\n",
    "        \n",
    "        #######################\n",
    "        \n",
    "        print(\"Epoch %d:\" %i)\n",
    "        # this help you compute the training accuracy\n",
    "        total_examples = 0\n",
    "        correct_examples = 0\n",
    "\n",
    "        train_loss = 0 # track training loss if you want\n",
    "        loader=train_loader\n",
    "        \n",
    "        # Train the model for 1 epoch.\n",
    "        for batch_idx, (inputs, targets) in enumerate(loader):\n",
    "            ####################################\n",
    "            # your code here\n",
    "            # copy inputs to device\n",
    "            inputs=inputs.to(device)\n",
    "            targets=targets.to(device).long()\n",
    "            # compute the output and loss\n",
    "            out=model(inputs)\n",
    "            loss=criterion(out,targets)\n",
    "            \n",
    "            # zero the gradient\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            # backpropagation\n",
    "            loss.backward()\n",
    "\n",
    "            \n",
    "            # apply gradient and update the weights\n",
    "            optimizer.step()\n",
    "            train_loss+=loss.item()\n",
    "            \n",
    "            # count the number of correctly predicted samples in the current batch\n",
    "            correct_examples+=torch.sum(out.argmax(-1)==targets).item()\n",
    "            ####################################\n",
    "        total_examples=len(train_loader.dataset)      \n",
    "        avg_loss = train_loss / len(train_loader)\n",
    "        avg_acc = correct_examples / total_examples\n",
    "        print(\"Training loss: %.4f, Training accuracy: %.4f\" %(avg_loss, avg_acc))\n",
    "\n",
    "        # Validate on the validation dataset\n",
    "        #######################\n",
    "        # your code here\n",
    "        # switch to eval mode\n",
    "        model.eval()\n",
    "        \n",
    "        #######################\n",
    "\n",
    "        # this help you compute the validation accuracy\n",
    "        total_examples = 0\n",
    "        correct_examples = 0\n",
    "        \n",
    "        val_loss = 0 # again, track the validation loss if you want\n",
    "\n",
    "        # disable gradient during validation, which can save GPU memory\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, (inputs, targets) in enumerate(val_loader):\n",
    "                ####################################\n",
    "                # your code here\n",
    "                # copy inputs to device\n",
    "                inputs=inputs.to(device)\n",
    "                targets=targets.to(device).long()\n",
    "                # compute the output and loss\n",
    "                out=model(inputs)\n",
    "                loss=criterion(out,targets)\n",
    "                # count the number of correctly predicted samples in the current batch\n",
    "                val_loss+=loss.item()\n",
    "                correct_examples+=torch.sum(out.argmax(-1)==targets).item()\n",
    "                \n",
    "                ####################################\n",
    "        total_examples=len(val_loader.dataset)\n",
    "        avg_loss = val_loss / len(val_loader)\n",
    "        avg_acc = correct_examples / total_examples\n",
    "        print(\"Validation loss: %.4f, Validation accuracy: %.4f\" % (avg_loss, avg_acc))\n",
    "        \n",
    "        # save the model checkpoint\n",
    "        if avg_acc > best_val_acc:\n",
    "            best_val_acc = avg_acc\n",
    "            if not os.path.exists(CHECKPOINT_FOLDER):\n",
    "                os.makedirs(CHECKPOINT_FOLDER)\n",
    "            print(\"Saving ...\")\n",
    "            state = {'state_dict': model.state_dict(),\n",
    "                    'epoch': i,\n",
    "                    }\n",
    "            torch.save(state, os.path.join(CHECKPOINT_FOLDER, \"res50\"+str(avg_acc)+'.pth'))\n",
    "            \n",
    "\n",
    "    print(\"=\"*50)\n",
    "    print(f\"==> Optimization finished! Best validation accuracy: {best_val_acc:.4f}\")\n",
    "    return best_val_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Training starts!\n",
      "==================================================\n",
      "Epoch 0:\n",
      "Training loss: 3.3901, Training accuracy: 0.1704\n",
      "Validation loss: 2.0135, Validation accuracy: 0.2316\n",
      "Saving ...\n",
      "Epoch 1:\n",
      "Training loss: 1.7112, Training accuracy: 0.3553\n",
      "Validation loss: 1.8202, Validation accuracy: 0.3739\n",
      "Saving ...\n",
      "Epoch 2:\n",
      "Training loss: 1.6265, Training accuracy: 0.3995\n",
      "Validation loss: 1.7643, Validation accuracy: 0.3522\n",
      "Epoch 3:\n",
      "Training loss: 1.5870, Training accuracy: 0.4148\n",
      "Validation loss: 1.6090, Validation accuracy: 0.4210\n",
      "Saving ...\n",
      "Epoch 4:\n",
      "Training loss: 1.5616, Training accuracy: 0.4289\n",
      "Validation loss: 1.8407, Validation accuracy: 0.3502\n",
      "Epoch 5:\n",
      "Training loss: 1.5455, Training accuracy: 0.4374\n",
      "Validation loss: 1.6466, Validation accuracy: 0.4002\n",
      "Epoch 6:\n",
      "Training loss: 1.5251, Training accuracy: 0.4489\n",
      "Validation loss: 2.1092, Validation accuracy: 0.3114\n",
      "Epoch 7:\n",
      "Training loss: 1.5193, Training accuracy: 0.4482\n",
      "Validation loss: 1.9360, Validation accuracy: 0.3347\n",
      "Epoch 8:\n",
      "Training loss: 1.5059, Training accuracy: 0.4565\n",
      "Validation loss: 1.4893, Validation accuracy: 0.4666\n",
      "Saving ...\n",
      "Epoch 9:\n",
      "Training loss: 1.5064, Training accuracy: 0.4587\n",
      "Validation loss: 2.0754, Validation accuracy: 0.3600\n",
      "Epoch 10:\n",
      "Training loss: 1.5076, Training accuracy: 0.4556\n",
      "Validation loss: 1.6864, Validation accuracy: 0.3918\n",
      "Epoch 11:\n",
      "Training loss: 1.5132, Training accuracy: 0.4551\n",
      "Validation loss: 1.8303, Validation accuracy: 0.3817\n",
      "Epoch 12:\n",
      "Training loss: 1.5124, Training accuracy: 0.4560\n",
      "Validation loss: 1.6097, Validation accuracy: 0.4083\n",
      "Epoch 13:\n",
      "Training loss: 1.5032, Training accuracy: 0.4536\n",
      "Validation loss: 1.6475, Validation accuracy: 0.4104\n",
      "Epoch 14:\n",
      "Training loss: 1.5028, Training accuracy: 0.4584\n",
      "Validation loss: 2.6851, Validation accuracy: 0.2669\n",
      "Epoch 15:\n",
      "Training loss: 1.5054, Training accuracy: 0.4568\n",
      "Validation loss: 1.7585, Validation accuracy: 0.3831\n",
      "Epoch 16:\n",
      "Training loss: 1.5199, Training accuracy: 0.4485\n",
      "Validation loss: 1.4506, Validation accuracy: 0.4795\n",
      "Saving ...\n",
      "Epoch 17:\n",
      "Training loss: 1.5075, Training accuracy: 0.4539\n",
      "Validation loss: 1.7216, Validation accuracy: 0.3901\n",
      "Epoch 18:\n",
      "Training loss: 1.5054, Training accuracy: 0.4569\n",
      "Validation loss: 1.7657, Validation accuracy: 0.3730\n",
      "Epoch 19:\n",
      "Training loss: 1.5078, Training accuracy: 0.4546\n",
      "Validation loss: 1.9825, Validation accuracy: 0.3228\n",
      "Epoch 20:\n",
      "Training loss: 1.5031, Training accuracy: 0.4561\n",
      "Validation loss: 1.7158, Validation accuracy: 0.3854\n",
      "Epoch 21:\n",
      "Training loss: 1.5035, Training accuracy: 0.4540\n",
      "Validation loss: 2.3415, Validation accuracy: 0.3241\n",
      "Epoch 22:\n",
      "Training loss: 1.5113, Training accuracy: 0.4537\n",
      "Validation loss: 1.7491, Validation accuracy: 0.3742\n",
      "Epoch 23:\n",
      "Training loss: 1.5199, Training accuracy: 0.4489\n",
      "Validation loss: 1.7628, Validation accuracy: 0.3777\n",
      "Epoch 24:\n",
      "Training loss: 1.5195, Training accuracy: 0.4476\n",
      "Validation loss: 1.8516, Validation accuracy: 0.3311\n",
      "Epoch 25:\n",
      "Training loss: 1.5107, Training accuracy: 0.4550\n",
      "Validation loss: 1.7895, Validation accuracy: 0.3740\n",
      "Epoch 26:\n",
      "Training loss: 1.5095, Training accuracy: 0.4559\n",
      "Validation loss: 1.5963, Validation accuracy: 0.4222\n",
      "Epoch 27:\n",
      "Training loss: 1.5132, Training accuracy: 0.4550\n",
      "Validation loss: 1.9620, Validation accuracy: 0.3610\n",
      "Epoch 28:\n",
      "Training loss: 1.5109, Training accuracy: 0.4556\n",
      "Validation loss: 1.7186, Validation accuracy: 0.3990\n",
      "Epoch 29:\n",
      "Training loss: 1.5136, Training accuracy: 0.4525\n",
      "Validation loss: 1.6957, Validation accuracy: 0.4105\n",
      "Epoch 30:\n",
      "Training loss: 1.5138, Training accuracy: 0.4567\n",
      "Validation loss: 1.6677, Validation accuracy: 0.4065\n",
      "Epoch 31:\n",
      "Training loss: 1.5116, Training accuracy: 0.4559\n",
      "Validation loss: 2.1385, Validation accuracy: 0.3417\n",
      "Epoch 32:\n",
      "Training loss: 1.5145, Training accuracy: 0.4553\n",
      "Validation loss: 1.6057, Validation accuracy: 0.4249\n",
      "Epoch 33:\n",
      "Training loss: 1.5213, Training accuracy: 0.4500\n",
      "Validation loss: 1.7743, Validation accuracy: 0.3999\n",
      "Epoch 34:\n",
      "Training loss: 1.5135, Training accuracy: 0.4561\n",
      "Validation loss: 1.6683, Validation accuracy: 0.4053\n",
      "Epoch 35:\n",
      "Training loss: 1.5214, Training accuracy: 0.4504\n",
      "Validation loss: 1.9541, Validation accuracy: 0.3408\n",
      "Epoch 36:\n",
      "Training loss: 1.5156, Training accuracy: 0.4495\n",
      "Validation loss: 1.6994, Validation accuracy: 0.3876\n",
      "Epoch 37:\n",
      "Training loss: 1.5260, Training accuracy: 0.4490\n",
      "Validation loss: 1.9324, Validation accuracy: 0.3831\n",
      "Epoch 38:\n",
      "Training loss: 1.5142, Training accuracy: 0.4531\n",
      "Validation loss: 1.7545, Validation accuracy: 0.3994\n",
      "Epoch 39:\n",
      "Training loss: 1.5189, Training accuracy: 0.4546\n",
      "Validation loss: 1.8586, Validation accuracy: 0.3684\n",
      "Epoch 40:\n",
      "Training loss: 1.5080, Training accuracy: 0.4541\n",
      "Validation loss: 1.5361, Validation accuracy: 0.4574\n",
      "Epoch 41:\n",
      "Training loss: 1.5166, Training accuracy: 0.4552\n",
      "Validation loss: 1.5271, Validation accuracy: 0.4533\n",
      "Epoch 42:\n",
      "Training loss: 1.5229, Training accuracy: 0.4484\n",
      "Validation loss: 1.6917, Validation accuracy: 0.4028\n",
      "Epoch 43:\n",
      "Training loss: 1.5254, Training accuracy: 0.4489\n",
      "Validation loss: 2.0157, Validation accuracy: 0.3989\n",
      "Epoch 44:\n",
      "Training loss: 1.5205, Training accuracy: 0.4516\n",
      "Validation loss: 1.7136, Validation accuracy: 0.3838\n",
      "Epoch 45:\n",
      "Training loss: 1.5201, Training accuracy: 0.4476\n",
      "Validation loss: 1.8037, Validation accuracy: 0.3622\n",
      "Epoch 46:\n",
      "Training loss: 1.5195, Training accuracy: 0.4487\n",
      "Validation loss: 1.8939, Validation accuracy: 0.3640\n",
      "Epoch 47:\n",
      "Training loss: 1.5236, Training accuracy: 0.4478\n",
      "Validation loss: 2.6913, Validation accuracy: 0.2250\n",
      "Epoch 48:\n",
      "Training loss: 1.5156, Training accuracy: 0.4535\n",
      "Validation loss: 1.6346, Validation accuracy: 0.4104\n",
      "Epoch 49:\n",
      "Training loss: 1.5206, Training accuracy: 0.4499\n",
      "Validation loss: 2.5733, Validation accuracy: 0.3278\n",
      "Epoch 50:\n",
      "Training loss: 1.5204, Training accuracy: 0.4497\n",
      "Validation loss: 1.8848, Validation accuracy: 0.3650\n",
      "Epoch 51:\n",
      "Training loss: 1.5238, Training accuracy: 0.4493\n",
      "Validation loss: 1.6075, Validation accuracy: 0.4069\n",
      "Epoch 52:\n",
      "Training loss: 1.5298, Training accuracy: 0.4438\n",
      "Validation loss: 1.5883, Validation accuracy: 0.4226\n",
      "Epoch 53:\n",
      "Training loss: 1.5156, Training accuracy: 0.4507\n",
      "Validation loss: 1.5562, Validation accuracy: 0.4288\n",
      "Epoch 54:\n",
      "Training loss: 1.5165, Training accuracy: 0.4508\n",
      "Validation loss: 2.3698, Validation accuracy: 0.3149\n",
      "Epoch 55:\n",
      "Training loss: 1.5185, Training accuracy: 0.4459\n",
      "Validation loss: 1.6587, Validation accuracy: 0.4172\n",
      "Epoch 56:\n",
      "Training loss: 1.5304, Training accuracy: 0.4465\n",
      "Validation loss: 1.6584, Validation accuracy: 0.3785\n",
      "Epoch 57:\n",
      "Training loss: 1.5227, Training accuracy: 0.4495\n",
      "Validation loss: 1.6995, Validation accuracy: 0.4130\n",
      "Epoch 58:\n",
      "Training loss: 1.5263, Training accuracy: 0.4488\n",
      "Validation loss: 1.7460, Validation accuracy: 0.3771\n",
      "Epoch 59:\n",
      "Training loss: 1.5312, Training accuracy: 0.4451\n",
      "Validation loss: 1.5807, Validation accuracy: 0.4163\n",
      "Epoch 60:\n",
      "Training loss: 1.2849, Training accuracy: 0.5388\n",
      "Validation loss: 1.2345, Validation accuracy: 0.5586\n",
      "Saving ...\n",
      "Epoch 61:\n",
      "Training loss: 1.2102, Training accuracy: 0.5680\n",
      "Validation loss: 1.2679, Validation accuracy: 0.5506\n",
      "Epoch 62:\n",
      "Training loss: 1.1823, Training accuracy: 0.5763\n",
      "Validation loss: 1.2285, Validation accuracy: 0.5601\n",
      "Saving ...\n",
      "Epoch 63:\n",
      "Training loss: 1.1611, Training accuracy: 0.5848\n",
      "Validation loss: 1.1773, Validation accuracy: 0.5777\n",
      "Saving ...\n",
      "Epoch 64:\n",
      "Training loss: 1.1526, Training accuracy: 0.5891\n",
      "Validation loss: 1.1488, Validation accuracy: 0.5979\n",
      "Saving ...\n",
      "Epoch 65:\n",
      "Training loss: 1.1308, Training accuracy: 0.5971\n",
      "Validation loss: 1.1882, Validation accuracy: 0.5865\n",
      "Epoch 66:\n",
      "Training loss: 1.1210, Training accuracy: 0.6008\n",
      "Validation loss: 1.1830, Validation accuracy: 0.5808\n",
      "Epoch 67:\n",
      "Training loss: 1.1038, Training accuracy: 0.6077\n",
      "Validation loss: 1.1805, Validation accuracy: 0.5927\n",
      "Epoch 68:\n",
      "Training loss: 1.0939, Training accuracy: 0.6118\n",
      "Validation loss: 1.1453, Validation accuracy: 0.5963\n",
      "Epoch 69:\n",
      "Training loss: 1.0840, Training accuracy: 0.6169\n",
      "Validation loss: 1.1316, Validation accuracy: 0.6038\n",
      "Saving ...\n",
      "Epoch 70:\n",
      "Training loss: 1.0745, Training accuracy: 0.6208\n",
      "Validation loss: 1.2069, Validation accuracy: 0.5749\n",
      "Epoch 71:\n",
      "Training loss: 1.0598, Training accuracy: 0.6274\n",
      "Validation loss: 1.1656, Validation accuracy: 0.5863\n",
      "Epoch 72:\n",
      "Training loss: 1.0491, Training accuracy: 0.6313\n",
      "Validation loss: 1.0596, Validation accuracy: 0.6159\n",
      "Saving ...\n",
      "Epoch 73:\n",
      "Training loss: 1.0404, Training accuracy: 0.6331\n",
      "Validation loss: 1.1337, Validation accuracy: 0.6078\n",
      "Epoch 74:\n",
      "Training loss: 1.0321, Training accuracy: 0.6360\n",
      "Validation loss: 0.9796, Validation accuracy: 0.6533\n",
      "Saving ...\n",
      "Epoch 75:\n",
      "Training loss: 1.0149, Training accuracy: 0.6415\n",
      "Validation loss: 0.9393, Validation accuracy: 0.6728\n",
      "Saving ...\n",
      "Epoch 76:\n",
      "Training loss: 1.0073, Training accuracy: 0.6483\n",
      "Validation loss: 1.1393, Validation accuracy: 0.6043\n",
      "Epoch 77:\n",
      "Training loss: 1.0041, Training accuracy: 0.6497\n",
      "Validation loss: 1.0041, Validation accuracy: 0.6499\n",
      "Epoch 78:\n",
      "Training loss: 0.9948, Training accuracy: 0.6529\n",
      "Validation loss: 1.0727, Validation accuracy: 0.6271\n",
      "Epoch 79:\n",
      "Training loss: 0.9889, Training accuracy: 0.6559\n",
      "Validation loss: 0.9801, Validation accuracy: 0.6575\n",
      "Epoch 80:\n",
      "Training loss: 0.9785, Training accuracy: 0.6602\n",
      "Validation loss: 1.0426, Validation accuracy: 0.6344\n",
      "Epoch 81:\n",
      "Training loss: 0.9822, Training accuracy: 0.6605\n",
      "Validation loss: 0.9318, Validation accuracy: 0.6751\n",
      "Saving ...\n",
      "Epoch 82:\n",
      "Training loss: 0.9751, Training accuracy: 0.6588\n",
      "Validation loss: 0.9918, Validation accuracy: 0.6568\n",
      "Epoch 83:\n",
      "Training loss: 0.9763, Training accuracy: 0.6631\n",
      "Validation loss: 1.0343, Validation accuracy: 0.6484\n",
      "Epoch 84:\n",
      "Training loss: 0.9638, Training accuracy: 0.6647\n",
      "Validation loss: 1.0057, Validation accuracy: 0.6555\n",
      "Epoch 85:\n",
      "Training loss: 0.9720, Training accuracy: 0.6611\n",
      "Validation loss: 1.0687, Validation accuracy: 0.6258\n",
      "Epoch 86:\n",
      "Training loss: 0.9617, Training accuracy: 0.6635\n",
      "Validation loss: 1.0670, Validation accuracy: 0.6389\n",
      "Epoch 87:\n",
      "Training loss: 0.9600, Training accuracy: 0.6669\n",
      "Validation loss: 0.9852, Validation accuracy: 0.6499\n",
      "Epoch 88:\n",
      "Training loss: 0.9625, Training accuracy: 0.6628\n",
      "Validation loss: 1.0705, Validation accuracy: 0.6274\n",
      "Epoch 89:\n",
      "Training loss: 0.9528, Training accuracy: 0.6696\n",
      "Validation loss: 0.9779, Validation accuracy: 0.6606\n",
      "Epoch 90:\n",
      "Training loss: 0.9516, Training accuracy: 0.6703\n",
      "Validation loss: 1.1075, Validation accuracy: 0.6268\n",
      "Epoch 91:\n",
      "Training loss: 0.9494, Training accuracy: 0.6699\n",
      "Validation loss: 0.9372, Validation accuracy: 0.6713\n",
      "Epoch 92:\n",
      "Training loss: 0.9513, Training accuracy: 0.6706\n",
      "Validation loss: 1.0531, Validation accuracy: 0.6375\n",
      "Epoch 93:\n",
      "Training loss: 0.9490, Training accuracy: 0.6722\n",
      "Validation loss: 0.9332, Validation accuracy: 0.6722\n",
      "Epoch 94:\n",
      "Training loss: 0.9443, Training accuracy: 0.6722\n",
      "Validation loss: 1.0410, Validation accuracy: 0.6392\n",
      "Epoch 95:\n",
      "Training loss: 0.9455, Training accuracy: 0.6703\n",
      "Validation loss: 1.0373, Validation accuracy: 0.6350\n",
      "Epoch 96:\n",
      "Training loss: 0.9424, Training accuracy: 0.6711\n",
      "Validation loss: 0.9228, Validation accuracy: 0.6800\n",
      "Saving ...\n",
      "Epoch 97:\n",
      "Training loss: 0.9393, Training accuracy: 0.6767\n",
      "Validation loss: 1.0238, Validation accuracy: 0.6470\n",
      "Epoch 98:\n",
      "Training loss: 0.9400, Training accuracy: 0.6736\n",
      "Validation loss: 1.0860, Validation accuracy: 0.6208\n",
      "Epoch 99:\n",
      "Training loss: 0.9429, Training accuracy: 0.6738\n",
      "Validation loss: 0.9709, Validation accuracy: 0.6684\n",
      "Epoch 100:\n",
      "Training loss: 0.9360, Training accuracy: 0.6758\n",
      "Validation loss: 1.1440, Validation accuracy: 0.6213\n",
      "Epoch 101:\n",
      "Training loss: 0.9378, Training accuracy: 0.6755\n",
      "Validation loss: 0.9571, Validation accuracy: 0.6678\n",
      "Epoch 102:\n",
      "Training loss: 0.9394, Training accuracy: 0.6729\n",
      "Validation loss: 1.0486, Validation accuracy: 0.6433\n",
      "Epoch 103:\n",
      "Training loss: 0.9366, Training accuracy: 0.6755\n",
      "Validation loss: 0.9352, Validation accuracy: 0.6790\n",
      "Epoch 104:\n",
      "Training loss: 0.9411, Training accuracy: 0.6753\n",
      "Validation loss: 1.0796, Validation accuracy: 0.6318\n",
      "Epoch 105:\n",
      "Training loss: 0.9319, Training accuracy: 0.6764\n",
      "Validation loss: 0.9878, Validation accuracy: 0.6657\n",
      "Epoch 106:\n",
      "Training loss: 0.9403, Training accuracy: 0.6762\n",
      "Validation loss: 1.0341, Validation accuracy: 0.6386\n",
      "Epoch 107:\n",
      "Training loss: 0.9370, Training accuracy: 0.6751\n",
      "Validation loss: 0.9222, Validation accuracy: 0.6800\n",
      "Epoch 108:\n",
      "Training loss: 0.9253, Training accuracy: 0.6783\n",
      "Validation loss: 1.1665, Validation accuracy: 0.5973\n",
      "Epoch 109:\n",
      "Training loss: 0.9272, Training accuracy: 0.6808\n",
      "Validation loss: 0.9388, Validation accuracy: 0.6768\n",
      "Epoch 110:\n",
      "Training loss: 0.9301, Training accuracy: 0.6763\n",
      "Validation loss: 0.8481, Validation accuracy: 0.7065\n",
      "Saving ...\n",
      "Epoch 111:\n",
      "Training loss: 0.9311, Training accuracy: 0.6766\n",
      "Validation loss: 1.0278, Validation accuracy: 0.6500\n",
      "Epoch 112:\n",
      "Training loss: 0.9280, Training accuracy: 0.6818\n",
      "Validation loss: 1.0085, Validation accuracy: 0.6535\n",
      "Epoch 113:\n",
      "Training loss: 0.9225, Training accuracy: 0.6830\n",
      "Validation loss: 0.8917, Validation accuracy: 0.6904\n",
      "Epoch 114:\n",
      "Training loss: 0.9321, Training accuracy: 0.6786\n",
      "Validation loss: 0.9194, Validation accuracy: 0.6809\n",
      "Epoch 115:\n",
      "Training loss: 0.9290, Training accuracy: 0.6770\n",
      "Validation loss: 1.0095, Validation accuracy: 0.6489\n",
      "Epoch 116:\n",
      "Training loss: 0.9271, Training accuracy: 0.6817\n",
      "Validation loss: 1.0093, Validation accuracy: 0.6540\n",
      "Epoch 117:\n",
      "Training loss: 0.9246, Training accuracy: 0.6789\n",
      "Validation loss: 1.0164, Validation accuracy: 0.6532\n",
      "Epoch 118:\n",
      "Training loss: 0.9203, Training accuracy: 0.6814\n",
      "Validation loss: 0.9364, Validation accuracy: 0.6782\n",
      "Epoch 119:\n",
      "Training loss: 0.9208, Training accuracy: 0.6812\n",
      "Validation loss: 0.9451, Validation accuracy: 0.6768\n",
      "Epoch 120:\n",
      "Training loss: 0.7707, Training accuracy: 0.7373\n",
      "Validation loss: 0.6988, Validation accuracy: 0.7608\n",
      "Saving ...\n",
      "Epoch 121:\n",
      "Training loss: 0.7158, Training accuracy: 0.7560\n",
      "Validation loss: 0.6875, Validation accuracy: 0.7647\n",
      "Saving ...\n",
      "Epoch 122:\n",
      "Training loss: 0.6957, Training accuracy: 0.7606\n",
      "Validation loss: 0.6630, Validation accuracy: 0.7742\n",
      "Saving ...\n",
      "Epoch 123:\n",
      "Training loss: 0.6803, Training accuracy: 0.7680\n",
      "Validation loss: 0.6495, Validation accuracy: 0.7766\n",
      "Saving ...\n",
      "Epoch 124:\n",
      "Training loss: 0.6707, Training accuracy: 0.7700\n",
      "Validation loss: 0.6440, Validation accuracy: 0.7777\n",
      "Saving ...\n",
      "Epoch 125:\n",
      "Training loss: 0.6619, Training accuracy: 0.7737\n",
      "Validation loss: 0.6448, Validation accuracy: 0.7796\n",
      "Saving ...\n",
      "Epoch 126:\n",
      "Training loss: 0.6587, Training accuracy: 0.7739\n",
      "Validation loss: 0.6361, Validation accuracy: 0.7808\n",
      "Saving ...\n",
      "Epoch 127:\n",
      "Training loss: 0.6482, Training accuracy: 0.7786\n",
      "Validation loss: 0.6254, Validation accuracy: 0.7877\n",
      "Saving ...\n",
      "Epoch 128:\n",
      "Training loss: 0.6474, Training accuracy: 0.7782\n",
      "Validation loss: 0.6232, Validation accuracy: 0.7885\n",
      "Saving ...\n",
      "Epoch 129:\n",
      "Training loss: 0.6436, Training accuracy: 0.7788\n",
      "Validation loss: 0.6350, Validation accuracy: 0.7844\n",
      "Epoch 130:\n",
      "Training loss: 0.6433, Training accuracy: 0.7802\n",
      "Validation loss: 0.6239, Validation accuracy: 0.7877\n",
      "Epoch 131:\n",
      "Training loss: 0.6403, Training accuracy: 0.7810\n",
      "Validation loss: 0.6479, Validation accuracy: 0.7780\n",
      "Epoch 132:\n",
      "Training loss: 0.6343, Training accuracy: 0.7838\n",
      "Validation loss: 0.6344, Validation accuracy: 0.7813\n",
      "Epoch 133:\n",
      "Training loss: 0.6337, Training accuracy: 0.7820\n",
      "Validation loss: 0.6468, Validation accuracy: 0.7787\n",
      "Epoch 134:\n",
      "Training loss: 0.6324, Training accuracy: 0.7833\n",
      "Validation loss: 0.6474, Validation accuracy: 0.7787\n",
      "Epoch 135:\n",
      "Training loss: 0.6316, Training accuracy: 0.7842\n",
      "Validation loss: 0.6496, Validation accuracy: 0.7800\n",
      "Epoch 136:\n",
      "Training loss: 0.6299, Training accuracy: 0.7862\n",
      "Validation loss: 0.6318, Validation accuracy: 0.7817\n",
      "Epoch 137:\n",
      "Training loss: 0.6313, Training accuracy: 0.7836\n",
      "Validation loss: 0.6422, Validation accuracy: 0.7797\n",
      "Epoch 138:\n",
      "Training loss: 0.6259, Training accuracy: 0.7848\n",
      "Validation loss: 0.6178, Validation accuracy: 0.7902\n",
      "Saving ...\n",
      "Epoch 139:\n",
      "Training loss: 0.6235, Training accuracy: 0.7874\n",
      "Validation loss: 0.6262, Validation accuracy: 0.7865\n",
      "Epoch 140:\n",
      "Training loss: 0.6225, Training accuracy: 0.7857\n",
      "Validation loss: 0.6518, Validation accuracy: 0.7758\n",
      "Epoch 141:\n",
      "Training loss: 0.6255, Training accuracy: 0.7853\n",
      "Validation loss: 0.6327, Validation accuracy: 0.7836\n",
      "Epoch 142:\n",
      "Training loss: 0.6197, Training accuracy: 0.7884\n",
      "Validation loss: 0.6639, Validation accuracy: 0.7707\n",
      "Epoch 143:\n",
      "Training loss: 0.6216, Training accuracy: 0.7863\n",
      "Validation loss: 0.6302, Validation accuracy: 0.7838\n",
      "Epoch 144:\n",
      "Training loss: 0.6197, Training accuracy: 0.7865\n",
      "Validation loss: 0.6379, Validation accuracy: 0.7811\n",
      "Epoch 145:\n",
      "Training loss: 0.6198, Training accuracy: 0.7897\n",
      "Validation loss: 0.6527, Validation accuracy: 0.7763\n",
      "Epoch 146:\n",
      "Training loss: 0.6202, Training accuracy: 0.7877\n",
      "Validation loss: 0.6531, Validation accuracy: 0.7754\n",
      "Epoch 147:\n",
      "Training loss: 0.6168, Training accuracy: 0.7901\n",
      "Validation loss: 0.6279, Validation accuracy: 0.7869\n",
      "Epoch 148:\n",
      "Training loss: 0.6211, Training accuracy: 0.7865\n",
      "Validation loss: 0.6464, Validation accuracy: 0.7815\n",
      "Epoch 149:\n",
      "Training loss: 0.6214, Training accuracy: 0.7876\n",
      "Validation loss: 0.6170, Validation accuracy: 0.7918\n",
      "Saving ...\n",
      "Epoch 150:\n",
      "Training loss: 0.6143, Training accuracy: 0.7913\n",
      "Validation loss: 0.6414, Validation accuracy: 0.7772\n",
      "Epoch 151:\n",
      "Training loss: 0.6147, Training accuracy: 0.7902\n",
      "Validation loss: 0.6474, Validation accuracy: 0.7774\n",
      "Epoch 152:\n",
      "Training loss: 0.6155, Training accuracy: 0.7873\n",
      "Validation loss: 0.6486, Validation accuracy: 0.7786\n",
      "Epoch 153:\n",
      "Training loss: 0.6104, Training accuracy: 0.7932\n",
      "Validation loss: 0.6401, Validation accuracy: 0.7836\n",
      "Epoch 154:\n",
      "Training loss: 0.6127, Training accuracy: 0.7910\n",
      "Validation loss: 0.6175, Validation accuracy: 0.7934\n",
      "Saving ...\n",
      "Epoch 155:\n",
      "Training loss: 0.6074, Training accuracy: 0.7932\n",
      "Validation loss: 0.6405, Validation accuracy: 0.7834\n",
      "Epoch 156:\n",
      "Training loss: 0.6090, Training accuracy: 0.7927\n",
      "Validation loss: 0.6304, Validation accuracy: 0.7873\n",
      "Epoch 157:\n",
      "Training loss: 0.6095, Training accuracy: 0.7917\n",
      "Validation loss: 0.6723, Validation accuracy: 0.7723\n",
      "Epoch 158:\n",
      "Training loss: 0.6087, Training accuracy: 0.7909\n",
      "Validation loss: 0.6452, Validation accuracy: 0.7821\n",
      "Epoch 159:\n",
      "Training loss: 0.6045, Training accuracy: 0.7933\n",
      "Validation loss: 0.6527, Validation accuracy: 0.7758\n",
      "Epoch 160:\n",
      "Training loss: 0.6056, Training accuracy: 0.7920\n",
      "Validation loss: 0.6323, Validation accuracy: 0.7867\n",
      "Epoch 161:\n",
      "Training loss: 0.6064, Training accuracy: 0.7924\n",
      "Validation loss: 0.6116, Validation accuracy: 0.7944\n",
      "Saving ...\n",
      "Epoch 162:\n",
      "Training loss: 0.6024, Training accuracy: 0.7954\n",
      "Validation loss: 0.6254, Validation accuracy: 0.7872\n",
      "Epoch 163:\n",
      "Training loss: 0.6010, Training accuracy: 0.7940\n",
      "Validation loss: 0.6647, Validation accuracy: 0.7769\n",
      "Epoch 164:\n",
      "Training loss: 0.6031, Training accuracy: 0.7929\n",
      "Validation loss: 0.6523, Validation accuracy: 0.7782\n",
      "Epoch 165:\n",
      "Training loss: 0.5961, Training accuracy: 0.7958\n",
      "Validation loss: 0.7033, Validation accuracy: 0.7638\n",
      "Epoch 166:\n",
      "Training loss: 0.5979, Training accuracy: 0.7977\n",
      "Validation loss: 0.6514, Validation accuracy: 0.7835\n",
      "Epoch 167:\n",
      "Training loss: 0.5996, Training accuracy: 0.7949\n",
      "Validation loss: 0.6593, Validation accuracy: 0.7786\n",
      "Epoch 168:\n",
      "Training loss: 0.5988, Training accuracy: 0.7949\n",
      "Validation loss: 0.6214, Validation accuracy: 0.7895\n",
      "Epoch 169:\n",
      "Training loss: 0.6014, Training accuracy: 0.7955\n",
      "Validation loss: 0.6370, Validation accuracy: 0.7834\n",
      "Epoch 170:\n",
      "Training loss: 0.5996, Training accuracy: 0.7930\n",
      "Validation loss: 0.6484, Validation accuracy: 0.7788\n",
      "Epoch 171:\n",
      "Training loss: 0.5878, Training accuracy: 0.7997\n",
      "Validation loss: 0.6408, Validation accuracy: 0.7842\n",
      "Epoch 172:\n",
      "Training loss: 0.5884, Training accuracy: 0.8004\n",
      "Validation loss: 0.6332, Validation accuracy: 0.7872\n",
      "Epoch 173:\n",
      "Training loss: 0.5930, Training accuracy: 0.7985\n",
      "Validation loss: 0.6323, Validation accuracy: 0.7832\n",
      "Epoch 174:\n",
      "Training loss: 0.5928, Training accuracy: 0.7972\n",
      "Validation loss: 0.6603, Validation accuracy: 0.7764\n",
      "Epoch 175:\n",
      "Training loss: 0.5899, Training accuracy: 0.7992\n",
      "Validation loss: 0.6160, Validation accuracy: 0.7863\n",
      "Epoch 176:\n",
      "Training loss: 0.5879, Training accuracy: 0.7994\n",
      "Validation loss: 0.6220, Validation accuracy: 0.7888\n",
      "Epoch 177:\n",
      "Training loss: 0.5905, Training accuracy: 0.7967\n",
      "Validation loss: 0.6171, Validation accuracy: 0.7874\n",
      "Epoch 178:\n",
      "Training loss: 0.5874, Training accuracy: 0.7997\n",
      "Validation loss: 0.6212, Validation accuracy: 0.7919\n",
      "Epoch 179:\n",
      "Training loss: 0.5848, Training accuracy: 0.8012\n",
      "Validation loss: 0.6181, Validation accuracy: 0.7907\n",
      "Epoch 180:\n",
      "Training loss: 0.5177, Training accuracy: 0.8247\n",
      "Validation loss: 0.5393, Validation accuracy: 0.8196\n",
      "Saving ...\n",
      "Epoch 181:\n",
      "Training loss: 0.4919, Training accuracy: 0.8344\n",
      "Validation loss: 0.5343, Validation accuracy: 0.8201\n",
      "Saving ...\n",
      "Epoch 182:\n",
      "Training loss: 0.4842, Training accuracy: 0.8369\n",
      "Validation loss: 0.5370, Validation accuracy: 0.8215\n",
      "Saving ...\n",
      "Epoch 183:\n",
      "Training loss: 0.4731, Training accuracy: 0.8390\n",
      "Validation loss: 0.5266, Validation accuracy: 0.8233\n",
      "Saving ...\n",
      "Epoch 184:\n",
      "Training loss: 0.4709, Training accuracy: 0.8429\n",
      "Validation loss: 0.5224, Validation accuracy: 0.8215\n",
      "Epoch 185:\n",
      "Training loss: 0.4675, Training accuracy: 0.8426\n",
      "Validation loss: 0.5256, Validation accuracy: 0.8221\n",
      "Epoch 186:\n",
      "Training loss: 0.4621, Training accuracy: 0.8451\n",
      "Validation loss: 0.5266, Validation accuracy: 0.8249\n",
      "Saving ...\n",
      "Epoch 187:\n",
      "Training loss: 0.4621, Training accuracy: 0.8451\n",
      "Validation loss: 0.5220, Validation accuracy: 0.8264\n",
      "Saving ...\n",
      "Epoch 188:\n",
      "Training loss: 0.4563, Training accuracy: 0.8478\n",
      "Validation loss: 0.5232, Validation accuracy: 0.8252\n",
      "Epoch 189:\n",
      "Training loss: 0.4522, Training accuracy: 0.8495\n",
      "Validation loss: 0.5232, Validation accuracy: 0.8223\n",
      "Epoch 190:\n",
      "Training loss: 0.4511, Training accuracy: 0.8484\n",
      "Validation loss: 0.5278, Validation accuracy: 0.8211\n",
      "Epoch 191:\n",
      "Training loss: 0.4484, Training accuracy: 0.8497\n",
      "Validation loss: 0.5271, Validation accuracy: 0.8226\n",
      "Epoch 192:\n",
      "Training loss: 0.4457, Training accuracy: 0.8514\n",
      "Validation loss: 0.5275, Validation accuracy: 0.8231\n",
      "Epoch 193:\n",
      "Training loss: 0.4397, Training accuracy: 0.8527\n",
      "Validation loss: 0.5196, Validation accuracy: 0.8240\n",
      "Epoch 194:\n",
      "Training loss: 0.4445, Training accuracy: 0.8511\n",
      "Validation loss: 0.5268, Validation accuracy: 0.8234\n",
      "Epoch 195:\n",
      "Training loss: 0.4414, Training accuracy: 0.8529\n",
      "Validation loss: 0.5195, Validation accuracy: 0.8231\n",
      "Epoch 196:\n",
      "Training loss: 0.4402, Training accuracy: 0.8538\n",
      "Validation loss: 0.5241, Validation accuracy: 0.8250\n",
      "Epoch 197:\n",
      "Training loss: 0.4312, Training accuracy: 0.8573\n",
      "Validation loss: 0.5241, Validation accuracy: 0.8227\n",
      "Epoch 198:\n",
      "Training loss: 0.4331, Training accuracy: 0.8547\n",
      "Validation loss: 0.5192, Validation accuracy: 0.8239\n",
      "Epoch 199:\n",
      "Training loss: 0.4338, Training accuracy: 0.8555\n",
      "Validation loss: 0.5198, Validation accuracy: 0.8247\n",
      "==================================================\n",
      "==> Optimization finished! Best validation accuracy: 0.8264\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8264"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_res50(train_loader,val_loader,INITIAL_LR = 0.1,REG = 0.006,DECAY_EPOCHS=60, DECAY=0.1,EPOCHS=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Training starts!\n",
      "==================================================\n",
      "Epoch 0:\n",
      "Training loss: 3.5819, Training accuracy: 0.1809\n",
      "Validation loss: 2.7670, Validation accuracy: 0.2662\n",
      "Saving ...\n",
      "Epoch 1:\n",
      "Training loss: 1.9021, Training accuracy: 0.2966\n",
      "Validation loss: 1.7865, Validation accuracy: 0.3394\n",
      "Saving ...\n",
      "Epoch 2:\n",
      "Training loss: 1.7073, Training accuracy: 0.3601\n",
      "Validation loss: 1.7529, Validation accuracy: 0.3573\n",
      "Saving ...\n",
      "Epoch 3:\n",
      "Training loss: 1.6005, Training accuracy: 0.4036\n",
      "Validation loss: 1.7760, Validation accuracy: 0.3764\n",
      "Saving ...\n",
      "Epoch 4:\n",
      "Training loss: 1.5132, Training accuracy: 0.4440\n",
      "Validation loss: 1.5327, Validation accuracy: 0.4545\n",
      "Saving ...\n",
      "Epoch 5:\n",
      "Training loss: 1.4416, Training accuracy: 0.4721\n",
      "Validation loss: 1.4366, Validation accuracy: 0.4853\n",
      "Saving ...\n",
      "Epoch 6:\n",
      "Training loss: 1.3681, Training accuracy: 0.5043\n",
      "Validation loss: 1.3236, Validation accuracy: 0.5345\n",
      "Saving ...\n",
      "Epoch 7:\n",
      "Training loss: 1.2973, Training accuracy: 0.5297\n",
      "Validation loss: 1.3484, Validation accuracy: 0.5318\n",
      "Epoch 8:\n",
      "Training loss: 1.2209, Training accuracy: 0.5603\n",
      "Validation loss: 1.3066, Validation accuracy: 0.5582\n",
      "Saving ...\n",
      "Epoch 9:\n",
      "Training loss: 1.1417, Training accuracy: 0.5943\n",
      "Validation loss: 1.0852, Validation accuracy: 0.6127\n",
      "Saving ...\n",
      "Epoch 10:\n",
      "Training loss: 1.0745, Training accuracy: 0.6196\n",
      "Validation loss: 1.2346, Validation accuracy: 0.5888\n",
      "Epoch 11:\n",
      "Training loss: 1.1106, Training accuracy: 0.6093\n",
      "Validation loss: 1.0087, Validation accuracy: 0.6440\n",
      "Saving ...\n",
      "Epoch 12:\n",
      "Training loss: 1.0208, Training accuracy: 0.6406\n",
      "Validation loss: 0.9590, Validation accuracy: 0.6692\n",
      "Saving ...\n",
      "Epoch 13:\n",
      "Training loss: 0.9576, Training accuracy: 0.6651\n",
      "Validation loss: 0.9264, Validation accuracy: 0.6791\n",
      "Saving ...\n",
      "Epoch 14:\n",
      "Training loss: 0.9074, Training accuracy: 0.6854\n",
      "Validation loss: 0.8757, Validation accuracy: 0.6977\n",
      "Saving ...\n",
      "Epoch 15:\n",
      "Training loss: 0.8720, Training accuracy: 0.6943\n",
      "Validation loss: 0.8300, Validation accuracy: 0.7165\n",
      "Saving ...\n",
      "Epoch 16:\n",
      "Training loss: 0.8456, Training accuracy: 0.7051\n",
      "Validation loss: 0.8122, Validation accuracy: 0.7208\n",
      "Saving ...\n",
      "Epoch 17:\n",
      "Training loss: 0.8234, Training accuracy: 0.7131\n",
      "Validation loss: 0.8114, Validation accuracy: 0.7204\n",
      "Epoch 18:\n",
      "Training loss: 0.7870, Training accuracy: 0.7254\n",
      "Validation loss: 0.7817, Validation accuracy: 0.7274\n",
      "Saving ...\n",
      "Epoch 19:\n",
      "Training loss: 0.7672, Training accuracy: 0.7347\n",
      "Validation loss: 0.8502, Validation accuracy: 0.7125\n",
      "Epoch 20:\n",
      "Training loss: 0.7512, Training accuracy: 0.7398\n",
      "Validation loss: 0.7637, Validation accuracy: 0.7412\n",
      "Saving ...\n",
      "Epoch 21:\n",
      "Training loss: 0.7362, Training accuracy: 0.7464\n",
      "Validation loss: 0.7633, Validation accuracy: 0.7358\n",
      "Epoch 22:\n",
      "Training loss: 0.7094, Training accuracy: 0.7533\n",
      "Validation loss: 0.7667, Validation accuracy: 0.7387\n",
      "Epoch 23:\n",
      "Training loss: 0.6949, Training accuracy: 0.7608\n",
      "Validation loss: 0.7004, Validation accuracy: 0.7601\n",
      "Saving ...\n",
      "Epoch 24:\n",
      "Training loss: 0.6727, Training accuracy: 0.7678\n",
      "Validation loss: 0.7104, Validation accuracy: 0.7548\n",
      "Epoch 25:\n",
      "Training loss: 0.6696, Training accuracy: 0.7696\n",
      "Validation loss: 0.6945, Validation accuracy: 0.7626\n",
      "Saving ...\n",
      "Epoch 26:\n",
      "Training loss: 0.6422, Training accuracy: 0.7768\n",
      "Validation loss: 0.7260, Validation accuracy: 0.7513\n",
      "Epoch 27:\n",
      "Training loss: 0.6349, Training accuracy: 0.7812\n",
      "Validation loss: 0.7529, Validation accuracy: 0.7399\n",
      "Epoch 28:\n",
      "Training loss: 0.6162, Training accuracy: 0.7869\n",
      "Validation loss: 0.7350, Validation accuracy: 0.7509\n",
      "Epoch 29:\n",
      "Training loss: 0.6037, Training accuracy: 0.7911\n",
      "Validation loss: 0.7057, Validation accuracy: 0.7634\n",
      "Saving ...\n",
      "Epoch 30:\n",
      "Training loss: 0.5956, Training accuracy: 0.7943\n",
      "Validation loss: 0.6388, Validation accuracy: 0.7776\n",
      "Saving ...\n",
      "Epoch 31:\n",
      "Training loss: 0.5762, Training accuracy: 0.7989\n",
      "Validation loss: 0.6186, Validation accuracy: 0.7864\n",
      "Saving ...\n",
      "Epoch 32:\n",
      "Training loss: 0.5661, Training accuracy: 0.8038\n",
      "Validation loss: 0.6171, Validation accuracy: 0.7917\n",
      "Saving ...\n",
      "Epoch 33:\n",
      "Training loss: 0.5535, Training accuracy: 0.8095\n",
      "Validation loss: 0.6269, Validation accuracy: 0.7871\n",
      "Epoch 34:\n",
      "Training loss: 0.5446, Training accuracy: 0.8102\n",
      "Validation loss: 0.5851, Validation accuracy: 0.8036\n",
      "Saving ...\n",
      "Epoch 35:\n",
      "Training loss: 0.5289, Training accuracy: 0.8180\n",
      "Validation loss: 0.5548, Validation accuracy: 0.8106\n",
      "Saving ...\n",
      "Epoch 36:\n",
      "Training loss: 0.5186, Training accuracy: 0.8223\n",
      "Validation loss: 0.5506, Validation accuracy: 0.8139\n",
      "Saving ...\n",
      "Epoch 37:\n",
      "Training loss: 0.5068, Training accuracy: 0.8253\n",
      "Validation loss: 0.5945, Validation accuracy: 0.8020\n",
      "Epoch 38:\n",
      "Training loss: 0.4961, Training accuracy: 0.8274\n",
      "Validation loss: 0.5568, Validation accuracy: 0.8143\n",
      "Saving ...\n",
      "Epoch 39:\n",
      "Training loss: 0.4872, Training accuracy: 0.8302\n",
      "Validation loss: 0.5668, Validation accuracy: 0.8102\n",
      "Epoch 40:\n",
      "Training loss: 0.4734, Training accuracy: 0.8362\n",
      "Validation loss: 0.5767, Validation accuracy: 0.8053\n",
      "Epoch 41:\n",
      "Training loss: 0.4686, Training accuracy: 0.8390\n",
      "Validation loss: 0.5374, Validation accuracy: 0.8184\n",
      "Saving ...\n",
      "Epoch 42:\n",
      "Training loss: 0.4545, Training accuracy: 0.8427\n",
      "Validation loss: 0.5177, Validation accuracy: 0.8263\n",
      "Saving ...\n",
      "Epoch 43:\n",
      "Training loss: 0.4486, Training accuracy: 0.8461\n",
      "Validation loss: 0.5557, Validation accuracy: 0.8131\n",
      "Epoch 44:\n",
      "Training loss: 0.4399, Training accuracy: 0.8484\n",
      "Validation loss: 0.5303, Validation accuracy: 0.8212\n",
      "Epoch 45:\n",
      "Training loss: 0.4240, Training accuracy: 0.8556\n",
      "Validation loss: 0.5372, Validation accuracy: 0.8180\n",
      "Epoch 46:\n",
      "Training loss: 0.4195, Training accuracy: 0.8551\n",
      "Validation loss: 0.5179, Validation accuracy: 0.8236\n",
      "Epoch 47:\n",
      "Training loss: 0.4071, Training accuracy: 0.8583\n",
      "Validation loss: 0.5404, Validation accuracy: 0.8200\n",
      "Epoch 48:\n",
      "Training loss: 0.3999, Training accuracy: 0.8605\n",
      "Validation loss: 0.5265, Validation accuracy: 0.8291\n",
      "Saving ...\n",
      "Epoch 49:\n",
      "Training loss: 0.3910, Training accuracy: 0.8639\n",
      "Validation loss: 0.5154, Validation accuracy: 0.8283\n",
      "Epoch 50:\n",
      "Training loss: 0.3782, Training accuracy: 0.8701\n",
      "Validation loss: 0.5381, Validation accuracy: 0.8252\n",
      "Epoch 51:\n",
      "Training loss: 0.3738, Training accuracy: 0.8703\n",
      "Validation loss: 0.5473, Validation accuracy: 0.8224\n",
      "Epoch 52:\n",
      "Training loss: 0.3596, Training accuracy: 0.8753\n",
      "Validation loss: 0.5162, Validation accuracy: 0.8317\n",
      "Saving ...\n",
      "Epoch 53:\n",
      "Training loss: 0.3552, Training accuracy: 0.8771\n",
      "Validation loss: 0.5231, Validation accuracy: 0.8326\n",
      "Saving ...\n",
      "Epoch 54:\n",
      "Training loss: 0.3396, Training accuracy: 0.8812\n",
      "Validation loss: 0.4982, Validation accuracy: 0.8340\n",
      "Saving ...\n",
      "Epoch 55:\n",
      "Training loss: 0.3338, Training accuracy: 0.8833\n",
      "Validation loss: 0.4793, Validation accuracy: 0.8443\n",
      "Saving ...\n",
      "Epoch 56:\n",
      "Training loss: 0.3245, Training accuracy: 0.8868\n",
      "Validation loss: 0.4769, Validation accuracy: 0.8444\n",
      "Saving ...\n",
      "Epoch 57:\n",
      "Training loss: 0.3146, Training accuracy: 0.8903\n",
      "Validation loss: 0.4902, Validation accuracy: 0.8427\n",
      "Epoch 58:\n",
      "Training loss: 0.3100, Training accuracy: 0.8923\n",
      "Validation loss: 0.5235, Validation accuracy: 0.8322\n",
      "Epoch 59:\n",
      "Training loss: 0.3020, Training accuracy: 0.8940\n",
      "Validation loss: 0.4927, Validation accuracy: 0.8437\n",
      "Epoch 60:\n",
      "Training loss: 0.2901, Training accuracy: 0.8985\n",
      "Validation loss: 0.5325, Validation accuracy: 0.8325\n",
      "Epoch 61:\n",
      "Training loss: 0.2871, Training accuracy: 0.9006\n",
      "Validation loss: 0.4741, Validation accuracy: 0.8496\n",
      "Saving ...\n",
      "Epoch 62:\n",
      "Training loss: 0.2790, Training accuracy: 0.9019\n",
      "Validation loss: 0.4712, Validation accuracy: 0.8484\n",
      "Epoch 63:\n",
      "Training loss: 0.2656, Training accuracy: 0.9088\n",
      "Validation loss: 0.4776, Validation accuracy: 0.8490\n",
      "Epoch 64:\n",
      "Training loss: 0.2559, Training accuracy: 0.9109\n",
      "Validation loss: 0.4856, Validation accuracy: 0.8483\n",
      "Epoch 65:\n",
      "Training loss: 0.2532, Training accuracy: 0.9119\n",
      "Validation loss: 0.4782, Validation accuracy: 0.8532\n",
      "Saving ...\n",
      "Epoch 66:\n",
      "Training loss: 0.2459, Training accuracy: 0.9147\n",
      "Validation loss: 0.4808, Validation accuracy: 0.8504\n",
      "Epoch 67:\n",
      "Training loss: 0.2408, Training accuracy: 0.9165\n",
      "Validation loss: 0.4976, Validation accuracy: 0.8477\n",
      "Epoch 68:\n",
      "Training loss: 0.2288, Training accuracy: 0.9202\n",
      "Validation loss: 0.4893, Validation accuracy: 0.8471\n",
      "Epoch 69:\n",
      "Training loss: 0.2231, Training accuracy: 0.9220\n",
      "Validation loss: 0.4942, Validation accuracy: 0.8512\n",
      "Epoch 70:\n",
      "Training loss: 0.2158, Training accuracy: 0.9250\n",
      "Validation loss: 0.4914, Validation accuracy: 0.8527\n",
      "Epoch 71:\n",
      "Training loss: 0.2098, Training accuracy: 0.9266\n",
      "Validation loss: 0.4886, Validation accuracy: 0.8531\n",
      "Epoch 72:\n",
      "Training loss: 0.2032, Training accuracy: 0.9279\n",
      "Validation loss: 0.4885, Validation accuracy: 0.8536\n",
      "Saving ...\n",
      "Epoch 73:\n",
      "Training loss: 0.1925, Training accuracy: 0.9330\n",
      "Validation loss: 0.5042, Validation accuracy: 0.8490\n",
      "Epoch 74:\n",
      "Training loss: 0.1841, Training accuracy: 0.9363\n",
      "Validation loss: 0.4897, Validation accuracy: 0.8554\n",
      "Saving ...\n",
      "Epoch 75:\n",
      "Training loss: 0.1843, Training accuracy: 0.9357\n",
      "Validation loss: 0.5022, Validation accuracy: 0.8512\n",
      "Epoch 76:\n",
      "Training loss: 0.1816, Training accuracy: 0.9369\n",
      "Validation loss: 0.4827, Validation accuracy: 0.8595\n",
      "Saving ...\n",
      "Epoch 77:\n",
      "Training loss: 0.1721, Training accuracy: 0.9389\n",
      "Validation loss: 0.4771, Validation accuracy: 0.8605\n",
      "Saving ...\n",
      "Epoch 78:\n",
      "Training loss: 0.1583, Training accuracy: 0.9447\n",
      "Validation loss: 0.4963, Validation accuracy: 0.8557\n",
      "Epoch 79:\n",
      "Training loss: 0.1557, Training accuracy: 0.9461\n",
      "Validation loss: 0.4976, Validation accuracy: 0.8571\n",
      "Epoch 80:\n",
      "Training loss: 0.1574, Training accuracy: 0.9449\n",
      "Validation loss: 0.4769, Validation accuracy: 0.8618\n",
      "Saving ...\n",
      "Epoch 81:\n",
      "Training loss: 0.1423, Training accuracy: 0.9509\n",
      "Validation loss: 0.4859, Validation accuracy: 0.8588\n",
      "Epoch 82:\n",
      "Training loss: 0.1377, Training accuracy: 0.9527\n",
      "Validation loss: 0.5007, Validation accuracy: 0.8591\n",
      "Epoch 83:\n",
      "Training loss: 0.1340, Training accuracy: 0.9527\n",
      "Validation loss: 0.5014, Validation accuracy: 0.8587\n",
      "Epoch 84:\n",
      "Training loss: 0.1305, Training accuracy: 0.9550\n",
      "Validation loss: 0.4867, Validation accuracy: 0.8634\n",
      "Saving ...\n",
      "Epoch 85:\n",
      "Training loss: 0.1235, Training accuracy: 0.9572\n",
      "Validation loss: 0.5012, Validation accuracy: 0.8608\n",
      "Epoch 86:\n",
      "Training loss: 0.1179, Training accuracy: 0.9589\n",
      "Validation loss: 0.5055, Validation accuracy: 0.8634\n",
      "Epoch 87:\n",
      "Training loss: 0.1144, Training accuracy: 0.9597\n",
      "Validation loss: 0.4957, Validation accuracy: 0.8625\n",
      "Epoch 88:\n",
      "Training loss: 0.1098, Training accuracy: 0.9625\n",
      "Validation loss: 0.5214, Validation accuracy: 0.8594\n",
      "Epoch 89:\n",
      "Training loss: 0.1058, Training accuracy: 0.9634\n",
      "Validation loss: 0.5006, Validation accuracy: 0.8622\n",
      "Epoch 90:\n",
      "Training loss: 0.1008, Training accuracy: 0.9650\n",
      "Validation loss: 0.5237, Validation accuracy: 0.8590\n",
      "Epoch 91:\n",
      "Training loss: 0.0957, Training accuracy: 0.9669\n",
      "Validation loss: 0.5017, Validation accuracy: 0.8617\n",
      "Epoch 92:\n",
      "Training loss: 0.0935, Training accuracy: 0.9682\n",
      "Validation loss: 0.5143, Validation accuracy: 0.8631\n",
      "Epoch 93:\n",
      "Training loss: 0.0910, Training accuracy: 0.9691\n",
      "Validation loss: 0.5106, Validation accuracy: 0.8657\n",
      "Saving ...\n",
      "Epoch 94:\n",
      "Training loss: 0.0826, Training accuracy: 0.9724\n",
      "Validation loss: 0.5200, Validation accuracy: 0.8633\n",
      "Epoch 95:\n",
      "Training loss: 0.0806, Training accuracy: 0.9716\n",
      "Validation loss: 0.5207, Validation accuracy: 0.8646\n",
      "Epoch 96:\n",
      "Training loss: 0.0764, Training accuracy: 0.9734\n",
      "Validation loss: 0.5398, Validation accuracy: 0.8644\n",
      "Epoch 97:\n",
      "Training loss: 0.0719, Training accuracy: 0.9753\n",
      "Validation loss: 0.5361, Validation accuracy: 0.8628\n",
      "Epoch 98:\n",
      "Training loss: 0.0771, Training accuracy: 0.9737\n",
      "Validation loss: 0.5261, Validation accuracy: 0.8659\n",
      "Saving ...\n",
      "Epoch 99:\n",
      "Training loss: 0.0672, Training accuracy: 0.9777\n",
      "Validation loss: 0.5280, Validation accuracy: 0.8665\n",
      "Saving ...\n",
      "Epoch 100:\n",
      "Training loss: 0.0674, Training accuracy: 0.9775\n",
      "Validation loss: 0.5204, Validation accuracy: 0.8664\n",
      "Epoch 101:\n",
      "Training loss: 0.0668, Training accuracy: 0.9776\n",
      "Validation loss: 0.5158, Validation accuracy: 0.8673\n",
      "Saving ...\n",
      "Epoch 102:\n",
      "Training loss: 0.0606, Training accuracy: 0.9798\n",
      "Validation loss: 0.5345, Validation accuracy: 0.8661\n",
      "Epoch 103:\n",
      "Training loss: 0.0579, Training accuracy: 0.9806\n",
      "Validation loss: 0.5390, Validation accuracy: 0.8647\n",
      "Epoch 104:\n",
      "Training loss: 0.0551, Training accuracy: 0.9819\n",
      "Validation loss: 0.5338, Validation accuracy: 0.8661\n",
      "Epoch 105:\n",
      "Training loss: 0.0507, Training accuracy: 0.9832\n",
      "Validation loss: 0.5562, Validation accuracy: 0.8648\n",
      "Epoch 106:\n",
      "Training loss: 0.0511, Training accuracy: 0.9831\n",
      "Validation loss: 0.5405, Validation accuracy: 0.8687\n",
      "Saving ...\n",
      "Epoch 107:\n",
      "Training loss: 0.0478, Training accuracy: 0.9839\n",
      "Validation loss: 0.5441, Validation accuracy: 0.8666\n",
      "Epoch 108:\n",
      "Training loss: 0.0474, Training accuracy: 0.9844\n",
      "Validation loss: 0.5371, Validation accuracy: 0.8705\n",
      "Saving ...\n",
      "Epoch 109:\n",
      "Training loss: 0.0448, Training accuracy: 0.9858\n",
      "Validation loss: 0.5468, Validation accuracy: 0.8694\n",
      "Epoch 110:\n",
      "Training loss: 0.0433, Training accuracy: 0.9858\n",
      "Validation loss: 0.5293, Validation accuracy: 0.8706\n",
      "Saving ...\n",
      "Epoch 111:\n",
      "Training loss: 0.0393, Training accuracy: 0.9870\n",
      "Validation loss: 0.5453, Validation accuracy: 0.8701\n",
      "Epoch 112:\n",
      "Training loss: 0.0389, Training accuracy: 0.9874\n",
      "Validation loss: 0.5534, Validation accuracy: 0.8705\n",
      "Epoch 113:\n",
      "Training loss: 0.0379, Training accuracy: 0.9882\n",
      "Validation loss: 0.5446, Validation accuracy: 0.8725\n",
      "Saving ...\n",
      "Epoch 114:\n",
      "Training loss: 0.0354, Training accuracy: 0.9886\n",
      "Validation loss: 0.5592, Validation accuracy: 0.8709\n",
      "Epoch 115:\n",
      "Training loss: 0.0326, Training accuracy: 0.9895\n",
      "Validation loss: 0.5522, Validation accuracy: 0.8706\n",
      "Epoch 116:\n",
      "Training loss: 0.0338, Training accuracy: 0.9889\n",
      "Validation loss: 0.5556, Validation accuracy: 0.8694\n",
      "Epoch 117:\n",
      "Training loss: 0.0317, Training accuracy: 0.9895\n",
      "Validation loss: 0.5603, Validation accuracy: 0.8722\n",
      "Epoch 118:\n",
      "Training loss: 0.0290, Training accuracy: 0.9909\n",
      "Validation loss: 0.5598, Validation accuracy: 0.8717\n",
      "Epoch 119:\n",
      "Training loss: 0.0283, Training accuracy: 0.9908\n",
      "Validation loss: 0.5651, Validation accuracy: 0.8729\n",
      "Saving ...\n",
      "Epoch 120:\n",
      "Training loss: 0.0296, Training accuracy: 0.9902\n",
      "Validation loss: 0.5696, Validation accuracy: 0.8724\n",
      "Epoch 121:\n",
      "Training loss: 0.0276, Training accuracy: 0.9910\n",
      "Validation loss: 0.5668, Validation accuracy: 0.8703\n",
      "Epoch 122:\n",
      "Training loss: 0.0271, Training accuracy: 0.9912\n",
      "Validation loss: 0.5678, Validation accuracy: 0.8711\n",
      "Epoch 123:\n",
      "Training loss: 0.0262, Training accuracy: 0.9917\n",
      "Validation loss: 0.5715, Validation accuracy: 0.8728\n",
      "Epoch 124:\n",
      "Training loss: 0.0242, Training accuracy: 0.9921\n",
      "Validation loss: 0.5723, Validation accuracy: 0.8721\n",
      "Epoch 125:\n",
      "Training loss: 0.0236, Training accuracy: 0.9925\n",
      "Validation loss: 0.5676, Validation accuracy: 0.8739\n",
      "Saving ...\n",
      "Epoch 126:\n",
      "Training loss: 0.0223, Training accuracy: 0.9932\n",
      "Validation loss: 0.5667, Validation accuracy: 0.8740\n",
      "Saving ...\n",
      "Epoch 127:\n",
      "Training loss: 0.0233, Training accuracy: 0.9929\n",
      "Validation loss: 0.5666, Validation accuracy: 0.8740\n",
      "Epoch 128:\n",
      "Training loss: 0.0212, Training accuracy: 0.9933\n",
      "Validation loss: 0.5695, Validation accuracy: 0.8732\n",
      "Epoch 129:\n",
      "Training loss: 0.0203, Training accuracy: 0.9940\n",
      "Validation loss: 0.5711, Validation accuracy: 0.8742\n",
      "Saving ...\n",
      "Epoch 130:\n",
      "Training loss: 0.0209, Training accuracy: 0.9935\n",
      "Validation loss: 0.5692, Validation accuracy: 0.8726\n",
      "Epoch 131:\n",
      "Training loss: 0.0124, Training accuracy: 0.9964\n",
      "Validation loss: 0.5858, Validation accuracy: 0.8736\n",
      "Epoch 154:\n",
      "Training loss: 0.0118, Training accuracy: 0.9965\n",
      "Validation loss: 0.5886, Validation accuracy: 0.8759\n",
      "Epoch 155:\n",
      "Training loss: 0.0135, Training accuracy: 0.9963\n",
      "Validation loss: 0.5846, Validation accuracy: 0.8757\n",
      "Epoch 156:\n",
      "Training loss: 0.0124, Training accuracy: 0.9965\n",
      "Validation loss: 0.5883, Validation accuracy: 0.8737\n",
      "Epoch 157:\n",
      "Training loss: 0.0117, Training accuracy: 0.9966\n",
      "Validation loss: 0.5873, Validation accuracy: 0.8762\n",
      "Epoch 158:\n",
      "Training loss: 0.0101, Training accuracy: 0.9973\n",
      "Validation loss: 0.5842, Validation accuracy: 0.8758\n",
      "Epoch 159:\n",
      "Training loss: 0.0108, Training accuracy: 0.9970\n",
      "Validation loss: 0.5889, Validation accuracy: 0.8745\n",
      "Epoch 160:\n",
      "Training loss: 0.0113, Training accuracy: 0.9967\n",
      "Validation loss: 0.5866, Validation accuracy: 0.8750\n",
      "Epoch 161:\n",
      "Training loss: 0.0114, Training accuracy: 0.9969\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_15177/4270397593.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_res50\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mINITIAL_LR\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mREG\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0006\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mDECAY_EPOCHS\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDECAY\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.96\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_15177/2234163048.py\u001b[0m in \u001b[0;36mtrain_res50\u001b[0;34m(train_loader, val_loader, INITIAL_LR, REG, DECAY_EPOCHS, DECAY, EPOCHS)\u001b[0m\n\u001b[1;32m    112\u001b[0m                 \u001b[0;31m# your code here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m                 \u001b[0;31m# copy inputs to device\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m                 \u001b[0mtargets\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m                 \u001b[0;31m# compute the output and loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_res50(train_loader,val_loader,INITIAL_LR = 0.1,REG = 0.0006,DECAY_EPOCHS=1, DECAY=0.96,EPOCHS=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "55f20d8859a1a0149f7d957af872e078c8283691172f5ca78f1d0b16a2e38dc4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
