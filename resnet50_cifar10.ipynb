{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os, sys\n",
    "import time\n",
    "import datetime\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Softloss(nn.Module):\n",
    "    def __init__(self,T=4,loss_portion=[1,0,0]) -> None:\n",
    "        '''\n",
    "        T: temperature\n",
    "        loss_portion: KLD, cosine, mse\n",
    "        '''\n",
    "        super(Softloss,self).__init__()\n",
    "        self.T=T\n",
    "        self.portion=loss_portion\n",
    "    def forward(self,x,y):\n",
    "        soft_x=F.log_softmax(x/self.T,dim=-1)\n",
    "        soft_y=F.softmax(y/self.T,dim=-1)\n",
    "        loss=self.portion[0]*F.kl_div(soft_x,soft_y,reduction=\"batchmean\")\\\n",
    "            +self.portion[1]*F.cosine_embedding_loss(soft_x,soft_y,torch.ones(soft_x.shape[0]).to(soft_x.device))\\\n",
    "            +self.portion[2]*F.mse_loss(soft_x,soft_y)\n",
    "        return loss*self.T*self.T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# useful libraries\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "#############################################\n",
    "# your code here\n",
    "# specify preprocessing function\n",
    "transform = transforms.Compose(\n",
    "    (\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "    )\n",
    ")\n",
    "transform_train = transforms.Compose(\n",
    "    (\n",
    "    \n",
    "    transforms.RandomCrop((32,32),padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    #transforms.RandomVerticalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "    \n",
    "    #\n",
    "    #transforms.ColorJitter(0.2,0,0)\n",
    "    \n",
    "    )\n",
    ")\n",
    "\n",
    "transform_val = transform\n",
    "#############################################\n",
    "# do NOT change these\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# a few arguments, do NOT change these\n",
    "DATA_ROOT = \"./data\"\n",
    "TRAIN_BATCH_SIZE = 128\n",
    "VAL_BATCH_SIZE = 100\n",
    "\n",
    "#############################################\n",
    "# your code here\n",
    "# construct dataset\n",
    "train_set = CIFAR10(\n",
    "    root=DATA_ROOT, \n",
    "    train=True, \n",
    "    download=True,\n",
    "    transform=transform_train    # your code\n",
    ")\n",
    "\n",
    "val_set = CIFAR10(\n",
    "    root=DATA_ROOT, \n",
    "    train=False, \n",
    "    download=True,\n",
    "    transform=transform_val    # your code\n",
    ")\n",
    "\n",
    "# construct dataloader\n",
    "train_loader = DataLoader(\n",
    "    train_set, \n",
    "    batch_size=TRAIN_BATCH_SIZE,  # your code\n",
    "    shuffle=True,     # your code\n",
    "    num_workers=2\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_set, \n",
    "    batch_size=VAL_BATCH_SIZE,  # your code\n",
    "    shuffle=False,     # your code\n",
    "    num_workers=2\n",
    ")\n",
    "#############################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models\n",
    "\n",
    "def train_res50(train_loader,val_loader,INITIAL_LR = 0.1,REG = 0.0006,DECAY_EPOCHS=[70,140], DECAY=0.1,EPOCHS=200):\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    student=torchvision.models.resnet50(num_classes=10)\n",
    "    student=student.to(device)\n",
    "    model=student\n",
    "    \n",
    "\n",
    "    # some hyperparameters\n",
    "    # total number of training epochs\n",
    "\n",
    "    # hyperparameters, do NOT change right now\n",
    "    # initial learning rate\n",
    "    \n",
    "\n",
    "    # momentum for optimizer\n",
    "    MOMENTUM = 0.9\n",
    "\n",
    "    # L2 regularization strength\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    # Add optimizer\n",
    "    optimizer = optim.SGD(student.parameters(),weight_decay=REG,lr=INITIAL_LR,momentum=MOMENTUM,nesterov=True)\n",
    "\n",
    "    # the folder where the trained model is saved\n",
    "    CHECKPOINT_FOLDER = \"./tmp_model\"\n",
    "    \n",
    "   \n",
    "    # start the training/validation process\n",
    "    # the process should take about 5 minutes on a GTX 1070-Ti\n",
    "    # if the code is written efficiently.\n",
    "    best_val_acc = 0\n",
    "    current_learning_rate = INITIAL_LR\n",
    "    \n",
    "    print(\"==> Training starts!\")\n",
    "    print(\"=\"*50)\n",
    "    for i in range(0, EPOCHS):\n",
    "        # handle the learning rate scheduler.\n",
    "        \n",
    "        if i in DECAY_EPOCHS:\n",
    "            current_learning_rate = current_learning_rate * DECAY\n",
    "        \n",
    "            for param_group in optimizer.param_groups:\n",
    "                param_group['lr'] = current_learning_rate\n",
    "            #print(\"Current learning rate has decayed to %f\" %current_learning_rate)\n",
    "        \n",
    "        #######################\n",
    "        # your code here\n",
    "        # switch to train mode\n",
    "        model.train()\n",
    "        \n",
    "        #######################\n",
    "        \n",
    "        print(\"Epoch %d:\" %i)\n",
    "        # this help you compute the training accuracy\n",
    "        total_examples = 0\n",
    "        correct_examples = 0\n",
    "\n",
    "        train_loss = 0 # track training loss if you want\n",
    "        loader=train_loader\n",
    "        \n",
    "        # Train the model for 1 epoch.\n",
    "        for batch_idx, (inputs, targets) in enumerate(loader):\n",
    "            ####################################\n",
    "            # your code here\n",
    "            # copy inputs to device\n",
    "            inputs=inputs.to(device)\n",
    "            targets=targets.to(device).long()\n",
    "            # compute the output and loss\n",
    "            out=model(inputs)\n",
    "            loss=criterion(out,targets)\n",
    "            \n",
    "            # zero the gradient\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            # backpropagation\n",
    "            loss.backward()\n",
    "\n",
    "            \n",
    "            # apply gradient and update the weights\n",
    "            optimizer.step()\n",
    "            train_loss+=loss.item()\n",
    "            \n",
    "            # count the number of correctly predicted samples in the current batch\n",
    "            correct_examples+=torch.sum(out.argmax(-1)==targets).item()\n",
    "            ####################################\n",
    "        total_examples=len(train_loader.dataset)      \n",
    "        avg_loss = train_loss / len(train_loader)\n",
    "        avg_acc = correct_examples / total_examples\n",
    "        print(\"Training loss: %.4f, Training accuracy: %.4f\" %(avg_loss, avg_acc))\n",
    "\n",
    "        # Validate on the validation dataset\n",
    "        #######################\n",
    "        # your code here\n",
    "        # switch to eval mode\n",
    "        model.eval()\n",
    "        \n",
    "        #######################\n",
    "\n",
    "        # this help you compute the validation accuracy\n",
    "        total_examples = 0\n",
    "        correct_examples = 0\n",
    "        \n",
    "        val_loss = 0 # again, track the validation loss if you want\n",
    "\n",
    "        # disable gradient during validation, which can save GPU memory\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, (inputs, targets) in enumerate(val_loader):\n",
    "                ####################################\n",
    "                # your code here\n",
    "                # copy inputs to device\n",
    "                inputs=inputs.to(device)\n",
    "                targets=targets.to(device).long()\n",
    "                # compute the output and loss\n",
    "                out=model(inputs)\n",
    "                loss=criterion(out,targets)\n",
    "                # count the number of correctly predicted samples in the current batch\n",
    "                val_loss+=loss.item()\n",
    "                correct_examples+=torch.sum(out.argmax(-1)==targets).item()\n",
    "                \n",
    "                ####################################\n",
    "        total_examples=len(val_loader.dataset)\n",
    "        avg_loss = val_loss / len(val_loader)\n",
    "        avg_acc = correct_examples / total_examples\n",
    "        print(\"Validation loss: %.4f, Validation accuracy: %.4f\" % (avg_loss, avg_acc))\n",
    "        \n",
    "        # save the model checkpoint\n",
    "        if avg_acc > best_val_acc:\n",
    "            best_val_acc = avg_acc\n",
    "            if not os.path.exists(CHECKPOINT_FOLDER):\n",
    "                os.makedirs(CHECKPOINT_FOLDER)\n",
    "            print(\"Saving ...\")\n",
    "            state = {'state_dict': model.state_dict(),\n",
    "                    'epoch': i,\n",
    "                    }\n",
    "            torch.save(state, os.path.join(CHECKPOINT_FOLDER, \"res50\"+str(avg_acc)+'.pth'))\n",
    "            \n",
    "\n",
    "    print(\"=\"*50)\n",
    "    print(f\"==> Optimization finished! Best validation accuracy: {best_val_acc:.4f}\")\n",
    "    return best_val_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Training starts!\n",
      "==================================================\n",
      "Epoch 0:\n",
      "Training loss: 3.3901, Training accuracy: 0.1704\n",
      "Validation loss: 2.0135, Validation accuracy: 0.2316\n",
      "Saving ...\n",
      "Epoch 1:\n",
      "Training loss: 1.7112, Training accuracy: 0.3553\n",
      "Validation loss: 1.8202, Validation accuracy: 0.3739\n",
      "Saving ...\n",
      "Epoch 2:\n",
      "Training loss: 1.6265, Training accuracy: 0.3995\n",
      "Validation loss: 1.7643, Validation accuracy: 0.3522\n",
      "Epoch 3:\n",
      "Training loss: 1.5870, Training accuracy: 0.4148\n",
      "Validation loss: 1.6090, Validation accuracy: 0.4210\n",
      "Saving ...\n",
      "Epoch 4:\n",
      "Training loss: 1.5616, Training accuracy: 0.4289\n",
      "Validation loss: 1.8407, Validation accuracy: 0.3502\n",
      "Epoch 5:\n",
      "Training loss: 1.5455, Training accuracy: 0.4374\n",
      "Validation loss: 1.6466, Validation accuracy: 0.4002\n",
      "Epoch 6:\n",
      "Training loss: 1.5251, Training accuracy: 0.4489\n",
      "Validation loss: 2.1092, Validation accuracy: 0.3114\n",
      "Epoch 7:\n",
      "Training loss: 1.5193, Training accuracy: 0.4482\n",
      "Validation loss: 1.9360, Validation accuracy: 0.3347\n",
      "Epoch 8:\n",
      "Training loss: 1.5059, Training accuracy: 0.4565\n",
      "Validation loss: 1.4893, Validation accuracy: 0.4666\n",
      "Saving ...\n",
      "Epoch 9:\n",
      "Training loss: 1.5064, Training accuracy: 0.4587\n",
      "Validation loss: 2.0754, Validation accuracy: 0.3600\n",
      "Epoch 10:\n",
      "Training loss: 1.5076, Training accuracy: 0.4556\n",
      "Validation loss: 1.6864, Validation accuracy: 0.3918\n",
      "Epoch 11:\n",
      "Training loss: 1.5132, Training accuracy: 0.4551\n",
      "Validation loss: 1.8303, Validation accuracy: 0.3817\n",
      "Epoch 12:\n",
      "Training loss: 1.5124, Training accuracy: 0.4560\n",
      "Validation loss: 1.6097, Validation accuracy: 0.4083\n",
      "Epoch 13:\n",
      "Training loss: 1.5032, Training accuracy: 0.4536\n",
      "Validation loss: 1.6475, Validation accuracy: 0.4104\n",
      "Epoch 14:\n",
      "Training loss: 1.5028, Training accuracy: 0.4584\n",
      "Validation loss: 2.6851, Validation accuracy: 0.2669\n",
      "Epoch 15:\n",
      "Training loss: 1.5054, Training accuracy: 0.4568\n",
      "Validation loss: 1.7585, Validation accuracy: 0.3831\n",
      "Epoch 16:\n",
      "Training loss: 1.5199, Training accuracy: 0.4485\n",
      "Validation loss: 1.4506, Validation accuracy: 0.4795\n",
      "Saving ...\n",
      "Epoch 17:\n",
      "Training loss: 1.5075, Training accuracy: 0.4539\n",
      "Validation loss: 1.7216, Validation accuracy: 0.3901\n",
      "Epoch 18:\n",
      "Training loss: 1.5054, Training accuracy: 0.4569\n",
      "Validation loss: 1.7657, Validation accuracy: 0.3730\n",
      "Epoch 19:\n",
      "Training loss: 1.5078, Training accuracy: 0.4546\n",
      "Validation loss: 1.9825, Validation accuracy: 0.3228\n",
      "Epoch 20:\n",
      "Training loss: 1.5031, Training accuracy: 0.4561\n",
      "Validation loss: 1.7158, Validation accuracy: 0.3854\n",
      "Epoch 21:\n",
      "Training loss: 1.5035, Training accuracy: 0.4540\n",
      "Validation loss: 2.3415, Validation accuracy: 0.3241\n",
      "Epoch 22:\n",
      "Training loss: 1.5113, Training accuracy: 0.4537\n",
      "Validation loss: 1.7491, Validation accuracy: 0.3742\n",
      "Epoch 23:\n",
      "Training loss: 1.5199, Training accuracy: 0.4489\n",
      "Validation loss: 1.7628, Validation accuracy: 0.3777\n",
      "Epoch 24:\n",
      "Training loss: 1.5195, Training accuracy: 0.4476\n",
      "Validation loss: 1.8516, Validation accuracy: 0.3311\n",
      "Epoch 25:\n",
      "Training loss: 1.5107, Training accuracy: 0.4550\n",
      "Validation loss: 1.7895, Validation accuracy: 0.3740\n",
      "Epoch 26:\n",
      "Training loss: 1.5095, Training accuracy: 0.4559\n",
      "Validation loss: 1.5963, Validation accuracy: 0.4222\n",
      "Epoch 27:\n",
      "Training loss: 1.5132, Training accuracy: 0.4550\n",
      "Validation loss: 1.9620, Validation accuracy: 0.3610\n",
      "Epoch 28:\n",
      "Training loss: 1.5109, Training accuracy: 0.4556\n",
      "Validation loss: 1.7186, Validation accuracy: 0.3990\n",
      "Epoch 29:\n",
      "Training loss: 1.5136, Training accuracy: 0.4525\n",
      "Validation loss: 1.6957, Validation accuracy: 0.4105\n",
      "Epoch 30:\n",
      "Training loss: 1.5138, Training accuracy: 0.4567\n",
      "Validation loss: 1.6677, Validation accuracy: 0.4065\n",
      "Epoch 31:\n",
      "Training loss: 1.5116, Training accuracy: 0.4559\n",
      "Validation loss: 2.1385, Validation accuracy: 0.3417\n",
      "Epoch 32:\n",
      "Training loss: 1.5145, Training accuracy: 0.4553\n",
      "Validation loss: 1.6057, Validation accuracy: 0.4249\n",
      "Epoch 33:\n",
      "Training loss: 1.5213, Training accuracy: 0.4500\n",
      "Validation loss: 1.7743, Validation accuracy: 0.3999\n",
      "Epoch 34:\n",
      "Training loss: 1.5135, Training accuracy: 0.4561\n",
      "Validation loss: 1.6683, Validation accuracy: 0.4053\n",
      "Epoch 35:\n",
      "Training loss: 1.5214, Training accuracy: 0.4504\n",
      "Validation loss: 1.9541, Validation accuracy: 0.3408\n",
      "Epoch 36:\n",
      "Training loss: 1.5156, Training accuracy: 0.4495\n",
      "Validation loss: 1.6994, Validation accuracy: 0.3876\n",
      "Epoch 37:\n",
      "Training loss: 1.5260, Training accuracy: 0.4490\n",
      "Validation loss: 1.9324, Validation accuracy: 0.3831\n",
      "Epoch 38:\n",
      "Training loss: 1.5142, Training accuracy: 0.4531\n",
      "Validation loss: 1.7545, Validation accuracy: 0.3994\n",
      "Epoch 39:\n",
      "Training loss: 1.5189, Training accuracy: 0.4546\n",
      "Validation loss: 1.8586, Validation accuracy: 0.3684\n",
      "Epoch 40:\n",
      "Training loss: 1.5080, Training accuracy: 0.4541\n",
      "Validation loss: 1.5361, Validation accuracy: 0.4574\n",
      "Epoch 41:\n",
      "Training loss: 1.5166, Training accuracy: 0.4552\n",
      "Validation loss: 1.5271, Validation accuracy: 0.4533\n",
      "Epoch 42:\n",
      "Training loss: 1.5229, Training accuracy: 0.4484\n",
      "Validation loss: 1.6917, Validation accuracy: 0.4028\n",
      "Epoch 43:\n",
      "Training loss: 1.5254, Training accuracy: 0.4489\n",
      "Validation loss: 2.0157, Validation accuracy: 0.3989\n",
      "Epoch 44:\n",
      "Training loss: 1.5205, Training accuracy: 0.4516\n",
      "Validation loss: 1.7136, Validation accuracy: 0.3838\n",
      "Epoch 45:\n",
      "Training loss: 1.5201, Training accuracy: 0.4476\n",
      "Validation loss: 1.8037, Validation accuracy: 0.3622\n",
      "Epoch 46:\n",
      "Training loss: 1.5195, Training accuracy: 0.4487\n",
      "Validation loss: 1.8939, Validation accuracy: 0.3640\n",
      "Epoch 47:\n",
      "Training loss: 1.5236, Training accuracy: 0.4478\n",
      "Validation loss: 2.6913, Validation accuracy: 0.2250\n",
      "Epoch 48:\n",
      "Training loss: 1.5156, Training accuracy: 0.4535\n",
      "Validation loss: 1.6346, Validation accuracy: 0.4104\n",
      "Epoch 49:\n",
      "Training loss: 1.5206, Training accuracy: 0.4499\n",
      "Validation loss: 2.5733, Validation accuracy: 0.3278\n",
      "Epoch 50:\n",
      "Training loss: 1.5204, Training accuracy: 0.4497\n",
      "Validation loss: 1.8848, Validation accuracy: 0.3650\n",
      "Epoch 51:\n",
      "Training loss: 1.5238, Training accuracy: 0.4493\n",
      "Validation loss: 1.6075, Validation accuracy: 0.4069\n",
      "Epoch 52:\n",
      "Training loss: 1.5298, Training accuracy: 0.4438\n",
      "Validation loss: 1.5883, Validation accuracy: 0.4226\n",
      "Epoch 53:\n",
      "Training loss: 1.5156, Training accuracy: 0.4507\n",
      "Validation loss: 1.5562, Validation accuracy: 0.4288\n",
      "Epoch 54:\n",
      "Training loss: 1.5165, Training accuracy: 0.4508\n",
      "Validation loss: 2.3698, Validation accuracy: 0.3149\n",
      "Epoch 55:\n",
      "Training loss: 1.5185, Training accuracy: 0.4459\n",
      "Validation loss: 1.6587, Validation accuracy: 0.4172\n",
      "Epoch 56:\n",
      "Training loss: 1.5304, Training accuracy: 0.4465\n",
      "Validation loss: 1.6584, Validation accuracy: 0.3785\n",
      "Epoch 57:\n",
      "Training loss: 1.5227, Training accuracy: 0.4495\n",
      "Validation loss: 1.6995, Validation accuracy: 0.4130\n",
      "Epoch 58:\n",
      "Training loss: 1.5263, Training accuracy: 0.4488\n",
      "Validation loss: 1.7460, Validation accuracy: 0.3771\n",
      "Epoch 59:\n",
      "Training loss: 1.5312, Training accuracy: 0.4451\n",
      "Validation loss: 1.5807, Validation accuracy: 0.4163\n",
      "Epoch 60:\n",
      "Training loss: 1.2849, Training accuracy: 0.5388\n",
      "Validation loss: 1.2345, Validation accuracy: 0.5586\n",
      "Saving ...\n",
      "Epoch 61:\n",
      "Training loss: 1.2102, Training accuracy: 0.5680\n",
      "Validation loss: 1.2679, Validation accuracy: 0.5506\n",
      "Epoch 62:\n",
      "Training loss: 1.1823, Training accuracy: 0.5763\n",
      "Validation loss: 1.2285, Validation accuracy: 0.5601\n",
      "Saving ...\n",
      "Epoch 63:\n",
      "Training loss: 1.1611, Training accuracy: 0.5848\n",
      "Validation loss: 1.1773, Validation accuracy: 0.5777\n",
      "Saving ...\n",
      "Epoch 64:\n",
      "Training loss: 1.1526, Training accuracy: 0.5891\n",
      "Validation loss: 1.1488, Validation accuracy: 0.5979\n",
      "Saving ...\n",
      "Epoch 65:\n",
      "Training loss: 1.1308, Training accuracy: 0.5971\n",
      "Validation loss: 1.1882, Validation accuracy: 0.5865\n",
      "Epoch 66:\n",
      "Training loss: 1.1210, Training accuracy: 0.6008\n",
      "Validation loss: 1.1830, Validation accuracy: 0.5808\n",
      "Epoch 67:\n",
      "Training loss: 1.1038, Training accuracy: 0.6077\n",
      "Validation loss: 1.1805, Validation accuracy: 0.5927\n",
      "Epoch 68:\n",
      "Training loss: 1.0939, Training accuracy: 0.6118\n",
      "Validation loss: 1.1453, Validation accuracy: 0.5963\n",
      "Epoch 69:\n",
      "Training loss: 1.0840, Training accuracy: 0.6169\n",
      "Validation loss: 1.1316, Validation accuracy: 0.6038\n",
      "Saving ...\n",
      "Epoch 70:\n",
      "Training loss: 1.0745, Training accuracy: 0.6208\n",
      "Validation loss: 1.2069, Validation accuracy: 0.5749\n",
      "Epoch 71:\n",
      "Training loss: 1.0598, Training accuracy: 0.6274\n",
      "Validation loss: 1.1656, Validation accuracy: 0.5863\n",
      "Epoch 72:\n",
      "Training loss: 1.0491, Training accuracy: 0.6313\n",
      "Validation loss: 1.0596, Validation accuracy: 0.6159\n",
      "Saving ...\n",
      "Epoch 73:\n",
      "Training loss: 1.0404, Training accuracy: 0.6331\n",
      "Validation loss: 1.1337, Validation accuracy: 0.6078\n",
      "Epoch 74:\n",
      "Training loss: 1.0321, Training accuracy: 0.6360\n",
      "Validation loss: 0.9796, Validation accuracy: 0.6533\n",
      "Saving ...\n",
      "Epoch 75:\n",
      "Training loss: 1.0149, Training accuracy: 0.6415\n",
      "Validation loss: 0.9393, Validation accuracy: 0.6728\n",
      "Saving ...\n",
      "Epoch 76:\n",
      "Training loss: 1.0073, Training accuracy: 0.6483\n",
      "Validation loss: 1.1393, Validation accuracy: 0.6043\n",
      "Epoch 77:\n",
      "Training loss: 1.0041, Training accuracy: 0.6497\n",
      "Validation loss: 1.0041, Validation accuracy: 0.6499\n",
      "Epoch 78:\n",
      "Training loss: 0.9948, Training accuracy: 0.6529\n",
      "Validation loss: 1.0727, Validation accuracy: 0.6271\n",
      "Epoch 79:\n",
      "Training loss: 0.9889, Training accuracy: 0.6559\n",
      "Validation loss: 0.9801, Validation accuracy: 0.6575\n",
      "Epoch 80:\n",
      "Training loss: 0.9785, Training accuracy: 0.6602\n",
      "Validation loss: 1.0426, Validation accuracy: 0.6344\n",
      "Epoch 81:\n",
      "Training loss: 0.9822, Training accuracy: 0.6605\n",
      "Validation loss: 0.9318, Validation accuracy: 0.6751\n",
      "Saving ...\n",
      "Epoch 82:\n",
      "Training loss: 0.9751, Training accuracy: 0.6588\n",
      "Validation loss: 0.9918, Validation accuracy: 0.6568\n",
      "Epoch 83:\n",
      "Training loss: 0.9763, Training accuracy: 0.6631\n",
      "Validation loss: 1.0343, Validation accuracy: 0.6484\n",
      "Epoch 84:\n",
      "Training loss: 0.9638, Training accuracy: 0.6647\n",
      "Validation loss: 1.0057, Validation accuracy: 0.6555\n",
      "Epoch 85:\n",
      "Training loss: 0.9720, Training accuracy: 0.6611\n",
      "Validation loss: 1.0687, Validation accuracy: 0.6258\n",
      "Epoch 86:\n",
      "Training loss: 0.9617, Training accuracy: 0.6635\n",
      "Validation loss: 1.0670, Validation accuracy: 0.6389\n",
      "Epoch 87:\n",
      "Training loss: 0.9600, Training accuracy: 0.6669\n",
      "Validation loss: 0.9852, Validation accuracy: 0.6499\n",
      "Epoch 88:\n",
      "Training loss: 0.9625, Training accuracy: 0.6628\n",
      "Validation loss: 1.0705, Validation accuracy: 0.6274\n",
      "Epoch 89:\n",
      "Training loss: 0.9528, Training accuracy: 0.6696\n",
      "Validation loss: 0.9779, Validation accuracy: 0.6606\n",
      "Epoch 90:\n",
      "Training loss: 0.9516, Training accuracy: 0.6703\n",
      "Validation loss: 1.1075, Validation accuracy: 0.6268\n",
      "Epoch 91:\n",
      "Training loss: 0.9494, Training accuracy: 0.6699\n",
      "Validation loss: 0.9372, Validation accuracy: 0.6713\n",
      "Epoch 92:\n",
      "Training loss: 0.9513, Training accuracy: 0.6706\n",
      "Validation loss: 1.0531, Validation accuracy: 0.6375\n",
      "Epoch 93:\n",
      "Training loss: 0.9490, Training accuracy: 0.6722\n",
      "Validation loss: 0.9332, Validation accuracy: 0.6722\n",
      "Epoch 94:\n",
      "Training loss: 0.9443, Training accuracy: 0.6722\n",
      "Validation loss: 1.0410, Validation accuracy: 0.6392\n",
      "Epoch 95:\n",
      "Training loss: 0.9455, Training accuracy: 0.6703\n",
      "Validation loss: 1.0373, Validation accuracy: 0.6350\n",
      "Epoch 96:\n",
      "Training loss: 0.9424, Training accuracy: 0.6711\n",
      "Validation loss: 0.9228, Validation accuracy: 0.6800\n",
      "Saving ...\n",
      "Epoch 97:\n",
      "Training loss: 0.9393, Training accuracy: 0.6767\n",
      "Validation loss: 1.0238, Validation accuracy: 0.6470\n",
      "Epoch 98:\n",
      "Training loss: 0.9400, Training accuracy: 0.6736\n",
      "Validation loss: 1.0860, Validation accuracy: 0.6208\n",
      "Epoch 99:\n",
      "Training loss: 0.9429, Training accuracy: 0.6738\n",
      "Validation loss: 0.9709, Validation accuracy: 0.6684\n",
      "Epoch 100:\n",
      "Training loss: 0.9360, Training accuracy: 0.6758\n",
      "Validation loss: 1.1440, Validation accuracy: 0.6213\n",
      "Epoch 101:\n",
      "Training loss: 0.9378, Training accuracy: 0.6755\n",
      "Validation loss: 0.9571, Validation accuracy: 0.6678\n",
      "Epoch 102:\n",
      "Training loss: 0.9394, Training accuracy: 0.6729\n",
      "Validation loss: 1.0486, Validation accuracy: 0.6433\n",
      "Epoch 103:\n",
      "Training loss: 0.9366, Training accuracy: 0.6755\n",
      "Validation loss: 0.9352, Validation accuracy: 0.6790\n",
      "Epoch 104:\n",
      "Training loss: 0.9411, Training accuracy: 0.6753\n",
      "Validation loss: 1.0796, Validation accuracy: 0.6318\n",
      "Epoch 105:\n",
      "Training loss: 0.9319, Training accuracy: 0.6764\n",
      "Validation loss: 0.9878, Validation accuracy: 0.6657\n",
      "Epoch 106:\n",
      "Training loss: 0.9403, Training accuracy: 0.6762\n",
      "Validation loss: 1.0341, Validation accuracy: 0.6386\n",
      "Epoch 107:\n",
      "Training loss: 0.9370, Training accuracy: 0.6751\n",
      "Validation loss: 0.9222, Validation accuracy: 0.6800\n",
      "Epoch 108:\n",
      "Training loss: 0.9253, Training accuracy: 0.6783\n",
      "Validation loss: 1.1665, Validation accuracy: 0.5973\n",
      "Epoch 109:\n",
      "Training loss: 0.9272, Training accuracy: 0.6808\n",
      "Validation loss: 0.9388, Validation accuracy: 0.6768\n",
      "Epoch 110:\n",
      "Training loss: 0.9301, Training accuracy: 0.6763\n",
      "Validation loss: 0.8481, Validation accuracy: 0.7065\n",
      "Saving ...\n",
      "Epoch 111:\n",
      "Training loss: 0.9311, Training accuracy: 0.6766\n",
      "Validation loss: 1.0278, Validation accuracy: 0.6500\n",
      "Epoch 112:\n",
      "Training loss: 0.9280, Training accuracy: 0.6818\n",
      "Validation loss: 1.0085, Validation accuracy: 0.6535\n",
      "Epoch 113:\n",
      "Training loss: 0.9225, Training accuracy: 0.6830\n",
      "Validation loss: 0.8917, Validation accuracy: 0.6904\n",
      "Epoch 114:\n",
      "Training loss: 0.9321, Training accuracy: 0.6786\n",
      "Validation loss: 0.9194, Validation accuracy: 0.6809\n",
      "Epoch 115:\n",
      "Training loss: 0.9290, Training accuracy: 0.6770\n",
      "Validation loss: 1.0095, Validation accuracy: 0.6489\n",
      "Epoch 116:\n",
      "Training loss: 0.9271, Training accuracy: 0.6817\n",
      "Validation loss: 1.0093, Validation accuracy: 0.6540\n",
      "Epoch 117:\n",
      "Training loss: 0.9246, Training accuracy: 0.6789\n",
      "Validation loss: 1.0164, Validation accuracy: 0.6532\n",
      "Epoch 118:\n",
      "Training loss: 0.9203, Training accuracy: 0.6814\n",
      "Validation loss: 0.9364, Validation accuracy: 0.6782\n",
      "Epoch 119:\n",
      "Training loss: 0.9208, Training accuracy: 0.6812\n",
      "Validation loss: 0.9451, Validation accuracy: 0.6768\n",
      "Epoch 120:\n",
      "Training loss: 0.7707, Training accuracy: 0.7373\n",
      "Validation loss: 0.6988, Validation accuracy: 0.7608\n",
      "Saving ...\n",
      "Epoch 121:\n",
      "Training loss: 0.7158, Training accuracy: 0.7560\n",
      "Validation loss: 0.6875, Validation accuracy: 0.7647\n",
      "Saving ...\n",
      "Epoch 122:\n",
      "Training loss: 0.6957, Training accuracy: 0.7606\n",
      "Validation loss: 0.6630, Validation accuracy: 0.7742\n",
      "Saving ...\n",
      "Epoch 123:\n",
      "Training loss: 0.6803, Training accuracy: 0.7680\n",
      "Validation loss: 0.6495, Validation accuracy: 0.7766\n",
      "Saving ...\n",
      "Epoch 124:\n",
      "Training loss: 0.6707, Training accuracy: 0.7700\n",
      "Validation loss: 0.6440, Validation accuracy: 0.7777\n",
      "Saving ...\n",
      "Epoch 125:\n",
      "Training loss: 0.6619, Training accuracy: 0.7737\n",
      "Validation loss: 0.6448, Validation accuracy: 0.7796\n",
      "Saving ...\n",
      "Epoch 126:\n",
      "Training loss: 0.6587, Training accuracy: 0.7739\n",
      "Validation loss: 0.6361, Validation accuracy: 0.7808\n",
      "Saving ...\n",
      "Epoch 127:\n",
      "Training loss: 0.6482, Training accuracy: 0.7786\n",
      "Validation loss: 0.6254, Validation accuracy: 0.7877\n",
      "Saving ...\n",
      "Epoch 128:\n",
      "Training loss: 0.6474, Training accuracy: 0.7782\n",
      "Validation loss: 0.6232, Validation accuracy: 0.7885\n",
      "Saving ...\n",
      "Epoch 129:\n",
      "Training loss: 0.6436, Training accuracy: 0.7788\n",
      "Validation loss: 0.6350, Validation accuracy: 0.7844\n",
      "Epoch 130:\n",
      "Training loss: 0.6433, Training accuracy: 0.7802\n",
      "Validation loss: 0.6239, Validation accuracy: 0.7877\n",
      "Epoch 131:\n",
      "Training loss: 0.6403, Training accuracy: 0.7810\n",
      "Validation loss: 0.6479, Validation accuracy: 0.7780\n",
      "Epoch 132:\n",
      "Training loss: 0.6343, Training accuracy: 0.7838\n",
      "Validation loss: 0.6344, Validation accuracy: 0.7813\n",
      "Epoch 133:\n",
      "Training loss: 0.6337, Training accuracy: 0.7820\n",
      "Validation loss: 0.6468, Validation accuracy: 0.7787\n",
      "Epoch 134:\n",
      "Training loss: 0.6324, Training accuracy: 0.7833\n",
      "Validation loss: 0.6474, Validation accuracy: 0.7787\n",
      "Epoch 135:\n",
      "Training loss: 0.6316, Training accuracy: 0.7842\n",
      "Validation loss: 0.6496, Validation accuracy: 0.7800\n",
      "Epoch 136:\n",
      "Training loss: 0.6299, Training accuracy: 0.7862\n",
      "Validation loss: 0.6318, Validation accuracy: 0.7817\n",
      "Epoch 137:\n",
      "Training loss: 0.6313, Training accuracy: 0.7836\n",
      "Validation loss: 0.6422, Validation accuracy: 0.7797\n",
      "Epoch 138:\n",
      "Training loss: 0.6259, Training accuracy: 0.7848\n",
      "Validation loss: 0.6178, Validation accuracy: 0.7902\n",
      "Saving ...\n",
      "Epoch 139:\n",
      "Training loss: 0.6235, Training accuracy: 0.7874\n",
      "Validation loss: 0.6262, Validation accuracy: 0.7865\n",
      "Epoch 140:\n",
      "Training loss: 0.6225, Training accuracy: 0.7857\n",
      "Validation loss: 0.6518, Validation accuracy: 0.7758\n",
      "Epoch 141:\n",
      "Training loss: 0.6255, Training accuracy: 0.7853\n",
      "Validation loss: 0.6327, Validation accuracy: 0.7836\n",
      "Epoch 142:\n",
      "Training loss: 0.6197, Training accuracy: 0.7884\n",
      "Validation loss: 0.6639, Validation accuracy: 0.7707\n",
      "Epoch 143:\n",
      "Training loss: 0.6216, Training accuracy: 0.7863\n",
      "Validation loss: 0.6302, Validation accuracy: 0.7838\n",
      "Epoch 144:\n",
      "Training loss: 0.6197, Training accuracy: 0.7865\n",
      "Validation loss: 0.6379, Validation accuracy: 0.7811\n",
      "Epoch 145:\n",
      "Training loss: 0.6198, Training accuracy: 0.7897\n",
      "Validation loss: 0.6527, Validation accuracy: 0.7763\n",
      "Epoch 146:\n",
      "Training loss: 0.6202, Training accuracy: 0.7877\n",
      "Validation loss: 0.6531, Validation accuracy: 0.7754\n",
      "Epoch 147:\n",
      "Training loss: 0.6168, Training accuracy: 0.7901\n",
      "Validation loss: 0.6279, Validation accuracy: 0.7869\n",
      "Epoch 148:\n",
      "Training loss: 0.6211, Training accuracy: 0.7865\n",
      "Validation loss: 0.6464, Validation accuracy: 0.7815\n",
      "Epoch 149:\n",
      "Training loss: 0.6214, Training accuracy: 0.7876\n",
      "Validation loss: 0.6170, Validation accuracy: 0.7918\n",
      "Saving ...\n",
      "Epoch 150:\n",
      "Training loss: 0.6143, Training accuracy: 0.7913\n",
      "Validation loss: 0.6414, Validation accuracy: 0.7772\n",
      "Epoch 151:\n",
      "Training loss: 0.6147, Training accuracy: 0.7902\n",
      "Validation loss: 0.6474, Validation accuracy: 0.7774\n",
      "Epoch 152:\n",
      "Training loss: 0.6155, Training accuracy: 0.7873\n",
      "Validation loss: 0.6486, Validation accuracy: 0.7786\n",
      "Epoch 153:\n",
      "Training loss: 0.6104, Training accuracy: 0.7932\n",
      "Validation loss: 0.6401, Validation accuracy: 0.7836\n",
      "Epoch 154:\n",
      "Training loss: 0.6127, Training accuracy: 0.7910\n",
      "Validation loss: 0.6175, Validation accuracy: 0.7934\n",
      "Saving ...\n",
      "Epoch 155:\n",
      "Training loss: 0.6074, Training accuracy: 0.7932\n",
      "Validation loss: 0.6405, Validation accuracy: 0.7834\n",
      "Epoch 156:\n",
      "Training loss: 0.6090, Training accuracy: 0.7927\n",
      "Validation loss: 0.6304, Validation accuracy: 0.7873\n",
      "Epoch 157:\n",
      "Training loss: 0.6095, Training accuracy: 0.7917\n",
      "Validation loss: 0.6723, Validation accuracy: 0.7723\n",
      "Epoch 158:\n",
      "Training loss: 0.6087, Training accuracy: 0.7909\n",
      "Validation loss: 0.6452, Validation accuracy: 0.7821\n",
      "Epoch 159:\n",
      "Training loss: 0.6045, Training accuracy: 0.7933\n",
      "Validation loss: 0.6527, Validation accuracy: 0.7758\n",
      "Epoch 160:\n",
      "Training loss: 0.6056, Training accuracy: 0.7920\n",
      "Validation loss: 0.6323, Validation accuracy: 0.7867\n",
      "Epoch 161:\n",
      "Training loss: 0.6064, Training accuracy: 0.7924\n",
      "Validation loss: 0.6116, Validation accuracy: 0.7944\n",
      "Saving ...\n",
      "Epoch 162:\n",
      "Training loss: 0.6024, Training accuracy: 0.7954\n",
      "Validation loss: 0.6254, Validation accuracy: 0.7872\n",
      "Epoch 163:\n",
      "Training loss: 0.6010, Training accuracy: 0.7940\n",
      "Validation loss: 0.6647, Validation accuracy: 0.7769\n",
      "Epoch 164:\n",
      "Training loss: 0.6031, Training accuracy: 0.7929\n",
      "Validation loss: 0.6523, Validation accuracy: 0.7782\n",
      "Epoch 165:\n",
      "Training loss: 0.5961, Training accuracy: 0.7958\n",
      "Validation loss: 0.7033, Validation accuracy: 0.7638\n",
      "Epoch 166:\n",
      "Training loss: 0.5979, Training accuracy: 0.7977\n",
      "Validation loss: 0.6514, Validation accuracy: 0.7835\n",
      "Epoch 167:\n",
      "Training loss: 0.5996, Training accuracy: 0.7949\n",
      "Validation loss: 0.6593, Validation accuracy: 0.7786\n",
      "Epoch 168:\n",
      "Training loss: 0.5988, Training accuracy: 0.7949\n",
      "Validation loss: 0.6214, Validation accuracy: 0.7895\n",
      "Epoch 169:\n",
      "Training loss: 0.6014, Training accuracy: 0.7955\n",
      "Validation loss: 0.6370, Validation accuracy: 0.7834\n",
      "Epoch 170:\n",
      "Training loss: 0.5996, Training accuracy: 0.7930\n",
      "Validation loss: 0.6484, Validation accuracy: 0.7788\n",
      "Epoch 171:\n",
      "Training loss: 0.5878, Training accuracy: 0.7997\n",
      "Validation loss: 0.6408, Validation accuracy: 0.7842\n",
      "Epoch 172:\n",
      "Training loss: 0.5884, Training accuracy: 0.8004\n",
      "Validation loss: 0.6332, Validation accuracy: 0.7872\n",
      "Epoch 173:\n",
      "Training loss: 0.5930, Training accuracy: 0.7985\n",
      "Validation loss: 0.6323, Validation accuracy: 0.7832\n",
      "Epoch 174:\n",
      "Training loss: 0.5928, Training accuracy: 0.7972\n",
      "Validation loss: 0.6603, Validation accuracy: 0.7764\n",
      "Epoch 175:\n",
      "Training loss: 0.5899, Training accuracy: 0.7992\n",
      "Validation loss: 0.6160, Validation accuracy: 0.7863\n",
      "Epoch 176:\n",
      "Training loss: 0.5879, Training accuracy: 0.7994\n",
      "Validation loss: 0.6220, Validation accuracy: 0.7888\n",
      "Epoch 177:\n",
      "Training loss: 0.5905, Training accuracy: 0.7967\n",
      "Validation loss: 0.6171, Validation accuracy: 0.7874\n",
      "Epoch 178:\n",
      "Training loss: 0.5874, Training accuracy: 0.7997\n",
      "Validation loss: 0.6212, Validation accuracy: 0.7919\n",
      "Epoch 179:\n",
      "Training loss: 0.5848, Training accuracy: 0.8012\n",
      "Validation loss: 0.6181, Validation accuracy: 0.7907\n",
      "Epoch 180:\n",
      "Training loss: 0.5177, Training accuracy: 0.8247\n",
      "Validation loss: 0.5393, Validation accuracy: 0.8196\n",
      "Saving ...\n",
      "Epoch 181:\n",
      "Training loss: 0.4919, Training accuracy: 0.8344\n",
      "Validation loss: 0.5343, Validation accuracy: 0.8201\n",
      "Saving ...\n",
      "Epoch 182:\n",
      "Training loss: 0.4842, Training accuracy: 0.8369\n",
      "Validation loss: 0.5370, Validation accuracy: 0.8215\n",
      "Saving ...\n",
      "Epoch 183:\n",
      "Training loss: 0.4731, Training accuracy: 0.8390\n",
      "Validation loss: 0.5266, Validation accuracy: 0.8233\n",
      "Saving ...\n",
      "Epoch 184:\n",
      "Training loss: 0.4709, Training accuracy: 0.8429\n",
      "Validation loss: 0.5224, Validation accuracy: 0.8215\n",
      "Epoch 185:\n",
      "Training loss: 0.4675, Training accuracy: 0.8426\n",
      "Validation loss: 0.5256, Validation accuracy: 0.8221\n",
      "Epoch 186:\n",
      "Training loss: 0.4621, Training accuracy: 0.8451\n",
      "Validation loss: 0.5266, Validation accuracy: 0.8249\n",
      "Saving ...\n",
      "Epoch 187:\n",
      "Training loss: 0.4621, Training accuracy: 0.8451\n",
      "Validation loss: 0.5220, Validation accuracy: 0.8264\n",
      "Saving ...\n",
      "Epoch 188:\n",
      "Training loss: 0.4563, Training accuracy: 0.8478\n",
      "Validation loss: 0.5232, Validation accuracy: 0.8252\n",
      "Epoch 189:\n",
      "Training loss: 0.4522, Training accuracy: 0.8495\n",
      "Validation loss: 0.5232, Validation accuracy: 0.8223\n",
      "Epoch 190:\n",
      "Training loss: 0.4511, Training accuracy: 0.8484\n",
      "Validation loss: 0.5278, Validation accuracy: 0.8211\n",
      "Epoch 191:\n",
      "Training loss: 0.4484, Training accuracy: 0.8497\n",
      "Validation loss: 0.5271, Validation accuracy: 0.8226\n",
      "Epoch 192:\n",
      "Training loss: 0.4457, Training accuracy: 0.8514\n",
      "Validation loss: 0.5275, Validation accuracy: 0.8231\n",
      "Epoch 193:\n",
      "Training loss: 0.4397, Training accuracy: 0.8527\n",
      "Validation loss: 0.5196, Validation accuracy: 0.8240\n",
      "Epoch 194:\n",
      "Training loss: 0.4445, Training accuracy: 0.8511\n",
      "Validation loss: 0.5268, Validation accuracy: 0.8234\n",
      "Epoch 195:\n",
      "Training loss: 0.4414, Training accuracy: 0.8529\n",
      "Validation loss: 0.5195, Validation accuracy: 0.8231\n",
      "Epoch 196:\n",
      "Training loss: 0.4402, Training accuracy: 0.8538\n",
      "Validation loss: 0.5241, Validation accuracy: 0.8250\n",
      "Epoch 197:\n",
      "Training loss: 0.4312, Training accuracy: 0.8573\n",
      "Validation loss: 0.5241, Validation accuracy: 0.8227\n",
      "Epoch 198:\n",
      "Training loss: 0.4331, Training accuracy: 0.8547\n",
      "Validation loss: 0.5192, Validation accuracy: 0.8239\n",
      "Epoch 199:\n",
      "Training loss: 0.4338, Training accuracy: 0.8555\n",
      "Validation loss: 0.5198, Validation accuracy: 0.8247\n",
      "==================================================\n",
      "==> Optimization finished! Best validation accuracy: 0.8264\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8264"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_res50(train_loader,val_loader,INITIAL_LR = 0.1,REG = 0.006,DECAY_EPOCHS=[60,120,180], DECAY=0.1,EPOCHS=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Training starts!\n",
      "==================================================\n",
      "Epoch 0:\n",
      "Training loss: 5.3251, Training accuracy: 0.1230\n",
      "Validation loss: 2.3692, Validation accuracy: 0.1009\n",
      "Saving ...\n",
      "Epoch 1:\n",
      "Training loss: 2.0562, Training accuracy: 0.2116\n",
      "Validation loss: 2.0630, Validation accuracy: 0.2581\n",
      "Saving ...\n",
      "Epoch 2:\n",
      "Training loss: 1.8195, Training accuracy: 0.3111\n",
      "Validation loss: 1.7196, Validation accuracy: 0.3611\n",
      "Saving ...\n",
      "Epoch 3:\n",
      "Training loss: 1.6759, Training accuracy: 0.3715\n",
      "Validation loss: 1.5940, Validation accuracy: 0.4056\n",
      "Saving ...\n",
      "Epoch 4:\n",
      "Training loss: 1.5640, Training accuracy: 0.4199\n",
      "Validation loss: 1.4656, Validation accuracy: 0.4695\n",
      "Saving ...\n",
      "Epoch 5:\n",
      "Training loss: 1.4678, Training accuracy: 0.4612\n",
      "Validation loss: 1.4877, Validation accuracy: 0.4754\n",
      "Saving ...\n",
      "Epoch 6:\n",
      "Training loss: 1.3831, Training accuracy: 0.4932\n",
      "Validation loss: 1.4731, Validation accuracy: 0.4892\n",
      "Saving ...\n",
      "Epoch 7:\n",
      "Training loss: 1.2886, Training accuracy: 0.5359\n",
      "Validation loss: 1.2471, Validation accuracy: 0.5529\n",
      "Saving ...\n",
      "Epoch 8:\n",
      "Training loss: 1.2111, Training accuracy: 0.5642\n",
      "Validation loss: 1.4397, Validation accuracy: 0.5637\n",
      "Saving ...\n",
      "Epoch 9:\n",
      "Training loss: 1.1506, Training accuracy: 0.5883\n",
      "Validation loss: 1.0808, Validation accuracy: 0.6225\n",
      "Saving ...\n",
      "Epoch 10:\n",
      "Training loss: 1.0705, Training accuracy: 0.6212\n",
      "Validation loss: 1.1700, Validation accuracy: 0.6254\n",
      "Saving ...\n",
      "Epoch 11:\n",
      "Training loss: 1.0155, Training accuracy: 0.6410\n",
      "Validation loss: 1.6915, Validation accuracy: 0.6131\n",
      "Epoch 12:\n",
      "Training loss: 1.0162, Training accuracy: 0.6437\n",
      "Validation loss: 0.9980, Validation accuracy: 0.6515\n",
      "Saving ...\n",
      "Epoch 13:\n",
      "Training loss: 0.9625, Training accuracy: 0.6628\n",
      "Validation loss: 1.0144, Validation accuracy: 0.6581\n",
      "Saving ...\n",
      "Epoch 14:\n",
      "Training loss: 0.9132, Training accuracy: 0.6821\n",
      "Validation loss: 0.9241, Validation accuracy: 0.6823\n",
      "Saving ...\n",
      "Epoch 15:\n",
      "Training loss: 0.8744, Training accuracy: 0.6985\n",
      "Validation loss: 1.0924, Validation accuracy: 0.6289\n",
      "Epoch 16:\n",
      "Training loss: 0.8605, Training accuracy: 0.7008\n",
      "Validation loss: 0.8318, Validation accuracy: 0.7100\n",
      "Saving ...\n",
      "Epoch 17:\n",
      "Training loss: 0.8300, Training accuracy: 0.7121\n",
      "Validation loss: 0.8832, Validation accuracy: 0.7008\n",
      "Epoch 18:\n",
      "Training loss: 0.8115, Training accuracy: 0.7207\n",
      "Validation loss: 0.8682, Validation accuracy: 0.7028\n",
      "Epoch 19:\n",
      "Training loss: 0.7913, Training accuracy: 0.7263\n",
      "Validation loss: 0.9222, Validation accuracy: 0.6918\n",
      "Epoch 20:\n",
      "Training loss: 0.7886, Training accuracy: 0.7304\n",
      "Validation loss: 0.8271, Validation accuracy: 0.7181\n",
      "Saving ...\n",
      "Epoch 21:\n",
      "Training loss: 0.7655, Training accuracy: 0.7356\n",
      "Validation loss: 0.7691, Validation accuracy: 0.7377\n",
      "Saving ...\n",
      "Epoch 22:\n",
      "Training loss: 0.7553, Training accuracy: 0.7403\n",
      "Validation loss: 0.8687, Validation accuracy: 0.7076\n",
      "Epoch 23:\n",
      "Training loss: 0.7487, Training accuracy: 0.7449\n",
      "Validation loss: 0.7864, Validation accuracy: 0.7287\n",
      "Epoch 24:\n",
      "Training loss: 0.7373, Training accuracy: 0.7444\n",
      "Validation loss: 0.7806, Validation accuracy: 0.7402\n",
      "Saving ...\n",
      "Epoch 25:\n",
      "Training loss: 0.7256, Training accuracy: 0.7508\n",
      "Validation loss: 0.7991, Validation accuracy: 0.7221\n",
      "Epoch 26:\n",
      "Training loss: 0.7172, Training accuracy: 0.7552\n",
      "Validation loss: 0.7831, Validation accuracy: 0.7356\n",
      "Epoch 27:\n",
      "Training loss: 0.7169, Training accuracy: 0.7535\n",
      "Validation loss: 0.7714, Validation accuracy: 0.7361\n",
      "Epoch 28:\n",
      "Training loss: 0.7080, Training accuracy: 0.7562\n",
      "Validation loss: 0.8037, Validation accuracy: 0.7280\n",
      "Epoch 29:\n",
      "Training loss: 0.7032, Training accuracy: 0.7592\n",
      "Validation loss: 0.8825, Validation accuracy: 0.7070\n",
      "Epoch 30:\n",
      "Training loss: 0.6969, Training accuracy: 0.7617\n",
      "Validation loss: 0.8249, Validation accuracy: 0.7265\n",
      "Epoch 31:\n",
      "Training loss: 0.6923, Training accuracy: 0.7637\n",
      "Validation loss: 0.7064, Validation accuracy: 0.7590\n",
      "Saving ...\n",
      "Epoch 32:\n",
      "Training loss: 0.6849, Training accuracy: 0.7645\n",
      "Validation loss: 0.7580, Validation accuracy: 0.7417\n",
      "Epoch 33:\n",
      "Training loss: 0.6826, Training accuracy: 0.7687\n",
      "Validation loss: 0.6785, Validation accuracy: 0.7693\n",
      "Saving ...\n",
      "Epoch 34:\n",
      "Training loss: 0.6718, Training accuracy: 0.7704\n",
      "Validation loss: 0.7432, Validation accuracy: 0.7526\n",
      "Epoch 35:\n",
      "Training loss: 0.6722, Training accuracy: 0.7703\n",
      "Validation loss: 0.7394, Validation accuracy: 0.7487\n",
      "Epoch 36:\n",
      "Training loss: 0.6720, Training accuracy: 0.7714\n",
      "Validation loss: 0.8128, Validation accuracy: 0.7256\n",
      "Epoch 37:\n",
      "Training loss: 0.6648, Training accuracy: 0.7728\n",
      "Validation loss: 0.7796, Validation accuracy: 0.7483\n",
      "Epoch 38:\n",
      "Training loss: 0.6659, Training accuracy: 0.7702\n",
      "Validation loss: 1.0580, Validation accuracy: 0.6668\n",
      "Epoch 39:\n",
      "Training loss: 0.6550, Training accuracy: 0.7755\n",
      "Validation loss: 0.7544, Validation accuracy: 0.7522\n",
      "Epoch 40:\n",
      "Training loss: 0.4821, Training accuracy: 0.8349\n",
      "Validation loss: 0.4770, Validation accuracy: 0.8346\n",
      "Saving ...\n",
      "Epoch 41:\n",
      "Training loss: 0.4192, Training accuracy: 0.8570\n",
      "Validation loss: 0.4524, Validation accuracy: 0.8425\n",
      "Saving ...\n",
      "Epoch 42:\n",
      "Training loss: 0.3990, Training accuracy: 0.8625\n",
      "Validation loss: 0.4431, Validation accuracy: 0.8477\n",
      "Saving ...\n",
      "Epoch 43:\n",
      "Training loss: 0.3796, Training accuracy: 0.8679\n",
      "Validation loss: 0.4333, Validation accuracy: 0.8516\n",
      "Saving ...\n",
      "Epoch 44:\n",
      "Training loss: 0.3680, Training accuracy: 0.8731\n",
      "Validation loss: 0.4359, Validation accuracy: 0.8508\n",
      "Epoch 45:\n",
      "Training loss: 0.3548, Training accuracy: 0.8783\n",
      "Validation loss: 0.4303, Validation accuracy: 0.8533\n",
      "Saving ...\n",
      "Epoch 46:\n",
      "Training loss: 0.3446, Training accuracy: 0.8807\n",
      "Validation loss: 0.4231, Validation accuracy: 0.8544\n",
      "Saving ...\n",
      "Epoch 47:\n",
      "Training loss: 0.3375, Training accuracy: 0.8845\n",
      "Validation loss: 0.4192, Validation accuracy: 0.8601\n",
      "Saving ...\n",
      "Epoch 48:\n",
      "Training loss: 0.3306, Training accuracy: 0.8846\n",
      "Validation loss: 0.4293, Validation accuracy: 0.8527\n",
      "Epoch 49:\n",
      "Training loss: 0.3199, Training accuracy: 0.8890\n",
      "Validation loss: 0.4260, Validation accuracy: 0.8570\n",
      "Epoch 50:\n",
      "Training loss: 0.3134, Training accuracy: 0.8933\n",
      "Validation loss: 0.4177, Validation accuracy: 0.8604\n",
      "Saving ...\n",
      "Epoch 51:\n",
      "Training loss: 0.3077, Training accuracy: 0.8931\n",
      "Validation loss: 0.4397, Validation accuracy: 0.8536\n",
      "Epoch 52:\n",
      "Training loss: 0.3064, Training accuracy: 0.8933\n",
      "Validation loss: 0.4161, Validation accuracy: 0.8585\n",
      "Epoch 53:\n",
      "Training loss: 0.2984, Training accuracy: 0.8962\n",
      "Validation loss: 0.4347, Validation accuracy: 0.8605\n",
      "Saving ...\n",
      "Epoch 54:\n",
      "Training loss: 0.2940, Training accuracy: 0.8986\n",
      "Validation loss: 0.4185, Validation accuracy: 0.8613\n",
      "Saving ...\n",
      "Epoch 55:\n",
      "Training loss: 0.2892, Training accuracy: 0.8996\n",
      "Validation loss: 0.4287, Validation accuracy: 0.8584\n",
      "Epoch 56:\n",
      "Training loss: 0.2844, Training accuracy: 0.9024\n",
      "Validation loss: 0.4376, Validation accuracy: 0.8526\n",
      "Epoch 57:\n",
      "Training loss: 0.2836, Training accuracy: 0.8997\n",
      "Validation loss: 0.4510, Validation accuracy: 0.8521\n",
      "Epoch 58:\n",
      "Training loss: 0.2773, Training accuracy: 0.9037\n",
      "Validation loss: 0.4272, Validation accuracy: 0.8616\n",
      "Saving ...\n",
      "Epoch 59:\n",
      "Training loss: 0.2812, Training accuracy: 0.9029\n",
      "Validation loss: 0.4326, Validation accuracy: 0.8563\n",
      "Epoch 60:\n",
      "Training loss: 0.2713, Training accuracy: 0.9063\n",
      "Validation loss: 0.4468, Validation accuracy: 0.8528\n",
      "Epoch 61:\n",
      "Training loss: 0.2708, Training accuracy: 0.9060\n",
      "Validation loss: 0.4439, Validation accuracy: 0.8575\n",
      "Epoch 62:\n",
      "Training loss: 0.2700, Training accuracy: 0.9048\n",
      "Validation loss: 0.4416, Validation accuracy: 0.8565\n",
      "Epoch 63:\n",
      "Training loss: 0.2654, Training accuracy: 0.9081\n",
      "Validation loss: 0.4330, Validation accuracy: 0.8603\n",
      "Epoch 64:\n",
      "Training loss: 0.2685, Training accuracy: 0.9062\n",
      "Validation loss: 0.4440, Validation accuracy: 0.8566\n",
      "Epoch 65:\n",
      "Training loss: 0.2648, Training accuracy: 0.9076\n",
      "Validation loss: 0.4581, Validation accuracy: 0.8504\n",
      "Epoch 66:\n",
      "Training loss: 0.2610, Training accuracy: 0.9106\n",
      "Validation loss: 0.4374, Validation accuracy: 0.8587\n",
      "Epoch 67:\n",
      "Training loss: 0.2576, Training accuracy: 0.9097\n",
      "Validation loss: 0.4369, Validation accuracy: 0.8634\n",
      "Saving ...\n",
      "Epoch 68:\n",
      "Training loss: 0.2628, Training accuracy: 0.9081\n",
      "Validation loss: 0.4393, Validation accuracy: 0.8576\n",
      "Epoch 69:\n",
      "Training loss: 0.2521, Training accuracy: 0.9129\n",
      "Validation loss: 0.4606, Validation accuracy: 0.8522\n",
      "Epoch 70:\n",
      "Training loss: 0.2528, Training accuracy: 0.9112\n",
      "Validation loss: 0.4402, Validation accuracy: 0.8586\n",
      "Epoch 71:\n",
      "Training loss: 0.2481, Training accuracy: 0.9143\n",
      "Validation loss: 0.4614, Validation accuracy: 0.8517\n",
      "Epoch 72:\n",
      "Training loss: 0.2513, Training accuracy: 0.9114\n",
      "Validation loss: 0.4558, Validation accuracy: 0.8551\n",
      "Epoch 73:\n",
      "Training loss: 0.2446, Training accuracy: 0.9151\n",
      "Validation loss: 0.4712, Validation accuracy: 0.8511\n",
      "Epoch 74:\n",
      "Training loss: 0.2470, Training accuracy: 0.9145\n",
      "Validation loss: 0.4341, Validation accuracy: 0.8617\n",
      "Epoch 75:\n",
      "Training loss: 0.2485, Training accuracy: 0.9138\n",
      "Validation loss: 0.4429, Validation accuracy: 0.8534\n",
      "Epoch 76:\n",
      "Training loss: 0.2440, Training accuracy: 0.9147\n",
      "Validation loss: 0.4556, Validation accuracy: 0.8536\n",
      "Epoch 77:\n",
      "Training loss: 0.2396, Training accuracy: 0.9163\n",
      "Validation loss: 0.4499, Validation accuracy: 0.8562\n",
      "Epoch 78:\n",
      "Training loss: 0.2407, Training accuracy: 0.9163\n",
      "Validation loss: 0.4749, Validation accuracy: 0.8545\n",
      "Epoch 79:\n",
      "Training loss: 0.2382, Training accuracy: 0.9158\n",
      "Validation loss: 0.4804, Validation accuracy: 0.8514\n",
      "Epoch 80:\n",
      "Training loss: 0.1754, Training accuracy: 0.9402\n",
      "Validation loss: 0.3891, Validation accuracy: 0.8764\n",
      "Saving ...\n",
      "Epoch 81:\n",
      "Training loss: 0.1469, Training accuracy: 0.9502\n",
      "Validation loss: 0.3888, Validation accuracy: 0.8782\n",
      "Saving ...\n",
      "Epoch 82:\n",
      "Training loss: 0.1360, Training accuracy: 0.9548\n",
      "Validation loss: 0.3891, Validation accuracy: 0.8783\n",
      "Saving ...\n",
      "Epoch 83:\n",
      "Training loss: 0.1289, Training accuracy: 0.9570\n",
      "Validation loss: 0.3865, Validation accuracy: 0.8799\n",
      "Saving ...\n",
      "Epoch 84:\n",
      "Training loss: 0.1244, Training accuracy: 0.9574\n",
      "Validation loss: 0.3891, Validation accuracy: 0.8804\n",
      "Saving ...\n",
      "Epoch 85:\n",
      "Training loss: 0.1187, Training accuracy: 0.9598\n",
      "Validation loss: 0.3870, Validation accuracy: 0.8811\n",
      "Saving ...\n",
      "Epoch 86:\n",
      "Training loss: 0.1134, Training accuracy: 0.9619\n",
      "Validation loss: 0.3914, Validation accuracy: 0.8802\n",
      "Epoch 87:\n",
      "Training loss: 0.1110, Training accuracy: 0.9628\n",
      "Validation loss: 0.3972, Validation accuracy: 0.8807\n",
      "Epoch 88:\n",
      "Training loss: 0.1081, Training accuracy: 0.9641\n",
      "Validation loss: 0.3946, Validation accuracy: 0.8819\n",
      "Saving ...\n",
      "Epoch 89:\n",
      "Training loss: 0.1009, Training accuracy: 0.9658\n",
      "Validation loss: 0.3947, Validation accuracy: 0.8811\n",
      "Epoch 90:\n",
      "Training loss: 0.1006, Training accuracy: 0.9665\n",
      "Validation loss: 0.3988, Validation accuracy: 0.8810\n",
      "Epoch 91:\n",
      "Training loss: 0.0973, Training accuracy: 0.9667\n",
      "Validation loss: 0.4037, Validation accuracy: 0.8808\n",
      "Epoch 92:\n",
      "Training loss: 0.0947, Training accuracy: 0.9686\n",
      "Validation loss: 0.4101, Validation accuracy: 0.8803\n",
      "Epoch 93:\n",
      "Training loss: 0.0926, Training accuracy: 0.9685\n",
      "Validation loss: 0.4085, Validation accuracy: 0.8815\n",
      "Epoch 94:\n",
      "Training loss: 0.0901, Training accuracy: 0.9703\n",
      "Validation loss: 0.4085, Validation accuracy: 0.8829\n",
      "Saving ...\n",
      "Epoch 95:\n",
      "Training loss: 0.0891, Training accuracy: 0.9701\n",
      "Validation loss: 0.4140, Validation accuracy: 0.8817\n",
      "Epoch 96:\n",
      "Training loss: 0.0860, Training accuracy: 0.9709\n",
      "Validation loss: 0.4162, Validation accuracy: 0.8812\n",
      "Epoch 97:\n",
      "Training loss: 0.0846, Training accuracy: 0.9713\n",
      "Validation loss: 0.4143, Validation accuracy: 0.8802\n",
      "Epoch 98:\n",
      "Training loss: 0.0832, Training accuracy: 0.9717\n",
      "Validation loss: 0.4166, Validation accuracy: 0.8843\n",
      "Saving ...\n",
      "Epoch 99:\n",
      "Training loss: 0.0828, Training accuracy: 0.9716\n",
      "Validation loss: 0.4151, Validation accuracy: 0.8836\n",
      "Epoch 100:\n",
      "Training loss: 0.0788, Training accuracy: 0.9737\n",
      "Validation loss: 0.4231, Validation accuracy: 0.8822\n",
      "Epoch 101:\n",
      "Training loss: 0.0769, Training accuracy: 0.9738\n",
      "Validation loss: 0.4245, Validation accuracy: 0.8817\n",
      "Epoch 102:\n",
      "Training loss: 0.0768, Training accuracy: 0.9744\n",
      "Validation loss: 0.4225, Validation accuracy: 0.8810\n",
      "Epoch 103:\n",
      "Training loss: 0.0752, Training accuracy: 0.9746\n",
      "Validation loss: 0.4239, Validation accuracy: 0.8810\n",
      "Epoch 104:\n",
      "Training loss: 0.0755, Training accuracy: 0.9746\n",
      "Validation loss: 0.4297, Validation accuracy: 0.8817\n",
      "Epoch 105:\n",
      "Training loss: 0.0734, Training accuracy: 0.9754\n",
      "Validation loss: 0.4346, Validation accuracy: 0.8811\n",
      "Epoch 106:\n",
      "Training loss: 0.0718, Training accuracy: 0.9760\n",
      "Validation loss: 0.4278, Validation accuracy: 0.8810\n",
      "Epoch 107:\n",
      "Training loss: 0.0695, Training accuracy: 0.9765\n",
      "Validation loss: 0.4333, Validation accuracy: 0.8833\n",
      "Epoch 108:\n",
      "Training loss: 0.0679, Training accuracy: 0.9769\n",
      "Validation loss: 0.4358, Validation accuracy: 0.8807\n",
      "Epoch 109:\n",
      "Training loss: 0.0693, Training accuracy: 0.9762\n",
      "Validation loss: 0.4393, Validation accuracy: 0.8815\n",
      "Epoch 110:\n",
      "Training loss: 0.0645, Training accuracy: 0.9790\n",
      "Validation loss: 0.4474, Validation accuracy: 0.8795\n",
      "Epoch 111:\n",
      "Training loss: 0.0640, Training accuracy: 0.9788\n",
      "Validation loss: 0.4480, Validation accuracy: 0.8816\n",
      "Epoch 112:\n",
      "Training loss: 0.0624, Training accuracy: 0.9792\n",
      "Validation loss: 0.4428, Validation accuracy: 0.8821\n",
      "Epoch 113:\n",
      "Training loss: 0.0632, Training accuracy: 0.9790\n",
      "Validation loss: 0.4537, Validation accuracy: 0.8806\n",
      "Epoch 114:\n",
      "Training loss: 0.0572, Training accuracy: 0.9809\n",
      "Validation loss: 0.4541, Validation accuracy: 0.8815\n",
      "Epoch 115:\n",
      "Training loss: 0.0585, Training accuracy: 0.9805\n",
      "Validation loss: 0.4628, Validation accuracy: 0.8797\n",
      "Epoch 116:\n",
      "Training loss: 0.0588, Training accuracy: 0.9800\n",
      "Validation loss: 0.4646, Validation accuracy: 0.8797\n",
      "Epoch 117:\n",
      "Training loss: 0.0590, Training accuracy: 0.9809\n",
      "Validation loss: 0.4618, Validation accuracy: 0.8798\n",
      "Epoch 118:\n",
      "Training loss: 0.0591, Training accuracy: 0.9800\n",
      "Validation loss: 0.4591, Validation accuracy: 0.8809\n",
      "Epoch 119:\n",
      "Training loss: 0.0566, Training accuracy: 0.9821\n",
      "Validation loss: 0.4728, Validation accuracy: 0.8792\n",
      "Epoch 120:\n",
      "Training loss: 0.0546, Training accuracy: 0.9817\n",
      "Validation loss: 0.4571, Validation accuracy: 0.8830\n",
      "Epoch 121:\n",
      "Training loss: 0.0571, Training accuracy: 0.9803\n",
      "Validation loss: 0.4684, Validation accuracy: 0.8797\n",
      "Epoch 122:\n",
      "Training loss: 0.0524, Training accuracy: 0.9828\n",
      "Validation loss: 0.4693, Validation accuracy: 0.8801\n",
      "Epoch 123:\n",
      "Training loss: 0.0558, Training accuracy: 0.9810\n",
      "Validation loss: 0.4673, Validation accuracy: 0.8822\n",
      "Epoch 124:\n",
      "Training loss: 0.0535, Training accuracy: 0.9814\n",
      "Validation loss: 0.4765, Validation accuracy: 0.8797\n",
      "Epoch 125:\n",
      "Training loss: 0.0525, Training accuracy: 0.9818\n",
      "Validation loss: 0.4638, Validation accuracy: 0.8839\n",
      "Epoch 126:\n",
      "Training loss: 0.0512, Training accuracy: 0.9830\n",
      "Validation loss: 0.4708, Validation accuracy: 0.8846\n",
      "Saving ...\n",
      "Epoch 127:\n",
      "Training loss: 0.0508, Training accuracy: 0.9828\n",
      "Validation loss: 0.4688, Validation accuracy: 0.8819\n",
      "Epoch 128:\n",
      "Training loss: 0.0479, Training accuracy: 0.9845\n",
      "Validation loss: 0.4784, Validation accuracy: 0.8798\n",
      "Epoch 129:\n",
      "Training loss: 0.0460, Training accuracy: 0.9846\n",
      "Validation loss: 0.4762, Validation accuracy: 0.8827\n",
      "Epoch 130:\n",
      "Training loss: 0.0499, Training accuracy: 0.9827\n",
      "Validation loss: 0.4808, Validation accuracy: 0.8811\n",
      "Epoch 131:\n",
      "Training loss: 0.0458, Training accuracy: 0.9846\n",
      "Validation loss: 0.4707, Validation accuracy: 0.8835\n",
      "Epoch 132:\n",
      "Training loss: 0.0442, Training accuracy: 0.9857\n",
      "Validation loss: 0.4769, Validation accuracy: 0.8817\n",
      "Epoch 133:\n",
      "Training loss: 0.0461, Training accuracy: 0.9843\n",
      "Validation loss: 0.4852, Validation accuracy: 0.8822\n",
      "Epoch 134:\n",
      "Training loss: 0.0475, Training accuracy: 0.9836\n",
      "Validation loss: 0.4815, Validation accuracy: 0.8821\n",
      "Epoch 135:\n",
      "Training loss: 0.0455, Training accuracy: 0.9853\n",
      "Validation loss: 0.4860, Validation accuracy: 0.8796\n",
      "Epoch 136:\n",
      "Training loss: 0.0450, Training accuracy: 0.9853\n",
      "Validation loss: 0.4744, Validation accuracy: 0.8850\n",
      "Saving ...\n",
      "Epoch 137:\n",
      "Training loss: 0.0441, Training accuracy: 0.9856\n",
      "Validation loss: 0.4860, Validation accuracy: 0.8805\n",
      "Epoch 138:\n",
      "Training loss: 0.0425, Training accuracy: 0.9857\n",
      "Validation loss: 0.4905, Validation accuracy: 0.8801\n",
      "Epoch 139:\n",
      "Training loss: 0.0424, Training accuracy: 0.9859\n",
      "Validation loss: 0.4975, Validation accuracy: 0.8789\n",
      "Epoch 140:\n",
      "Training loss: 0.0411, Training accuracy: 0.9865\n",
      "Validation loss: 0.4943, Validation accuracy: 0.8829\n",
      "Epoch 141:\n",
      "Training loss: 0.0434, Training accuracy: 0.9857\n",
      "Validation loss: 0.5025, Validation accuracy: 0.8801\n",
      "Epoch 142:\n",
      "Training loss: 0.0419, Training accuracy: 0.9860\n",
      "Validation loss: 0.5110, Validation accuracy: 0.8785\n",
      "Epoch 143:\n",
      "Training loss: 0.0394, Training accuracy: 0.9872\n",
      "Validation loss: 0.4932, Validation accuracy: 0.8838\n",
      "Epoch 144:\n",
      "Training loss: 0.0407, Training accuracy: 0.9860\n",
      "Validation loss: 0.5047, Validation accuracy: 0.8808\n",
      "Epoch 145:\n",
      "Training loss: 0.0385, Training accuracy: 0.9872\n",
      "Validation loss: 0.4976, Validation accuracy: 0.8792\n",
      "Epoch 146:\n",
      "Training loss: 0.0376, Training accuracy: 0.9876\n",
      "Validation loss: 0.5026, Validation accuracy: 0.8818\n",
      "Epoch 147:\n",
      "Training loss: 0.0392, Training accuracy: 0.9866\n",
      "Validation loss: 0.5104, Validation accuracy: 0.8789\n",
      "Epoch 148:\n",
      "Training loss: 0.0389, Training accuracy: 0.9870\n",
      "Validation loss: 0.5072, Validation accuracy: 0.8805\n",
      "Epoch 149:\n",
      "Training loss: 0.0396, Training accuracy: 0.9868\n",
      "Validation loss: 0.5095, Validation accuracy: 0.8771\n",
      "Epoch 150:\n",
      "Training loss: 0.0395, Training accuracy: 0.9873\n",
      "Validation loss: 0.5108, Validation accuracy: 0.8805\n",
      "Epoch 151:\n",
      "Training loss: 0.0392, Training accuracy: 0.9869\n",
      "Validation loss: 0.5049, Validation accuracy: 0.8811\n",
      "Epoch 152:\n",
      "Training loss: 0.0383, Training accuracy: 0.9873\n",
      "Validation loss: 0.5051, Validation accuracy: 0.8816\n",
      "Epoch 153:\n",
      "Training loss: 0.0353, Training accuracy: 0.9880\n",
      "Validation loss: 0.4989, Validation accuracy: 0.8807\n",
      "Epoch 154:\n",
      "Training loss: 0.0365, Training accuracy: 0.9875\n",
      "Validation loss: 0.5112, Validation accuracy: 0.8803\n",
      "Epoch 155:\n",
      "Training loss: 0.0368, Training accuracy: 0.9877\n",
      "Validation loss: 0.4962, Validation accuracy: 0.8823\n",
      "Epoch 156:\n",
      "Training loss: 0.0390, Training accuracy: 0.9864\n",
      "Validation loss: 0.5134, Validation accuracy: 0.8798\n",
      "Epoch 157:\n",
      "Training loss: 0.0370, Training accuracy: 0.9876\n",
      "Validation loss: 0.5084, Validation accuracy: 0.8803\n",
      "Epoch 158:\n",
      "Training loss: 0.0345, Training accuracy: 0.9882\n",
      "Validation loss: 0.5076, Validation accuracy: 0.8815\n",
      "Epoch 159:\n",
      "Training loss: 0.0320, Training accuracy: 0.9894\n",
      "Validation loss: 0.5162, Validation accuracy: 0.8818\n",
      "Epoch 160:\n",
      "Training loss: 0.0308, Training accuracy: 0.9896\n",
      "Validation loss: 0.5065, Validation accuracy: 0.8840\n",
      "Epoch 161:\n",
      "Training loss: 0.0281, Training accuracy: 0.9909\n",
      "Validation loss: 0.5022, Validation accuracy: 0.8852\n",
      "Saving ...\n",
      "Epoch 162:\n",
      "Training loss: 0.0276, Training accuracy: 0.9909\n",
      "Validation loss: 0.5021, Validation accuracy: 0.8856\n",
      "Saving ...\n",
      "Epoch 163:\n",
      "Training loss: 0.0277, Training accuracy: 0.9914\n",
      "Validation loss: 0.4985, Validation accuracy: 0.8848\n",
      "Epoch 164:\n",
      "Training loss: 0.0258, Training accuracy: 0.9917\n",
      "Validation loss: 0.5012, Validation accuracy: 0.8848\n",
      "Epoch 165:\n",
      "Training loss: 0.0260, Training accuracy: 0.9916\n",
      "Validation loss: 0.5003, Validation accuracy: 0.8833\n",
      "Epoch 166:\n",
      "Training loss: 0.0227, Training accuracy: 0.9928\n",
      "Validation loss: 0.5001, Validation accuracy: 0.8849\n",
      "Epoch 167:\n",
      "Training loss: 0.0256, Training accuracy: 0.9914\n",
      "Validation loss: 0.5016, Validation accuracy: 0.8848\n",
      "Epoch 168:\n",
      "Training loss: 0.0231, Training accuracy: 0.9934\n",
      "Validation loss: 0.4997, Validation accuracy: 0.8846\n",
      "Epoch 169:\n",
      "Training loss: 0.0230, Training accuracy: 0.9929\n",
      "Validation loss: 0.5005, Validation accuracy: 0.8842\n",
      "Epoch 170:\n",
      "Training loss: 0.0227, Training accuracy: 0.9930\n",
      "Validation loss: 0.5031, Validation accuracy: 0.8852\n",
      "Epoch 171:\n",
      "Training loss: 0.0228, Training accuracy: 0.9930\n",
      "Validation loss: 0.5046, Validation accuracy: 0.8853\n",
      "Epoch 172:\n",
      "Training loss: 0.0231, Training accuracy: 0.9929\n",
      "Validation loss: 0.5041, Validation accuracy: 0.8856\n",
      "Epoch 173:\n",
      "Training loss: 0.0231, Training accuracy: 0.9930\n",
      "Validation loss: 0.5019, Validation accuracy: 0.8849\n",
      "Epoch 174:\n",
      "Training loss: 0.0234, Training accuracy: 0.9927\n",
      "Validation loss: 0.5043, Validation accuracy: 0.8862\n",
      "Saving ...\n",
      "Epoch 175:\n",
      "Training loss: 0.0212, Training accuracy: 0.9937\n",
      "Validation loss: 0.5031, Validation accuracy: 0.8854\n",
      "Epoch 176:\n",
      "Training loss: 0.0224, Training accuracy: 0.9934\n",
      "Validation loss: 0.5021, Validation accuracy: 0.8862\n",
      "Epoch 177:\n",
      "Training loss: 0.0220, Training accuracy: 0.9935\n",
      "Validation loss: 0.5048, Validation accuracy: 0.8853\n",
      "Epoch 178:\n",
      "Training loss: 0.0205, Training accuracy: 0.9939\n",
      "Validation loss: 0.5047, Validation accuracy: 0.8865\n",
      "Saving ...\n",
      "Epoch 179:\n",
      "Training loss: 0.0207, Training accuracy: 0.9939\n",
      "Validation loss: 0.5054, Validation accuracy: 0.8857\n",
      "Epoch 180:\n",
      "Training loss: 0.0212, Training accuracy: 0.9937\n",
      "Validation loss: 0.5070, Validation accuracy: 0.8844\n",
      "Epoch 181:\n",
      "Training loss: 0.0206, Training accuracy: 0.9935\n",
      "Validation loss: 0.5081, Validation accuracy: 0.8847\n",
      "Epoch 182:\n",
      "Training loss: 0.0209, Training accuracy: 0.9931\n",
      "Validation loss: 0.5072, Validation accuracy: 0.8852\n",
      "Epoch 183:\n",
      "Training loss: 0.0219, Training accuracy: 0.9932\n",
      "Validation loss: 0.5077, Validation accuracy: 0.8843\n",
      "Epoch 184:\n",
      "Training loss: 0.0202, Training accuracy: 0.9936\n",
      "Validation loss: 0.5026, Validation accuracy: 0.8857\n",
      "Epoch 185:\n",
      "Training loss: 0.0200, Training accuracy: 0.9939\n",
      "Validation loss: 0.5075, Validation accuracy: 0.8863\n",
      "Epoch 186:\n",
      "Training loss: 0.0211, Training accuracy: 0.9938\n",
      "Validation loss: 0.5073, Validation accuracy: 0.8855\n",
      "Epoch 187:\n",
      "Training loss: 0.0197, Training accuracy: 0.9940\n",
      "Validation loss: 0.5090, Validation accuracy: 0.8847\n",
      "Epoch 188:\n",
      "Training loss: 0.0209, Training accuracy: 0.9934\n",
      "Validation loss: 0.5071, Validation accuracy: 0.8864\n",
      "Epoch 189:\n",
      "Training loss: 0.0202, Training accuracy: 0.9938\n",
      "Validation loss: 0.5086, Validation accuracy: 0.8863\n",
      "Epoch 190:\n",
      "Training loss: 0.0204, Training accuracy: 0.9939\n",
      "Validation loss: 0.5099, Validation accuracy: 0.8863\n",
      "Epoch 191:\n",
      "Training loss: 0.0201, Training accuracy: 0.9937\n",
      "Validation loss: 0.5111, Validation accuracy: 0.8860\n",
      "Epoch 192:\n",
      "Training loss: 0.0194, Training accuracy: 0.9943\n",
      "Validation loss: 0.5116, Validation accuracy: 0.8861\n",
      "Epoch 193:\n"
     ]
    }
   ],
   "source": [
    "train_res50(train_loader,val_loader,INITIAL_LR = 0.1,REG = 4e-4,DECAY_EPOCHS=[40,80,160], DECAY=0.1,EPOCHS=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "55f20d8859a1a0149f7d957af872e078c8283691172f5ca78f1d0b16a2e38dc4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
