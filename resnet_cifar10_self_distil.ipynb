{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os, sys\n",
    "import time\n",
    "import datetime\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Softloss(nn.Module):\n",
    "    def __init__(self,T=4,loss_portion=[1,0,0]) -> None:\n",
    "        '''\n",
    "        T: temperature\n",
    "        loss_portion: KLD, cosine, mse\n",
    "        '''\n",
    "        super(Softloss,self).__init__()\n",
    "        self.T=T\n",
    "        self.portion=loss_portion\n",
    "    def forward(self,x,y):\n",
    "        soft_x=F.log_softmax(x/self.T,dim=-1)\n",
    "        soft_y=F.softmax(y/self.T,dim=-1)\n",
    "        loss=self.portion[0]*F.kl_div(soft_x,soft_y,reduction=\"batchmean\")\n",
    "        return loss*self.T*self.T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torchvision\n",
    "class ResNet_self_distil(nn.Module):\n",
    "    def __init__(self ):\n",
    "        super(ResNet_self_distil, self).__init__()\n",
    "        self.resnet50=torchvision.models.resnet50(num_classes=10)\n",
    "        self.neck1=torchvision.models.resnet.Bottleneck(256,512,downsample=nn.Sequential(\n",
    "                nn.Conv2d(256, 2048, kernel_size=(1, 1), stride=1, bias=False),\n",
    "                nn.BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "            ))\n",
    "        self.pool1=nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc1=nn.Linear(in_features=2048, out_features=10, bias=True)\n",
    "        self.neck2=torchvision.models.resnet.Bottleneck(512,512,downsample=nn.Sequential(\n",
    "                nn.Conv2d(512, 2048, kernel_size=(1, 1), stride=1, bias=False),\n",
    "                nn.BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "            ))\n",
    "        self.pool2=nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc2=nn.Linear(in_features=2048, out_features=10, bias=True)\n",
    "        self.neck3=torchvision.models.resnet.Bottleneck(1024,512,downsample=nn.Sequential(\n",
    "                nn.Conv2d(1024, 2048, kernel_size=(1, 1), stride=1, bias=False),\n",
    "                nn.BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "            ))\n",
    "        self.pool3=nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc3=nn.Linear(in_features=2048, out_features=10, bias=True)\n",
    "    def forward(self, x,is_eval=True):\n",
    "        if is_eval:\n",
    "            return self.resnet50(x)\n",
    "        feature=[]\n",
    "        out=[]\n",
    "        x = self.resnet50.conv1(x)\n",
    "        x = self.resnet50.bn1(x)\n",
    "        x = self.resnet50.relu(x)\n",
    "        x = self.resnet50.maxpool(x)\n",
    "        x = self.resnet50.layer1(x)\n",
    "        feature1= torch.flatten(self.pool1(self.neck1(x)),1)\n",
    "        feature.append(feature1)\n",
    "        out.append(self.fc1(feature1))\n",
    "\n",
    "        x = self.resnet50.layer2(x)\n",
    "        feature2= torch.flatten(self.pool2(self.neck2(x)),1)\n",
    "        feature.append(feature2)\n",
    "        out.append(self.fc2(feature2))\n",
    "        x = self.resnet50.layer3(x)\n",
    "        feature3= torch.flatten(self.pool3(self.neck3(x)),1)\n",
    "        feature.append(feature3)\n",
    "        out.append(self.fc3(feature3))\n",
    "        x = self.resnet50.layer4(x)\n",
    "        x = self.resnet50.avgpool(x)\n",
    "        feature4 = torch.flatten(x, 1)\n",
    "        x = self.resnet50.fc(feature4)\n",
    "        feature.append(feature4)\n",
    "        out.append(x)\n",
    "        return feature,out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# useful libraries\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "#############################################\n",
    "# your code here\n",
    "# specify preprocessing function\n",
    "transform = transforms.Compose(\n",
    "    (\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "    )\n",
    ")\n",
    "transform_train = transforms.Compose(\n",
    "    (\n",
    "    \n",
    "    transforms.RandomCrop((32,32),padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    #transforms.RandomVerticalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "    \n",
    "    #\n",
    "    #transforms.ColorJitter(0.2,0,0)\n",
    "    \n",
    "    )\n",
    ")\n",
    "\n",
    "transform_val = transform\n",
    "#############################################\n",
    "# do NOT change these\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# a few arguments, do NOT change these\n",
    "DATA_ROOT = \"./data\"\n",
    "TRAIN_BATCH_SIZE = 64\n",
    "VAL_BATCH_SIZE = 100\n",
    "\n",
    "#############################################\n",
    "# your code here\n",
    "# construct dataset\n",
    "train_set = CIFAR10(\n",
    "    root=DATA_ROOT, \n",
    "    train=True, \n",
    "    download=True,\n",
    "    transform=transform_train    # your code\n",
    ")\n",
    "\n",
    "val_set = CIFAR10(\n",
    "    root=DATA_ROOT, \n",
    "    train=False, \n",
    "    download=True,\n",
    "    transform=transform_val    # your code\n",
    ")\n",
    "\n",
    "# construct dataloader\n",
    "train_loader = DataLoader(\n",
    "    train_set, \n",
    "    batch_size=TRAIN_BATCH_SIZE,  # your code\n",
    "    shuffle=True,     # your code\n",
    "    num_workers=2\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_set, \n",
    "    batch_size=VAL_BATCH_SIZE,  # your code\n",
    "    shuffle=False,     # your code\n",
    "    num_workers=2\n",
    ")\n",
    "#############################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "def train(T,lamb,alpha,train_loader,val_loader,INITIAL_LR=0.1,DECAY_EPOCHS=[40,100,180],DECAY=0.1,EPOCHS=200,REG = 5e-4):\n",
    "    # some hyperparameters\n",
    "    # total number of training epochs\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    model=ResNet_self_distil()\n",
    "    model=model.to(device)\n",
    "    MOMENTUM = 0.9\n",
    "\n",
    "    # L2 regularization strength\n",
    "    \n",
    "    tmpalpha=alpha\n",
    "    alpha=0\n",
    "    #############################################\n",
    "    # your code here\n",
    "    # create loss function\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    # Add optimizer\n",
    "    optimizer = optim.SGD(model.parameters(),lr=INITIAL_LR,momentum=MOMENTUM,weight_decay=REG,nesterov=True)\n",
    "    soft_criterion=Softloss(T)\n",
    "    # the folder where the trained model is saved\n",
    "    CHECKPOINT_FOLDER = \"./saved_model\"\n",
    "  \n",
    "    # start the training/validation process\n",
    "    # the process should take about 5 minutes on a GTX 1070-Ti\n",
    "    # if the code is written efficiently.\n",
    "    best_val_acc = 0\n",
    "    current_learning_rate = INITIAL_LR\n",
    "    \n",
    "    print(\"==> Training starts!\")\n",
    "    print(\"=\"*50)\n",
    "    for i in range(0, EPOCHS):\n",
    "        # handle the learning rate scheduler.\n",
    "        if i==10:\n",
    "            alpha=tmpalpha\n",
    "        if i in DECAY_EPOCHS and i != 0 :\n",
    "            current_learning_rate = current_learning_rate * DECAY\n",
    "        \n",
    "            for param_group in optimizer.param_groups:\n",
    "                param_group['lr'] = current_learning_rate\n",
    "            print(\"Current learning rate has decayed to %f\" %current_learning_rate)\n",
    "        \n",
    "        #######################\n",
    "        # your code here\n",
    "        # switch to train mode\n",
    "        model.train()\n",
    "        \n",
    "        #######################\n",
    "        \n",
    "        print(\"Epoch %d:\" %i)\n",
    "        # this help you compute the training accuracy\n",
    "        total_examples = 0\n",
    "        correct_examples = 0\n",
    "\n",
    "        train_loss = 0 # track training loss if you want\n",
    "        loader=train_loader\n",
    "        \n",
    "        # Train the model for 1 epoch.\n",
    "        for batch_idx, (inputs, targets) in enumerate(loader):\n",
    "            ####################################\n",
    "            # your code here\n",
    "            # copy inputs to device\n",
    "            inputs=inputs.to(device)\n",
    "            targets=targets.to(device).long()\n",
    "\n",
    "            \n",
    "            # compute the output and loss\n",
    "            feature,out=model(inputs,False)\n",
    "            loss=lamb*(F.mse_loss(feature[0],feature[3])+F.mse_loss(feature[1],feature[3])+F.mse_loss(feature[2],feature[3]))\n",
    "            for i in range(3):\n",
    "                loss+=(1-alpha)*criterion(out[i],targets)+alpha*soft_criterion(out[i],out[3])\n",
    "            loss+=criterion(out[3],targets)\n",
    "            loss/=5\n",
    "            # zero the gradient\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            # backpropagation\n",
    "            loss.backward()\n",
    "\n",
    "            \n",
    "            # apply gradient and update the weights\n",
    "            optimizer.step()\n",
    "            train_loss+=loss.item()\n",
    "            \n",
    "            # count the number of correctly predicted samples in the current batch\n",
    "            correct_examples+=torch.sum(out[3].argmax(-1)==targets).item()\n",
    "            ####################################\n",
    "        total_examples=len(train_loader.dataset)      \n",
    "        avg_loss = train_loss / len(train_loader)\n",
    "        avg_acc = correct_examples / total_examples\n",
    "        print(\"Training loss: %.4f, Training accuracy: %.4f\" %(avg_loss, avg_acc))\n",
    "\n",
    "        # Validate on the validation dataset\n",
    "        #######################\n",
    "        # your code here\n",
    "        # switch to eval mode\n",
    "        model.eval()\n",
    "        \n",
    "        #######################\n",
    "\n",
    "        # this help you compute the validation accuracy\n",
    "        total_examples = 0\n",
    "        correct_examples = 0\n",
    "        \n",
    "        val_loss = 0 # again, track the validation loss if you want\n",
    "\n",
    "        # disable gradient during validation, which can save GPU memory\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, (inputs, targets) in enumerate(val_loader):\n",
    "                ####################################\n",
    "                # your code here\n",
    "                # copy inputs to device\n",
    "                inputs=inputs.to(device)\n",
    "                targets=targets.to(device).long()\n",
    "                # compute the output and loss\n",
    "                out=model(inputs)\n",
    "                loss=criterion(out,targets)\n",
    "                # count the number of correctly predicted samples in the current batch\n",
    "                val_loss+=loss.item()\n",
    "                correct_examples+=torch.sum(out.argmax(-1)==targets).item()\n",
    "                \n",
    "                ####################################\n",
    "        total_examples=len(val_loader.dataset)\n",
    "        avg_loss = val_loss / len(val_loader)\n",
    "        avg_acc = correct_examples / total_examples\n",
    "        print(\"Validation loss: %.4f, Validation accuracy: %.4f\" % (avg_loss, avg_acc))\n",
    "        \n",
    "        # save the model checkpoint\n",
    "        if avg_acc > best_val_acc:\n",
    "            best_val_acc = avg_acc\n",
    "            if not os.path.exists(CHECKPOINT_FOLDER):\n",
    "                os.makedirs(CHECKPOINT_FOLDER)\n",
    "            print(\"Saving ...\")\n",
    "            state = {'state_dict': model.resnet50.state_dict(),\n",
    "                    'epoch': i,\n",
    "                    }\n",
    "            torch.save(state, os.path.join(CHECKPOINT_FOLDER, 'self_distilled.pth'))\n",
    "            \n",
    "        print('')\n",
    "\n",
    "    print(\"=\"*50)\n",
    "    print(f\"==> Optimization finished! Best validation accuracy: {best_val_acc:.4f}\")\n",
    "    return best_val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Training starts!\n",
      "==================================================\n",
      "Epoch 0:\n",
      "Training loss: 10.0389, Training accuracy: 0.1275\n",
      "Validation loss: 4.6680, Validation accuracy: 0.1670\n",
      "Saving ...\n",
      "\n",
      "Current learning rate has decayed to 0.009600\n",
      "Epoch 1:\n",
      "Training loss: 6.2845, Training accuracy: 0.1972\n",
      "Validation loss: 10.8242, Validation accuracy: 0.2645\n",
      "Saving ...\n",
      "\n",
      "Current learning rate has decayed to 0.009216\n",
      "Epoch 2:\n",
      "Training loss: 5.2151, Training accuracy: 0.2898\n",
      "Validation loss: 3.7247, Validation accuracy: 0.3487\n",
      "Saving ...\n",
      "\n",
      "Current learning rate has decayed to 0.008847\n",
      "Epoch 3:\n",
      "Training loss: 4.4960, Training accuracy: 0.3429\n",
      "Validation loss: 1.9922, Validation accuracy: 0.3886\n",
      "Saving ...\n",
      "\n",
      "Current learning rate has decayed to 0.008493\n",
      "Epoch 4:\n",
      "Training loss: 3.8123, Training accuracy: 0.3762\n",
      "Validation loss: 1.6493, Validation accuracy: 0.4204\n",
      "Saving ...\n",
      "\n",
      "Current learning rate has decayed to 0.008154\n",
      "Epoch 5:\n",
      "Training loss: 3.5777, Training accuracy: 0.4144\n",
      "Validation loss: 1.5861, Validation accuracy: 0.4486\n",
      "Saving ...\n",
      "\n",
      "Current learning rate has decayed to 0.007828\n",
      "Epoch 6:\n",
      "Training loss: 3.4099, Training accuracy: 0.4467\n",
      "Validation loss: 1.7603, Validation accuracy: 0.4722\n",
      "Saving ...\n",
      "\n",
      "Current learning rate has decayed to 0.007514\n",
      "Epoch 7:\n",
      "Training loss: 3.2665, Training accuracy: 0.4732\n",
      "Validation loss: 1.7925, Validation accuracy: 0.5031\n",
      "Saving ...\n",
      "\n",
      "Current learning rate has decayed to 0.007214\n",
      "Epoch 8:\n",
      "Training loss: 3.1326, Training accuracy: 0.4971\n",
      "Validation loss: 1.5332, Validation accuracy: 0.5272\n",
      "Saving ...\n",
      "\n",
      "Current learning rate has decayed to 0.006925\n",
      "Epoch 9:\n",
      "Training loss: 3.0187, Training accuracy: 0.5197\n",
      "Validation loss: 1.4685, Validation accuracy: 0.5548\n",
      "Saving ...\n",
      "\n",
      "Current learning rate has decayed to 0.006648\n",
      "Epoch 10:\n",
      "Training loss: 2.9150, Training accuracy: 0.5400\n",
      "Validation loss: 1.2962, Validation accuracy: 0.5713\n",
      "Saving ...\n",
      "\n",
      "Current learning rate has decayed to 0.006382\n",
      "Epoch 11:\n",
      "Training loss: 2.8018, Training accuracy: 0.5568\n",
      "Validation loss: 1.7719, Validation accuracy: 0.5701\n",
      "\n",
      "Current learning rate has decayed to 0.006127\n",
      "Epoch 12:\n",
      "Training loss: 2.7488, Training accuracy: 0.5676\n",
      "Validation loss: 1.1633, Validation accuracy: 0.5825\n",
      "Saving ...\n",
      "\n",
      "Current learning rate has decayed to 0.005882\n",
      "Epoch 13:\n",
      "Training loss: 2.6972, Training accuracy: 0.5792\n",
      "Validation loss: 1.1110, Validation accuracy: 0.6054\n",
      "Saving ...\n",
      "\n",
      "Current learning rate has decayed to 0.005647\n",
      "Epoch 14:\n",
      "Training loss: 2.6014, Training accuracy: 0.5901\n",
      "Validation loss: 1.1821, Validation accuracy: 0.6125\n",
      "Saving ...\n",
      "\n",
      "Current learning rate has decayed to 0.005421\n",
      "Epoch 15:\n",
      "Training loss: 2.5024, Training accuracy: 0.6109\n",
      "Validation loss: 1.2532, Validation accuracy: 0.6381\n",
      "Saving ...\n",
      "\n",
      "Current learning rate has decayed to 0.005204\n",
      "Epoch 16:\n",
      "Training loss: 2.4435, Training accuracy: 0.6210\n",
      "Validation loss: 1.4101, Validation accuracy: 0.6369\n",
      "\n",
      "Current learning rate has decayed to 0.004996\n",
      "Epoch 17:\n",
      "Training loss: 2.3687, Training accuracy: 0.6359\n",
      "Validation loss: 1.1316, Validation accuracy: 0.6432\n",
      "Saving ...\n",
      "\n",
      "Current learning rate has decayed to 0.004796\n",
      "Epoch 18:\n",
      "Training loss: 2.2906, Training accuracy: 0.6483\n",
      "Validation loss: 1.5051, Validation accuracy: 0.6580\n",
      "Saving ...\n",
      "\n",
      "Current learning rate has decayed to 0.004604\n",
      "Epoch 19:\n",
      "Training loss: 2.2404, Training accuracy: 0.6581\n",
      "Validation loss: 1.9994, Validation accuracy: 0.6757\n",
      "Saving ...\n",
      "\n",
      "Current learning rate has decayed to 0.004420\n",
      "Epoch 20:\n",
      "Training loss: 2.1706, Training accuracy: 0.6692\n",
      "Validation loss: 3.3940, Validation accuracy: 0.6757\n",
      "\n",
      "Current learning rate has decayed to 0.004243\n",
      "Epoch 21:\n",
      "Training loss: 2.1000, Training accuracy: 0.6827\n",
      "Validation loss: 2.3770, Validation accuracy: 0.6889\n",
      "Saving ...\n",
      "\n",
      "Current learning rate has decayed to 0.004073\n",
      "Epoch 22:\n",
      "Training loss: 2.0608, Training accuracy: 0.6884\n",
      "Validation loss: 1.0517, Validation accuracy: 0.6994\n",
      "Saving ...\n",
      "\n",
      "Current learning rate has decayed to 0.003911\n",
      "Epoch 23:\n",
      "Training loss: 2.0180, Training accuracy: 0.6971\n",
      "Validation loss: 0.9990, Validation accuracy: 0.6873\n",
      "\n",
      "Current learning rate has decayed to 0.003754\n",
      "Epoch 24:\n",
      "Training loss: 1.9953, Training accuracy: 0.6994\n",
      "Validation loss: 1.1228, Validation accuracy: 0.7009\n",
      "Saving ...\n",
      "\n",
      "Current learning rate has decayed to 0.003604\n",
      "Epoch 25:\n",
      "Training loss: 1.9335, Training accuracy: 0.7098\n",
      "Validation loss: 1.2254, Validation accuracy: 0.7153\n",
      "Saving ...\n",
      "\n",
      "Current learning rate has decayed to 0.003460\n",
      "Epoch 26:\n",
      "Training loss: 1.9284, Training accuracy: 0.7106\n",
      "Validation loss: 1.2093, Validation accuracy: 0.7170\n",
      "Saving ...\n",
      "\n",
      "Current learning rate has decayed to 0.003321\n",
      "Epoch 27:\n",
      "Training loss: 1.9129, Training accuracy: 0.7158\n",
      "Validation loss: 2.1415, Validation accuracy: 0.7230\n",
      "Saving ...\n",
      "\n",
      "Current learning rate has decayed to 0.003189\n",
      "Epoch 28:\n",
      "Training loss: 1.8288, Training accuracy: 0.7299\n",
      "Validation loss: 1.3296, Validation accuracy: 0.7271\n",
      "Saving ...\n",
      "\n",
      "Current learning rate has decayed to 0.003061\n",
      "Epoch 29:\n",
      "Training loss: 1.8206, Training accuracy: 0.7307\n",
      "Validation loss: 2.0506, Validation accuracy: 0.7246\n",
      "\n",
      "Current learning rate has decayed to 0.002939\n",
      "Epoch 30:\n",
      "Training loss: 1.7743, Training accuracy: 0.7389\n",
      "Validation loss: 3.7639, Validation accuracy: 0.7318\n",
      "Saving ...\n",
      "\n",
      "Current learning rate has decayed to 0.002821\n",
      "Epoch 31:\n",
      "Training loss: 1.7601, Training accuracy: 0.7409\n",
      "Validation loss: 3.3850, Validation accuracy: 0.7316\n",
      "\n",
      "Current learning rate has decayed to 0.002708\n",
      "Epoch 32:\n",
      "Training loss: 1.9965, Training accuracy: 0.7020\n",
      "Validation loss: 0.7940, Validation accuracy: 0.7238\n",
      "\n",
      "Current learning rate has decayed to 0.002600\n",
      "Epoch 33:\n",
      "Training loss: 1.8428, Training accuracy: 0.7278\n",
      "Validation loss: 0.7466, Validation accuracy: 0.7380\n",
      "Saving ...\n",
      "\n",
      "Current learning rate has decayed to 0.002496\n",
      "Epoch 34:\n",
      "Training loss: 1.7529, Training accuracy: 0.7436\n",
      "Validation loss: 0.7430, Validation accuracy: 0.7453\n",
      "Saving ...\n",
      "\n",
      "Current learning rate has decayed to 0.002396\n",
      "Epoch 35:\n",
      "Training loss: 1.7120, Training accuracy: 0.7492\n",
      "Validation loss: 0.7246, Validation accuracy: 0.7481\n",
      "Saving ...\n",
      "\n",
      "Current learning rate has decayed to 0.002300\n",
      "Epoch 36:\n",
      "Training loss: 1.6654, Training accuracy: 0.7570\n",
      "Validation loss: 0.7019, Validation accuracy: 0.7537\n",
      "Saving ...\n",
      "\n",
      "Current learning rate has decayed to 0.002208\n",
      "Epoch 37:\n",
      "Training loss: 1.6846, Training accuracy: 0.7551\n",
      "Validation loss: 0.7051, Validation accuracy: 0.7557\n",
      "Saving ...\n",
      "\n",
      "Current learning rate has decayed to 0.002120\n",
      "Epoch 38:\n",
      "Training loss: 1.6306, Training accuracy: 0.7634\n",
      "Validation loss: 1.3752, Validation accuracy: 0.7575\n",
      "Saving ...\n",
      "\n",
      "Current learning rate has decayed to 0.002035\n",
      "Epoch 39:\n",
      "Training loss: 1.7302, Training accuracy: 0.7474\n",
      "Validation loss: 0.7004, Validation accuracy: 0.7553\n",
      "\n",
      "Current learning rate has decayed to 0.001954\n",
      "Epoch 40:\n",
      "Training loss: 1.6186, Training accuracy: 0.7661\n",
      "Validation loss: 0.6690, Validation accuracy: 0.7656\n",
      "Saving ...\n",
      "\n",
      "Current learning rate has decayed to 0.001876\n",
      "Epoch 41:\n",
      "Training loss: 1.5646, Training accuracy: 0.7740\n",
      "Validation loss: 0.6617, Validation accuracy: 0.7670\n",
      "Saving ...\n",
      "\n",
      "Current learning rate has decayed to 0.001800\n",
      "Epoch 42:\n",
      "Training loss: 1.5363, Training accuracy: 0.7796\n",
      "Validation loss: 0.6552, Validation accuracy: 0.7698\n",
      "Saving ...\n",
      "\n",
      "Current learning rate has decayed to 0.001728\n",
      "Epoch 43:\n",
      "Training loss: 1.5111, Training accuracy: 0.7844\n",
      "Validation loss: 0.6568, Validation accuracy: 0.7701\n",
      "Saving ...\n",
      "\n",
      "Current learning rate has decayed to 0.001659\n",
      "Epoch 44:\n",
      "Training loss: 1.4921, Training accuracy: 0.7877\n",
      "Validation loss: 0.6492, Validation accuracy: 0.7751\n",
      "Saving ...\n",
      "\n",
      "Current learning rate has decayed to 0.001593\n",
      "Epoch 45:\n",
      "Training loss: 1.5875, Training accuracy: 0.7706\n",
      "Validation loss: 0.6742, Validation accuracy: 0.7673\n",
      "\n",
      "Current learning rate has decayed to 0.001529\n",
      "Epoch 46:\n",
      "Training loss: 1.5241, Training accuracy: 0.7807\n",
      "Validation loss: 0.6551, Validation accuracy: 0.7745\n",
      "\n",
      "Current learning rate has decayed to 0.001468\n",
      "Epoch 47:\n",
      "Training loss: 1.4745, Training accuracy: 0.7903\n",
      "Validation loss: 0.6408, Validation accuracy: 0.7751\n",
      "\n",
      "Current learning rate has decayed to 0.001409\n",
      "Epoch 48:\n",
      "Training loss: 1.4592, Training accuracy: 0.7916\n",
      "Validation loss: 0.7837, Validation accuracy: 0.7415\n",
      "\n",
      "Current learning rate has decayed to 0.001353\n",
      "Epoch 49:\n",
      "Training loss: 1.4524, Training accuracy: 0.7930\n",
      "Validation loss: 0.6417, Validation accuracy: 0.7758\n",
      "Saving ...\n",
      "\n",
      "Current learning rate has decayed to 0.001299\n",
      "Epoch 50:\n",
      "Training loss: 1.4168, Training accuracy: 0.8000\n",
      "Validation loss: 0.6494, Validation accuracy: 0.7814\n",
      "Saving ...\n",
      "\n",
      "Current learning rate has decayed to 0.001247\n",
      "Epoch 51:\n",
      "Training loss: 1.4084, Training accuracy: 0.8019\n",
      "Validation loss: 0.6335, Validation accuracy: 0.7827\n",
      "Saving ...\n",
      "\n",
      "Current learning rate has decayed to 0.001197\n",
      "Epoch 52:\n",
      "Training loss: 1.3968, Training accuracy: 0.8039\n",
      "Validation loss: 0.6250, Validation accuracy: 0.7795\n",
      "\n",
      "Current learning rate has decayed to 0.001149\n",
      "Epoch 53:\n",
      "Training loss: 1.3913, Training accuracy: 0.8052\n",
      "Validation loss: 0.6411, Validation accuracy: 0.7821\n",
      "\n",
      "Current learning rate has decayed to 0.001103\n",
      "Epoch 54:\n",
      "Training loss: 1.3740, Training accuracy: 0.8082\n",
      "Validation loss: 0.6622, Validation accuracy: 0.7821\n",
      "\n",
      "Current learning rate has decayed to 0.001059\n",
      "Epoch 55:\n",
      "Training loss: 1.3732, Training accuracy: 0.8091\n",
      "Validation loss: 0.6579, Validation accuracy: 0.7690\n",
      "\n",
      "Current learning rate has decayed to 0.001017\n",
      "Epoch 56:\n",
      "Training loss: 1.4027, Training accuracy: 0.8031\n",
      "Validation loss: 0.6219, Validation accuracy: 0.7849\n",
      "Saving ...\n",
      "\n",
      "Current learning rate has decayed to 0.000976\n",
      "Epoch 57:\n",
      "Training loss: 1.3564, Training accuracy: 0.8104\n",
      "Validation loss: 0.6154, Validation accuracy: 0.7845\n",
      "\n",
      "Current learning rate has decayed to 0.000937\n",
      "Epoch 58:\n",
      "Training loss: 1.3402, Training accuracy: 0.8153\n",
      "Validation loss: 0.6074, Validation accuracy: 0.7876\n",
      "Saving ...\n",
      "\n",
      "Current learning rate has decayed to 0.000900\n",
      "Epoch 59:\n",
      "Training loss: 1.3218, Training accuracy: 0.8148\n",
      "Validation loss: 0.6050, Validation accuracy: 0.7902\n",
      "Saving ...\n",
      "\n",
      "Current learning rate has decayed to 0.000864\n",
      "Epoch 60:\n",
      "Training loss: 1.3084, Training accuracy: 0.8204\n",
      "Validation loss: 0.6058, Validation accuracy: 0.7902\n",
      "\n",
      "Current learning rate has decayed to 0.000829\n",
      "Epoch 61:\n",
      "Training loss: 1.3033, Training accuracy: 0.8207\n",
      "Validation loss: 0.5956, Validation accuracy: 0.7935\n",
      "Saving ...\n",
      "\n",
      "Current learning rate has decayed to 0.000796\n",
      "Epoch 62:\n",
      "Training loss: 1.2854, Training accuracy: 0.8228\n",
      "Validation loss: 0.6005, Validation accuracy: 0.7886\n",
      "\n",
      "Current learning rate has decayed to 0.000764\n",
      "Epoch 63:\n",
      "Training loss: 1.3319, Training accuracy: 0.8161\n",
      "Validation loss: 0.6192, Validation accuracy: 0.7871\n",
      "\n",
      "Current learning rate has decayed to 0.000733\n",
      "Epoch 64:\n",
      "Training loss: 1.3139, Training accuracy: 0.8199\n",
      "Validation loss: 0.6138, Validation accuracy: 0.7891\n",
      "\n",
      "Current learning rate has decayed to 0.000704\n",
      "Epoch 65:\n",
      "Training loss: 1.2861, Training accuracy: 0.8239\n",
      "Validation loss: 0.6101, Validation accuracy: 0.7895\n",
      "\n",
      "Current learning rate has decayed to 0.000676\n",
      "Epoch 66:\n",
      "Training loss: 1.3038, Training accuracy: 0.8214\n",
      "Validation loss: 0.6053, Validation accuracy: 0.7886\n",
      "\n",
      "Current learning rate has decayed to 0.000649\n",
      "Epoch 67:\n",
      "Training loss: 1.2948, Training accuracy: 0.8219\n",
      "Validation loss: 0.5971, Validation accuracy: 0.7934\n",
      "\n",
      "Current learning rate has decayed to 0.000623\n",
      "Epoch 68:\n",
      "Training loss: 1.3123, Training accuracy: 0.8179\n",
      "Validation loss: 0.6104, Validation accuracy: 0.7875\n",
      "\n",
      "Current learning rate has decayed to 0.000598\n",
      "Epoch 69:\n",
      "Training loss: 1.2837, Training accuracy: 0.8235\n",
      "Validation loss: 0.5919, Validation accuracy: 0.7928\n",
      "\n",
      "Current learning rate has decayed to 0.000574\n",
      "Epoch 70:\n",
      "Training loss: 1.2559, Training accuracy: 0.8296\n",
      "Validation loss: 0.6006, Validation accuracy: 0.7946\n",
      "Saving ...\n",
      "\n",
      "Current learning rate has decayed to 0.000551\n",
      "Epoch 71:\n",
      "Training loss: 1.2537, Training accuracy: 0.8311\n",
      "Validation loss: 0.5941, Validation accuracy: 0.7954\n",
      "Saving ...\n",
      "\n",
      "Current learning rate has decayed to 0.000529\n",
      "Epoch 72:\n",
      "Training loss: 1.2503, Training accuracy: 0.8297\n",
      "Validation loss: 0.5863, Validation accuracy: 0.7987\n",
      "Saving ...\n",
      "\n",
      "Current learning rate has decayed to 0.000508\n",
      "Epoch 73:\n",
      "Training loss: 1.2267, Training accuracy: 0.8330\n",
      "Validation loss: 0.5905, Validation accuracy: 0.7936\n",
      "\n",
      "Current learning rate has decayed to 0.000488\n",
      "Epoch 74:\n",
      "Training loss: 1.2218, Training accuracy: 0.8345\n",
      "Validation loss: 0.5856, Validation accuracy: 0.7965\n",
      "\n",
      "Current learning rate has decayed to 0.000468\n",
      "Epoch 75:\n",
      "Training loss: 1.2106, Training accuracy: 0.8361\n",
      "Validation loss: 0.5840, Validation accuracy: 0.7989\n",
      "Saving ...\n",
      "\n",
      "Current learning rate has decayed to 0.000449\n",
      "Epoch 76:\n",
      "Training loss: 1.2107, Training accuracy: 0.8360\n",
      "Validation loss: 0.5871, Validation accuracy: 0.7967\n",
      "\n",
      "Current learning rate has decayed to 0.000431\n",
      "Epoch 77:\n",
      "Training loss: 1.2079, Training accuracy: 0.8369\n",
      "Validation loss: 0.5843, Validation accuracy: 0.7993\n",
      "Saving ...\n",
      "\n",
      "Current learning rate has decayed to 0.000414\n",
      "Epoch 78:\n",
      "Training loss: 1.2004, Training accuracy: 0.8390\n",
      "Validation loss: 0.5796, Validation accuracy: 0.7981\n",
      "\n",
      "Current learning rate has decayed to 0.000398\n",
      "Epoch 79:\n",
      "Training loss: 1.1863, Training accuracy: 0.8410\n",
      "Validation loss: 0.5807, Validation accuracy: 0.8015\n",
      "Saving ...\n",
      "\n",
      "Current learning rate has decayed to 0.000382\n",
      "Epoch 80:\n",
      "Training loss: 1.1833, Training accuracy: 0.8417\n",
      "Validation loss: 0.5844, Validation accuracy: 0.7989\n",
      "\n",
      "Current learning rate has decayed to 0.000366\n",
      "Epoch 81:\n",
      "Training loss: 1.1792, Training accuracy: 0.8434\n",
      "Validation loss: 0.5762, Validation accuracy: 0.7988\n",
      "\n",
      "Current learning rate has decayed to 0.000352\n",
      "Epoch 82:\n",
      "Training loss: 1.1780, Training accuracy: 0.8419\n",
      "Validation loss: 0.5738, Validation accuracy: 0.7994\n",
      "\n",
      "Current learning rate has decayed to 0.000338\n",
      "Epoch 83:\n",
      "Training loss: 1.1742, Training accuracy: 0.8429\n",
      "Validation loss: 0.5748, Validation accuracy: 0.7997\n",
      "\n",
      "Current learning rate has decayed to 0.000324\n",
      "Epoch 84:\n",
      "Training loss: 1.1683, Training accuracy: 0.8435\n",
      "Validation loss: 0.5697, Validation accuracy: 0.8031\n",
      "Saving ...\n",
      "\n",
      "Current learning rate has decayed to 0.000311\n",
      "Epoch 85:\n",
      "Training loss: 1.1604, Training accuracy: 0.8461\n",
      "Validation loss: 0.5964, Validation accuracy: 0.7996\n",
      "\n",
      "Current learning rate has decayed to 0.000299\n",
      "Epoch 86:\n",
      "Training loss: 1.1672, Training accuracy: 0.8432\n",
      "Validation loss: 0.5962, Validation accuracy: 0.8025\n",
      "\n",
      "Current learning rate has decayed to 0.000287\n",
      "Epoch 87:\n",
      "Training loss: 1.1596, Training accuracy: 0.8457\n",
      "Validation loss: 0.5861, Validation accuracy: 0.8021\n",
      "\n",
      "Current learning rate has decayed to 0.000275\n",
      "Epoch 88:\n",
      "Training loss: 1.1516, Training accuracy: 0.8466\n",
      "Validation loss: 0.5701, Validation accuracy: 0.8046\n",
      "Saving ...\n",
      "\n",
      "Current learning rate has decayed to 0.000264\n",
      "Epoch 89:\n",
      "Training loss: 1.1473, Training accuracy: 0.8470\n",
      "Validation loss: 0.5751, Validation accuracy: 0.8057\n",
      "Saving ...\n",
      "\n",
      "Current learning rate has decayed to 0.000254\n",
      "Epoch 90:\n",
      "Training loss: 1.1468, Training accuracy: 0.8497\n",
      "Validation loss: 0.5676, Validation accuracy: 0.8030\n",
      "\n",
      "Current learning rate has decayed to 0.000244\n",
      "Epoch 91:\n",
      "Training loss: 1.1496, Training accuracy: 0.8474\n",
      "Validation loss: 0.5699, Validation accuracy: 0.8046\n",
      "\n",
      "Current learning rate has decayed to 0.000234\n",
      "Epoch 92:\n",
      "Training loss: 1.1405, Training accuracy: 0.8478\n",
      "Validation loss: 0.5746, Validation accuracy: 0.8038\n",
      "\n",
      "Current learning rate has decayed to 0.000225\n",
      "Epoch 93:\n",
      "Training loss: 1.1373, Training accuracy: 0.8493\n",
      "Validation loss: 0.5719, Validation accuracy: 0.8069\n",
      "Saving ...\n",
      "\n",
      "Current learning rate has decayed to 0.000216\n",
      "Epoch 94:\n",
      "Training loss: 1.1337, Training accuracy: 0.8510\n",
      "Validation loss: 0.5749, Validation accuracy: 0.8048\n",
      "\n",
      "Current learning rate has decayed to 0.000207\n",
      "Epoch 95:\n",
      "Training loss: 1.1376, Training accuracy: 0.8504\n",
      "Validation loss: 0.5775, Validation accuracy: 0.8039\n",
      "\n",
      "Current learning rate has decayed to 0.000199\n",
      "Epoch 96:\n",
      "Training loss: 1.1340, Training accuracy: 0.8497\n",
      "Validation loss: 0.5720, Validation accuracy: 0.8032\n",
      "\n",
      "Current learning rate has decayed to 0.000191\n",
      "Epoch 97:\n",
      "Training loss: 1.1371, Training accuracy: 0.8489\n",
      "Validation loss: 0.5697, Validation accuracy: 0.8059\n",
      "\n",
      "Current learning rate has decayed to 0.000183\n",
      "Epoch 98:\n",
      "Training loss: 1.1290, Training accuracy: 0.8513\n",
      "Validation loss: 0.5787, Validation accuracy: 0.8052\n",
      "\n",
      "Current learning rate has decayed to 0.000176\n",
      "Epoch 99:\n",
      "Training loss: 1.1287, Training accuracy: 0.8517\n",
      "Validation loss: 0.5694, Validation accuracy: 0.8058\n",
      "\n",
      "Current learning rate has decayed to 0.000169\n",
      "Epoch 100:\n",
      "Training loss: 1.1272, Training accuracy: 0.8526\n",
      "Validation loss: 0.5709, Validation accuracy: 0.8052\n",
      "\n",
      "Current learning rate has decayed to 0.000162\n",
      "Epoch 101:\n",
      "Training loss: 1.1219, Training accuracy: 0.8531\n",
      "Validation loss: 0.5659, Validation accuracy: 0.8040\n",
      "\n",
      "Current learning rate has decayed to 0.000155\n",
      "Epoch 102:\n",
      "Training loss: 1.1120, Training accuracy: 0.8548\n",
      "Validation loss: 0.5645, Validation accuracy: 0.8075\n",
      "Saving ...\n",
      "\n",
      "Current learning rate has decayed to 0.000149\n",
      "Epoch 103:\n",
      "Training loss: 1.1097, Training accuracy: 0.8555\n",
      "Validation loss: 0.5685, Validation accuracy: 0.8059\n",
      "\n",
      "Current learning rate has decayed to 0.000143\n",
      "Epoch 104:\n",
      "Training loss: 1.1131, Training accuracy: 0.8553\n",
      "Validation loss: 0.5684, Validation accuracy: 0.8039\n",
      "\n",
      "Current learning rate has decayed to 0.000138\n",
      "Epoch 105:\n",
      "Training loss: 1.1155, Training accuracy: 0.8541\n",
      "Validation loss: 0.5667, Validation accuracy: 0.8054\n",
      "\n",
      "Current learning rate has decayed to 0.000132\n",
      "Epoch 106:\n",
      "Training loss: 1.1031, Training accuracy: 0.8564\n",
      "Validation loss: 0.5654, Validation accuracy: 0.8057\n",
      "\n",
      "Current learning rate has decayed to 0.000127\n",
      "Epoch 107:\n",
      "Training loss: 1.1060, Training accuracy: 0.8539\n",
      "Validation loss: 0.5836, Validation accuracy: 0.8004\n",
      "\n",
      "Current learning rate has decayed to 0.000122\n",
      "Epoch 108:\n",
      "Training loss: 1.1158, Training accuracy: 0.8541\n",
      "Validation loss: 0.5667, Validation accuracy: 0.8061\n",
      "\n",
      "Current learning rate has decayed to 0.000117\n",
      "Epoch 109:\n",
      "Training loss: 1.1155, Training accuracy: 0.8544\n",
      "Validation loss: 0.5669, Validation accuracy: 0.8041\n",
      "\n",
      "Current learning rate has decayed to 0.000112\n",
      "Epoch 110:\n",
      "Training loss: 1.1078, Training accuracy: 0.8544\n",
      "Validation loss: 0.5679, Validation accuracy: 0.8072\n",
      "\n",
      "Current learning rate has decayed to 0.000108\n",
      "Epoch 111:\n",
      "Training loss: 1.1060, Training accuracy: 0.8552\n",
      "Validation loss: 0.5670, Validation accuracy: 0.8056\n",
      "\n",
      "Current learning rate has decayed to 0.000103\n",
      "Epoch 112:\n",
      "Training loss: 1.1093, Training accuracy: 0.8543\n",
      "Validation loss: 0.5689, Validation accuracy: 0.8069\n",
      "\n",
      "Current learning rate has decayed to 0.000099\n",
      "Epoch 113:\n",
      "Training loss: 1.1076, Training accuracy: 0.8551\n",
      "Validation loss: 0.5688, Validation accuracy: 0.8082\n",
      "Saving ...\n",
      "\n",
      "Current learning rate has decayed to 0.000095\n",
      "Epoch 114:\n",
      "Training loss: 1.1254, Training accuracy: 0.8514\n",
      "Validation loss: 0.5832, Validation accuracy: 0.8002\n",
      "\n",
      "Current learning rate has decayed to 0.000091\n",
      "Epoch 115:\n",
      "Training loss: 1.1151, Training accuracy: 0.8534\n",
      "Validation loss: 0.5807, Validation accuracy: 0.8038\n",
      "\n",
      "Current learning rate has decayed to 0.000088\n",
      "Epoch 116:\n",
      "Training loss: 1.1019, Training accuracy: 0.8554\n",
      "Validation loss: 0.5673, Validation accuracy: 0.8045\n",
      "\n",
      "Current learning rate has decayed to 0.000084\n",
      "Epoch 117:\n",
      "Training loss: 1.1014, Training accuracy: 0.8576\n",
      "Validation loss: 0.5670, Validation accuracy: 0.8065\n",
      "\n",
      "Current learning rate has decayed to 0.000081\n",
      "Epoch 118:\n",
      "Training loss: 1.0965, Training accuracy: 0.8574\n",
      "Validation loss: 0.5654, Validation accuracy: 0.8062\n",
      "\n",
      "Current learning rate has decayed to 0.000078\n",
      "Epoch 119:\n",
      "Training loss: 1.0898, Training accuracy: 0.8591\n",
      "Validation loss: 0.5641, Validation accuracy: 0.8052\n",
      "\n",
      "Current learning rate has decayed to 0.000075\n",
      "Epoch 120:\n",
      "Training loss: 1.0889, Training accuracy: 0.8598\n",
      "Validation loss: 0.5819, Validation accuracy: 0.8060\n",
      "\n",
      "Current learning rate has decayed to 0.000072\n",
      "Epoch 121:\n",
      "Training loss: 1.0915, Training accuracy: 0.8578\n",
      "Validation loss: 0.5768, Validation accuracy: 0.8042\n",
      "\n",
      "Current learning rate has decayed to 0.000069\n",
      "Epoch 122:\n",
      "Training loss: 1.0944, Training accuracy: 0.8575\n",
      "Validation loss: 0.5652, Validation accuracy: 0.8056\n",
      "\n",
      "Current learning rate has decayed to 0.000066\n",
      "Epoch 123:\n",
      "Training loss: 1.0947, Training accuracy: 0.8573\n",
      "Validation loss: 0.5672, Validation accuracy: 0.8061\n",
      "\n",
      "Current learning rate has decayed to 0.000063\n",
      "Epoch 124:\n",
      "Training loss: 1.0932, Training accuracy: 0.8584\n",
      "Validation loss: 0.5782, Validation accuracy: 0.8059\n",
      "\n",
      "Current learning rate has decayed to 0.000061\n",
      "Epoch 125:\n",
      "Training loss: 1.0887, Training accuracy: 0.8583\n",
      "Validation loss: 0.5703, Validation accuracy: 0.8071\n",
      "\n",
      "Current learning rate has decayed to 0.000058\n",
      "Epoch 126:\n",
      "Training loss: 1.0915, Training accuracy: 0.8579\n",
      "Validation loss: 0.5640, Validation accuracy: 0.8078\n",
      "\n",
      "Current learning rate has decayed to 0.000056\n",
      "Epoch 127:\n",
      "Training loss: 1.0843, Training accuracy: 0.8580\n",
      "Validation loss: 0.5783, Validation accuracy: 0.8079\n",
      "\n",
      "Current learning rate has decayed to 0.000054\n",
      "Epoch 128:\n",
      "Training loss: 1.0899, Training accuracy: 0.8587\n",
      "Validation loss: 0.5626, Validation accuracy: 0.8076\n",
      "\n",
      "Current learning rate has decayed to 0.000052\n",
      "Epoch 129:\n",
      "Training loss: 1.0847, Training accuracy: 0.8590\n",
      "Validation loss: 0.5627, Validation accuracy: 0.8072\n",
      "\n",
      "Current learning rate has decayed to 0.000050\n",
      "Epoch 130:\n",
      "Training loss: 1.0850, Training accuracy: 0.8594\n",
      "Validation loss: 0.5737, Validation accuracy: 0.8081\n",
      "\n",
      "Current learning rate has decayed to 0.000048\n",
      "Epoch 131:\n",
      "Training loss: 1.0802, Training accuracy: 0.8599\n",
      "Validation loss: 0.5769, Validation accuracy: 0.8067\n",
      "\n",
      "Current learning rate has decayed to 0.000046\n",
      "Epoch 132:\n",
      "Training loss: 1.0841, Training accuracy: 0.8583\n",
      "Validation loss: 0.5624, Validation accuracy: 0.8069\n",
      "\n",
      "Current learning rate has decayed to 0.000044\n",
      "Epoch 133:\n",
      "Training loss: 1.0838, Training accuracy: 0.8602\n",
      "Validation loss: 0.5727, Validation accuracy: 0.8070\n",
      "\n",
      "Current learning rate has decayed to 0.000042\n",
      "Epoch 134:\n",
      "Training loss: 1.0801, Training accuracy: 0.8599\n",
      "Validation loss: 0.5677, Validation accuracy: 0.8075\n",
      "\n",
      "Current learning rate has decayed to 0.000040\n",
      "Epoch 135:\n",
      "Training loss: 1.0796, Training accuracy: 0.8600\n",
      "Validation loss: 0.5625, Validation accuracy: 0.8070\n",
      "\n",
      "Current learning rate has decayed to 0.000039\n",
      "Epoch 136:\n",
      "Training loss: 1.0846, Training accuracy: 0.8595\n",
      "Validation loss: 0.5665, Validation accuracy: 0.8065\n",
      "\n",
      "Current learning rate has decayed to 0.000037\n",
      "Epoch 137:\n",
      "Training loss: 1.0748, Training accuracy: 0.8632\n",
      "Validation loss: 0.5631, Validation accuracy: 0.8067\n",
      "\n",
      "Current learning rate has decayed to 0.000036\n",
      "Epoch 138:\n",
      "Training loss: 1.0784, Training accuracy: 0.8602\n",
      "Validation loss: 0.5656, Validation accuracy: 0.8064\n",
      "\n",
      "Current learning rate has decayed to 0.000034\n",
      "Epoch 139:\n",
      "Training loss: 1.0782, Training accuracy: 0.8609\n",
      "Validation loss: 0.5637, Validation accuracy: 0.8081\n",
      "\n",
      "Current learning rate has decayed to 0.000033\n",
      "Epoch 140:\n",
      "Training loss: 1.0733, Training accuracy: 0.8602\n",
      "Validation loss: 0.5704, Validation accuracy: 0.8063\n",
      "\n",
      "Current learning rate has decayed to 0.000032\n",
      "Epoch 141:\n",
      "Training loss: 1.0753, Training accuracy: 0.8621\n",
      "Validation loss: 0.5678, Validation accuracy: 0.8081\n",
      "\n",
      "Current learning rate has decayed to 0.000030\n",
      "Epoch 142:\n",
      "Training loss: 1.0750, Training accuracy: 0.8610\n",
      "Validation loss: 0.5779, Validation accuracy: 0.8078\n",
      "\n",
      "Current learning rate has decayed to 0.000029\n",
      "Epoch 143:\n",
      "Training loss: 1.0794, Training accuracy: 0.8609\n",
      "Validation loss: 0.5635, Validation accuracy: 0.8084\n",
      "Saving ...\n",
      "\n",
      "Current learning rate has decayed to 0.000028\n",
      "Epoch 144:\n",
      "Training loss: 1.0680, Training accuracy: 0.8639\n",
      "Validation loss: 0.5621, Validation accuracy: 0.8080\n",
      "\n",
      "Current learning rate has decayed to 0.000027\n",
      "Epoch 145:\n",
      "Training loss: 1.0707, Training accuracy: 0.8620\n",
      "Validation loss: 0.5629, Validation accuracy: 0.8069\n",
      "\n",
      "Current learning rate has decayed to 0.000026\n",
      "Epoch 146:\n",
      "Training loss: 1.0690, Training accuracy: 0.8614\n",
      "Validation loss: 0.6025, Validation accuracy: 0.8063\n",
      "\n",
      "Current learning rate has decayed to 0.000025\n",
      "Epoch 147:\n",
      "Training loss: 1.0731, Training accuracy: 0.8610\n",
      "Validation loss: 0.5649, Validation accuracy: 0.8076\n",
      "\n",
      "Current learning rate has decayed to 0.000024\n",
      "Epoch 148:\n",
      "Training loss: 1.0705, Training accuracy: 0.8627\n",
      "Validation loss: 0.5618, Validation accuracy: 0.8089\n",
      "Saving ...\n",
      "\n",
      "Current learning rate has decayed to 0.000023\n",
      "Epoch 149:\n",
      "Training loss: 1.0763, Training accuracy: 0.8603\n",
      "Validation loss: 0.5738, Validation accuracy: 0.8085\n",
      "\n",
      "Current learning rate has decayed to 0.000022\n",
      "Epoch 150:\n",
      "Training loss: 1.0747, Training accuracy: 0.8621\n",
      "Validation loss: 0.5717, Validation accuracy: 0.8071\n",
      "\n",
      "Current learning rate has decayed to 0.000021\n",
      "Epoch 151:\n",
      "Training loss: 1.0787, Training accuracy: 0.8611\n",
      "Validation loss: 0.5612, Validation accuracy: 0.8093\n",
      "Saving ...\n",
      "\n",
      "Current learning rate has decayed to 0.000020\n",
      "Epoch 152:\n",
      "Training loss: 1.0733, Training accuracy: 0.8603\n",
      "Validation loss: 0.5638, Validation accuracy: 0.8072\n",
      "\n",
      "Current learning rate has decayed to 0.000019\n",
      "Epoch 153:\n",
      "Training loss: 1.0735, Training accuracy: 0.8620\n",
      "Validation loss: 0.5839, Validation accuracy: 0.8075\n",
      "\n",
      "Current learning rate has decayed to 0.000019\n",
      "Epoch 154:\n",
      "Training loss: 1.0675, Training accuracy: 0.8617\n",
      "Validation loss: 0.5701, Validation accuracy: 0.8076\n",
      "\n",
      "Current learning rate has decayed to 0.000018\n",
      "Epoch 155:\n",
      "Training loss: 1.0723, Training accuracy: 0.8623\n",
      "Validation loss: 0.5756, Validation accuracy: 0.8082\n",
      "\n",
      "Current learning rate has decayed to 0.000017\n",
      "Epoch 156:\n",
      "Training loss: 1.0719, Training accuracy: 0.8608\n",
      "Validation loss: 0.5631, Validation accuracy: 0.8069\n",
      "\n",
      "Current learning rate has decayed to 0.000016\n",
      "Epoch 157:\n",
      "Training loss: 1.0746, Training accuracy: 0.8613\n",
      "Validation loss: 0.5674, Validation accuracy: 0.8085\n",
      "\n",
      "Current learning rate has decayed to 0.000016\n",
      "Epoch 158:\n",
      "Training loss: 1.0767, Training accuracy: 0.8606\n",
      "Validation loss: 0.5736, Validation accuracy: 0.8078\n",
      "\n",
      "Current learning rate has decayed to 0.000015\n",
      "Epoch 159:\n",
      "Training loss: 1.0660, Training accuracy: 0.8621\n",
      "Validation loss: 0.5685, Validation accuracy: 0.8066\n",
      "\n",
      "Current learning rate has decayed to 0.000015\n",
      "Epoch 160:\n",
      "Training loss: 1.0735, Training accuracy: 0.8626\n",
      "Validation loss: 0.5934, Validation accuracy: 0.8097\n",
      "Saving ...\n",
      "\n",
      "Current learning rate has decayed to 0.000014\n",
      "Epoch 161:\n",
      "Training loss: 1.0728, Training accuracy: 0.8605\n",
      "Validation loss: 0.5638, Validation accuracy: 0.8074\n",
      "\n",
      "Current learning rate has decayed to 0.000013\n",
      "Epoch 162:\n",
      "Training loss: 1.0740, Training accuracy: 0.8603\n",
      "Validation loss: 0.5674, Validation accuracy: 0.8070\n",
      "\n",
      "Current learning rate has decayed to 0.000013\n",
      "Epoch 163:\n",
      "Training loss: 1.0662, Training accuracy: 0.8614\n",
      "Validation loss: 0.5685, Validation accuracy: 0.8082\n",
      "\n",
      "Current learning rate has decayed to 0.000012\n",
      "Epoch 164:\n",
      "Training loss: 1.0681, Training accuracy: 0.8635\n",
      "Validation loss: 0.5712, Validation accuracy: 0.8079\n",
      "\n",
      "Current learning rate has decayed to 0.000012\n",
      "Epoch 165:\n",
      "Training loss: 1.0730, Training accuracy: 0.8600\n",
      "Validation loss: 0.5765, Validation accuracy: 0.8065\n",
      "\n",
      "Current learning rate has decayed to 0.000011\n",
      "Epoch 166:\n",
      "Training loss: 1.0604, Training accuracy: 0.8641\n",
      "Validation loss: 0.5609, Validation accuracy: 0.8086\n",
      "\n",
      "Current learning rate has decayed to 0.000011\n",
      "Epoch 167:\n",
      "Training loss: 1.0688, Training accuracy: 0.8623\n",
      "Validation loss: 0.5604, Validation accuracy: 0.8083\n",
      "\n",
      "Current learning rate has decayed to 0.000011\n",
      "Epoch 168:\n",
      "Training loss: 1.0644, Training accuracy: 0.8615\n",
      "Validation loss: 0.5622, Validation accuracy: 0.8073\n",
      "\n",
      "Current learning rate has decayed to 0.000010\n",
      "Epoch 169:\n",
      "Training loss: 1.0710, Training accuracy: 0.8633\n",
      "Validation loss: 0.5635, Validation accuracy: 0.8086\n",
      "\n",
      "Current learning rate has decayed to 0.000010\n",
      "Epoch 170:\n",
      "Training loss: 1.0725, Training accuracy: 0.8624\n",
      "Validation loss: 0.5622, Validation accuracy: 0.8056\n",
      "\n",
      "Current learning rate has decayed to 0.000009\n",
      "Epoch 171:\n",
      "Training loss: 1.0706, Training accuracy: 0.8611\n",
      "Validation loss: 0.5623, Validation accuracy: 0.8092\n",
      "\n",
      "Current learning rate has decayed to 0.000009\n",
      "Epoch 172:\n",
      "Training loss: 1.0695, Training accuracy: 0.8633\n",
      "Validation loss: 0.5952, Validation accuracy: 0.8067\n",
      "\n",
      "Current learning rate has decayed to 0.000009\n",
      "Epoch 173:\n",
      "Training loss: 1.0702, Training accuracy: 0.8607\n",
      "Validation loss: 0.5605, Validation accuracy: 0.8084\n",
      "\n",
      "Current learning rate has decayed to 0.000008\n",
      "Epoch 174:\n",
      "Training loss: 1.0656, Training accuracy: 0.8622\n",
      "Validation loss: 0.5968, Validation accuracy: 0.8086\n",
      "\n",
      "Current learning rate has decayed to 0.000008\n",
      "Epoch 175:\n",
      "Training loss: 1.0657, Training accuracy: 0.8640\n",
      "Validation loss: 0.5724, Validation accuracy: 0.8069\n",
      "\n",
      "Current learning rate has decayed to 0.000008\n",
      "Epoch 176:\n",
      "Training loss: 1.0657, Training accuracy: 0.8618\n",
      "Validation loss: 0.6209, Validation accuracy: 0.8076\n",
      "\n",
      "Current learning rate has decayed to 0.000007\n",
      "Epoch 177:\n",
      "Training loss: 1.0656, Training accuracy: 0.8625\n",
      "Validation loss: 0.5764, Validation accuracy: 0.8079\n",
      "\n",
      "Current learning rate has decayed to 0.000007\n",
      "Epoch 178:\n",
      "Training loss: 1.0646, Training accuracy: 0.8630\n",
      "Validation loss: 0.5604, Validation accuracy: 0.8080\n",
      "\n",
      "Current learning rate has decayed to 0.000007\n",
      "Epoch 179:\n",
      "Training loss: 1.0680, Training accuracy: 0.8618\n",
      "Validation loss: 0.5693, Validation accuracy: 0.8085\n",
      "\n",
      "Current learning rate has decayed to 0.000006\n",
      "Epoch 180:\n",
      "Training loss: 1.0668, Training accuracy: 0.8629\n",
      "Validation loss: 0.5611, Validation accuracy: 0.8082\n",
      "\n",
      "Current learning rate has decayed to 0.000006\n",
      "Epoch 181:\n",
      "Training loss: 1.0654, Training accuracy: 0.8624\n",
      "Validation loss: 0.5620, Validation accuracy: 0.8076\n",
      "\n",
      "Current learning rate has decayed to 0.000006\n",
      "Epoch 182:\n",
      "Training loss: 1.0679, Training accuracy: 0.8613\n",
      "Validation loss: 0.5780, Validation accuracy: 0.8085\n",
      "\n",
      "Current learning rate has decayed to 0.000006\n",
      "Epoch 183:\n",
      "Training loss: 1.0691, Training accuracy: 0.8634\n",
      "Validation loss: 0.5608, Validation accuracy: 0.8070\n",
      "\n",
      "Current learning rate has decayed to 0.000005\n",
      "Epoch 184:\n",
      "Training loss: 1.0654, Training accuracy: 0.8626\n",
      "Validation loss: 0.5622, Validation accuracy: 0.8091\n",
      "\n",
      "Current learning rate has decayed to 0.000005\n",
      "Epoch 185:\n",
      "Training loss: 1.0692, Training accuracy: 0.8631\n",
      "Validation loss: 0.5612, Validation accuracy: 0.8083\n",
      "\n",
      "Current learning rate has decayed to 0.000005\n",
      "Epoch 186:\n",
      "Training loss: 1.0616, Training accuracy: 0.8643\n",
      "Validation loss: 0.5610, Validation accuracy: 0.8077\n",
      "\n",
      "Current learning rate has decayed to 0.000005\n",
      "Epoch 187:\n",
      "Training loss: 1.0674, Training accuracy: 0.8618\n",
      "Validation loss: 0.5752, Validation accuracy: 0.8082\n",
      "\n",
      "Current learning rate has decayed to 0.000005\n",
      "Epoch 188:\n",
      "Training loss: 1.0636, Training accuracy: 0.8638\n",
      "Validation loss: 0.6079, Validation accuracy: 0.8086\n",
      "\n",
      "Current learning rate has decayed to 0.000004\n",
      "Epoch 189:\n",
      "Training loss: 1.0676, Training accuracy: 0.8616\n",
      "Validation loss: 0.5657, Validation accuracy: 0.8063\n",
      "\n",
      "Current learning rate has decayed to 0.000004\n",
      "Epoch 190:\n",
      "Training loss: 1.0743, Training accuracy: 0.8613\n",
      "Validation loss: 0.5673, Validation accuracy: 0.8077\n",
      "\n",
      "Current learning rate has decayed to 0.000004\n",
      "Epoch 191:\n",
      "Training loss: 1.0657, Training accuracy: 0.8635\n",
      "Validation loss: 0.5744, Validation accuracy: 0.8092\n",
      "\n",
      "Current learning rate has decayed to 0.000004\n",
      "Epoch 192:\n",
      "Training loss: 1.0648, Training accuracy: 0.8637\n",
      "Validation loss: 0.5632, Validation accuracy: 0.8067\n",
      "\n",
      "Current learning rate has decayed to 0.000004\n",
      "Epoch 193:\n",
      "Training loss: 1.0661, Training accuracy: 0.8631\n",
      "Validation loss: 0.5628, Validation accuracy: 0.8079\n",
      "\n",
      "Current learning rate has decayed to 0.000004\n",
      "Epoch 194:\n",
      "Training loss: 1.0598, Training accuracy: 0.8642\n",
      "Validation loss: 0.5862, Validation accuracy: 0.8091\n",
      "\n",
      "Current learning rate has decayed to 0.000003\n",
      "Epoch 195:\n",
      "Training loss: 1.0687, Training accuracy: 0.8632\n",
      "Validation loss: 0.5604, Validation accuracy: 0.8084\n",
      "\n",
      "Current learning rate has decayed to 0.000003\n",
      "Epoch 196:\n",
      "Training loss: 1.0647, Training accuracy: 0.8616\n",
      "Validation loss: 0.5809, Validation accuracy: 0.8072\n",
      "\n",
      "Current learning rate has decayed to 0.000003\n",
      "Epoch 197:\n",
      "Training loss: 1.0685, Training accuracy: 0.8636\n",
      "Validation loss: 0.5599, Validation accuracy: 0.8086\n",
      "\n",
      "Current learning rate has decayed to 0.000003\n",
      "Epoch 198:\n",
      "Training loss: 1.0661, Training accuracy: 0.8619\n",
      "Validation loss: 0.5635, Validation accuracy: 0.8090\n",
      "\n",
      "Current learning rate has decayed to 0.000003\n",
      "Epoch 199:\n",
      "Training loss: 1.0708, Training accuracy: 0.8615\n",
      "Validation loss: 0.5929, Validation accuracy: 0.8078\n",
      "\n",
      "==================================================\n",
      "==> Optimization finished! Best validation accuracy: 0.8097\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8097"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train(T=4,lamb=0.1,alpha=0.6,train_loader=train_loader,val_loader=val_loader,INITIAL_LR=0.01,DECAY_EPOCHS=1,DECAY=0.96,EPOCHS=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Training starts!\n",
      "==================================================\n",
      "Epoch 0:\n",
      "Training loss: 6.6577, Training accuracy: 0.2007\n",
      "Validation loss: 1.9295, Validation accuracy: 0.3176\n",
      "Saving ...\n",
      "\n",
      "Epoch 1:\n",
      "Training loss: 4.3437, Training accuracy: 0.3484\n",
      "Validation loss: 5.0593, Validation accuracy: 0.3881\n",
      "Saving ...\n",
      "\n",
      "Epoch 2:\n",
      "Training loss: 3.8511, Training accuracy: 0.4049\n",
      "Validation loss: 1.8465, Validation accuracy: 0.4371\n",
      "Saving ...\n",
      "\n",
      "Epoch 3:\n",
      "Training loss: 3.5779, Training accuracy: 0.4458\n",
      "Validation loss: 1.7672, Validation accuracy: 0.4559\n",
      "Saving ...\n",
      "\n",
      "Epoch 4:\n",
      "Training loss: 3.3376, Training accuracy: 0.4814\n",
      "Validation loss: 1.8684, Validation accuracy: 0.5180\n",
      "Saving ...\n",
      "\n",
      "Epoch 5:\n",
      "Training loss: 3.0764, Training accuracy: 0.5225\n",
      "Validation loss: 4.6228, Validation accuracy: 0.5256\n",
      "Saving ...\n",
      "\n",
      "Epoch 6:\n",
      "Training loss: 2.8768, Training accuracy: 0.5546\n",
      "Validation loss: 2.4551, Validation accuracy: 0.5908\n",
      "Saving ...\n",
      "\n",
      "Epoch 7:\n",
      "Training loss: 2.6774, Training accuracy: 0.5887\n",
      "Validation loss: 1.6507, Validation accuracy: 0.6262\n",
      "Saving ...\n",
      "\n",
      "Epoch 8:\n",
      "Training loss: 2.4598, Training accuracy: 0.6203\n",
      "Validation loss: 1.9241, Validation accuracy: 0.6451\n",
      "Saving ...\n",
      "\n",
      "Epoch 9:\n",
      "Training loss: 2.2915, Training accuracy: 0.6487\n",
      "Validation loss: 2.9970, Validation accuracy: 0.6519\n",
      "Saving ...\n",
      "\n",
      "Epoch 10:\n",
      "Training loss: 2.1725, Training accuracy: 0.6693\n",
      "Validation loss: 3.7450, Validation accuracy: 0.6814\n",
      "Saving ...\n",
      "\n",
      "Epoch 11:\n",
      "Training loss: 2.0521, Training accuracy: 0.6854\n",
      "Validation loss: 2.4628, Validation accuracy: 0.6799\n",
      "\n",
      "Epoch 12:\n",
      "Training loss: 1.9486, Training accuracy: 0.7046\n",
      "Validation loss: 1.7253, Validation accuracy: 0.6669\n",
      "\n",
      "Epoch 13:\n",
      "Training loss: 1.8819, Training accuracy: 0.7155\n",
      "Validation loss: 1.4886, Validation accuracy: 0.7063\n",
      "Saving ...\n",
      "\n",
      "Epoch 14:\n",
      "Training loss: 1.7944, Training accuracy: 0.7293\n",
      "Validation loss: 1.1872, Validation accuracy: 0.7207\n",
      "Saving ...\n",
      "\n",
      "Epoch 15:\n",
      "Training loss: 1.7244, Training accuracy: 0.7413\n",
      "Validation loss: 1.0487, Validation accuracy: 0.7317\n",
      "Saving ...\n",
      "\n",
      "Epoch 16:\n",
      "Training loss: 1.6709, Training accuracy: 0.7491\n",
      "Validation loss: 1.1867, Validation accuracy: 0.7430\n",
      "Saving ...\n",
      "\n",
      "Epoch 17:\n",
      "Training loss: 1.6039, Training accuracy: 0.7605\n",
      "Validation loss: 2.1349, Validation accuracy: 0.7264\n",
      "\n",
      "Epoch 18:\n",
      "Training loss: 1.5725, Training accuracy: 0.7657\n",
      "Validation loss: 1.2072, Validation accuracy: 0.7374\n",
      "\n",
      "Epoch 19:\n",
      "Training loss: 1.5240, Training accuracy: 0.7742\n",
      "Validation loss: 2.7792, Validation accuracy: 0.7515\n",
      "Saving ...\n",
      "\n",
      "Epoch 20:\n",
      "Training loss: 1.4858, Training accuracy: 0.7805\n",
      "Validation loss: 1.3111, Validation accuracy: 0.7660\n",
      "Saving ...\n",
      "\n",
      "Epoch 21:\n",
      "Training loss: 1.4764, Training accuracy: 0.7805\n",
      "Validation loss: 1.4689, Validation accuracy: 0.7595\n",
      "\n",
      "Epoch 22:\n",
      "Training loss: 1.3974, Training accuracy: 0.7946\n",
      "Validation loss: 3.2354, Validation accuracy: 0.7732\n",
      "Saving ...\n",
      "\n",
      "Epoch 23:\n",
      "Training loss: 1.3541, Training accuracy: 0.8023\n",
      "Validation loss: 1.0432, Validation accuracy: 0.7800\n",
      "Saving ...\n",
      "\n",
      "Epoch 24:\n",
      "Training loss: 1.3209, Training accuracy: 0.8043\n",
      "Validation loss: 1.0493, Validation accuracy: 0.7851\n",
      "Saving ...\n",
      "\n",
      "Epoch 25:\n",
      "Training loss: 1.2906, Training accuracy: 0.8099\n",
      "Validation loss: 0.9890, Validation accuracy: 0.7906\n",
      "Saving ...\n",
      "\n",
      "Epoch 26:\n",
      "Training loss: 1.2650, Training accuracy: 0.8168\n",
      "Validation loss: 0.9996, Validation accuracy: 0.7984\n",
      "Saving ...\n",
      "\n",
      "Epoch 27:\n",
      "Training loss: 1.2383, Training accuracy: 0.8173\n",
      "Validation loss: 0.9644, Validation accuracy: 0.7897\n",
      "\n",
      "Epoch 28:\n",
      "Training loss: 1.2093, Training accuracy: 0.8250\n",
      "Validation loss: 0.6116, Validation accuracy: 0.8019\n",
      "Saving ...\n",
      "\n",
      "Epoch 29:\n",
      "Training loss: 1.1848, Training accuracy: 0.8281\n",
      "Validation loss: 0.7652, Validation accuracy: 0.8031\n",
      "Saving ...\n",
      "\n",
      "Epoch 30:\n",
      "Training loss: 1.1571, Training accuracy: 0.8326\n",
      "Validation loss: 0.6804, Validation accuracy: 0.8041\n",
      "Saving ...\n",
      "\n",
      "Epoch 31:\n",
      "Training loss: 1.1343, Training accuracy: 0.8358\n",
      "Validation loss: 0.6238, Validation accuracy: 0.7926\n",
      "\n",
      "Epoch 32:\n",
      "Training loss: 1.1274, Training accuracy: 0.8368\n",
      "Validation loss: 0.6286, Validation accuracy: 0.7951\n",
      "\n",
      "Epoch 33:\n",
      "Training loss: 1.0947, Training accuracy: 0.8405\n",
      "Validation loss: 0.7195, Validation accuracy: 0.8073\n",
      "Saving ...\n",
      "\n",
      "Epoch 34:\n",
      "Training loss: 1.0841, Training accuracy: 0.8423\n",
      "Validation loss: 0.6104, Validation accuracy: 0.8114\n",
      "Saving ...\n",
      "\n",
      "Epoch 35:\n",
      "Training loss: 1.0514, Training accuracy: 0.8488\n",
      "Validation loss: 0.8521, Validation accuracy: 0.8095\n",
      "\n",
      "Epoch 36:\n",
      "Training loss: 1.0365, Training accuracy: 0.8524\n",
      "Validation loss: 0.5622, Validation accuracy: 0.8130\n",
      "Saving ...\n",
      "\n",
      "Epoch 37:\n",
      "Training loss: 1.0373, Training accuracy: 0.8516\n",
      "Validation loss: 0.5524, Validation accuracy: 0.8143\n",
      "Saving ...\n",
      "\n",
      "Epoch 38:\n",
      "Training loss: 1.0136, Training accuracy: 0.8544\n",
      "Validation loss: 0.5398, Validation accuracy: 0.8156\n",
      "Saving ...\n",
      "\n",
      "Epoch 39:\n",
      "Training loss: 0.9817, Training accuracy: 0.8601\n",
      "Validation loss: 0.5393, Validation accuracy: 0.8146\n",
      "\n",
      "Epoch 40:\n",
      "Training loss: 1.0138, Training accuracy: 0.8550\n",
      "Validation loss: 0.5627, Validation accuracy: 0.8181\n",
      "Saving ...\n",
      "\n",
      "Epoch 41:\n",
      "Training loss: 0.9616, Training accuracy: 0.8617\n",
      "Validation loss: 0.6455, Validation accuracy: 0.8154\n",
      "\n",
      "Epoch 42:\n",
      "Training loss: 0.9543, Training accuracy: 0.8637\n",
      "Validation loss: 0.5443, Validation accuracy: 0.8251\n",
      "Saving ...\n",
      "\n",
      "Epoch 43:\n",
      "Training loss: 0.9388, Training accuracy: 0.8665\n",
      "Validation loss: 0.5245, Validation accuracy: 0.8236\n",
      "\n",
      "Epoch 44:\n",
      "Training loss: 0.9272, Training accuracy: 0.8702\n",
      "Validation loss: 0.6567, Validation accuracy: 0.8143\n",
      "\n",
      "Epoch 45:\n",
      "Training loss: 0.9185, Training accuracy: 0.8700\n",
      "Validation loss: 0.7010, Validation accuracy: 0.8268\n",
      "Saving ...\n",
      "\n",
      "Epoch 46:\n",
      "Training loss: 0.8908, Training accuracy: 0.8753\n",
      "Validation loss: 0.5385, Validation accuracy: 0.8228\n",
      "\n",
      "Epoch 47:\n",
      "Training loss: 0.8960, Training accuracy: 0.8719\n",
      "Validation loss: 0.6617, Validation accuracy: 0.8020\n",
      "\n",
      "Epoch 48:\n",
      "Training loss: 0.9036, Training accuracy: 0.8739\n",
      "Validation loss: 1.9856, Validation accuracy: 0.8216\n",
      "\n",
      "Epoch 49:\n",
      "Training loss: 0.8630, Training accuracy: 0.8784\n",
      "Validation loss: 0.6339, Validation accuracy: 0.8279\n",
      "Saving ...\n",
      "\n",
      "Epoch 50:\n",
      "Training loss: 0.8613, Training accuracy: 0.8793\n",
      "Validation loss: 0.5221, Validation accuracy: 0.8325\n",
      "Saving ...\n",
      "\n",
      "Epoch 51:\n",
      "Training loss: 0.8584, Training accuracy: 0.8792\n",
      "Validation loss: 0.5638, Validation accuracy: 0.8378\n",
      "Saving ...\n",
      "\n",
      "Epoch 52:\n",
      "Training loss: 0.8313, Training accuracy: 0.8841\n",
      "Validation loss: 0.5244, Validation accuracy: 0.8298\n",
      "\n",
      "Epoch 53:\n",
      "Training loss: 0.8335, Training accuracy: 0.8833\n",
      "Validation loss: 0.5345, Validation accuracy: 0.8371\n",
      "\n",
      "Epoch 54:\n",
      "Training loss: 0.8075, Training accuracy: 0.8870\n",
      "Validation loss: 0.4734, Validation accuracy: 0.8420\n",
      "Saving ...\n",
      "\n",
      "Epoch 55:\n",
      "Training loss: 0.8014, Training accuracy: 0.8889\n",
      "Validation loss: 0.7192, Validation accuracy: 0.8237\n",
      "\n",
      "Epoch 56:\n",
      "Training loss: 0.8110, Training accuracy: 0.8850\n",
      "Validation loss: 0.5943, Validation accuracy: 0.8248\n",
      "\n",
      "Epoch 57:\n",
      "Training loss: 0.8030, Training accuracy: 0.8875\n",
      "Validation loss: 0.5244, Validation accuracy: 0.8327\n",
      "\n",
      "Epoch 58:\n",
      "Training loss: 0.7743, Training accuracy: 0.8923\n",
      "Validation loss: 0.4935, Validation accuracy: 0.8378\n",
      "\n",
      "Epoch 59:\n",
      "Training loss: 0.7601, Training accuracy: 0.8954\n",
      "Validation loss: 0.4880, Validation accuracy: 0.8433\n",
      "Saving ...\n",
      "\n",
      "Current learning rate has decayed to 0.001000\n",
      "Epoch 60:\n",
      "Training loss: 0.5848, Training accuracy: 0.9218\n",
      "Validation loss: 0.4021, Validation accuracy: 0.8661\n",
      "Saving ...\n",
      "\n",
      "Epoch 61:\n",
      "Training loss: 0.5138, Training accuracy: 0.9331\n",
      "Validation loss: 0.3936, Validation accuracy: 0.8702\n",
      "Saving ...\n",
      "\n",
      "Epoch 62:\n",
      "Training loss: 0.4930, Training accuracy: 0.9371\n",
      "Validation loss: 0.3920, Validation accuracy: 0.8721\n",
      "Saving ...\n",
      "\n",
      "Epoch 63:\n",
      "Training loss: 0.4793, Training accuracy: 0.9385\n",
      "Validation loss: 0.3906, Validation accuracy: 0.8721\n",
      "\n",
      "Epoch 64:\n",
      "Training loss: 0.4627, Training accuracy: 0.9427\n",
      "Validation loss: 0.3961, Validation accuracy: 0.8709\n",
      "\n",
      "Epoch 65:\n",
      "Training loss: 0.4476, Training accuracy: 0.9450\n",
      "Validation loss: 0.3909, Validation accuracy: 0.8730\n",
      "Saving ...\n",
      "\n",
      "Epoch 66:\n",
      "Training loss: 0.4411, Training accuracy: 0.9461\n",
      "Validation loss: 0.3992, Validation accuracy: 0.8727\n",
      "\n",
      "Epoch 67:\n",
      "Training loss: 0.4362, Training accuracy: 0.9457\n",
      "Validation loss: 0.3985, Validation accuracy: 0.8721\n",
      "\n",
      "Epoch 68:\n",
      "Training loss: 0.4234, Training accuracy: 0.9494\n",
      "Validation loss: 0.4020, Validation accuracy: 0.8711\n",
      "\n",
      "Epoch 69:\n",
      "Training loss: 0.4123, Training accuracy: 0.9498\n",
      "Validation loss: 0.4031, Validation accuracy: 0.8724\n",
      "\n",
      "Epoch 70:\n",
      "Training loss: 0.4124, Training accuracy: 0.9508\n",
      "Validation loss: 0.4044, Validation accuracy: 0.8714\n",
      "\n",
      "Epoch 71:\n",
      "Training loss: 0.4035, Training accuracy: 0.9526\n",
      "Validation loss: 0.4047, Validation accuracy: 0.8732\n",
      "Saving ...\n",
      "\n",
      "Epoch 72:\n",
      "Training loss: 0.4004, Training accuracy: 0.9520\n",
      "Validation loss: 0.4052, Validation accuracy: 0.8733\n",
      "Saving ...\n",
      "\n",
      "Epoch 73:\n",
      "Training loss: 0.3914, Training accuracy: 0.9539\n",
      "Validation loss: 0.4065, Validation accuracy: 0.8711\n",
      "\n",
      "Epoch 74:\n",
      "Training loss: 0.3876, Training accuracy: 0.9556\n",
      "Validation loss: 0.4032, Validation accuracy: 0.8700\n",
      "\n",
      "Epoch 75:\n",
      "Training loss: 0.3857, Training accuracy: 0.9550\n",
      "Validation loss: 0.4055, Validation accuracy: 0.8715\n",
      "\n",
      "Epoch 76:\n",
      "Training loss: 0.3765, Training accuracy: 0.9561\n",
      "Validation loss: 0.4061, Validation accuracy: 0.8724\n",
      "\n",
      "Epoch 77:\n",
      "Training loss: 0.3755, Training accuracy: 0.9564\n",
      "Validation loss: 0.4064, Validation accuracy: 0.8708\n",
      "\n",
      "Epoch 78:\n",
      "Training loss: 0.3669, Training accuracy: 0.9579\n",
      "Validation loss: 0.4106, Validation accuracy: 0.8728\n",
      "\n",
      "Epoch 79:\n",
      "Training loss: 0.3588, Training accuracy: 0.9592\n",
      "Validation loss: 0.4114, Validation accuracy: 0.8708\n",
      "\n",
      "Epoch 80:\n",
      "Training loss: 0.3571, Training accuracy: 0.9596\n",
      "Validation loss: 0.4109, Validation accuracy: 0.8726\n",
      "\n",
      "Epoch 81:\n",
      "Training loss: 0.3529, Training accuracy: 0.9607\n",
      "Validation loss: 0.4098, Validation accuracy: 0.8729\n",
      "\n",
      "Epoch 82:\n",
      "Training loss: 0.3584, Training accuracy: 0.9589\n",
      "Validation loss: 0.4101, Validation accuracy: 0.8709\n",
      "\n",
      "Epoch 83:\n",
      "Training loss: 0.3510, Training accuracy: 0.9604\n",
      "Validation loss: 0.4172, Validation accuracy: 0.8730\n",
      "\n",
      "Epoch 84:\n",
      "Training loss: 0.3466, Training accuracy: 0.9613\n",
      "Validation loss: 0.4177, Validation accuracy: 0.8740\n",
      "Saving ...\n",
      "\n",
      "Epoch 85:\n",
      "Training loss: 0.3365, Training accuracy: 0.9630\n",
      "Validation loss: 0.4173, Validation accuracy: 0.8725\n",
      "\n",
      "Epoch 86:\n",
      "Training loss: 0.3344, Training accuracy: 0.9635\n",
      "Validation loss: 0.4174, Validation accuracy: 0.8732\n",
      "\n",
      "Epoch 87:\n",
      "Training loss: 0.3311, Training accuracy: 0.9638\n",
      "Validation loss: 0.4154, Validation accuracy: 0.8739\n",
      "\n",
      "Epoch 88:\n",
      "Training loss: 0.3266, Training accuracy: 0.9642\n",
      "Validation loss: 0.4200, Validation accuracy: 0.8738\n",
      "\n",
      "Epoch 89:\n",
      "Training loss: 0.3243, Training accuracy: 0.9641\n",
      "Validation loss: 0.4198, Validation accuracy: 0.8740\n",
      "\n",
      "Epoch 90:\n",
      "Training loss: 0.3183, Training accuracy: 0.9660\n",
      "Validation loss: 0.4223, Validation accuracy: 0.8716\n",
      "\n",
      "Epoch 91:\n",
      "Training loss: 0.3190, Training accuracy: 0.9653\n",
      "Validation loss: 0.4195, Validation accuracy: 0.8742\n",
      "Saving ...\n",
      "\n",
      "Epoch 92:\n",
      "Training loss: 0.3178, Training accuracy: 0.9650\n",
      "Validation loss: 0.4334, Validation accuracy: 0.8708\n",
      "\n",
      "Epoch 93:\n",
      "Training loss: 0.3087, Training accuracy: 0.9672\n",
      "Validation loss: 0.4231, Validation accuracy: 0.8740\n",
      "\n",
      "Epoch 94:\n",
      "Training loss: 0.3085, Training accuracy: 0.9675\n",
      "Validation loss: 0.4193, Validation accuracy: 0.8752\n",
      "Saving ...\n",
      "\n",
      "Epoch 95:\n",
      "Training loss: 0.3054, Training accuracy: 0.9678\n",
      "Validation loss: 0.4270, Validation accuracy: 0.8744\n",
      "\n",
      "Epoch 96:\n",
      "Training loss: 0.2993, Training accuracy: 0.9683\n",
      "Validation loss: 0.4362, Validation accuracy: 0.8701\n",
      "\n",
      "Epoch 97:\n",
      "Training loss: 0.2949, Training accuracy: 0.9688\n",
      "Validation loss: 0.4295, Validation accuracy: 0.8735\n",
      "\n",
      "Epoch 98:\n",
      "Training loss: 0.2976, Training accuracy: 0.9693\n",
      "Validation loss: 0.4312, Validation accuracy: 0.8724\n",
      "\n",
      "Epoch 99:\n",
      "Training loss: 0.2972, Training accuracy: 0.9691\n",
      "Validation loss: 0.4280, Validation accuracy: 0.8748\n",
      "\n",
      "Epoch 100:\n",
      "Training loss: 0.2926, Training accuracy: 0.9691\n",
      "Validation loss: 0.4359, Validation accuracy: 0.8700\n",
      "\n",
      "Epoch 101:\n",
      "Training loss: 0.2861, Training accuracy: 0.9699\n",
      "Validation loss: 0.4322, Validation accuracy: 0.8726\n",
      "\n",
      "Epoch 102:\n",
      "Training loss: 0.2809, Training accuracy: 0.9714\n",
      "Validation loss: 0.4458, Validation accuracy: 0.8686\n",
      "\n",
      "Epoch 103:\n",
      "Training loss: 0.2830, Training accuracy: 0.9710\n",
      "Validation loss: 0.4341, Validation accuracy: 0.8714\n",
      "\n",
      "Epoch 104:\n",
      "Training loss: 0.2840, Training accuracy: 0.9718\n",
      "Validation loss: 0.4304, Validation accuracy: 0.8746\n",
      "\n",
      "Epoch 105:\n",
      "Training loss: 0.2743, Training accuracy: 0.9731\n",
      "Validation loss: 0.4346, Validation accuracy: 0.8726\n",
      "\n",
      "Epoch 106:\n",
      "Training loss: 0.2778, Training accuracy: 0.9710\n",
      "Validation loss: 0.4323, Validation accuracy: 0.8710\n",
      "\n",
      "Epoch 107:\n",
      "Training loss: 0.2723, Training accuracy: 0.9730\n",
      "Validation loss: 0.4383, Validation accuracy: 0.8727\n",
      "\n",
      "Epoch 108:\n",
      "Training loss: 0.2642, Training accuracy: 0.9744\n",
      "Validation loss: 0.4378, Validation accuracy: 0.8729\n",
      "\n",
      "Epoch 109:\n",
      "Training loss: 0.2647, Training accuracy: 0.9742\n",
      "Validation loss: 0.4462, Validation accuracy: 0.8720\n",
      "\n",
      "Epoch 110:\n",
      "Training loss: 0.2614, Training accuracy: 0.9743\n",
      "Validation loss: 0.4395, Validation accuracy: 0.8730\n",
      "\n",
      "Epoch 111:\n",
      "Training loss: 0.2632, Training accuracy: 0.9736\n",
      "Validation loss: 0.4436, Validation accuracy: 0.8724\n",
      "\n",
      "Epoch 112:\n",
      "Training loss: 0.2546, Training accuracy: 0.9764\n",
      "Validation loss: 0.4508, Validation accuracy: 0.8705\n",
      "\n",
      "Epoch 113:\n",
      "Training loss: 0.2601, Training accuracy: 0.9743\n",
      "Validation loss: 0.4435, Validation accuracy: 0.8723\n",
      "\n",
      "Epoch 114:\n",
      "Training loss: 0.2568, Training accuracy: 0.9748\n",
      "Validation loss: 0.4421, Validation accuracy: 0.8731\n",
      "\n",
      "Epoch 115:\n",
      "Training loss: 0.2509, Training accuracy: 0.9760\n",
      "Validation loss: 0.4523, Validation accuracy: 0.8717\n",
      "\n",
      "Epoch 116:\n",
      "Training loss: 0.2475, Training accuracy: 0.9769\n",
      "Validation loss: 0.4475, Validation accuracy: 0.8732\n",
      "\n",
      "Epoch 117:\n",
      "Training loss: 0.2504, Training accuracy: 0.9762\n",
      "Validation loss: 0.4510, Validation accuracy: 0.8718\n",
      "\n",
      "Epoch 118:\n",
      "Training loss: 0.2449, Training accuracy: 0.9770\n",
      "Validation loss: 0.4507, Validation accuracy: 0.8712\n",
      "\n",
      "Epoch 119:\n",
      "Training loss: 0.2399, Training accuracy: 0.9775\n",
      "Validation loss: 0.4548, Validation accuracy: 0.8705\n",
      "\n",
      "Current learning rate has decayed to 0.000100\n",
      "Epoch 120:\n",
      "Training loss: 0.2267, Training accuracy: 0.9791\n",
      "Validation loss: 0.4480, Validation accuracy: 0.8733\n",
      "\n",
      "Epoch 121:\n",
      "Training loss: 0.2197, Training accuracy: 0.9801\n",
      "Validation loss: 0.4458, Validation accuracy: 0.8744\n",
      "\n",
      "Epoch 122:\n",
      "Training loss: 0.2119, Training accuracy: 0.9822\n",
      "Validation loss: 0.4452, Validation accuracy: 0.8741\n",
      "\n",
      "Epoch 123:\n",
      "Training loss: 0.2074, Training accuracy: 0.9827\n",
      "Validation loss: 0.4461, Validation accuracy: 0.8740\n",
      "\n",
      "Epoch 124:\n",
      "Training loss: 0.2043, Training accuracy: 0.9840\n",
      "Validation loss: 0.4479, Validation accuracy: 0.8727\n",
      "\n",
      "Epoch 125:\n",
      "Training loss: 0.2049, Training accuracy: 0.9829\n",
      "Validation loss: 0.4418, Validation accuracy: 0.8745\n",
      "\n",
      "Epoch 126:\n",
      "Training loss: 0.2025, Training accuracy: 0.9833\n",
      "Validation loss: 0.4445, Validation accuracy: 0.8748\n",
      "\n",
      "Epoch 127:\n",
      "Training loss: 0.2056, Training accuracy: 0.9823\n",
      "Validation loss: 0.4448, Validation accuracy: 0.8749\n",
      "\n",
      "Epoch 128:\n",
      "Training loss: 0.2027, Training accuracy: 0.9827\n",
      "Validation loss: 0.4447, Validation accuracy: 0.8731\n",
      "\n",
      "Epoch 129:\n",
      "Training loss: 0.2000, Training accuracy: 0.9840\n",
      "Validation loss: 0.4460, Validation accuracy: 0.8730\n",
      "\n",
      "Epoch 130:\n",
      "Training loss: 0.1981, Training accuracy: 0.9843\n",
      "Validation loss: 0.4486, Validation accuracy: 0.8744\n",
      "\n",
      "Epoch 131:\n",
      "Training loss: 0.2000, Training accuracy: 0.9830\n",
      "Validation loss: 0.4483, Validation accuracy: 0.8750\n",
      "\n",
      "Epoch 132:\n",
      "Training loss: 0.1970, Training accuracy: 0.9839\n",
      "Validation loss: 0.4471, Validation accuracy: 0.8740\n",
      "\n",
      "Epoch 133:\n",
      "Training loss: 0.2005, Training accuracy: 0.9835\n",
      "Validation loss: 0.4482, Validation accuracy: 0.8752\n",
      "\n",
      "Epoch 134:\n",
      "Training loss: 0.1959, Training accuracy: 0.9849\n",
      "Validation loss: 0.4424, Validation accuracy: 0.8733\n",
      "\n",
      "Epoch 135:\n",
      "Training loss: 0.1954, Training accuracy: 0.9840\n",
      "Validation loss: 0.4462, Validation accuracy: 0.8748\n",
      "\n",
      "Epoch 136:\n",
      "Training loss: 0.1952, Training accuracy: 0.9841\n",
      "Validation loss: 0.4447, Validation accuracy: 0.8751\n",
      "\n",
      "Epoch 137:\n",
      "Training loss: 0.1921, Training accuracy: 0.9848\n",
      "Validation loss: 0.4489, Validation accuracy: 0.8760\n",
      "Saving ...\n",
      "\n",
      "Epoch 138:\n",
      "Training loss: 0.1923, Training accuracy: 0.9846\n",
      "Validation loss: 0.4484, Validation accuracy: 0.8746\n",
      "\n",
      "Epoch 139:\n",
      "Training loss: 0.1952, Training accuracy: 0.9845\n",
      "Validation loss: 0.4440, Validation accuracy: 0.8741\n",
      "\n",
      "Epoch 140:\n",
      "Training loss: 0.1917, Training accuracy: 0.9850\n",
      "Validation loss: 0.4463, Validation accuracy: 0.8754\n",
      "\n",
      "Epoch 141:\n",
      "Training loss: 0.1932, Training accuracy: 0.9849\n",
      "Validation loss: 0.4484, Validation accuracy: 0.8734\n",
      "\n",
      "Epoch 142:\n",
      "Training loss: 0.1950, Training accuracy: 0.9843\n",
      "Validation loss: 0.4470, Validation accuracy: 0.8755\n",
      "\n",
      "Epoch 143:\n",
      "Training loss: 0.1923, Training accuracy: 0.9849\n",
      "Validation loss: 0.4495, Validation accuracy: 0.8744\n",
      "\n",
      "Epoch 144:\n",
      "Training loss: 0.1894, Training accuracy: 0.9858\n",
      "Validation loss: 0.4476, Validation accuracy: 0.8740\n",
      "\n",
      "Epoch 145:\n",
      "Training loss: 0.1901, Training accuracy: 0.9854\n",
      "Validation loss: 0.4500, Validation accuracy: 0.8745\n",
      "\n",
      "Epoch 146:\n",
      "Training loss: 0.1932, Training accuracy: 0.9847\n",
      "Validation loss: 0.4449, Validation accuracy: 0.8747\n",
      "\n",
      "Epoch 147:\n",
      "Training loss: 0.1880, Training accuracy: 0.9856\n",
      "Validation loss: 0.4498, Validation accuracy: 0.8751\n",
      "\n",
      "Epoch 148:\n",
      "Training loss: 0.1896, Training accuracy: 0.9852\n",
      "Validation loss: 0.4486, Validation accuracy: 0.8760\n",
      "\n",
      "Epoch 149:\n",
      "Training loss: 0.1877, Training accuracy: 0.9860\n",
      "Validation loss: 0.4450, Validation accuracy: 0.8768\n",
      "Saving ...\n",
      "\n",
      "Epoch 150:\n",
      "Training loss: 0.1887, Training accuracy: 0.9858\n",
      "Validation loss: 0.4485, Validation accuracy: 0.8756\n",
      "\n",
      "Epoch 151:\n",
      "Training loss: 0.1866, Training accuracy: 0.9854\n",
      "Validation loss: 0.4475, Validation accuracy: 0.8745\n",
      "\n",
      "Epoch 152:\n",
      "Training loss: 0.1881, Training accuracy: 0.9857\n",
      "Validation loss: 0.4488, Validation accuracy: 0.8754\n",
      "\n",
      "Epoch 153:\n",
      "Training loss: 0.1905, Training accuracy: 0.9850\n",
      "Validation loss: 0.4502, Validation accuracy: 0.8746\n",
      "\n",
      "Epoch 154:\n",
      "Training loss: 0.1860, Training accuracy: 0.9860\n",
      "Validation loss: 0.4503, Validation accuracy: 0.8750\n",
      "\n",
      "Epoch 155:\n",
      "Training loss: 0.1862, Training accuracy: 0.9858\n",
      "Validation loss: 0.4508, Validation accuracy: 0.8740\n",
      "\n",
      "Epoch 156:\n",
      "Training loss: 0.1855, Training accuracy: 0.9854\n",
      "Validation loss: 0.4478, Validation accuracy: 0.8747\n",
      "\n",
      "Epoch 157:\n",
      "Training loss: 0.1843, Training accuracy: 0.9857\n",
      "Validation loss: 0.4481, Validation accuracy: 0.8756\n",
      "\n",
      "Epoch 158:\n",
      "Training loss: 0.1845, Training accuracy: 0.9861\n",
      "Validation loss: 0.4491, Validation accuracy: 0.8755\n",
      "\n",
      "Epoch 159:\n",
      "Training loss: 0.1863, Training accuracy: 0.9859\n",
      "Validation loss: 0.4486, Validation accuracy: 0.8772\n",
      "Saving ...\n",
      "\n",
      "Epoch 160:\n",
      "Training loss: 0.1868, Training accuracy: 0.9856\n",
      "Validation loss: 0.4520, Validation accuracy: 0.8749\n",
      "\n",
      "Epoch 161:\n",
      "Training loss: 0.1804, Training accuracy: 0.9870\n",
      "Validation loss: 0.4495, Validation accuracy: 0.8759\n",
      "\n",
      "Epoch 162:\n",
      "Training loss: 0.1822, Training accuracy: 0.9864\n",
      "Validation loss: 0.4483, Validation accuracy: 0.8753\n",
      "\n",
      "Epoch 163:\n",
      "Training loss: 0.1820, Training accuracy: 0.9859\n",
      "Validation loss: 0.4502, Validation accuracy: 0.8751\n",
      "\n",
      "Epoch 164:\n",
      "Training loss: 0.1844, Training accuracy: 0.9851\n",
      "Validation loss: 0.4514, Validation accuracy: 0.8757\n",
      "\n",
      "Epoch 165:\n",
      "Training loss: 0.1785, Training accuracy: 0.9869\n",
      "Validation loss: 0.4545, Validation accuracy: 0.8760\n",
      "\n",
      "Epoch 166:\n",
      "Training loss: 0.1786, Training accuracy: 0.9871\n",
      "Validation loss: 0.4533, Validation accuracy: 0.8754\n",
      "\n",
      "Epoch 167:\n",
      "Training loss: 0.1817, Training accuracy: 0.9862\n",
      "Validation loss: 0.4499, Validation accuracy: 0.8762\n",
      "\n",
      "Epoch 168:\n",
      "Training loss: 0.1818, Training accuracy: 0.9858\n",
      "Validation loss: 0.4491, Validation accuracy: 0.8762\n",
      "\n",
      "Epoch 169:\n",
      "Training loss: 0.1809, Training accuracy: 0.9862\n",
      "Validation loss: 0.4500, Validation accuracy: 0.8744\n",
      "\n",
      "Epoch 170:\n",
      "Training loss: 0.1819, Training accuracy: 0.9860\n",
      "Validation loss: 0.4515, Validation accuracy: 0.8751\n",
      "\n",
      "Epoch 171:\n",
      "Training loss: 0.1785, Training accuracy: 0.9867\n",
      "Validation loss: 0.4512, Validation accuracy: 0.8744\n",
      "\n",
      "Epoch 172:\n",
      "Training loss: 0.1828, Training accuracy: 0.9859\n",
      "Validation loss: 0.4566, Validation accuracy: 0.8748\n",
      "\n",
      "Epoch 173:\n",
      "Training loss: 0.1823, Training accuracy: 0.9860\n",
      "Validation loss: 0.4561, Validation accuracy: 0.8732\n",
      "\n",
      "Epoch 174:\n",
      "Training loss: 0.1811, Training accuracy: 0.9862\n",
      "Validation loss: 0.4560, Validation accuracy: 0.8738\n",
      "\n",
      "Epoch 175:\n",
      "Training loss: 0.1781, Training accuracy: 0.9865\n",
      "Validation loss: 0.4569, Validation accuracy: 0.8735\n",
      "\n",
      "Epoch 176:\n",
      "Training loss: 0.1786, Training accuracy: 0.9863\n",
      "Validation loss: 0.4537, Validation accuracy: 0.8747\n",
      "\n",
      "Epoch 177:\n",
      "Training loss: 0.1819, Training accuracy: 0.9866\n",
      "Validation loss: 0.4516, Validation accuracy: 0.8749\n",
      "\n",
      "Epoch 178:\n",
      "Training loss: 0.1821, Training accuracy: 0.9854\n",
      "Validation loss: 0.4554, Validation accuracy: 0.8744\n",
      "\n",
      "Epoch 179:\n",
      "Training loss: 0.1801, Training accuracy: 0.9868\n",
      "Validation loss: 0.4527, Validation accuracy: 0.8756\n",
      "\n",
      "Current learning rate has decayed to 0.000010\n",
      "Epoch 180:\n",
      "Training loss: 0.1786, Training accuracy: 0.9863\n",
      "Validation loss: 0.4533, Validation accuracy: 0.8771\n",
      "\n",
      "Epoch 181:\n",
      "Training loss: 0.1734, Training accuracy: 0.9874\n",
      "Validation loss: 0.4549, Validation accuracy: 0.8752\n",
      "\n",
      "Epoch 182:\n",
      "Training loss: 0.1768, Training accuracy: 0.9866\n",
      "Validation loss: 0.4538, Validation accuracy: 0.8755\n",
      "\n",
      "Epoch 183:\n",
      "Training loss: 0.1756, Training accuracy: 0.9870\n",
      "Validation loss: 0.4548, Validation accuracy: 0.8759\n",
      "\n",
      "Epoch 184:\n",
      "Training loss: 0.1757, Training accuracy: 0.9868\n",
      "Validation loss: 0.4541, Validation accuracy: 0.8747\n",
      "\n",
      "Epoch 185:\n",
      "Training loss: 0.1727, Training accuracy: 0.9875\n",
      "Validation loss: 0.4550, Validation accuracy: 0.8751\n",
      "\n",
      "Epoch 186:\n",
      "Training loss: 0.1778, Training accuracy: 0.9864\n",
      "Validation loss: 0.4546, Validation accuracy: 0.8758\n",
      "\n",
      "Epoch 187:\n",
      "Training loss: 0.1759, Training accuracy: 0.9873\n",
      "Validation loss: 0.4597, Validation accuracy: 0.8746\n",
      "\n",
      "Epoch 188:\n",
      "Training loss: 0.1779, Training accuracy: 0.9863\n",
      "Validation loss: 0.4579, Validation accuracy: 0.8749\n",
      "\n",
      "Epoch 189:\n",
      "Training loss: 0.1734, Training accuracy: 0.9873\n",
      "Validation loss: 0.4534, Validation accuracy: 0.8753\n",
      "\n",
      "Epoch 190:\n",
      "Training loss: 0.1749, Training accuracy: 0.9871\n",
      "Validation loss: 0.4559, Validation accuracy: 0.8735\n",
      "\n",
      "Epoch 191:\n",
      "Training loss: 0.1750, Training accuracy: 0.9869\n",
      "Validation loss: 0.4538, Validation accuracy: 0.8755\n",
      "\n",
      "Epoch 192:\n",
      "Training loss: 0.1761, Training accuracy: 0.9868\n",
      "Validation loss: 0.4558, Validation accuracy: 0.8750\n",
      "\n",
      "Epoch 193:\n",
      "Training loss: 0.1747, Training accuracy: 0.9869\n",
      "Validation loss: 0.4560, Validation accuracy: 0.8755\n",
      "\n",
      "Epoch 194:\n",
      "Training loss: 0.1754, Training accuracy: 0.9872\n",
      "Validation loss: 0.4543, Validation accuracy: 0.8746\n",
      "\n",
      "Epoch 195:\n",
      "Training loss: 0.1727, Training accuracy: 0.9878\n",
      "Validation loss: 0.4538, Validation accuracy: 0.8764\n",
      "\n",
      "Epoch 196:\n",
      "Training loss: 0.1758, Training accuracy: 0.9869\n",
      "Validation loss: 0.4594, Validation accuracy: 0.8751\n",
      "\n",
      "Epoch 197:\n",
      "Training loss: 0.1774, Training accuracy: 0.9862\n",
      "Validation loss: 0.4533, Validation accuracy: 0.8753\n",
      "\n",
      "Epoch 198:\n",
      "Training loss: 0.1756, Training accuracy: 0.9866\n",
      "Validation loss: 0.4518, Validation accuracy: 0.8745\n",
      "\n",
      "Epoch 199:\n",
      "Training loss: 0.1737, Training accuracy: 0.9869\n",
      "Validation loss: 0.4558, Validation accuracy: 0.8753\n",
      "\n",
      "==================================================\n",
      "==> Optimization finished! Best validation accuracy: 0.8772\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8772"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train(T=2,lamb=0.1,alpha=0.6,train_loader=train_loader,val_loader=val_loader,INITIAL_LR=0.01,DECAY_EPOCHS=60,DECAY=0.1,EPOCHS=200,REG = 5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Training starts!\n",
      "==================================================\n",
      "Epoch 0:\n",
      "Training loss: 8.5146, Training accuracy: 0.1418\n",
      "Validation loss: 4.4801, Validation accuracy: 0.2027\n",
      "Saving ...\n",
      "\n",
      "Current learning rate has decayed to 0.009600\n",
      "Epoch 1:\n",
      "Training loss: 4.9650, Training accuracy: 0.2760\n",
      "Validation loss: 2.1240, Validation accuracy: 0.3355\n",
      "Saving ...\n",
      "\n",
      "Current learning rate has decayed to 0.009216\n",
      "Epoch 2:\n",
      "Training loss: 4.9722, Training accuracy: 0.2874\n",
      "Validation loss: 3.5183, Validation accuracy: 0.3463\n",
      "Saving ...\n",
      "\n",
      "Current learning rate has decayed to 0.008847\n",
      "Epoch 3:\n",
      "Training loss: 4.4124, Training accuracy: 0.3490\n",
      "Validation loss: 2.1100, Validation accuracy: 0.3947\n",
      "Saving ...\n",
      "\n",
      "Current learning rate has decayed to 0.008493\n",
      "Epoch 4:\n",
      "Training loss: 4.0438, Training accuracy: 0.3839\n",
      "Validation loss: 1.5908, Validation accuracy: 0.4318\n",
      "Saving ...\n",
      "\n",
      "Current learning rate has decayed to 0.008154\n",
      "Epoch 5:\n",
      "Training loss: 3.7963, Training accuracy: 0.4159\n",
      "Validation loss: 5.4809, Validation accuracy: 0.4244\n",
      "\n",
      "Current learning rate has decayed to 0.007828\n",
      "Epoch 6:\n",
      "Training loss: 3.6391, Training accuracy: 0.4352\n",
      "Validation loss: 2.0672, Validation accuracy: 0.4660\n",
      "Saving ...\n",
      "\n",
      "Current learning rate has decayed to 0.007514\n",
      "Epoch 7:\n",
      "Training loss: 3.5083, Training accuracy: 0.4605\n",
      "Validation loss: 2.0602, Validation accuracy: 0.4738\n",
      "Saving ...\n",
      "\n",
      "Current learning rate has decayed to 0.007214\n",
      "Epoch 8:\n",
      "Training loss: 3.3790, Training accuracy: 0.4776\n",
      "Validation loss: 2.2947, Validation accuracy: 0.5030\n",
      "Saving ...\n",
      "\n",
      "Current learning rate has decayed to 0.006925\n",
      "Epoch 9:\n",
      "Training loss: 3.2290, Training accuracy: 0.5009\n",
      "Validation loss: 4.3140, Validation accuracy: 0.5269\n",
      "Saving ...\n",
      "\n",
      "Current learning rate has decayed to 0.006648\n",
      "Epoch 10:\n",
      "Training loss: 3.1499, Training accuracy: 0.5115\n",
      "Validation loss: 2.1355, Validation accuracy: 0.5192\n",
      "\n",
      "Current learning rate has decayed to 0.006382\n",
      "Epoch 11:\n",
      "Training loss: 3.0400, Training accuracy: 0.5272\n",
      "Validation loss: 2.9695, Validation accuracy: 0.5211\n",
      "\n",
      "Current learning rate has decayed to 0.006127\n",
      "Epoch 12:\n",
      "Training loss: 2.9319, Training accuracy: 0.5424\n",
      "Validation loss: 1.5403, Validation accuracy: 0.5600\n",
      "Saving ...\n",
      "\n",
      "Current learning rate has decayed to 0.005882\n",
      "Epoch 13:\n",
      "Training loss: 2.8456, Training accuracy: 0.5578\n",
      "Validation loss: 5.5972, Validation accuracy: 0.5491\n",
      "\n",
      "Current learning rate has decayed to 0.005647\n",
      "Epoch 14:\n",
      "Training loss: 2.7619, Training accuracy: 0.5710\n",
      "Validation loss: 1.7224, Validation accuracy: 0.5846\n",
      "Saving ...\n",
      "\n",
      "Current learning rate has decayed to 0.005421\n",
      "Epoch 15:\n",
      "Training loss: 2.6927, Training accuracy: 0.5835\n",
      "Validation loss: 1.6215, Validation accuracy: 0.5930\n",
      "Saving ...\n",
      "\n",
      "Current learning rate has decayed to 0.005204\n",
      "Epoch 16:\n",
      "Training loss: 2.6268, Training accuracy: 0.5931\n",
      "Validation loss: 1.3589, Validation accuracy: 0.6211\n",
      "Saving ...\n",
      "\n",
      "Current learning rate has decayed to 0.004996\n",
      "Epoch 17:\n",
      "Training loss: 2.5551, Training accuracy: 0.6056\n",
      "Validation loss: 4.0367, Validation accuracy: 0.6102\n",
      "\n",
      "Current learning rate has decayed to 0.004796\n",
      "Epoch 18:\n",
      "Training loss: 2.4999, Training accuracy: 0.6173\n",
      "Validation loss: 1.3595, Validation accuracy: 0.6251\n",
      "Saving ...\n",
      "\n",
      "Current learning rate has decayed to 0.004604\n",
      "Epoch 19:\n",
      "Training loss: 2.4466, Training accuracy: 0.6253\n",
      "Validation loss: 1.6763, Validation accuracy: 0.6375\n",
      "Saving ...\n",
      "\n",
      "Current learning rate has decayed to 0.004420\n",
      "Epoch 20:\n",
      "Training loss: 2.3973, Training accuracy: 0.6346\n",
      "Validation loss: 1.7938, Validation accuracy: 0.6439\n",
      "Saving ...\n",
      "\n",
      "Current learning rate has decayed to 0.004243\n",
      "Epoch 21:\n",
      "Training loss: 2.3341, Training accuracy: 0.6475\n",
      "Validation loss: 5.6026, Validation accuracy: 0.6322\n",
      "\n",
      "Current learning rate has decayed to 0.004073\n",
      "Epoch 22:\n",
      "Training loss: 2.2951, Training accuracy: 0.6546\n",
      "Validation loss: 3.5253, Validation accuracy: 0.6534\n",
      "Saving ...\n",
      "\n",
      "Current learning rate has decayed to 0.003911\n",
      "Epoch 23:\n",
      "Training loss: 2.2467, Training accuracy: 0.6598\n",
      "Validation loss: 1.6592, Validation accuracy: 0.6594\n",
      "Saving ...\n",
      "\n",
      "Current learning rate has decayed to 0.003754\n",
      "Epoch 24:\n",
      "Training loss: 2.1985, Training accuracy: 0.6704\n",
      "Validation loss: 7.3630, Validation accuracy: 0.6670\n",
      "Saving ...\n",
      "\n",
      "Current learning rate has decayed to 0.003604\n",
      "Epoch 25:\n",
      "Training loss: 2.1577, Training accuracy: 0.6792\n",
      "Validation loss: 6.3149, Validation accuracy: 0.6634\n",
      "\n",
      "Current learning rate has decayed to 0.003460\n",
      "Epoch 26:\n",
      "Training loss: 2.1170, Training accuracy: 0.6851\n",
      "Validation loss: 6.2501, Validation accuracy: 0.6649\n",
      "\n",
      "Current learning rate has decayed to 0.003321\n",
      "Epoch 27:\n",
      "Training loss: 2.0782, Training accuracy: 0.6921\n",
      "Validation loss: 1.9045, Validation accuracy: 0.6837\n",
      "Saving ...\n",
      "\n",
      "Current learning rate has decayed to 0.003189\n",
      "Epoch 28:\n",
      "Training loss: 2.0357, Training accuracy: 0.6953\n",
      "Validation loss: 12.0835, Validation accuracy: 0.6870\n",
      "Saving ...\n",
      "\n",
      "Current learning rate has decayed to 0.003061\n",
      "Epoch 29:\n",
      "Training loss: 2.0019, Training accuracy: 0.7027\n",
      "Validation loss: 2.0465, Validation accuracy: 0.6929\n",
      "Saving ...\n",
      "\n",
      "Current learning rate has decayed to 0.002939\n",
      "Epoch 30:\n",
      "Training loss: 1.9716, Training accuracy: 0.7108\n",
      "Validation loss: 2.8828, Validation accuracy: 0.7004\n",
      "Saving ...\n",
      "\n",
      "Current learning rate has decayed to 0.002821\n",
      "Epoch 31:\n",
      "Training loss: 1.9497, Training accuracy: 0.7151\n",
      "Validation loss: 1.1700, Validation accuracy: 0.5963\n",
      "\n",
      "Current learning rate has decayed to 0.002708\n",
      "Epoch 32:\n",
      "Training loss: 2.1645, Training accuracy: 0.6762\n",
      "Validation loss: 1.4039, Validation accuracy: 0.6961\n",
      "\n",
      "Current learning rate has decayed to 0.002600\n",
      "Epoch 33:\n",
      "Training loss: 1.9752, Training accuracy: 0.7089\n",
      "Validation loss: 1.7560, Validation accuracy: 0.7053\n",
      "Saving ...\n",
      "\n",
      "Current learning rate has decayed to 0.002496\n",
      "Epoch 34:\n",
      "Training loss: 1.9220, Training accuracy: 0.7186\n",
      "Validation loss: 1.0149, Validation accuracy: 0.7121\n",
      "Saving ...\n",
      "\n",
      "Current learning rate has decayed to 0.002396\n",
      "Epoch 35:\n",
      "Training loss: 1.8732, Training accuracy: 0.7260\n",
      "Validation loss: 2.0596, Validation accuracy: 0.7081\n",
      "\n",
      "Current learning rate has decayed to 0.002300\n",
      "Epoch 36:\n",
      "Training loss: 1.8499, Training accuracy: 0.7304\n",
      "Validation loss: 4.7467, Validation accuracy: 0.7196\n",
      "Saving ...\n",
      "\n",
      "Current learning rate has decayed to 0.002208\n",
      "Epoch 37:\n",
      "Training loss: 1.8113, Training accuracy: 0.7389\n",
      "Validation loss: 1.5326, Validation accuracy: 0.7255\n",
      "Saving ...\n",
      "\n",
      "Current learning rate has decayed to 0.002120\n",
      "Epoch 38:\n",
      "Training loss: 1.7821, Training accuracy: 0.7431\n",
      "Validation loss: 1.8810, Validation accuracy: 0.7223\n",
      "\n",
      "Current learning rate has decayed to 0.002035\n",
      "Epoch 39:\n",
      "Training loss: 1.7755, Training accuracy: 0.7415\n",
      "Validation loss: 1.2990, Validation accuracy: 0.7264\n",
      "Saving ...\n",
      "\n",
      "Current learning rate has decayed to 0.001954\n",
      "Epoch 40:\n",
      "Training loss: 1.7365, Training accuracy: 0.7518\n",
      "Validation loss: 2.0658, Validation accuracy: 0.7344\n",
      "Saving ...\n",
      "\n",
      "Current learning rate has decayed to 0.001876\n",
      "Epoch 41:\n",
      "Training loss: 1.7134, Training accuracy: 0.7547\n",
      "Validation loss: 2.0332, Validation accuracy: 0.7380\n",
      "Saving ...\n",
      "\n",
      "Current learning rate has decayed to 0.001800\n",
      "Epoch 42:\n",
      "Training loss: 1.6949, Training accuracy: 0.7577\n",
      "Validation loss: 1.1774, Validation accuracy: 0.7421\n",
      "Saving ...\n",
      "\n",
      "Current learning rate has decayed to 0.001728\n",
      "Epoch 43:\n",
      "Training loss: 1.6697, Training accuracy: 0.7631\n",
      "Validation loss: 2.3576, Validation accuracy: 0.7438\n",
      "Saving ...\n",
      "\n",
      "Current learning rate has decayed to 0.001659\n",
      "Epoch 44:\n",
      "Training loss: 1.6498, Training accuracy: 0.7650\n",
      "Validation loss: 2.2892, Validation accuracy: 0.7413\n",
      "\n",
      "Current learning rate has decayed to 0.001593\n",
      "Epoch 45:\n",
      "Training loss: 1.6374, Training accuracy: 0.7675\n",
      "Validation loss: 1.8223, Validation accuracy: 0.7431\n",
      "\n",
      "Current learning rate has decayed to 0.001529\n",
      "Epoch 46:\n",
      "Training loss: 1.6283, Training accuracy: 0.7685\n",
      "Validation loss: 4.3027, Validation accuracy: 0.7395\n",
      "\n",
      "Current learning rate has decayed to 0.001468\n",
      "Epoch 47:\n",
      "Training loss: 1.6034, Training accuracy: 0.7727\n",
      "Validation loss: 2.1707, Validation accuracy: 0.7385\n",
      "\n",
      "Current learning rate has decayed to 0.001409\n",
      "Epoch 48:\n",
      "Training loss: 1.5891, Training accuracy: 0.7757\n",
      "Validation loss: 2.0189, Validation accuracy: 0.7444\n",
      "Saving ...\n",
      "\n",
      "Current learning rate has decayed to 0.001353\n",
      "Epoch 49:\n",
      "Training loss: 1.5715, Training accuracy: 0.7798\n",
      "Validation loss: 3.8138, Validation accuracy: 0.7476\n",
      "Saving ...\n",
      "\n",
      "Current learning rate has decayed to 0.001299\n",
      "Epoch 50:\n",
      "Training loss: 1.5543, Training accuracy: 0.7799\n",
      "Validation loss: 1.7799, Validation accuracy: 0.7535\n",
      "Saving ...\n",
      "\n",
      "Current learning rate has decayed to 0.001247\n",
      "Epoch 51:\n",
      "Training loss: 1.5380, Training accuracy: 0.7854\n",
      "Validation loss: 2.8416, Validation accuracy: 0.7508\n",
      "\n",
      "Current learning rate has decayed to 0.001197\n",
      "Epoch 52:\n",
      "Training loss: 1.5315, Training accuracy: 0.7838\n",
      "Validation loss: 1.7697, Validation accuracy: 0.7548\n",
      "Saving ...\n",
      "\n",
      "Current learning rate has decayed to 0.001149\n",
      "Epoch 53:\n",
      "Training loss: 1.5105, Training accuracy: 0.7886\n",
      "Validation loss: 3.5446, Validation accuracy: 0.7507\n",
      "\n",
      "Current learning rate has decayed to 0.001103\n",
      "Epoch 54:\n",
      "Training loss: 1.5006, Training accuracy: 0.7914\n",
      "Validation loss: 3.6888, Validation accuracy: 0.7517\n",
      "\n",
      "Current learning rate has decayed to 0.001059\n",
      "Epoch 55:\n",
      "Training loss: 1.4994, Training accuracy: 0.7921\n",
      "Validation loss: 5.7446, Validation accuracy: 0.7527\n",
      "\n",
      "Current learning rate has decayed to 0.001017\n",
      "Epoch 56:\n",
      "Training loss: 1.4780, Training accuracy: 0.7935\n",
      "Validation loss: 2.8468, Validation accuracy: 0.7595\n",
      "Saving ...\n",
      "\n",
      "Current learning rate has decayed to 0.000976\n",
      "Epoch 57:\n",
      "Training loss: 1.4697, Training accuracy: 0.7979\n",
      "Validation loss: 2.0497, Validation accuracy: 0.7600\n",
      "Saving ...\n",
      "\n",
      "Current learning rate has decayed to 0.000937\n",
      "Epoch 58:\n",
      "Training loss: 1.4467, Training accuracy: 0.8012\n",
      "Validation loss: 4.1771, Validation accuracy: 0.7553\n",
      "\n",
      "Current learning rate has decayed to 0.000900\n",
      "Epoch 59:\n",
      "Training loss: 1.4515, Training accuracy: 0.7991\n",
      "Validation loss: 3.8146, Validation accuracy: 0.7631\n",
      "Saving ...\n",
      "\n",
      "Current learning rate has decayed to 0.000864\n",
      "Epoch 60:\n",
      "Training loss: 1.4425, Training accuracy: 0.8009\n",
      "Validation loss: 3.5710, Validation accuracy: 0.7605\n",
      "\n",
      "Current learning rate has decayed to 0.000829\n",
      "Epoch 61:\n",
      "Training loss: 1.4232, Training accuracy: 0.8029\n",
      "Validation loss: 7.8126, Validation accuracy: 0.7582\n",
      "\n",
      "Current learning rate has decayed to 0.000796\n",
      "Epoch 62:\n",
      "Training loss: 1.4190, Training accuracy: 0.8053\n",
      "Validation loss: 2.2967, Validation accuracy: 0.7669\n",
      "Saving ...\n",
      "\n",
      "Current learning rate has decayed to 0.000764\n",
      "Epoch 63:\n",
      "Training loss: 1.4058, Training accuracy: 0.8084\n",
      "Validation loss: 4.4272, Validation accuracy: 0.7647\n",
      "\n",
      "Current learning rate has decayed to 0.000733\n",
      "Epoch 64:\n",
      "Training loss: 1.4012, Training accuracy: 0.8095\n",
      "Validation loss: 3.6353, Validation accuracy: 0.7667\n",
      "\n",
      "Current learning rate has decayed to 0.000704\n",
      "Epoch 65:\n",
      "Training loss: 1.3956, Training accuracy: 0.8087\n",
      "Validation loss: 4.0414, Validation accuracy: 0.7670\n",
      "Saving ...\n",
      "\n",
      "Current learning rate has decayed to 0.000676\n",
      "Epoch 66:\n",
      "Training loss: 1.3818, Training accuracy: 0.8110\n",
      "Validation loss: 3.9974, Validation accuracy: 0.7636\n",
      "\n",
      "Current learning rate has decayed to 0.000649\n",
      "Epoch 67:\n",
      "Training loss: 1.3802, Training accuracy: 0.8136\n",
      "Validation loss: 2.9649, Validation accuracy: 0.7639\n",
      "\n",
      "Current learning rate has decayed to 0.000623\n",
      "Epoch 68:\n",
      "Training loss: 1.3613, Training accuracy: 0.8151\n",
      "Validation loss: 6.9648, Validation accuracy: 0.7622\n",
      "\n",
      "Current learning rate has decayed to 0.000598\n",
      "Epoch 69:\n",
      "Training loss: 1.3574, Training accuracy: 0.8165\n",
      "Validation loss: 2.1029, Validation accuracy: 0.7670\n",
      "\n",
      "Current learning rate has decayed to 0.000574\n",
      "Epoch 70:\n",
      "Training loss: 1.3633, Training accuracy: 0.8153\n",
      "Validation loss: 4.3655, Validation accuracy: 0.7700\n",
      "Saving ...\n",
      "\n",
      "Current learning rate has decayed to 0.000551\n",
      "Epoch 71:\n",
      "Training loss: 1.3499, Training accuracy: 0.8167\n",
      "Validation loss: 3.6786, Validation accuracy: 0.7676\n",
      "\n",
      "Current learning rate has decayed to 0.000529\n",
      "Epoch 72:\n",
      "Training loss: 1.3476, Training accuracy: 0.8170\n",
      "Validation loss: 4.4970, Validation accuracy: 0.7685\n",
      "\n",
      "Current learning rate has decayed to 0.000508\n",
      "Epoch 73:\n",
      "Training loss: 1.3243, Training accuracy: 0.8214\n",
      "Validation loss: 7.0862, Validation accuracy: 0.7696\n",
      "\n",
      "Current learning rate has decayed to 0.000488\n",
      "Epoch 74:\n",
      "Training loss: 1.3187, Training accuracy: 0.8227\n",
      "Validation loss: 3.7954, Validation accuracy: 0.7661\n",
      "\n",
      "Current learning rate has decayed to 0.000468\n",
      "Epoch 75:\n",
      "Training loss: 1.3189, Training accuracy: 0.8246\n",
      "Validation loss: 5.4286, Validation accuracy: 0.7715\n",
      "Saving ...\n",
      "\n",
      "Current learning rate has decayed to 0.000449\n",
      "Epoch 76:\n",
      "Training loss: 1.3099, Training accuracy: 0.8265\n",
      "Validation loss: 11.9018, Validation accuracy: 0.7650\n",
      "\n",
      "Current learning rate has decayed to 0.000431\n",
      "Epoch 77:\n",
      "Training loss: 1.3040, Training accuracy: 0.8253\n",
      "Validation loss: 6.1164, Validation accuracy: 0.7698\n",
      "\n",
      "Current learning rate has decayed to 0.000414\n",
      "Epoch 78:\n",
      "Training loss: 1.2983, Training accuracy: 0.8257\n",
      "Validation loss: 4.5413, Validation accuracy: 0.7718\n",
      "Saving ...\n",
      "\n",
      "Current learning rate has decayed to 0.000398\n",
      "Epoch 79:\n",
      "Training loss: 1.2939, Training accuracy: 0.8268\n",
      "Validation loss: 4.9355, Validation accuracy: 0.7691\n",
      "\n",
      "Current learning rate has decayed to 0.000382\n",
      "Epoch 80:\n",
      "Training loss: 1.2907, Training accuracy: 0.8284\n",
      "Validation loss: 9.0935, Validation accuracy: 0.7695\n",
      "\n",
      "Current learning rate has decayed to 0.000366\n",
      "Epoch 81:\n",
      "Training loss: 1.2859, Training accuracy: 0.8288\n",
      "Validation loss: 7.1171, Validation accuracy: 0.7701\n",
      "\n",
      "Current learning rate has decayed to 0.000352\n",
      "Epoch 82:\n",
      "Training loss: 1.2773, Training accuracy: 0.8304\n",
      "Validation loss: 6.3637, Validation accuracy: 0.7743\n",
      "Saving ...\n",
      "\n",
      "Current learning rate has decayed to 0.000338\n",
      "Epoch 83:\n",
      "Training loss: 1.2731, Training accuracy: 0.8322\n",
      "Validation loss: 8.8210, Validation accuracy: 0.7692\n",
      "\n",
      "Current learning rate has decayed to 0.000324\n",
      "Epoch 84:\n",
      "Training loss: 1.2694, Training accuracy: 0.8328\n",
      "Validation loss: 12.7639, Validation accuracy: 0.7692\n",
      "\n",
      "Current learning rate has decayed to 0.000311\n",
      "Epoch 85:\n",
      "Training loss: 1.2615, Training accuracy: 0.8337\n",
      "Validation loss: 9.5649, Validation accuracy: 0.7694\n",
      "\n",
      "Current learning rate has decayed to 0.000299\n",
      "Epoch 86:\n",
      "Training loss: 1.2616, Training accuracy: 0.8342\n",
      "Validation loss: 11.3894, Validation accuracy: 0.7698\n",
      "\n",
      "Current learning rate has decayed to 0.000287\n",
      "Epoch 87:\n",
      "Training loss: 1.2629, Training accuracy: 0.8337\n",
      "Validation loss: 12.9117, Validation accuracy: 0.7698\n",
      "\n",
      "Current learning rate has decayed to 0.000275\n",
      "Epoch 88:\n",
      "Training loss: 1.2590, Training accuracy: 0.8335\n",
      "Validation loss: 5.8124, Validation accuracy: 0.7744\n",
      "Saving ...\n",
      "\n",
      "Current learning rate has decayed to 0.000264\n",
      "Epoch 89:\n",
      "Training loss: 1.2512, Training accuracy: 0.8345\n",
      "Validation loss: 13.8784, Validation accuracy: 0.7699\n",
      "\n",
      "Current learning rate has decayed to 0.000254\n",
      "Epoch 90:\n",
      "Training loss: 1.2413, Training accuracy: 0.8387\n",
      "Validation loss: 9.9369, Validation accuracy: 0.7745\n",
      "Saving ...\n",
      "\n",
      "Current learning rate has decayed to 0.000244\n",
      "Epoch 91:\n",
      "Training loss: 1.2408, Training accuracy: 0.8393\n",
      "Validation loss: 12.0915, Validation accuracy: 0.7728\n",
      "\n",
      "Current learning rate has decayed to 0.000234\n",
      "Epoch 92:\n",
      "Training loss: 1.2404, Training accuracy: 0.8391\n",
      "Validation loss: 10.1100, Validation accuracy: 0.7755\n",
      "Saving ...\n",
      "\n",
      "Current learning rate has decayed to 0.000225\n",
      "Epoch 93:\n",
      "Training loss: 1.2353, Training accuracy: 0.8388\n",
      "Validation loss: 17.4111, Validation accuracy: 0.7730\n",
      "\n",
      "Current learning rate has decayed to 0.000216\n",
      "Epoch 94:\n",
      "Training loss: 1.2328, Training accuracy: 0.8390\n",
      "Validation loss: 18.0772, Validation accuracy: 0.7705\n",
      "\n",
      "Current learning rate has decayed to 0.000207\n",
      "Epoch 95:\n",
      "Training loss: 1.2242, Training accuracy: 0.8406\n",
      "Validation loss: 12.6345, Validation accuracy: 0.7746\n",
      "\n",
      "Current learning rate has decayed to 0.000199\n",
      "Epoch 96:\n",
      "Training loss: 1.2299, Training accuracy: 0.8401\n",
      "Validation loss: 14.6781, Validation accuracy: 0.7703\n",
      "\n",
      "Current learning rate has decayed to 0.000191\n",
      "Epoch 97:\n",
      "Training loss: 1.2179, Training accuracy: 0.8420\n",
      "Validation loss: 10.3352, Validation accuracy: 0.7756\n",
      "Saving ...\n",
      "\n",
      "Current learning rate has decayed to 0.000183\n",
      "Epoch 98:\n",
      "Training loss: 1.2220, Training accuracy: 0.8404\n",
      "Validation loss: 10.2635, Validation accuracy: 0.7749\n",
      "\n",
      "Current learning rate has decayed to 0.000176\n",
      "Epoch 99:\n",
      "Training loss: 1.2226, Training accuracy: 0.8413\n",
      "Validation loss: 11.7950, Validation accuracy: 0.7770\n",
      "Saving ...\n",
      "\n",
      "Current learning rate has decayed to 0.000169\n",
      "Epoch 100:\n",
      "Training loss: 1.2127, Training accuracy: 0.8434\n",
      "Validation loss: 13.8722, Validation accuracy: 0.7749\n",
      "\n",
      "Current learning rate has decayed to 0.000162\n",
      "Epoch 101:\n",
      "Training loss: 1.2217, Training accuracy: 0.8397\n",
      "Validation loss: 14.3915, Validation accuracy: 0.7724\n",
      "\n",
      "Current learning rate has decayed to 0.000155\n",
      "Epoch 102:\n",
      "Training loss: 1.2124, Training accuracy: 0.8421\n",
      "Validation loss: 9.6329, Validation accuracy: 0.7783\n",
      "Saving ...\n",
      "\n",
      "Current learning rate has decayed to 0.000149\n",
      "Epoch 103:\n",
      "Training loss: 1.2071, Training accuracy: 0.8446\n",
      "Validation loss: 14.6119, Validation accuracy: 0.7757\n",
      "\n",
      "Current learning rate has decayed to 0.000143\n",
      "Epoch 104:\n",
      "Training loss: 1.2022, Training accuracy: 0.8434\n",
      "Validation loss: 13.1749, Validation accuracy: 0.7727\n",
      "\n",
      "Current learning rate has decayed to 0.000138\n",
      "Epoch 105:\n",
      "Training loss: 1.2064, Training accuracy: 0.8445\n",
      "Validation loss: 12.1094, Validation accuracy: 0.7759\n",
      "\n",
      "Current learning rate has decayed to 0.000132\n",
      "Epoch 106:\n",
      "Training loss: 1.1993, Training accuracy: 0.8459\n",
      "Validation loss: 15.0194, Validation accuracy: 0.7739\n",
      "\n",
      "Current learning rate has decayed to 0.000127\n",
      "Epoch 107:\n",
      "Training loss: 1.1962, Training accuracy: 0.8452\n",
      "Validation loss: 9.5783, Validation accuracy: 0.7772\n",
      "\n",
      "Current learning rate has decayed to 0.000122\n",
      "Epoch 108:\n",
      "Training loss: 1.1989, Training accuracy: 0.8453\n",
      "Validation loss: 13.9872, Validation accuracy: 0.7730\n",
      "\n",
      "Current learning rate has decayed to 0.000117\n",
      "Epoch 109:\n",
      "Training loss: 1.1952, Training accuracy: 0.8475\n",
      "Validation loss: 12.5974, Validation accuracy: 0.7747\n",
      "\n",
      "Current learning rate has decayed to 0.000112\n",
      "Epoch 110:\n",
      "Training loss: 1.1885, Training accuracy: 0.8474\n",
      "Validation loss: 11.1613, Validation accuracy: 0.7744\n",
      "\n",
      "Current learning rate has decayed to 0.000108\n",
      "Epoch 111:\n",
      "Training loss: 1.1929, Training accuracy: 0.8463\n",
      "Validation loss: 11.5738, Validation accuracy: 0.7772\n",
      "\n",
      "Current learning rate has decayed to 0.000103\n",
      "Epoch 112:\n",
      "Training loss: 1.1869, Training accuracy: 0.8472\n",
      "Validation loss: 10.3365, Validation accuracy: 0.7744\n",
      "\n",
      "Current learning rate has decayed to 0.000099\n",
      "Epoch 113:\n",
      "Training loss: 1.1851, Training accuracy: 0.8479\n",
      "Validation loss: 12.7703, Validation accuracy: 0.7744\n",
      "\n",
      "Current learning rate has decayed to 0.000095\n",
      "Epoch 114:\n",
      "Training loss: 1.1868, Training accuracy: 0.8459\n",
      "Validation loss: 20.4568, Validation accuracy: 0.7689\n",
      "\n",
      "Current learning rate has decayed to 0.000091\n",
      "Epoch 115:\n",
      "Training loss: 1.1832, Training accuracy: 0.8480\n",
      "Validation loss: 12.0764, Validation accuracy: 0.7778\n",
      "\n",
      "Current learning rate has decayed to 0.000088\n",
      "Epoch 116:\n",
      "Training loss: 1.1855, Training accuracy: 0.8479\n",
      "Validation loss: 10.7940, Validation accuracy: 0.7769\n",
      "\n",
      "Current learning rate has decayed to 0.000084\n",
      "Epoch 117:\n",
      "Training loss: 1.1793, Training accuracy: 0.8488\n",
      "Validation loss: 19.3958, Validation accuracy: 0.7725\n",
      "\n",
      "Current learning rate has decayed to 0.000081\n",
      "Epoch 118:\n",
      "Training loss: 1.1864, Training accuracy: 0.8480\n",
      "Validation loss: 21.4897, Validation accuracy: 0.7730\n",
      "\n",
      "Current learning rate has decayed to 0.000078\n",
      "Epoch 119:\n",
      "Training loss: 1.1823, Training accuracy: 0.8491\n",
      "Validation loss: 17.4837, Validation accuracy: 0.7758\n",
      "\n",
      "Current learning rate has decayed to 0.000075\n",
      "Epoch 120:\n",
      "Training loss: 1.1794, Training accuracy: 0.8478\n",
      "Validation loss: 17.5784, Validation accuracy: 0.7771\n",
      "\n",
      "Current learning rate has decayed to 0.000072\n",
      "Epoch 121:\n",
      "Training loss: 1.1764, Training accuracy: 0.8494\n",
      "Validation loss: 17.6599, Validation accuracy: 0.7754\n",
      "\n",
      "Current learning rate has decayed to 0.000069\n",
      "Epoch 122:\n",
      "Training loss: 1.1784, Training accuracy: 0.8492\n",
      "Validation loss: 14.0093, Validation accuracy: 0.7774\n",
      "\n",
      "Current learning rate has decayed to 0.000066\n",
      "Epoch 123:\n",
      "Training loss: 1.1770, Training accuracy: 0.8489\n",
      "Validation loss: 19.9031, Validation accuracy: 0.7753\n",
      "\n",
      "Current learning rate has decayed to 0.000063\n",
      "Epoch 124:\n",
      "Training loss: 1.1684, Training accuracy: 0.8518\n",
      "Validation loss: 18.8395, Validation accuracy: 0.7761\n",
      "\n",
      "Current learning rate has decayed to 0.000061\n",
      "Epoch 125:\n",
      "Training loss: 1.1647, Training accuracy: 0.8526\n",
      "Validation loss: 24.7691, Validation accuracy: 0.7749\n",
      "\n",
      "Current learning rate has decayed to 0.000058\n",
      "Epoch 126:\n",
      "Training loss: 1.1706, Training accuracy: 0.8507\n",
      "Validation loss: 15.4530, Validation accuracy: 0.7769\n",
      "\n",
      "Current learning rate has decayed to 0.000056\n",
      "Epoch 127:\n",
      "Training loss: 1.1706, Training accuracy: 0.8507\n",
      "Validation loss: 8.8041, Validation accuracy: 0.7814\n",
      "Saving ...\n",
      "\n",
      "Current learning rate has decayed to 0.000054\n",
      "Epoch 128:\n",
      "Training loss: 1.1648, Training accuracy: 0.8514\n",
      "Validation loss: 13.8449, Validation accuracy: 0.7758\n",
      "\n",
      "Current learning rate has decayed to 0.000052\n",
      "Epoch 129:\n",
      "Training loss: 1.1621, Training accuracy: 0.8521\n",
      "Validation loss: 16.4245, Validation accuracy: 0.7746\n",
      "\n",
      "Current learning rate has decayed to 0.000050\n",
      "Epoch 130:\n",
      "Training loss: 1.1728, Training accuracy: 0.8500\n",
      "Validation loss: 21.7650, Validation accuracy: 0.7740\n",
      "\n",
      "Current learning rate has decayed to 0.000048\n",
      "Epoch 131:\n",
      "Training loss: 1.1626, Training accuracy: 0.8513\n",
      "Validation loss: 13.0722, Validation accuracy: 0.7790\n",
      "\n",
      "Current learning rate has decayed to 0.000046\n",
      "Epoch 132:\n",
      "Training loss: 1.1682, Training accuracy: 0.8518\n",
      "Validation loss: 17.9931, Validation accuracy: 0.7747\n",
      "\n",
      "Current learning rate has decayed to 0.000044\n",
      "Epoch 133:\n",
      "Training loss: 1.1632, Training accuracy: 0.8520\n",
      "Validation loss: 11.0764, Validation accuracy: 0.7797\n",
      "\n",
      "Current learning rate has decayed to 0.000042\n",
      "Epoch 134:\n",
      "Training loss: 1.1667, Training accuracy: 0.8510\n",
      "Validation loss: 8.0091, Validation accuracy: 0.7811\n",
      "\n",
      "Current learning rate has decayed to 0.000040\n",
      "Epoch 135:\n",
      "Training loss: 1.1550, Training accuracy: 0.8535\n",
      "Validation loss: 13.0699, Validation accuracy: 0.7806\n",
      "\n",
      "Current learning rate has decayed to 0.000039\n",
      "Epoch 136:\n",
      "Training loss: 1.1655, Training accuracy: 0.8506\n",
      "Validation loss: 19.4024, Validation accuracy: 0.7758\n",
      "\n",
      "Current learning rate has decayed to 0.000037\n",
      "Epoch 137:\n",
      "Training loss: 1.1538, Training accuracy: 0.8527\n",
      "Validation loss: 12.8972, Validation accuracy: 0.7799\n",
      "\n",
      "Current learning rate has decayed to 0.000036\n",
      "Epoch 138:\n",
      "Training loss: 1.1595, Training accuracy: 0.8509\n",
      "Validation loss: 8.7549, Validation accuracy: 0.7822\n",
      "Saving ...\n",
      "\n",
      "Current learning rate has decayed to 0.000034\n",
      "Epoch 139:\n",
      "Training loss: 1.1577, Training accuracy: 0.8518\n",
      "Validation loss: 8.8971, Validation accuracy: 0.7807\n",
      "\n",
      "Current learning rate has decayed to 0.000033\n",
      "Epoch 140:\n",
      "Training loss: 1.1599, Training accuracy: 0.8521\n",
      "Validation loss: 17.6557, Validation accuracy: 0.7745\n",
      "\n",
      "Current learning rate has decayed to 0.000032\n",
      "Epoch 141:\n",
      "Training loss: 1.1601, Training accuracy: 0.8515\n",
      "Validation loss: 18.6922, Validation accuracy: 0.7752\n",
      "\n",
      "Current learning rate has decayed to 0.000030\n",
      "Epoch 142:\n",
      "Training loss: 1.1648, Training accuracy: 0.8517\n",
      "Validation loss: 11.4592, Validation accuracy: 0.7800\n",
      "\n",
      "Current learning rate has decayed to 0.000029\n",
      "Epoch 143:\n",
      "Training loss: 1.1541, Training accuracy: 0.8536\n",
      "Validation loss: 8.6179, Validation accuracy: 0.7802\n",
      "\n",
      "Current learning rate has decayed to 0.000028\n",
      "Epoch 144:\n",
      "Training loss: 1.1625, Training accuracy: 0.8526\n",
      "Validation loss: 9.6498, Validation accuracy: 0.7821\n",
      "\n",
      "Current learning rate has decayed to 0.000027\n",
      "Epoch 145:\n",
      "Training loss: 1.1637, Training accuracy: 0.8519\n",
      "Validation loss: 16.4232, Validation accuracy: 0.7784\n",
      "\n",
      "Current learning rate has decayed to 0.000026\n",
      "Epoch 146:\n",
      "Training loss: 1.1597, Training accuracy: 0.8522\n",
      "Validation loss: 14.0631, Validation accuracy: 0.7804\n",
      "\n",
      "Current learning rate has decayed to 0.000025\n",
      "Epoch 147:\n",
      "Training loss: 1.1622, Training accuracy: 0.8526\n",
      "Validation loss: 16.8415, Validation accuracy: 0.7774\n",
      "\n",
      "Current learning rate has decayed to 0.000024\n",
      "Epoch 148:\n",
      "Training loss: 1.1547, Training accuracy: 0.8553\n",
      "Validation loss: 19.3935, Validation accuracy: 0.7757\n",
      "\n",
      "Current learning rate has decayed to 0.000023\n",
      "Epoch 149:\n",
      "Training loss: 1.1552, Training accuracy: 0.8537\n",
      "Validation loss: 9.3202, Validation accuracy: 0.7824\n",
      "Saving ...\n",
      "\n",
      "Current learning rate has decayed to 0.000022\n",
      "Epoch 150:\n",
      "Training loss: 1.1477, Training accuracy: 0.8543\n",
      "Validation loss: 11.4416, Validation accuracy: 0.7782\n",
      "\n",
      "Current learning rate has decayed to 0.000021\n",
      "Epoch 151:\n",
      "Training loss: 1.1494, Training accuracy: 0.8540\n",
      "Validation loss: 10.3469, Validation accuracy: 0.7807\n",
      "\n",
      "Current learning rate has decayed to 0.000020\n",
      "Epoch 152:\n",
      "Training loss: 1.1577, Training accuracy: 0.8523\n",
      "Validation loss: 25.3139, Validation accuracy: 0.7720\n",
      "\n",
      "Current learning rate has decayed to 0.000019\n",
      "Epoch 153:\n",
      "Training loss: 1.1480, Training accuracy: 0.8541\n",
      "Validation loss: 18.8157, Validation accuracy: 0.7747\n",
      "\n",
      "Current learning rate has decayed to 0.000019\n",
      "Epoch 154:\n",
      "Training loss: 1.1576, Training accuracy: 0.8516\n",
      "Validation loss: 15.3563, Validation accuracy: 0.7773\n",
      "\n",
      "Current learning rate has decayed to 0.000018\n",
      "Epoch 155:\n",
      "Training loss: 1.1564, Training accuracy: 0.8519\n",
      "Validation loss: 8.6480, Validation accuracy: 0.7807\n",
      "\n",
      "Current learning rate has decayed to 0.000017\n",
      "Epoch 156:\n",
      "Training loss: 1.1464, Training accuracy: 0.8537\n",
      "Validation loss: 21.4330, Validation accuracy: 0.7759\n",
      "\n",
      "Current learning rate has decayed to 0.000016\n",
      "Epoch 157:\n",
      "Training loss: 1.1518, Training accuracy: 0.8536\n",
      "Validation loss: 12.6088, Validation accuracy: 0.7804\n",
      "\n",
      "Current learning rate has decayed to 0.000016\n",
      "Epoch 158:\n",
      "Training loss: 1.1489, Training accuracy: 0.8551\n",
      "Validation loss: 11.4797, Validation accuracy: 0.7817\n",
      "\n",
      "Current learning rate has decayed to 0.000015\n",
      "Epoch 159:\n",
      "Training loss: 1.1496, Training accuracy: 0.8534\n",
      "Validation loss: 12.6001, Validation accuracy: 0.7809\n",
      "\n",
      "Current learning rate has decayed to 0.000015\n",
      "Epoch 160:\n",
      "Training loss: 1.1496, Training accuracy: 0.8535\n",
      "Validation loss: 12.0576, Validation accuracy: 0.7811\n",
      "\n",
      "Current learning rate has decayed to 0.000014\n",
      "Epoch 161:\n",
      "Training loss: 1.1532, Training accuracy: 0.8543\n",
      "Validation loss: 10.9426, Validation accuracy: 0.7828\n",
      "Saving ...\n",
      "\n",
      "Current learning rate has decayed to 0.000013\n",
      "Epoch 162:\n",
      "Training loss: 1.1483, Training accuracy: 0.8543\n",
      "Validation loss: 17.6576, Validation accuracy: 0.7768\n",
      "\n",
      "Current learning rate has decayed to 0.000013\n",
      "Epoch 163:\n",
      "Training loss: 1.1535, Training accuracy: 0.8531\n",
      "Validation loss: 9.7457, Validation accuracy: 0.7804\n",
      "\n",
      "Current learning rate has decayed to 0.000012\n",
      "Epoch 164:\n",
      "Training loss: 1.1584, Training accuracy: 0.8524\n",
      "Validation loss: 10.5733, Validation accuracy: 0.7803\n",
      "\n",
      "Current learning rate has decayed to 0.000012\n",
      "Epoch 165:\n",
      "Training loss: 1.1420, Training accuracy: 0.8553\n",
      "Validation loss: 12.7567, Validation accuracy: 0.7815\n",
      "\n",
      "Current learning rate has decayed to 0.000011\n",
      "Epoch 166:\n",
      "Training loss: 1.1504, Training accuracy: 0.8548\n",
      "Validation loss: 15.2424, Validation accuracy: 0.7797\n",
      "\n",
      "Current learning rate has decayed to 0.000011\n",
      "Epoch 167:\n",
      "Training loss: 1.1503, Training accuracy: 0.8546\n",
      "Validation loss: 19.9061, Validation accuracy: 0.7774\n",
      "\n",
      "Current learning rate has decayed to 0.000011\n",
      "Epoch 168:\n",
      "Training loss: 1.1542, Training accuracy: 0.8528\n",
      "Validation loss: 15.1708, Validation accuracy: 0.7767\n",
      "\n",
      "Current learning rate has decayed to 0.000010\n",
      "Epoch 169:\n",
      "Training loss: 1.1536, Training accuracy: 0.8538\n",
      "Validation loss: 18.5782, Validation accuracy: 0.7774\n",
      "\n",
      "Current learning rate has decayed to 0.000010\n",
      "Epoch 170:\n",
      "Training loss: 1.1515, Training accuracy: 0.8535\n",
      "Validation loss: 15.8622, Validation accuracy: 0.7781\n",
      "\n",
      "Current learning rate has decayed to 0.000009\n",
      "Epoch 171:\n",
      "Training loss: 1.1520, Training accuracy: 0.8538\n",
      "Validation loss: 12.3730, Validation accuracy: 0.7811\n",
      "\n",
      "Current learning rate has decayed to 0.000009\n",
      "Epoch 172:\n",
      "Training loss: 1.1505, Training accuracy: 0.8535\n",
      "Validation loss: 23.4088, Validation accuracy: 0.7746\n",
      "\n",
      "Current learning rate has decayed to 0.000009\n",
      "Epoch 173:\n",
      "Training loss: 1.1492, Training accuracy: 0.8546\n",
      "Validation loss: 13.3730, Validation accuracy: 0.7798\n",
      "\n",
      "Current learning rate has decayed to 0.000008\n",
      "Epoch 174:\n",
      "Training loss: 1.1419, Training accuracy: 0.8549\n",
      "Validation loss: 31.3187, Validation accuracy: 0.7713\n",
      "\n",
      "Current learning rate has decayed to 0.000008\n",
      "Epoch 175:\n",
      "Training loss: 1.1489, Training accuracy: 0.8540\n",
      "Validation loss: 14.4940, Validation accuracy: 0.7768\n",
      "\n",
      "Current learning rate has decayed to 0.000008\n",
      "Epoch 176:\n",
      "Training loss: 1.1420, Training accuracy: 0.8556\n",
      "Validation loss: 16.5679, Validation accuracy: 0.7783\n",
      "\n",
      "Current learning rate has decayed to 0.000007\n",
      "Epoch 177:\n",
      "Training loss: 1.1493, Training accuracy: 0.8536\n",
      "Validation loss: 13.2179, Validation accuracy: 0.7812\n",
      "\n",
      "Current learning rate has decayed to 0.000007\n",
      "Epoch 178:\n",
      "Training loss: 1.1470, Training accuracy: 0.8552\n",
      "Validation loss: 12.9192, Validation accuracy: 0.7803\n",
      "\n",
      "Current learning rate has decayed to 0.000007\n",
      "Epoch 179:\n",
      "Training loss: 1.1493, Training accuracy: 0.8542\n",
      "Validation loss: 14.2384, Validation accuracy: 0.7787\n",
      "\n",
      "Current learning rate has decayed to 0.000006\n",
      "Epoch 180:\n",
      "Training loss: 1.1455, Training accuracy: 0.8549\n",
      "Validation loss: 9.1483, Validation accuracy: 0.7820\n",
      "\n",
      "Current learning rate has decayed to 0.000006\n",
      "Epoch 181:\n",
      "Training loss: 1.1498, Training accuracy: 0.8546\n",
      "Validation loss: 12.3131, Validation accuracy: 0.7800\n",
      "\n",
      "Current learning rate has decayed to 0.000006\n",
      "Epoch 182:\n",
      "Training loss: 1.1545, Training accuracy: 0.8530\n",
      "Validation loss: 16.1979, Validation accuracy: 0.7772\n",
      "\n",
      "Current learning rate has decayed to 0.000006\n",
      "Epoch 183:\n",
      "Training loss: 1.1477, Training accuracy: 0.8550\n",
      "Validation loss: 17.3186, Validation accuracy: 0.7778\n",
      "\n",
      "Current learning rate has decayed to 0.000005\n",
      "Epoch 184:\n",
      "Training loss: 1.1486, Training accuracy: 0.8534\n",
      "Validation loss: 13.0777, Validation accuracy: 0.7783\n",
      "\n",
      "Current learning rate has decayed to 0.000005\n",
      "Epoch 185:\n",
      "Training loss: 1.1425, Training accuracy: 0.8558\n",
      "Validation loss: 20.4884, Validation accuracy: 0.7766\n",
      "\n",
      "Current learning rate has decayed to 0.000005\n",
      "Epoch 186:\n",
      "Training loss: 1.1445, Training accuracy: 0.8560\n",
      "Validation loss: 20.7740, Validation accuracy: 0.7772\n",
      "\n",
      "Current learning rate has decayed to 0.000005\n",
      "Epoch 187:\n",
      "Training loss: 1.1487, Training accuracy: 0.8564\n",
      "Validation loss: 16.8023, Validation accuracy: 0.7795\n",
      "\n",
      "Current learning rate has decayed to 0.000005\n",
      "Epoch 188:\n",
      "Training loss: 1.1466, Training accuracy: 0.8543\n",
      "Validation loss: 18.2464, Validation accuracy: 0.7774\n",
      "\n",
      "Current learning rate has decayed to 0.000004\n",
      "Epoch 189:\n",
      "Training loss: 1.1479, Training accuracy: 0.8546\n",
      "Validation loss: 12.6660, Validation accuracy: 0.7797\n",
      "\n",
      "Current learning rate has decayed to 0.000004\n",
      "Epoch 190:\n",
      "Training loss: 1.1496, Training accuracy: 0.8544\n",
      "Validation loss: 15.2662, Validation accuracy: 0.7792\n",
      "\n",
      "Current learning rate has decayed to 0.000004\n",
      "Epoch 191:\n",
      "Training loss: 1.1440, Training accuracy: 0.8560\n",
      "Validation loss: 15.8096, Validation accuracy: 0.7790\n",
      "\n",
      "Current learning rate has decayed to 0.000004\n",
      "Epoch 192:\n",
      "Training loss: 1.1518, Training accuracy: 0.8541\n",
      "Validation loss: 17.7161, Validation accuracy: 0.7771\n",
      "\n",
      "Current learning rate has decayed to 0.000004\n",
      "Epoch 193:\n",
      "Training loss: 1.1397, Training accuracy: 0.8558\n",
      "Validation loss: 19.0509, Validation accuracy: 0.7771\n",
      "\n",
      "Current learning rate has decayed to 0.000004\n",
      "Epoch 194:\n",
      "Training loss: 1.1471, Training accuracy: 0.8544\n",
      "Validation loss: 12.6029, Validation accuracy: 0.7804\n",
      "\n",
      "Current learning rate has decayed to 0.000003\n",
      "Epoch 195:\n",
      "Training loss: 1.1495, Training accuracy: 0.8544\n",
      "Validation loss: 12.6969, Validation accuracy: 0.7799\n",
      "\n",
      "Current learning rate has decayed to 0.000003\n",
      "Epoch 196:\n",
      "Training loss: 1.1475, Training accuracy: 0.8542\n",
      "Validation loss: 15.7957, Validation accuracy: 0.7781\n",
      "\n",
      "Current learning rate has decayed to 0.000003\n",
      "Epoch 197:\n",
      "Training loss: 1.1516, Training accuracy: 0.8546\n",
      "Validation loss: 12.2313, Validation accuracy: 0.7809\n",
      "\n",
      "Current learning rate has decayed to 0.000003\n",
      "Epoch 198:\n",
      "Training loss: 1.1502, Training accuracy: 0.8522\n",
      "Validation loss: 9.0628, Validation accuracy: 0.7822\n",
      "\n",
      "Current learning rate has decayed to 0.000003\n",
      "Epoch 199:\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_672/1254288282.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlamb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.6\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mval_loader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mINITIAL_LR\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mDECAY_EPOCHS\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mDECAY\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.96\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_672/3317302493.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(T, lamb, alpha, train_loader, val_loader, INITIAL_LR, DECAY_EPOCHS, DECAY, EPOCHS, REG)\u001b[0m\n\u001b[1;32m     81\u001b[0m             \u001b[0;31m# apply gradient and update the weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m             \u001b[0mtrain_loss\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m             \u001b[0;31m# count the number of correctly predicted samples in the current batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(T=2,lamb=0.1,alpha=0.6,train_loader=train_loader,val_loader=val_loader,INITIAL_LR=0.01,DECAY_EPOCHS=1,DECAY=0.96,EPOCHS=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Training starts!\n",
      "==================================================\n",
      "Epoch 0:\n",
      "Training loss: 7.4699, Training accuracy: 0.3456\n",
      "Validation loss: 1.7335, Validation accuracy: 0.4443\n",
      "Saving ...\n",
      "\n",
      "Epoch 1:\n",
      "Training loss: 5.9567, Training accuracy: 0.4718\n",
      "Validation loss: 1.3902, Validation accuracy: 0.5137\n",
      "Saving ...\n",
      "\n",
      "Epoch 2:\n",
      "Training loss: 5.2342, Training accuracy: 0.5369\n",
      "Validation loss: 1.6304, Validation accuracy: 0.5766\n",
      "Saving ...\n",
      "\n",
      "Epoch 3:\n",
      "Training loss: 4.7386, Training accuracy: 0.5849\n",
      "Validation loss: 1.2054, Validation accuracy: 0.6172\n",
      "Saving ...\n",
      "\n",
      "Epoch 4:\n",
      "Training loss: 4.3893, Training accuracy: 0.6161\n",
      "Validation loss: 1.5881, Validation accuracy: 0.6299\n",
      "Saving ...\n",
      "\n",
      "Epoch 5:\n",
      "Training loss: 2.8000, Training accuracy: 0.6154\n",
      "Validation loss: 1.1984, Validation accuracy: 0.5752\n",
      "\n",
      "Epoch 6:\n",
      "Training loss: 3.0001, Training accuracy: 0.5600\n",
      "Validation loss: 1.2919, Validation accuracy: 0.5789\n",
      "\n",
      "Epoch 7:\n",
      "Training loss: 2.6126, Training accuracy: 0.6102\n",
      "Validation loss: 1.1215, Validation accuracy: 0.6632\n",
      "Saving ...\n",
      "\n",
      "Epoch 8:\n",
      "Training loss: 2.2391, Training accuracy: 0.6645\n",
      "Validation loss: 0.9048, Validation accuracy: 0.6953\n",
      "Saving ...\n",
      "\n",
      "Epoch 9:\n",
      "Training loss: 2.2373, Training accuracy: 0.6658\n",
      "Validation loss: 0.9818, Validation accuracy: 0.6784\n",
      "\n",
      "Epoch 10:\n",
      "Training loss: 2.1800, Training accuracy: 0.6762\n",
      "Validation loss: 0.9217, Validation accuracy: 0.7040\n",
      "Saving ...\n",
      "\n",
      "Epoch 11:\n",
      "Training loss: 2.0824, Training accuracy: 0.6908\n",
      "Validation loss: 0.8849, Validation accuracy: 0.7012\n",
      "\n",
      "Epoch 12:\n",
      "Training loss: 1.9155, Training accuracy: 0.7127\n",
      "Validation loss: 0.8381, Validation accuracy: 0.7190\n",
      "Saving ...\n",
      "\n",
      "Epoch 13:\n",
      "Training loss: 1.7868, Training accuracy: 0.7315\n",
      "Validation loss: 0.7689, Validation accuracy: 0.7366\n",
      "Saving ...\n",
      "\n",
      "Epoch 14:\n",
      "Training loss: 1.8221, Training accuracy: 0.7284\n",
      "Validation loss: 1.3055, Validation accuracy: 0.5664\n",
      "\n",
      "Epoch 15:\n",
      "Training loss: 2.1011, Training accuracy: 0.6864\n",
      "Validation loss: 0.9776, Validation accuracy: 0.7249\n",
      "\n",
      "Epoch 16:\n",
      "Training loss: 1.7896, Training accuracy: 0.7345\n",
      "Validation loss: 0.7565, Validation accuracy: 0.7478\n",
      "Saving ...\n",
      "\n",
      "Epoch 17:\n",
      "Training loss: 1.7001, Training accuracy: 0.7477\n",
      "Validation loss: 0.7486, Validation accuracy: 0.7418\n",
      "\n",
      "Epoch 18:\n",
      "Training loss: 1.6051, Training accuracy: 0.7612\n",
      "Validation loss: 0.7065, Validation accuracy: 0.7572\n",
      "Saving ...\n",
      "\n",
      "Epoch 19:\n",
      "Training loss: 1.5271, Training accuracy: 0.7724\n",
      "Validation loss: 0.6850, Validation accuracy: 0.7649\n",
      "Saving ...\n",
      "\n",
      "Epoch 20:\n",
      "Training loss: 1.4825, Training accuracy: 0.7805\n",
      "Validation loss: 0.6663, Validation accuracy: 0.7725\n",
      "Saving ...\n",
      "\n",
      "Epoch 21:\n",
      "Training loss: 1.4414, Training accuracy: 0.7868\n",
      "Validation loss: 0.6725, Validation accuracy: 0.7704\n",
      "\n",
      "Epoch 22:\n",
      "Training loss: 1.3908, Training accuracy: 0.7953\n",
      "Validation loss: 0.6443, Validation accuracy: 0.7792\n",
      "Saving ...\n",
      "\n",
      "Epoch 23:\n",
      "Training loss: 1.3610, Training accuracy: 0.8010\n",
      "Validation loss: 0.6350, Validation accuracy: 0.7839\n",
      "Saving ...\n",
      "\n",
      "Epoch 24:\n",
      "Training loss: 1.3974, Training accuracy: 0.7936\n",
      "Validation loss: 0.6234, Validation accuracy: 0.7866\n",
      "Saving ...\n",
      "\n",
      "Epoch 25:\n",
      "Training loss: 1.3106, Training accuracy: 0.8077\n",
      "Validation loss: 0.6252, Validation accuracy: 0.7833\n",
      "\n",
      "Epoch 26:\n",
      "Training loss: 1.2791, Training accuracy: 0.8147\n",
      "Validation loss: 0.6106, Validation accuracy: 0.7913\n",
      "Saving ...\n",
      "\n",
      "Epoch 27:\n",
      "Training loss: 1.2403, Training accuracy: 0.8206\n",
      "Validation loss: 0.6027, Validation accuracy: 0.7956\n",
      "Saving ...\n",
      "\n",
      "Epoch 28:\n",
      "Training loss: 1.2045, Training accuracy: 0.8250\n",
      "Validation loss: 0.6152, Validation accuracy: 0.7883\n",
      "\n",
      "Epoch 29:\n",
      "Training loss: 1.1845, Training accuracy: 0.8285\n",
      "Validation loss: 0.5833, Validation accuracy: 0.8044\n",
      "Saving ...\n",
      "\n",
      "Epoch 30:\n",
      "Training loss: 1.1621, Training accuracy: 0.8320\n",
      "Validation loss: 0.5898, Validation accuracy: 0.8044\n",
      "\n",
      "Epoch 31:\n",
      "Training loss: 1.1410, Training accuracy: 0.8361\n",
      "Validation loss: 0.5751, Validation accuracy: 0.8067\n",
      "Saving ...\n",
      "\n",
      "Epoch 32:\n",
      "Training loss: 1.1159, Training accuracy: 0.8402\n",
      "Validation loss: 0.6026, Validation accuracy: 0.7967\n",
      "\n",
      "Epoch 33:\n",
      "Training loss: 1.0911, Training accuracy: 0.8432\n",
      "Validation loss: 0.5885, Validation accuracy: 0.8028\n",
      "\n",
      "Epoch 34:\n",
      "Training loss: 1.0720, Training accuracy: 0.8470\n",
      "Validation loss: 0.5768, Validation accuracy: 0.8047\n",
      "\n",
      "Epoch 35:\n",
      "Training loss: 1.0513, Training accuracy: 0.8496\n",
      "Validation loss: 0.5658, Validation accuracy: 0.8125\n",
      "Saving ...\n",
      "\n",
      "Epoch 36:\n",
      "Training loss: 1.0333, Training accuracy: 0.8543\n",
      "Validation loss: 0.5511, Validation accuracy: 0.8152\n",
      "Saving ...\n",
      "\n",
      "Epoch 37:\n",
      "Training loss: 1.0130, Training accuracy: 0.8571\n",
      "Validation loss: 0.5498, Validation accuracy: 0.8150\n",
      "\n",
      "Epoch 38:\n",
      "Training loss: 0.9957, Training accuracy: 0.8580\n",
      "Validation loss: 0.5678, Validation accuracy: 0.8119\n",
      "\n",
      "Epoch 39:\n",
      "Training loss: 0.9836, Training accuracy: 0.8600\n",
      "Validation loss: 0.5494, Validation accuracy: 0.8167\n",
      "Saving ...\n",
      "\n",
      "Epoch 40:\n",
      "Training loss: 0.9647, Training accuracy: 0.8646\n",
      "Validation loss: 0.5576, Validation accuracy: 0.8190\n",
      "Saving ...\n",
      "\n",
      "Epoch 41:\n",
      "Training loss: 0.9468, Training accuracy: 0.8662\n",
      "Validation loss: 0.5732, Validation accuracy: 0.8134\n",
      "\n",
      "Epoch 42:\n",
      "Training loss: 0.9307, Training accuracy: 0.8692\n",
      "Validation loss: 0.5307, Validation accuracy: 0.8261\n",
      "Saving ...\n",
      "\n",
      "Epoch 43:\n",
      "Training loss: 0.9104, Training accuracy: 0.8738\n",
      "Validation loss: 0.5492, Validation accuracy: 0.8246\n",
      "\n",
      "Epoch 44:\n",
      "Training loss: 0.8934, Training accuracy: 0.8756\n",
      "Validation loss: 0.5584, Validation accuracy: 0.8146\n",
      "\n",
      "Epoch 45:\n",
      "Training loss: 0.8804, Training accuracy: 0.8766\n",
      "Validation loss: 0.5586, Validation accuracy: 0.8143\n",
      "\n",
      "Epoch 46:\n",
      "Training loss: 0.8636, Training accuracy: 0.8830\n",
      "Validation loss: 0.5356, Validation accuracy: 0.8240\n",
      "\n",
      "Epoch 47:\n",
      "Training loss: 0.8580, Training accuracy: 0.8816\n",
      "Validation loss: 0.5334, Validation accuracy: 0.8283\n",
      "Saving ...\n",
      "\n",
      "Epoch 48:\n",
      "Training loss: 0.8388, Training accuracy: 0.8856\n",
      "Validation loss: 0.5487, Validation accuracy: 0.8210\n",
      "\n",
      "Epoch 49:\n",
      "Training loss: 0.8210, Training accuracy: 0.8881\n",
      "Validation loss: 0.5470, Validation accuracy: 0.8235\n",
      "\n",
      "Epoch 50:\n",
      "Training loss: 0.8071, Training accuracy: 0.8903\n",
      "Validation loss: 0.5385, Validation accuracy: 0.8268\n",
      "\n",
      "Epoch 51:\n",
      "Training loss: 0.8029, Training accuracy: 0.8911\n",
      "Validation loss: 0.5510, Validation accuracy: 0.8235\n",
      "\n",
      "Epoch 52:\n",
      "Training loss: 0.7845, Training accuracy: 0.8942\n",
      "Validation loss: 0.5409, Validation accuracy: 0.8286\n",
      "Saving ...\n",
      "\n",
      "Epoch 53:\n",
      "Training loss: 0.7726, Training accuracy: 0.8965\n",
      "Validation loss: 0.5353, Validation accuracy: 0.8267\n",
      "\n",
      "Epoch 54:\n",
      "Training loss: 0.7583, Training accuracy: 0.8984\n",
      "Validation loss: 0.5372, Validation accuracy: 0.8344\n",
      "Saving ...\n",
      "\n",
      "Epoch 55:\n",
      "Training loss: 0.7483, Training accuracy: 0.9016\n",
      "Validation loss: 0.5447, Validation accuracy: 0.8304\n",
      "\n",
      "Epoch 56:\n",
      "Training loss: 0.7419, Training accuracy: 0.9009\n",
      "Validation loss: 0.5397, Validation accuracy: 0.8316\n",
      "\n",
      "Epoch 57:\n",
      "Training loss: 0.7205, Training accuracy: 0.9058\n",
      "Validation loss: 0.5203, Validation accuracy: 0.8372\n",
      "Saving ...\n",
      "\n",
      "Epoch 58:\n",
      "Training loss: 0.7222, Training accuracy: 0.9045\n",
      "Validation loss: 0.5297, Validation accuracy: 0.8333\n",
      "\n",
      "Epoch 59:\n",
      "Training loss: 0.7154, Training accuracy: 0.9052\n",
      "Validation loss: 0.5553, Validation accuracy: 0.8312\n",
      "\n",
      "Current learning rate has decayed to 0.001000\n",
      "Epoch 60:\n",
      "Training loss: 0.5922, Training accuracy: 0.9246\n",
      "Validation loss: 0.4930, Validation accuracy: 0.8472\n",
      "Saving ...\n",
      "\n",
      "Epoch 61:\n",
      "Training loss: 0.5473, Training accuracy: 0.9316\n",
      "Validation loss: 0.4976, Validation accuracy: 0.8456\n",
      "\n",
      "Epoch 62:\n",
      "Training loss: 0.5382, Training accuracy: 0.9318\n",
      "Validation loss: 0.4959, Validation accuracy: 0.8478\n",
      "Saving ...\n",
      "\n",
      "Epoch 63:\n",
      "Training loss: 0.5248, Training accuracy: 0.9365\n",
      "Validation loss: 0.4998, Validation accuracy: 0.8486\n",
      "Saving ...\n",
      "\n",
      "Epoch 64:\n",
      "Training loss: 0.5200, Training accuracy: 0.9359\n",
      "Validation loss: 0.4999, Validation accuracy: 0.8484\n",
      "\n",
      "Epoch 65:\n",
      "Training loss: 0.5191, Training accuracy: 0.9358\n",
      "Validation loss: 0.5032, Validation accuracy: 0.8479\n",
      "\n",
      "Epoch 66:\n",
      "Training loss: 0.5086, Training accuracy: 0.9381\n",
      "Validation loss: 0.5069, Validation accuracy: 0.8499\n",
      "Saving ...\n",
      "\n",
      "Epoch 67:\n",
      "Training loss: 0.5035, Training accuracy: 0.9378\n",
      "Validation loss: 0.5054, Validation accuracy: 0.8474\n",
      "\n",
      "Epoch 68:\n",
      "Training loss: 0.5016, Training accuracy: 0.9396\n",
      "Validation loss: 0.5078, Validation accuracy: 0.8498\n",
      "\n",
      "Epoch 69:\n",
      "Training loss: 0.4937, Training accuracy: 0.9405\n",
      "Validation loss: 0.5093, Validation accuracy: 0.8483\n",
      "\n",
      "Epoch 70:\n",
      "Training loss: 0.4929, Training accuracy: 0.9412\n",
      "Validation loss: 0.5102, Validation accuracy: 0.8468\n",
      "\n",
      "Epoch 71:\n",
      "Training loss: 0.4903, Training accuracy: 0.9412\n",
      "Validation loss: 0.5115, Validation accuracy: 0.8475\n",
      "\n",
      "Epoch 72:\n",
      "Training loss: 0.4827, Training accuracy: 0.9417\n",
      "Validation loss: 0.5114, Validation accuracy: 0.8485\n",
      "\n",
      "Epoch 73:\n",
      "Training loss: 0.4779, Training accuracy: 0.9427\n",
      "Validation loss: 0.5145, Validation accuracy: 0.8484\n",
      "\n",
      "Epoch 74:\n",
      "Training loss: 0.4809, Training accuracy: 0.9419\n",
      "Validation loss: 0.5162, Validation accuracy: 0.8467\n",
      "\n",
      "Epoch 75:\n",
      "Training loss: 0.4732, Training accuracy: 0.9439\n",
      "Validation loss: 0.5148, Validation accuracy: 0.8490\n",
      "\n",
      "Epoch 76:\n",
      "Training loss: 0.4703, Training accuracy: 0.9439\n",
      "Validation loss: 0.5160, Validation accuracy: 0.8494\n",
      "\n",
      "Epoch 77:\n",
      "Training loss: 0.4582, Training accuracy: 0.9477\n",
      "Validation loss: 0.5184, Validation accuracy: 0.8503\n",
      "Saving ...\n",
      "\n",
      "Epoch 78:\n",
      "Training loss: 0.4676, Training accuracy: 0.9442\n",
      "Validation loss: 0.5190, Validation accuracy: 0.8494\n",
      "\n",
      "Epoch 79:\n",
      "Training loss: 0.4664, Training accuracy: 0.9432\n",
      "Validation loss: 0.5158, Validation accuracy: 0.8495\n",
      "\n",
      "Epoch 80:\n",
      "Training loss: 0.4597, Training accuracy: 0.9459\n",
      "Validation loss: 0.5227, Validation accuracy: 0.8499\n",
      "\n",
      "Epoch 81:\n",
      "Training loss: 0.4645, Training accuracy: 0.9450\n",
      "Validation loss: 0.5198, Validation accuracy: 0.8512\n",
      "Saving ...\n",
      "\n",
      "Epoch 82:\n",
      "Training loss: 0.4547, Training accuracy: 0.9477\n",
      "Validation loss: 0.5222, Validation accuracy: 0.8504\n",
      "\n",
      "Epoch 83:\n",
      "Training loss: 0.4502, Training accuracy: 0.9466\n",
      "Validation loss: 0.5275, Validation accuracy: 0.8508\n",
      "\n",
      "Epoch 84:\n",
      "Training loss: 0.4503, Training accuracy: 0.9482\n",
      "Validation loss: 0.5256, Validation accuracy: 0.8495\n",
      "\n",
      "Epoch 85:\n",
      "Training loss: 0.4506, Training accuracy: 0.9483\n",
      "Validation loss: 0.5288, Validation accuracy: 0.8489\n",
      "\n",
      "Epoch 86:\n",
      "Training loss: 0.4470, Training accuracy: 0.9486\n",
      "Validation loss: 0.5278, Validation accuracy: 0.8478\n",
      "\n",
      "Epoch 87:\n",
      "Training loss: 0.4445, Training accuracy: 0.9479\n",
      "Validation loss: 0.5264, Validation accuracy: 0.8489\n",
      "\n",
      "Epoch 88:\n",
      "Training loss: 0.4430, Training accuracy: 0.9484\n",
      "Validation loss: 0.5322, Validation accuracy: 0.8503\n",
      "\n",
      "Epoch 89:\n",
      "Training loss: 0.4361, Training accuracy: 0.9505\n",
      "Validation loss: 0.5312, Validation accuracy: 0.8488\n",
      "\n",
      "Epoch 90:\n",
      "Training loss: 0.4344, Training accuracy: 0.9498\n",
      "Validation loss: 0.5245, Validation accuracy: 0.8523\n",
      "Saving ...\n",
      "\n",
      "Epoch 91:\n",
      "Training loss: 0.4372, Training accuracy: 0.9497\n",
      "Validation loss: 0.5328, Validation accuracy: 0.8509\n",
      "\n",
      "Epoch 92:\n",
      "Training loss: 0.4283, Training accuracy: 0.9511\n",
      "Validation loss: 0.5358, Validation accuracy: 0.8478\n",
      "\n",
      "Epoch 93:\n",
      "Training loss: 0.4328, Training accuracy: 0.9498\n",
      "Validation loss: 0.5339, Validation accuracy: 0.8505\n",
      "\n",
      "Epoch 94:\n",
      "Training loss: 0.4317, Training accuracy: 0.9500\n",
      "Validation loss: 0.5338, Validation accuracy: 0.8502\n",
      "\n",
      "Epoch 95:\n",
      "Training loss: 0.4220, Training accuracy: 0.9523\n",
      "Validation loss: 0.5356, Validation accuracy: 0.8506\n",
      "\n",
      "Epoch 96:\n",
      "Training loss: 0.4193, Training accuracy: 0.9520\n",
      "Validation loss: 0.5348, Validation accuracy: 0.8496\n",
      "\n",
      "Epoch 97:\n",
      "Training loss: 0.4217, Training accuracy: 0.9523\n",
      "Validation loss: 0.5371, Validation accuracy: 0.8501\n",
      "\n",
      "Epoch 98:\n",
      "Training loss: 0.4183, Training accuracy: 0.9523\n",
      "Validation loss: 0.5396, Validation accuracy: 0.8517\n",
      "\n",
      "Epoch 99:\n",
      "Training loss: 0.4182, Training accuracy: 0.9543\n",
      "Validation loss: 0.5379, Validation accuracy: 0.8493\n",
      "\n",
      "Epoch 100:\n",
      "Training loss: 0.4199, Training accuracy: 0.9523\n",
      "Validation loss: 0.5407, Validation accuracy: 0.8507\n",
      "\n",
      "Epoch 101:\n",
      "Training loss: 0.4171, Training accuracy: 0.9537\n",
      "Validation loss: 0.5448, Validation accuracy: 0.8475\n",
      "\n",
      "Epoch 102:\n",
      "Training loss: 0.4141, Training accuracy: 0.9532\n",
      "Validation loss: 0.5375, Validation accuracy: 0.8485\n",
      "\n",
      "Epoch 103:\n",
      "Training loss: 0.4094, Training accuracy: 0.9536\n",
      "Validation loss: 0.5395, Validation accuracy: 0.8483\n",
      "\n",
      "Epoch 104:\n",
      "Training loss: 0.4134, Training accuracy: 0.9539\n",
      "Validation loss: 0.5410, Validation accuracy: 0.8489\n",
      "\n",
      "Epoch 105:\n",
      "Training loss: 0.4102, Training accuracy: 0.9557\n",
      "Validation loss: 0.5472, Validation accuracy: 0.8468\n",
      "\n",
      "Epoch 106:\n",
      "Training loss: 0.4050, Training accuracy: 0.9543\n",
      "Validation loss: 0.5395, Validation accuracy: 0.8512\n",
      "\n",
      "Epoch 107:\n",
      "Training loss: 0.4035, Training accuracy: 0.9552\n",
      "Validation loss: 0.5400, Validation accuracy: 0.8479\n",
      "\n",
      "Epoch 108:\n",
      "Training loss: 0.3978, Training accuracy: 0.9564\n",
      "Validation loss: 0.5469, Validation accuracy: 0.8488\n",
      "\n",
      "Epoch 109:\n",
      "Training loss: 0.4021, Training accuracy: 0.9552\n",
      "Validation loss: 0.5473, Validation accuracy: 0.8495\n",
      "\n",
      "Epoch 110:\n",
      "Training loss: 0.3901, Training accuracy: 0.9574\n",
      "Validation loss: 0.5530, Validation accuracy: 0.8495\n",
      "\n",
      "Epoch 111:\n",
      "Training loss: 0.3942, Training accuracy: 0.9569\n",
      "Validation loss: 0.5521, Validation accuracy: 0.8480\n",
      "\n",
      "Epoch 112:\n",
      "Training loss: 0.3930, Training accuracy: 0.9568\n",
      "Validation loss: 0.5576, Validation accuracy: 0.8486\n",
      "\n",
      "Epoch 113:\n",
      "Training loss: 0.3870, Training accuracy: 0.9580\n",
      "Validation loss: 0.5564, Validation accuracy: 0.8484\n",
      "\n",
      "Epoch 114:\n",
      "Training loss: 0.3871, Training accuracy: 0.9574\n",
      "Validation loss: 0.5548, Validation accuracy: 0.8505\n",
      "\n",
      "Epoch 115:\n",
      "Training loss: 0.3875, Training accuracy: 0.9575\n",
      "Validation loss: 0.5621, Validation accuracy: 0.8474\n",
      "\n",
      "Epoch 116:\n",
      "Training loss: 0.3893, Training accuracy: 0.9572\n",
      "Validation loss: 0.5546, Validation accuracy: 0.8507\n",
      "\n",
      "Epoch 117:\n",
      "Training loss: 0.3761, Training accuracy: 0.9600\n",
      "Validation loss: 0.5573, Validation accuracy: 0.8489\n",
      "\n",
      "Epoch 118:\n",
      "Training loss: 0.3866, Training accuracy: 0.9573\n",
      "Validation loss: 0.5600, Validation accuracy: 0.8499\n",
      "\n",
      "Epoch 119:\n",
      "Training loss: 0.3817, Training accuracy: 0.9575\n",
      "Validation loss: 0.5596, Validation accuracy: 0.8483\n",
      "\n",
      "Current learning rate has decayed to 0.000100\n",
      "Epoch 120:\n",
      "Training loss: 0.3665, Training accuracy: 0.9614\n",
      "Validation loss: 0.5547, Validation accuracy: 0.8490\n",
      "\n",
      "Epoch 121:\n",
      "Training loss: 0.3600, Training accuracy: 0.9622\n",
      "Validation loss: 0.5564, Validation accuracy: 0.8499\n",
      "\n",
      "Epoch 122:\n",
      "Training loss: 0.3602, Training accuracy: 0.9621\n",
      "Validation loss: 0.5592, Validation accuracy: 0.8498\n",
      "\n",
      "Epoch 123:\n",
      "Training loss: 0.3547, Training accuracy: 0.9613\n",
      "Validation loss: 0.5563, Validation accuracy: 0.8491\n",
      "\n",
      "Epoch 124:\n",
      "Training loss: 0.3579, Training accuracy: 0.9627\n",
      "Validation loss: 0.5553, Validation accuracy: 0.8497\n",
      "\n",
      "Epoch 125:\n",
      "Training loss: 0.3540, Training accuracy: 0.9629\n",
      "Validation loss: 0.5544, Validation accuracy: 0.8497\n",
      "\n",
      "Epoch 126:\n",
      "Training loss: 0.3585, Training accuracy: 0.9616\n",
      "Validation loss: 0.5579, Validation accuracy: 0.8506\n",
      "\n",
      "Epoch 127:\n",
      "Training loss: 0.3561, Training accuracy: 0.9621\n",
      "Validation loss: 0.5583, Validation accuracy: 0.8504\n",
      "\n",
      "Epoch 128:\n",
      "Training loss: 0.3579, Training accuracy: 0.9618\n",
      "Validation loss: 0.5584, Validation accuracy: 0.8500\n",
      "\n",
      "Epoch 129:\n",
      "Training loss: 0.3542, Training accuracy: 0.9629\n",
      "Validation loss: 0.5567, Validation accuracy: 0.8513\n",
      "\n",
      "Epoch 130:\n",
      "Training loss: 0.3580, Training accuracy: 0.9613\n",
      "Validation loss: 0.5567, Validation accuracy: 0.8506\n",
      "\n",
      "Epoch 131:\n",
      "Training loss: 0.3563, Training accuracy: 0.9632\n",
      "Validation loss: 0.5571, Validation accuracy: 0.8510\n",
      "\n",
      "Epoch 132:\n",
      "Training loss: 0.3519, Training accuracy: 0.9629\n",
      "Validation loss: 0.5583, Validation accuracy: 0.8502\n",
      "\n",
      "Epoch 133:\n",
      "Training loss: 0.3570, Training accuracy: 0.9626\n",
      "Validation loss: 0.5600, Validation accuracy: 0.8488\n",
      "\n",
      "Epoch 134:\n",
      "Training loss: 0.3534, Training accuracy: 0.9628\n",
      "Validation loss: 0.5611, Validation accuracy: 0.8499\n",
      "\n",
      "Epoch 135:\n",
      "Training loss: 0.3555, Training accuracy: 0.9619\n",
      "Validation loss: 0.5597, Validation accuracy: 0.8501\n",
      "\n",
      "Epoch 136:\n",
      "Training loss: 0.3531, Training accuracy: 0.9621\n",
      "Validation loss: 0.5646, Validation accuracy: 0.8488\n",
      "\n",
      "Epoch 137:\n",
      "Training loss: 0.3549, Training accuracy: 0.9622\n",
      "Validation loss: 0.5587, Validation accuracy: 0.8499\n",
      "\n",
      "Epoch 138:\n",
      "Training loss: 0.3556, Training accuracy: 0.9627\n",
      "Validation loss: 0.5587, Validation accuracy: 0.8499\n",
      "\n",
      "Epoch 139:\n",
      "Training loss: 0.3495, Training accuracy: 0.9635\n",
      "Validation loss: 0.5603, Validation accuracy: 0.8509\n",
      "\n",
      "Epoch 140:\n",
      "Training loss: 0.3511, Training accuracy: 0.9631\n",
      "Validation loss: 0.5611, Validation accuracy: 0.8495\n",
      "\n",
      "Epoch 141:\n",
      "Training loss: 0.3505, Training accuracy: 0.9627\n",
      "Validation loss: 0.5602, Validation accuracy: 0.8482\n",
      "\n",
      "Epoch 142:\n",
      "Training loss: 0.3502, Training accuracy: 0.9632\n",
      "Validation loss: 0.5583, Validation accuracy: 0.8508\n",
      "\n",
      "Epoch 143:\n",
      "Training loss: 0.3566, Training accuracy: 0.9617\n",
      "Validation loss: 0.5580, Validation accuracy: 0.8490\n",
      "\n",
      "Epoch 144:\n",
      "Training loss: 0.3487, Training accuracy: 0.9639\n",
      "Validation loss: 0.5607, Validation accuracy: 0.8501\n",
      "\n",
      "Epoch 145:\n",
      "Training loss: 0.3513, Training accuracy: 0.9624\n",
      "Validation loss: 0.5604, Validation accuracy: 0.8521\n",
      "\n",
      "Epoch 146:\n",
      "Training loss: 0.3492, Training accuracy: 0.9635\n",
      "Validation loss: 0.5624, Validation accuracy: 0.8503\n",
      "\n",
      "Epoch 147:\n",
      "Training loss: 0.3491, Training accuracy: 0.9643\n",
      "Validation loss: 0.5633, Validation accuracy: 0.8489\n",
      "\n",
      "Epoch 148:\n",
      "Training loss: 0.3500, Training accuracy: 0.9634\n",
      "Validation loss: 0.5585, Validation accuracy: 0.8508\n",
      "\n",
      "Epoch 149:\n",
      "Training loss: 0.3528, Training accuracy: 0.9639\n",
      "Validation loss: 0.5617, Validation accuracy: 0.8496\n",
      "\n",
      "Epoch 150:\n",
      "Training loss: 0.3489, Training accuracy: 0.9637\n",
      "Validation loss: 0.5600, Validation accuracy: 0.8498\n",
      "\n",
      "Epoch 151:\n",
      "Training loss: 0.3420, Training accuracy: 0.9649\n",
      "Validation loss: 0.5630, Validation accuracy: 0.8492\n",
      "\n",
      "Epoch 152:\n",
      "Training loss: 0.3519, Training accuracy: 0.9637\n",
      "Validation loss: 0.5592, Validation accuracy: 0.8489\n",
      "\n",
      "Epoch 153:\n",
      "Training loss: 0.3479, Training accuracy: 0.9640\n",
      "Validation loss: 0.5600, Validation accuracy: 0.8506\n",
      "\n",
      "Epoch 154:\n",
      "Training loss: 0.3470, Training accuracy: 0.9636\n",
      "Validation loss: 0.5570, Validation accuracy: 0.8494\n",
      "\n",
      "Epoch 155:\n",
      "Training loss: 0.3464, Training accuracy: 0.9635\n",
      "Validation loss: 0.5660, Validation accuracy: 0.8477\n",
      "\n",
      "Epoch 156:\n",
      "Training loss: 0.3485, Training accuracy: 0.9637\n",
      "Validation loss: 0.5606, Validation accuracy: 0.8493\n",
      "\n",
      "Epoch 157:\n",
      "Training loss: 0.3493, Training accuracy: 0.9629\n",
      "Validation loss: 0.5634, Validation accuracy: 0.8495\n",
      "\n",
      "Epoch 158:\n",
      "Training loss: 0.3521, Training accuracy: 0.9628\n",
      "Validation loss: 0.5633, Validation accuracy: 0.8489\n",
      "\n",
      "Epoch 159:\n",
      "Training loss: 0.3496, Training accuracy: 0.9638\n",
      "Validation loss: 0.5661, Validation accuracy: 0.8495\n",
      "\n",
      "Epoch 160:\n",
      "Training loss: 0.3513, Training accuracy: 0.9623\n",
      "Validation loss: 0.5595, Validation accuracy: 0.8501\n",
      "\n",
      "Epoch 161:\n",
      "Training loss: 0.3416, Training accuracy: 0.9640\n",
      "Validation loss: 0.5650, Validation accuracy: 0.8507\n",
      "\n",
      "Epoch 162:\n",
      "Training loss: 0.3428, Training accuracy: 0.9643\n",
      "Validation loss: 0.5625, Validation accuracy: 0.8510\n",
      "\n",
      "Epoch 163:\n",
      "Training loss: 0.3473, Training accuracy: 0.9628\n",
      "Validation loss: 0.5620, Validation accuracy: 0.8515\n",
      "\n",
      "Epoch 164:\n",
      "Training loss: 0.3444, Training accuracy: 0.9649\n",
      "Validation loss: 0.5644, Validation accuracy: 0.8508\n",
      "\n",
      "Epoch 165:\n",
      "Training loss: 0.3485, Training accuracy: 0.9633\n",
      "Validation loss: 0.5635, Validation accuracy: 0.8508\n",
      "\n",
      "Epoch 166:\n",
      "Training loss: 0.3441, Training accuracy: 0.9635\n",
      "Validation loss: 0.5639, Validation accuracy: 0.8502\n",
      "\n",
      "Epoch 167:\n",
      "Training loss: 0.3420, Training accuracy: 0.9650\n",
      "Validation loss: 0.5636, Validation accuracy: 0.8509\n",
      "\n",
      "Epoch 168:\n",
      "Training loss: 0.3427, Training accuracy: 0.9647\n",
      "Validation loss: 0.5677, Validation accuracy: 0.8502\n",
      "\n",
      "Epoch 169:\n",
      "Training loss: 0.3490, Training accuracy: 0.9632\n",
      "Validation loss: 0.5628, Validation accuracy: 0.8501\n",
      "\n",
      "Epoch 170:\n",
      "Training loss: 0.3418, Training accuracy: 0.9649\n",
      "Validation loss: 0.5642, Validation accuracy: 0.8478\n",
      "\n",
      "Epoch 171:\n",
      "Training loss: 0.3475, Training accuracy: 0.9631\n",
      "Validation loss: 0.5626, Validation accuracy: 0.8498\n",
      "\n",
      "Epoch 172:\n",
      "Training loss: 0.3482, Training accuracy: 0.9626\n",
      "Validation loss: 0.5625, Validation accuracy: 0.8512\n",
      "\n",
      "Epoch 173:\n",
      "Training loss: 0.3408, Training accuracy: 0.9649\n",
      "Validation loss: 0.5653, Validation accuracy: 0.8487\n",
      "\n",
      "Epoch 174:\n",
      "Training loss: 0.3404, Training accuracy: 0.9646\n",
      "Validation loss: 0.5606, Validation accuracy: 0.8494\n",
      "\n",
      "Epoch 175:\n",
      "Training loss: 0.3404, Training accuracy: 0.9655\n",
      "Validation loss: 0.5648, Validation accuracy: 0.8514\n",
      "\n",
      "Epoch 176:\n",
      "Training loss: 0.3406, Training accuracy: 0.9638\n",
      "Validation loss: 0.5639, Validation accuracy: 0.8513\n",
      "\n",
      "Epoch 177:\n",
      "Training loss: 0.3436, Training accuracy: 0.9651\n",
      "Validation loss: 0.5631, Validation accuracy: 0.8508\n",
      "\n",
      "Epoch 178:\n",
      "Training loss: 0.3423, Training accuracy: 0.9641\n",
      "Validation loss: 0.5659, Validation accuracy: 0.8494\n",
      "\n",
      "Epoch 179:\n",
      "Training loss: 0.3411, Training accuracy: 0.9654\n",
      "Validation loss: 0.5624, Validation accuracy: 0.8507\n",
      "\n",
      "Current learning rate has decayed to 0.000010\n",
      "Epoch 180:\n",
      "Training loss: 0.3414, Training accuracy: 0.9653\n",
      "Validation loss: 0.5693, Validation accuracy: 0.8503\n",
      "\n",
      "Epoch 181:\n",
      "Training loss: 0.3404, Training accuracy: 0.9650\n",
      "Validation loss: 0.5659, Validation accuracy: 0.8509\n",
      "\n",
      "Epoch 182:\n",
      "Training loss: 0.3341, Training accuracy: 0.9657\n",
      "Validation loss: 0.5612, Validation accuracy: 0.8507\n",
      "\n",
      "Epoch 183:\n",
      "Training loss: 0.3375, Training accuracy: 0.9647\n",
      "Validation loss: 0.5642, Validation accuracy: 0.8499\n",
      "\n",
      "Epoch 184:\n",
      "Training loss: 0.3352, Training accuracy: 0.9662\n",
      "Validation loss: 0.5644, Validation accuracy: 0.8495\n",
      "\n",
      "Epoch 185:\n",
      "Training loss: 0.3346, Training accuracy: 0.9663\n",
      "Validation loss: 0.5646, Validation accuracy: 0.8498\n",
      "\n",
      "Epoch 186:\n",
      "Training loss: 0.3413, Training accuracy: 0.9645\n",
      "Validation loss: 0.5616, Validation accuracy: 0.8510\n",
      "\n",
      "Epoch 187:\n",
      "Training loss: 0.3432, Training accuracy: 0.9641\n",
      "Validation loss: 0.5653, Validation accuracy: 0.8522\n",
      "\n",
      "Epoch 188:\n",
      "Training loss: 0.3376, Training accuracy: 0.9641\n",
      "Validation loss: 0.5630, Validation accuracy: 0.8509\n",
      "\n",
      "Epoch 189:\n",
      "Training loss: 0.3408, Training accuracy: 0.9649\n",
      "Validation loss: 0.5661, Validation accuracy: 0.8494\n",
      "\n",
      "Epoch 190:\n",
      "Training loss: 0.3367, Training accuracy: 0.9648\n",
      "Validation loss: 0.5678, Validation accuracy: 0.8494\n",
      "\n",
      "Epoch 191:\n",
      "Training loss: 0.3442, Training accuracy: 0.9636\n",
      "Validation loss: 0.5629, Validation accuracy: 0.8507\n",
      "\n",
      "Epoch 192:\n",
      "Training loss: 0.3413, Training accuracy: 0.9638\n",
      "Validation loss: 0.5672, Validation accuracy: 0.8495\n",
      "\n",
      "Epoch 193:\n",
      "Training loss: 0.3444, Training accuracy: 0.9644\n",
      "Validation loss: 0.5669, Validation accuracy: 0.8510\n",
      "\n",
      "Epoch 194:\n",
      "Training loss: 0.3375, Training accuracy: 0.9645\n",
      "Validation loss: 0.5647, Validation accuracy: 0.8499\n",
      "\n",
      "Epoch 195:\n",
      "Training loss: 0.3370, Training accuracy: 0.9661\n",
      "Validation loss: 0.5669, Validation accuracy: 0.8477\n",
      "\n",
      "Epoch 196:\n",
      "Training loss: 0.3378, Training accuracy: 0.9654\n",
      "Validation loss: 0.5668, Validation accuracy: 0.8492\n",
      "\n",
      "Epoch 197:\n",
      "Training loss: 0.3409, Training accuracy: 0.9649\n",
      "Validation loss: 0.5664, Validation accuracy: 0.8488\n",
      "\n",
      "Epoch 198:\n",
      "Training loss: 0.3363, Training accuracy: 0.9663\n",
      "Validation loss: 0.5676, Validation accuracy: 0.8496\n",
      "\n",
      "Epoch 199:\n",
      "Training loss: 0.3453, Training accuracy: 0.9643\n",
      "Validation loss: 0.5686, Validation accuracy: 0.8488\n",
      "\n",
      "==================================================\n",
      "==> Optimization finished! Best validation accuracy: 0.8523\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8523"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train(T=2,lamb=0.1,alpha=0.6,train_loader=train_loader,val_loader=val_loader,INITIAL_LR=0.01,DECAY_EPOCHS=60,DECAY=0.1,EPOCHS=200,REG = 5e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Training starts!\n",
      "==================================================\n",
      "Epoch 0:\n",
      "Training loss: 1.6775, Training accuracy: 0.2894\n",
      "Validation loss: 1.4901, Validation accuracy: 0.4511\n",
      "Saving ...\n",
      "\n",
      "Epoch 1:\n",
      "Training loss: 1.1993, Training accuracy: 0.4661\n",
      "Validation loss: 1.3051, Validation accuracy: 0.5334\n",
      "Saving ...\n",
      "\n",
      "Epoch 2:\n",
      "Training loss: 1.0120, Training accuracy: 0.5504\n",
      "Validation loss: 1.2628, Validation accuracy: 0.5511\n",
      "Saving ...\n",
      "\n",
      "Epoch 3:\n",
      "Training loss: 0.8768, Training accuracy: 0.6080\n",
      "Validation loss: 1.0583, Validation accuracy: 0.6335\n",
      "Saving ...\n",
      "\n",
      "Epoch 4:\n",
      "Training loss: 0.7839, Training accuracy: 0.6512\n",
      "Validation loss: 1.0361, Validation accuracy: 0.6401\n",
      "Saving ...\n",
      "\n",
      "Epoch 5:\n",
      "Training loss: 0.7124, Training accuracy: 0.6858\n",
      "Validation loss: 0.8621, Validation accuracy: 0.6972\n",
      "Saving ...\n",
      "\n",
      "Epoch 6:\n",
      "Training loss: 0.6660, Training accuracy: 0.7079\n",
      "Validation loss: 0.8567, Validation accuracy: 0.7091\n",
      "Saving ...\n",
      "\n",
      "Epoch 7:\n",
      "Training loss: 0.6324, Training accuracy: 0.7228\n",
      "Validation loss: 0.8144, Validation accuracy: 0.7197\n",
      "Saving ...\n",
      "\n",
      "Epoch 8:\n",
      "Training loss: 0.6073, Training accuracy: 0.7335\n",
      "Validation loss: 0.7516, Validation accuracy: 0.7458\n",
      "Saving ...\n",
      "\n",
      "Epoch 9:\n",
      "Training loss: 0.5897, Training accuracy: 0.7413\n",
      "Validation loss: 0.7789, Validation accuracy: 0.7311\n",
      "\n",
      "Epoch 10:\n",
      "Training loss: 0.3884, Training accuracy: 0.7691\n",
      "Validation loss: 0.7018, Validation accuracy: 0.7546\n",
      "Saving ...\n",
      "\n",
      "Epoch 11:\n",
      "Training loss: 0.3861, Training accuracy: 0.7724\n",
      "Validation loss: 0.7536, Validation accuracy: 0.7378\n",
      "\n",
      "Epoch 12:\n",
      "Training loss: 0.3883, Training accuracy: 0.7696\n",
      "Validation loss: 0.8149, Validation accuracy: 0.7091\n",
      "\n",
      "Epoch 13:\n",
      "Training loss: 0.3881, Training accuracy: 0.7711\n",
      "Validation loss: 0.8038, Validation accuracy: 0.7209\n",
      "\n",
      "Epoch 14:\n",
      "Training loss: 0.3839, Training accuracy: 0.7719\n",
      "Validation loss: 0.6993, Validation accuracy: 0.7632\n",
      "Saving ...\n",
      "\n",
      "Epoch 15:\n",
      "Training loss: 0.3848, Training accuracy: 0.7717\n",
      "Validation loss: 0.7042, Validation accuracy: 0.7586\n",
      "\n",
      "Epoch 16:\n",
      "Training loss: 0.3778, Training accuracy: 0.7769\n",
      "Validation loss: 0.8171, Validation accuracy: 0.7201\n",
      "\n",
      "Epoch 17:\n",
      "Training loss: 0.3770, Training accuracy: 0.7773\n",
      "Validation loss: 0.8037, Validation accuracy: 0.7274\n",
      "\n",
      "Epoch 18:\n",
      "Training loss: 0.3712, Training accuracy: 0.7790\n",
      "Validation loss: 0.7336, Validation accuracy: 0.7506\n",
      "\n",
      "Epoch 19:\n",
      "Training loss: 0.3674, Training accuracy: 0.7835\n",
      "Validation loss: 0.7991, Validation accuracy: 0.7317\n",
      "\n",
      "Epoch 20:\n",
      "Training loss: 0.3672, Training accuracy: 0.7828\n",
      "Validation loss: 0.8395, Validation accuracy: 0.7210\n",
      "\n",
      "Epoch 21:\n",
      "Training loss: 0.3636, Training accuracy: 0.7861\n",
      "Validation loss: 0.7608, Validation accuracy: 0.7428\n",
      "\n",
      "Epoch 22:\n",
      "Training loss: 0.3620, Training accuracy: 0.7856\n",
      "Validation loss: 0.7778, Validation accuracy: 0.7384\n",
      "\n",
      "Epoch 23:\n",
      "Training loss: 0.3570, Training accuracy: 0.7906\n",
      "Validation loss: 0.7109, Validation accuracy: 0.7609\n",
      "\n",
      "Epoch 24:\n",
      "Training loss: 0.3557, Training accuracy: 0.7922\n",
      "Validation loss: 0.8468, Validation accuracy: 0.7224\n",
      "\n",
      "Epoch 25:\n",
      "Training loss: 0.3559, Training accuracy: 0.7902\n",
      "Validation loss: 0.7536, Validation accuracy: 0.7447\n",
      "\n",
      "Epoch 26:\n",
      "Training loss: 0.3517, Training accuracy: 0.7941\n",
      "Validation loss: 0.6936, Validation accuracy: 0.7649\n",
      "Saving ...\n",
      "\n",
      "Epoch 27:\n",
      "Training loss: 0.3487, Training accuracy: 0.7964\n",
      "Validation loss: 0.7299, Validation accuracy: 0.7558\n",
      "\n",
      "Epoch 28:\n",
      "Training loss: 0.3472, Training accuracy: 0.7965\n",
      "Validation loss: 0.7573, Validation accuracy: 0.7375\n",
      "\n",
      "Epoch 29:\n",
      "Training loss: 0.3492, Training accuracy: 0.7948\n",
      "Validation loss: 0.7002, Validation accuracy: 0.7647\n",
      "\n",
      "Epoch 30:\n",
      "Training loss: 0.3449, Training accuracy: 0.7980\n",
      "Validation loss: 0.7757, Validation accuracy: 0.7304\n",
      "\n",
      "Epoch 31:\n",
      "Training loss: 0.3440, Training accuracy: 0.7989\n",
      "Validation loss: 0.7462, Validation accuracy: 0.7475\n",
      "\n",
      "Epoch 32:\n",
      "Training loss: 0.3442, Training accuracy: 0.7976\n",
      "Validation loss: 0.6945, Validation accuracy: 0.7718\n",
      "Saving ...\n",
      "\n",
      "Epoch 33:\n",
      "Training loss: 0.3416, Training accuracy: 0.7994\n",
      "Validation loss: 0.7848, Validation accuracy: 0.7341\n",
      "\n",
      "Epoch 34:\n",
      "Training loss: 0.3380, Training accuracy: 0.7989\n",
      "Validation loss: 0.6587, Validation accuracy: 0.7771\n",
      "Saving ...\n",
      "\n",
      "Epoch 35:\n",
      "Training loss: 0.3391, Training accuracy: 0.8016\n",
      "Validation loss: 0.8964, Validation accuracy: 0.7047\n",
      "\n",
      "Epoch 36:\n",
      "Training loss: 0.3383, Training accuracy: 0.8022\n",
      "Validation loss: 0.7259, Validation accuracy: 0.7509\n",
      "\n",
      "Epoch 37:\n",
      "Training loss: 0.3349, Training accuracy: 0.8044\n",
      "Validation loss: 0.7251, Validation accuracy: 0.7420\n",
      "\n",
      "Epoch 38:\n",
      "Training loss: 0.3354, Training accuracy: 0.8039\n",
      "Validation loss: 0.6642, Validation accuracy: 0.7749\n",
      "\n",
      "Epoch 39:\n",
      "Training loss: 0.3345, Training accuracy: 0.8045\n",
      "Validation loss: 0.6609, Validation accuracy: 0.7758\n",
      "\n",
      "Epoch 40:\n",
      "Training loss: 0.3328, Training accuracy: 0.8045\n",
      "Validation loss: 0.7186, Validation accuracy: 0.7598\n",
      "\n",
      "Epoch 41:\n",
      "Training loss: 0.3326, Training accuracy: 0.8053\n",
      "Validation loss: 0.7818, Validation accuracy: 0.7404\n",
      "\n",
      "Epoch 42:\n",
      "Training loss: 0.3297, Training accuracy: 0.8083\n",
      "Validation loss: 0.7430, Validation accuracy: 0.7469\n",
      "\n",
      "Epoch 43:\n",
      "Training loss: 0.3319, Training accuracy: 0.8060\n",
      "Validation loss: 0.6940, Validation accuracy: 0.7623\n",
      "\n",
      "Epoch 44:\n",
      "Training loss: 0.3315, Training accuracy: 0.8050\n",
      "Validation loss: 0.7742, Validation accuracy: 0.7311\n",
      "\n",
      "Epoch 45:\n",
      "Training loss: 0.3321, Training accuracy: 0.8072\n",
      "Validation loss: 0.6255, Validation accuracy: 0.7863\n",
      "Saving ...\n",
      "\n",
      "Epoch 46:\n",
      "Training loss: 0.3291, Training accuracy: 0.8078\n",
      "Validation loss: 0.7713, Validation accuracy: 0.7448\n",
      "\n",
      "Epoch 47:\n",
      "Training loss: 0.3294, Training accuracy: 0.8082\n",
      "Validation loss: 0.6436, Validation accuracy: 0.7814\n",
      "\n",
      "Epoch 48:\n",
      "Training loss: 0.3279, Training accuracy: 0.8080\n",
      "Validation loss: 0.6943, Validation accuracy: 0.7656\n",
      "\n",
      "Epoch 49:\n",
      "Training loss: 0.3288, Training accuracy: 0.8081\n",
      "Validation loss: 0.7408, Validation accuracy: 0.7499\n",
      "\n",
      "Epoch 50:\n",
      "Training loss: 0.3278, Training accuracy: 0.8096\n",
      "Validation loss: 0.6473, Validation accuracy: 0.7798\n",
      "\n",
      "Epoch 51:\n",
      "Training loss: 0.3225, Training accuracy: 0.8113\n",
      "Validation loss: 0.8169, Validation accuracy: 0.7290\n",
      "\n",
      "Epoch 52:\n",
      "Training loss: 0.3269, Training accuracy: 0.8082\n",
      "Validation loss: 0.6762, Validation accuracy: 0.7752\n",
      "\n",
      "Epoch 53:\n",
      "Training loss: 0.3235, Training accuracy: 0.8122\n",
      "Validation loss: 0.6440, Validation accuracy: 0.7808\n",
      "\n",
      "Epoch 54:\n",
      "Training loss: 0.3229, Training accuracy: 0.8118\n",
      "Validation loss: 0.7821, Validation accuracy: 0.7442\n",
      "\n",
      "Epoch 55:\n",
      "Training loss: 0.3253, Training accuracy: 0.8096\n",
      "Validation loss: 0.6409, Validation accuracy: 0.7855\n",
      "\n",
      "Epoch 56:\n",
      "Training loss: 0.3214, Training accuracy: 0.8128\n",
      "Validation loss: 0.7407, Validation accuracy: 0.7488\n",
      "\n",
      "Epoch 57:\n",
      "Training loss: 0.3205, Training accuracy: 0.8135\n",
      "Validation loss: 0.6376, Validation accuracy: 0.7876\n",
      "Saving ...\n",
      "\n",
      "Epoch 58:\n",
      "Training loss: 0.3228, Training accuracy: 0.8109\n",
      "Validation loss: 0.7990, Validation accuracy: 0.7366\n",
      "\n",
      "Epoch 59:\n",
      "Training loss: 0.3234, Training accuracy: 0.8108\n",
      "Validation loss: 0.6563, Validation accuracy: 0.7805\n",
      "\n",
      "Current learning rate has decayed to 0.010000\n",
      "Epoch 60:\n",
      "Training loss: 0.2290, Training accuracy: 0.8719\n",
      "Validation loss: 0.3958, Validation accuracy: 0.8657\n",
      "Saving ...\n",
      "\n",
      "Epoch 61:\n",
      "Training loss: 0.1963, Training accuracy: 0.8922\n",
      "Validation loss: 0.3670, Validation accuracy: 0.8764\n",
      "Saving ...\n",
      "\n",
      "Epoch 62:\n",
      "Training loss: 0.1854, Training accuracy: 0.8976\n",
      "Validation loss: 0.3653, Validation accuracy: 0.8791\n",
      "Saving ...\n",
      "\n",
      "Epoch 63:\n",
      "Training loss: 0.1752, Training accuracy: 0.9051\n",
      "Validation loss: 0.3514, Validation accuracy: 0.8836\n",
      "Saving ...\n",
      "\n",
      "Epoch 64:\n",
      "Training loss: 0.1684, Training accuracy: 0.9090\n",
      "Validation loss: 0.3560, Validation accuracy: 0.8802\n",
      "\n",
      "Epoch 65:\n",
      "Training loss: 0.1636, Training accuracy: 0.9126\n",
      "Validation loss: 0.3493, Validation accuracy: 0.8855\n",
      "Saving ...\n",
      "\n",
      "Epoch 66:\n",
      "Training loss: 0.1581, Training accuracy: 0.9146\n",
      "Validation loss: 0.3572, Validation accuracy: 0.8796\n",
      "\n",
      "Epoch 67:\n",
      "Training loss: 0.1542, Training accuracy: 0.9173\n",
      "Validation loss: 0.3573, Validation accuracy: 0.8792\n",
      "\n",
      "Epoch 68:\n",
      "Training loss: 0.1505, Training accuracy: 0.9204\n",
      "Validation loss: 0.3579, Validation accuracy: 0.8789\n",
      "\n",
      "Epoch 69:\n",
      "Training loss: 0.1483, Training accuracy: 0.9203\n",
      "Validation loss: 0.3507, Validation accuracy: 0.8834\n",
      "\n",
      "Epoch 70:\n",
      "Training loss: 0.1446, Training accuracy: 0.9235\n",
      "Validation loss: 0.3535, Validation accuracy: 0.8810\n",
      "\n",
      "Epoch 71:\n",
      "Training loss: 0.1409, Training accuracy: 0.9257\n",
      "Validation loss: 0.3475, Validation accuracy: 0.8812\n",
      "\n",
      "Epoch 72:\n",
      "Training loss: 0.1394, Training accuracy: 0.9266\n",
      "Validation loss: 0.3515, Validation accuracy: 0.8817\n",
      "\n",
      "Epoch 73:\n",
      "Training loss: 0.1367, Training accuracy: 0.9283\n",
      "Validation loss: 0.3539, Validation accuracy: 0.8817\n",
      "\n",
      "Epoch 74:\n",
      "Training loss: 0.1336, Training accuracy: 0.9308\n",
      "Validation loss: 0.3543, Validation accuracy: 0.8829\n",
      "\n",
      "Epoch 75:\n",
      "Training loss: 0.1329, Training accuracy: 0.9310\n",
      "Validation loss: 0.3763, Validation accuracy: 0.8730\n",
      "\n",
      "Epoch 76:\n",
      "Training loss: 0.1323, Training accuracy: 0.9316\n",
      "Validation loss: 0.3635, Validation accuracy: 0.8773\n",
      "\n",
      "Epoch 77:\n",
      "Training loss: 0.1297, Training accuracy: 0.9323\n",
      "Validation loss: 0.3492, Validation accuracy: 0.8830\n",
      "\n",
      "Epoch 78:\n",
      "Training loss: 0.1296, Training accuracy: 0.9320\n",
      "Validation loss: 0.3729, Validation accuracy: 0.8758\n",
      "\n",
      "Epoch 79:\n",
      "Training loss: 0.1290, Training accuracy: 0.9337\n",
      "Validation loss: 0.3639, Validation accuracy: 0.8805\n",
      "\n",
      "Epoch 80:\n",
      "Training loss: 0.1275, Training accuracy: 0.9352\n",
      "Validation loss: 0.3536, Validation accuracy: 0.8818\n",
      "\n",
      "Epoch 81:\n",
      "Training loss: 0.1264, Training accuracy: 0.9348\n",
      "Validation loss: 0.3640, Validation accuracy: 0.8796\n",
      "\n",
      "Epoch 82:\n",
      "Training loss: 0.1260, Training accuracy: 0.9362\n",
      "Validation loss: 0.3673, Validation accuracy: 0.8783\n",
      "\n",
      "Epoch 83:\n",
      "Training loss: 0.1249, Training accuracy: 0.9365\n",
      "Validation loss: 0.3831, Validation accuracy: 0.8724\n",
      "\n",
      "Epoch 84:\n",
      "Training loss: 0.1237, Training accuracy: 0.9376\n",
      "Validation loss: 0.3836, Validation accuracy: 0.8723\n",
      "\n",
      "Epoch 85:\n",
      "Training loss: 0.1258, Training accuracy: 0.9362\n",
      "Validation loss: 0.3737, Validation accuracy: 0.8751\n",
      "\n",
      "Epoch 86:\n",
      "Training loss: 0.1244, Training accuracy: 0.9359\n",
      "Validation loss: 0.3732, Validation accuracy: 0.8804\n",
      "\n",
      "Epoch 87:\n",
      "Training loss: 0.1250, Training accuracy: 0.9368\n",
      "Validation loss: 0.3737, Validation accuracy: 0.8778\n",
      "\n",
      "Epoch 88:\n",
      "Training loss: 0.1229, Training accuracy: 0.9372\n",
      "Validation loss: 0.4166, Validation accuracy: 0.8616\n",
      "\n",
      "Epoch 89:\n",
      "Training loss: 0.1229, Training accuracy: 0.9375\n",
      "Validation loss: 0.3985, Validation accuracy: 0.8723\n",
      "\n",
      "Epoch 90:\n",
      "Training loss: 0.1217, Training accuracy: 0.9388\n",
      "Validation loss: 0.3779, Validation accuracy: 0.8781\n",
      "\n",
      "Epoch 91:\n",
      "Training loss: 0.1212, Training accuracy: 0.9384\n",
      "Validation loss: 0.4071, Validation accuracy: 0.8647\n",
      "\n",
      "Epoch 92:\n",
      "Training loss: 0.1241, Training accuracy: 0.9358\n",
      "Validation loss: 0.4126, Validation accuracy: 0.8701\n",
      "\n",
      "Epoch 93:\n",
      "Training loss: 0.1219, Training accuracy: 0.9380\n",
      "Validation loss: 0.3642, Validation accuracy: 0.8807\n",
      "\n",
      "Epoch 94:\n",
      "Training loss: 0.1205, Training accuracy: 0.9389\n",
      "Validation loss: 0.3979, Validation accuracy: 0.8714\n",
      "\n",
      "Epoch 95:\n",
      "Training loss: 0.1196, Training accuracy: 0.9399\n",
      "Validation loss: 0.3895, Validation accuracy: 0.8730\n",
      "\n",
      "Epoch 96:\n",
      "Training loss: 0.1183, Training accuracy: 0.9409\n",
      "Validation loss: 0.3824, Validation accuracy: 0.8748\n",
      "\n",
      "Epoch 97:\n",
      "Training loss: 0.1202, Training accuracy: 0.9395\n",
      "Validation loss: 0.3912, Validation accuracy: 0.8715\n",
      "\n",
      "Epoch 98:\n",
      "Training loss: 0.1215, Training accuracy: 0.9380\n",
      "Validation loss: 0.3985, Validation accuracy: 0.8700\n",
      "\n",
      "Epoch 99:\n",
      "Training loss: 0.1194, Training accuracy: 0.9397\n",
      "Validation loss: 0.3905, Validation accuracy: 0.8748\n",
      "\n",
      "Epoch 100:\n",
      "Training loss: 0.1213, Training accuracy: 0.9394\n",
      "Validation loss: 0.3969, Validation accuracy: 0.8739\n",
      "\n",
      "Epoch 101:\n",
      "Training loss: 0.1179, Training accuracy: 0.9412\n",
      "Validation loss: 0.4076, Validation accuracy: 0.8726\n",
      "\n",
      "Epoch 102:\n",
      "Training loss: 0.1175, Training accuracy: 0.9411\n",
      "Validation loss: 0.4149, Validation accuracy: 0.8664\n",
      "\n",
      "Epoch 103:\n",
      "Training loss: 0.1183, Training accuracy: 0.9413\n",
      "Validation loss: 0.3831, Validation accuracy: 0.8789\n",
      "\n",
      "Epoch 104:\n",
      "Training loss: 0.1171, Training accuracy: 0.9411\n",
      "Validation loss: 0.3787, Validation accuracy: 0.8742\n",
      "\n",
      "Epoch 105:\n",
      "Training loss: 0.1140, Training accuracy: 0.9432\n",
      "Validation loss: 0.3900, Validation accuracy: 0.8719\n",
      "\n",
      "Epoch 106:\n",
      "Training loss: 0.1184, Training accuracy: 0.9416\n",
      "Validation loss: 0.3695, Validation accuracy: 0.8805\n",
      "\n",
      "Epoch 107:\n",
      "Training loss: 0.1162, Training accuracy: 0.9418\n",
      "Validation loss: 0.3720, Validation accuracy: 0.8823\n",
      "\n",
      "Epoch 108:\n",
      "Training loss: 0.1143, Training accuracy: 0.9424\n",
      "Validation loss: 0.3888, Validation accuracy: 0.8748\n",
      "\n",
      "Epoch 109:\n",
      "Training loss: 0.1147, Training accuracy: 0.9439\n",
      "Validation loss: 0.3880, Validation accuracy: 0.8725\n",
      "\n",
      "Epoch 110:\n",
      "Training loss: 0.1127, Training accuracy: 0.9443\n",
      "Validation loss: 0.3994, Validation accuracy: 0.8726\n",
      "\n",
      "Epoch 111:\n",
      "Training loss: 0.1140, Training accuracy: 0.9438\n",
      "Validation loss: 0.3826, Validation accuracy: 0.8755\n",
      "\n",
      "Epoch 112:\n",
      "Training loss: 0.1138, Training accuracy: 0.9435\n",
      "Validation loss: 0.3954, Validation accuracy: 0.8729\n",
      "\n",
      "Epoch 113:\n",
      "Training loss: 0.1150, Training accuracy: 0.9426\n",
      "Validation loss: 0.3957, Validation accuracy: 0.8715\n",
      "\n",
      "Epoch 114:\n",
      "Training loss: 0.1131, Training accuracy: 0.9442\n",
      "Validation loss: 0.3944, Validation accuracy: 0.8731\n",
      "\n",
      "Epoch 115:\n",
      "Training loss: 0.1117, Training accuracy: 0.9452\n",
      "Validation loss: 0.3857, Validation accuracy: 0.8751\n",
      "\n",
      "Epoch 116:\n",
      "Training loss: 0.1126, Training accuracy: 0.9454\n",
      "Validation loss: 0.3826, Validation accuracy: 0.8793\n",
      "\n",
      "Epoch 117:\n",
      "Training loss: 0.1142, Training accuracy: 0.9439\n",
      "Validation loss: 0.3844, Validation accuracy: 0.8750\n",
      "\n",
      "Epoch 118:\n",
      "Training loss: 0.1098, Training accuracy: 0.9457\n",
      "Validation loss: 0.3893, Validation accuracy: 0.8745\n",
      "\n",
      "Epoch 119:\n",
      "Training loss: 0.1106, Training accuracy: 0.9468\n",
      "Validation loss: 0.3967, Validation accuracy: 0.8746\n",
      "\n",
      "Current learning rate has decayed to 0.001000\n",
      "Epoch 120:\n",
      "Training loss: 0.0760, Training accuracy: 0.9694\n",
      "Validation loss: 0.3095, Validation accuracy: 0.8985\n",
      "Saving ...\n",
      "\n",
      "Epoch 121:\n",
      "Training loss: 0.0627, Training accuracy: 0.9781\n",
      "Validation loss: 0.3028, Validation accuracy: 0.9035\n",
      "Saving ...\n",
      "\n",
      "Epoch 122:\n",
      "Training loss: 0.0591, Training accuracy: 0.9796\n",
      "Validation loss: 0.3070, Validation accuracy: 0.9027\n",
      "\n",
      "Epoch 123:\n",
      "Training loss: 0.0547, Training accuracy: 0.9832\n",
      "Validation loss: 0.3049, Validation accuracy: 0.9036\n",
      "Saving ...\n",
      "\n",
      "Epoch 124:\n",
      "Training loss: 0.0532, Training accuracy: 0.9838\n",
      "Validation loss: 0.3059, Validation accuracy: 0.9039\n",
      "Saving ...\n",
      "\n",
      "Epoch 125:\n",
      "Training loss: 0.0498, Training accuracy: 0.9861\n",
      "Validation loss: 0.3056, Validation accuracy: 0.9048\n",
      "Saving ...\n",
      "\n",
      "Epoch 126:\n",
      "Training loss: 0.0501, Training accuracy: 0.9862\n",
      "Validation loss: 0.3067, Validation accuracy: 0.9055\n",
      "Saving ...\n",
      "\n",
      "Epoch 127:\n",
      "Training loss: 0.0481, Training accuracy: 0.9871\n",
      "Validation loss: 0.3087, Validation accuracy: 0.9043\n",
      "\n",
      "Epoch 128:\n",
      "Training loss: 0.0472, Training accuracy: 0.9874\n",
      "Validation loss: 0.3081, Validation accuracy: 0.9045\n",
      "\n",
      "Epoch 129:\n",
      "Training loss: 0.0470, Training accuracy: 0.9876\n",
      "Validation loss: 0.3091, Validation accuracy: 0.9023\n",
      "\n",
      "Epoch 130:\n",
      "Training loss: 0.0461, Training accuracy: 0.9882\n",
      "Validation loss: 0.3103, Validation accuracy: 0.9045\n",
      "\n",
      "Epoch 131:\n",
      "Training loss: 0.0439, Training accuracy: 0.9895\n",
      "Validation loss: 0.3144, Validation accuracy: 0.9032\n",
      "\n",
      "Epoch 132:\n",
      "Training loss: 0.0441, Training accuracy: 0.9892\n",
      "Validation loss: 0.3118, Validation accuracy: 0.9038\n",
      "\n",
      "Epoch 133:\n",
      "Training loss: 0.0429, Training accuracy: 0.9902\n",
      "Validation loss: 0.3129, Validation accuracy: 0.9037\n",
      "\n",
      "Epoch 134:\n",
      "Training loss: 0.0423, Training accuracy: 0.9902\n",
      "Validation loss: 0.3153, Validation accuracy: 0.9016\n",
      "\n",
      "Epoch 135:\n",
      "Training loss: 0.0419, Training accuracy: 0.9903\n",
      "Validation loss: 0.3147, Validation accuracy: 0.9036\n",
      "\n",
      "Epoch 136:\n",
      "Training loss: 0.0401, Training accuracy: 0.9915\n",
      "Validation loss: 0.3171, Validation accuracy: 0.9039\n",
      "\n",
      "Epoch 137:\n",
      "Training loss: 0.0408, Training accuracy: 0.9908\n",
      "Validation loss: 0.3177, Validation accuracy: 0.9035\n",
      "\n",
      "Epoch 138:\n",
      "Training loss: 0.0404, Training accuracy: 0.9910\n",
      "Validation loss: 0.3170, Validation accuracy: 0.9026\n",
      "\n",
      "Epoch 139:\n",
      "Training loss: 0.0394, Training accuracy: 0.9920\n",
      "Validation loss: 0.3169, Validation accuracy: 0.9029\n",
      "\n",
      "Epoch 140:\n",
      "Training loss: 0.0392, Training accuracy: 0.9917\n",
      "Validation loss: 0.3241, Validation accuracy: 0.9021\n",
      "\n",
      "Epoch 141:\n",
      "Training loss: 0.0383, Training accuracy: 0.9925\n",
      "Validation loss: 0.3220, Validation accuracy: 0.9029\n",
      "\n",
      "Epoch 142:\n",
      "Training loss: 0.0379, Training accuracy: 0.9926\n",
      "Validation loss: 0.3220, Validation accuracy: 0.9027\n",
      "\n",
      "Epoch 143:\n",
      "Training loss: 0.0381, Training accuracy: 0.9922\n",
      "Validation loss: 0.3207, Validation accuracy: 0.9025\n",
      "\n",
      "Epoch 144:\n",
      "Training loss: 0.0368, Training accuracy: 0.9935\n",
      "Validation loss: 0.3241, Validation accuracy: 0.9039\n",
      "\n",
      "Epoch 145:\n",
      "Training loss: 0.0364, Training accuracy: 0.9930\n",
      "Validation loss: 0.3213, Validation accuracy: 0.9044\n",
      "\n",
      "Epoch 146:\n",
      "Training loss: 0.0373, Training accuracy: 0.9922\n",
      "Validation loss: 0.3251, Validation accuracy: 0.9040\n",
      "\n",
      "Epoch 147:\n",
      "Training loss: 0.0366, Training accuracy: 0.9928\n",
      "Validation loss: 0.3291, Validation accuracy: 0.9023\n",
      "\n",
      "Epoch 148:\n",
      "Training loss: 0.0352, Training accuracy: 0.9941\n",
      "Validation loss: 0.3264, Validation accuracy: 0.9032\n",
      "\n",
      "Epoch 149:\n",
      "Training loss: 0.0355, Training accuracy: 0.9937\n",
      "Validation loss: 0.3238, Validation accuracy: 0.9045\n",
      "\n",
      "Epoch 150:\n",
      "Training loss: 0.0362, Training accuracy: 0.9932\n",
      "Validation loss: 0.3227, Validation accuracy: 0.9041\n",
      "\n",
      "Epoch 151:\n",
      "Training loss: 0.0352, Training accuracy: 0.9935\n",
      "Validation loss: 0.3269, Validation accuracy: 0.9024\n",
      "\n",
      "Epoch 152:\n",
      "Training loss: 0.0350, Training accuracy: 0.9933\n",
      "Validation loss: 0.3256, Validation accuracy: 0.9031\n",
      "\n",
      "Epoch 153:\n",
      "Training loss: 0.0344, Training accuracy: 0.9946\n",
      "Validation loss: 0.3296, Validation accuracy: 0.9023\n",
      "\n",
      "Epoch 154:\n",
      "Training loss: 0.0345, Training accuracy: 0.9939\n",
      "Validation loss: 0.3299, Validation accuracy: 0.9040\n",
      "\n",
      "Epoch 155:\n",
      "Training loss: 0.0342, Training accuracy: 0.9941\n",
      "Validation loss: 0.3320, Validation accuracy: 0.9016\n",
      "\n",
      "Epoch 156:\n",
      "Training loss: 0.0335, Training accuracy: 0.9945\n",
      "Validation loss: 0.3284, Validation accuracy: 0.9037\n",
      "\n",
      "Epoch 157:\n",
      "Training loss: 0.0336, Training accuracy: 0.9947\n",
      "Validation loss: 0.3271, Validation accuracy: 0.9039\n",
      "\n",
      "Epoch 158:\n",
      "Training loss: 0.0333, Training accuracy: 0.9949\n",
      "Validation loss: 0.3286, Validation accuracy: 0.9023\n",
      "\n",
      "Epoch 159:\n",
      "Training loss: 0.0332, Training accuracy: 0.9948\n",
      "Validation loss: 0.3314, Validation accuracy: 0.9016\n",
      "\n",
      "Epoch 160:\n",
      "Training loss: 0.0329, Training accuracy: 0.9948\n",
      "Validation loss: 0.3352, Validation accuracy: 0.9022\n",
      "\n",
      "Epoch 161:\n",
      "Training loss: 0.0329, Training accuracy: 0.9946\n",
      "Validation loss: 0.3306, Validation accuracy: 0.9025\n",
      "\n",
      "Epoch 162:\n",
      "Training loss: 0.0325, Training accuracy: 0.9947\n",
      "Validation loss: 0.3357, Validation accuracy: 0.8996\n",
      "\n",
      "Epoch 163:\n",
      "Training loss: 0.0322, Training accuracy: 0.9950\n",
      "Validation loss: 0.3394, Validation accuracy: 0.9001\n",
      "\n",
      "Epoch 164:\n",
      "Training loss: 0.0316, Training accuracy: 0.9956\n",
      "Validation loss: 0.3352, Validation accuracy: 0.9013\n",
      "\n",
      "Epoch 165:\n",
      "Training loss: 0.0318, Training accuracy: 0.9953\n",
      "Validation loss: 0.3334, Validation accuracy: 0.9021\n",
      "\n",
      "Epoch 166:\n",
      "Training loss: 0.0319, Training accuracy: 0.9954\n",
      "Validation loss: 0.3419, Validation accuracy: 0.9009\n",
      "\n",
      "Epoch 167:\n",
      "Training loss: 0.0307, Training accuracy: 0.9957\n",
      "Validation loss: 0.3374, Validation accuracy: 0.9009\n",
      "\n",
      "Epoch 168:\n",
      "Training loss: 0.0310, Training accuracy: 0.9956\n",
      "Validation loss: 0.3433, Validation accuracy: 0.8999\n",
      "\n",
      "Epoch 169:\n",
      "Training loss: 0.0305, Training accuracy: 0.9960\n",
      "Validation loss: 0.3366, Validation accuracy: 0.9030\n",
      "\n",
      "Epoch 170:\n",
      "Training loss: 0.0310, Training accuracy: 0.9958\n",
      "Validation loss: 0.3405, Validation accuracy: 0.9023\n",
      "\n",
      "Epoch 171:\n",
      "Training loss: 0.0311, Training accuracy: 0.9956\n",
      "Validation loss: 0.3323, Validation accuracy: 0.9040\n",
      "\n",
      "Epoch 172:\n",
      "Training loss: 0.0311, Training accuracy: 0.9952\n",
      "Validation loss: 0.3351, Validation accuracy: 0.9030\n",
      "\n",
      "Epoch 173:\n",
      "Training loss: 0.0306, Training accuracy: 0.9958\n",
      "Validation loss: 0.3415, Validation accuracy: 0.8987\n",
      "\n",
      "Epoch 174:\n",
      "Training loss: 0.0314, Training accuracy: 0.9950\n",
      "Validation loss: 0.3351, Validation accuracy: 0.9027\n",
      "\n",
      "Epoch 175:\n",
      "Training loss: 0.0297, Training accuracy: 0.9963\n",
      "Validation loss: 0.3374, Validation accuracy: 0.9029\n",
      "\n",
      "Epoch 176:\n",
      "Training loss: 0.0297, Training accuracy: 0.9961\n",
      "Validation loss: 0.3418, Validation accuracy: 0.9027\n",
      "\n",
      "Epoch 177:\n",
      "Training loss: 0.0294, Training accuracy: 0.9962\n",
      "Validation loss: 0.3388, Validation accuracy: 0.9040\n",
      "\n",
      "Epoch 178:\n",
      "Training loss: 0.0300, Training accuracy: 0.9961\n",
      "Validation loss: 0.3409, Validation accuracy: 0.9041\n",
      "\n",
      "Epoch 179:\n",
      "Training loss: 0.0294, Training accuracy: 0.9961\n",
      "Validation loss: 0.3409, Validation accuracy: 0.9038\n",
      "\n",
      "Current learning rate has decayed to 0.000100\n",
      "Epoch 180:\n",
      "Training loss: 0.0285, Training accuracy: 0.9967\n",
      "Validation loss: 0.3351, Validation accuracy: 0.9032\n",
      "\n",
      "Epoch 181:\n",
      "Training loss: 0.0283, Training accuracy: 0.9966\n",
      "Validation loss: 0.3363, Validation accuracy: 0.9036\n",
      "\n",
      "Epoch 182:\n",
      "Training loss: 0.0276, Training accuracy: 0.9971\n",
      "Validation loss: 0.3342, Validation accuracy: 0.9046\n",
      "\n",
      "Epoch 183:\n",
      "Training loss: 0.0279, Training accuracy: 0.9969\n",
      "Validation loss: 0.3331, Validation accuracy: 0.9042\n",
      "\n",
      "Epoch 184:\n",
      "Training loss: 0.0275, Training accuracy: 0.9970\n",
      "Validation loss: 0.3338, Validation accuracy: 0.9051\n",
      "\n",
      "Epoch 185:\n",
      "Training loss: 0.0267, Training accuracy: 0.9974\n",
      "Validation loss: 0.3354, Validation accuracy: 0.9051\n",
      "\n",
      "Epoch 186:\n",
      "Training loss: 0.0280, Training accuracy: 0.9967\n",
      "Validation loss: 0.3340, Validation accuracy: 0.9046\n",
      "\n",
      "Epoch 187:\n",
      "Training loss: 0.0268, Training accuracy: 0.9976\n",
      "Validation loss: 0.3328, Validation accuracy: 0.9052\n",
      "\n",
      "Epoch 188:\n",
      "Training loss: 0.0273, Training accuracy: 0.9970\n",
      "Validation loss: 0.3332, Validation accuracy: 0.9054\n",
      "\n",
      "Epoch 189:\n",
      "Training loss: 0.0273, Training accuracy: 0.9970\n",
      "Validation loss: 0.3344, Validation accuracy: 0.9046\n",
      "\n",
      "Epoch 190:\n",
      "Training loss: 0.0272, Training accuracy: 0.9973\n",
      "Validation loss: 0.3340, Validation accuracy: 0.9036\n",
      "\n",
      "Epoch 191:\n",
      "Training loss: 0.0271, Training accuracy: 0.9972\n",
      "Validation loss: 0.3358, Validation accuracy: 0.9046\n",
      "\n",
      "Epoch 192:\n",
      "Training loss: 0.0273, Training accuracy: 0.9972\n",
      "Validation loss: 0.3348, Validation accuracy: 0.9049\n",
      "\n",
      "Epoch 193:\n",
      "Training loss: 0.0271, Training accuracy: 0.9972\n",
      "Validation loss: 0.3349, Validation accuracy: 0.9042\n",
      "\n",
      "Epoch 194:\n",
      "Training loss: 0.0271, Training accuracy: 0.9972\n",
      "Validation loss: 0.3363, Validation accuracy: 0.9053\n",
      "\n",
      "Epoch 195:\n",
      "Training loss: 0.0270, Training accuracy: 0.9970\n",
      "Validation loss: 0.3324, Validation accuracy: 0.9051\n",
      "\n",
      "Epoch 196:\n",
      "Training loss: 0.0268, Training accuracy: 0.9975\n",
      "Validation loss: 0.3333, Validation accuracy: 0.9030\n",
      "\n",
      "Epoch 197:\n",
      "Training loss: 0.0265, Training accuracy: 0.9975\n",
      "Validation loss: 0.3350, Validation accuracy: 0.9045\n",
      "\n",
      "Epoch 198:\n",
      "Training loss: 0.0268, Training accuracy: 0.9974\n",
      "Validation loss: 0.3353, Validation accuracy: 0.9039\n",
      "\n",
      "Epoch 199:\n",
      "Training loss: 0.0265, Training accuracy: 0.9974\n",
      "Validation loss: 0.3369, Validation accuracy: 0.9033\n",
      "\n",
      "==================================================\n",
      "==> Optimization finished! Best validation accuracy: 0.9055\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9055"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train(T=3,lamb=0.2,alpha=0.4,train_loader=train_loader,val_loader=val_loader,INITIAL_LR=0.1,DECAY_EPOCHS=60,DECAY=0.1,EPOCHS=200,REG = 5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Training starts!\n",
      "==================================================\n",
      "Epoch 0:\n",
      "Training loss: 1.5443, Training accuracy: 0.3033\n",
      "Validation loss: 1.7406, Validation accuracy: 0.3394\n",
      "Saving ...\n",
      "\n",
      "Epoch 1:\n",
      "Training loss: 1.3322, Training accuracy: 0.3849\n",
      "Validation loss: 1.9870, Validation accuracy: 0.2698\n",
      "\n",
      "Epoch 2:\n",
      "Training loss: 1.3192, Training accuracy: 0.3916\n",
      "Validation loss: 2.2902, Validation accuracy: 0.2238\n",
      "\n",
      "Epoch 3:\n",
      "Training loss: 1.3180, Training accuracy: 0.3918\n",
      "Validation loss: 2.9051, Validation accuracy: 0.2243\n",
      "\n",
      "Epoch 4:\n",
      "Training loss: 1.3207, Training accuracy: 0.3894\n",
      "Validation loss: 3.3420, Validation accuracy: 0.1832\n",
      "\n",
      "Epoch 5:\n",
      "Training loss: 1.3151, Training accuracy: 0.3957\n",
      "Validation loss: 1.7995, Validation accuracy: 0.3477\n",
      "Saving ...\n",
      "\n",
      "Epoch 6:\n",
      "Training loss: 1.3144, Training accuracy: 0.3962\n",
      "Validation loss: 1.6417, Validation accuracy: 0.3984\n",
      "Saving ...\n",
      "\n",
      "Epoch 7:\n",
      "Training loss: 1.3222, Training accuracy: 0.3901\n",
      "Validation loss: 1.8657, Validation accuracy: 0.3375\n",
      "\n",
      "Epoch 8:\n",
      "Training loss: 1.3161, Training accuracy: 0.3918\n",
      "Validation loss: 2.0381, Validation accuracy: 0.2959\n",
      "\n",
      "Epoch 9:\n",
      "Training loss: 1.3135, Training accuracy: 0.3902\n",
      "Validation loss: 1.9154, Validation accuracy: 0.2874\n",
      "\n",
      "Epoch 10:\n",
      "Training loss: 0.9335, Training accuracy: 0.3946\n",
      "Validation loss: 2.2872, Validation accuracy: 0.2014\n",
      "\n",
      "Epoch 11:\n",
      "Training loss: 0.9475, Training accuracy: 0.3802\n",
      "Validation loss: 2.2173, Validation accuracy: 0.2705\n",
      "\n",
      "Epoch 12:\n",
      "Training loss: 0.9424, Training accuracy: 0.3796\n",
      "Validation loss: 1.8709, Validation accuracy: 0.3108\n",
      "\n",
      "Epoch 13:\n",
      "Training loss: 0.9508, Training accuracy: 0.3670\n",
      "Validation loss: 2.0361, Validation accuracy: 0.2456\n",
      "\n",
      "Epoch 14:\n",
      "Training loss: 0.9522, Training accuracy: 0.3652\n",
      "Validation loss: 1.8580, Validation accuracy: 0.2916\n",
      "\n",
      "Epoch 15:\n",
      "Training loss: 0.9534, Training accuracy: 0.3588\n",
      "Validation loss: 1.7600, Validation accuracy: 0.3247\n",
      "\n",
      "Epoch 16:\n",
      "Training loss: 0.9577, Training accuracy: 0.3579\n",
      "Validation loss: 2.0926, Validation accuracy: 0.2436\n",
      "\n",
      "Epoch 17:\n",
      "Training loss: 0.9611, Training accuracy: 0.3555\n",
      "Validation loss: 2.0160, Validation accuracy: 0.2520\n",
      "\n",
      "Epoch 18:\n",
      "Training loss: 0.9627, Training accuracy: 0.3566\n",
      "Validation loss: 1.8060, Validation accuracy: 0.3034\n",
      "\n",
      "Epoch 19:\n",
      "Training loss: 0.9599, Training accuracy: 0.3536\n",
      "Validation loss: 1.8821, Validation accuracy: 0.2993\n",
      "\n",
      "Epoch 20:\n",
      "Training loss: 0.9566, Training accuracy: 0.3585\n",
      "Validation loss: 1.8007, Validation accuracy: 0.2961\n",
      "\n",
      "Epoch 21:\n",
      "Training loss: 0.9593, Training accuracy: 0.3585\n",
      "Validation loss: 2.0295, Validation accuracy: 0.2760\n",
      "\n",
      "Epoch 22:\n",
      "Training loss: 0.9583, Training accuracy: 0.3584\n",
      "Validation loss: 1.8003, Validation accuracy: 0.3162\n",
      "\n",
      "Epoch 23:\n",
      "Training loss: 0.9611, Training accuracy: 0.3567\n",
      "Validation loss: 2.1271, Validation accuracy: 0.2487\n",
      "\n",
      "Epoch 24:\n",
      "Training loss: 0.9638, Training accuracy: 0.3544\n",
      "Validation loss: 1.8467, Validation accuracy: 0.2893\n",
      "\n",
      "Epoch 25:\n",
      "Training loss: 0.9636, Training accuracy: 0.3534\n",
      "Validation loss: 2.1106, Validation accuracy: 0.2327\n",
      "\n",
      "Epoch 26:\n",
      "Training loss: 0.9626, Training accuracy: 0.3539\n",
      "Validation loss: 1.8272, Validation accuracy: 0.2981\n",
      "\n",
      "Epoch 27:\n",
      "Training loss: 0.9668, Training accuracy: 0.3512\n",
      "Validation loss: 2.2668, Validation accuracy: 0.2488\n",
      "\n",
      "Epoch 28:\n",
      "Training loss: 0.9627, Training accuracy: 0.3545\n",
      "Validation loss: 1.8018, Validation accuracy: 0.3099\n",
      "\n",
      "Epoch 29:\n",
      "Training loss: 0.9610, Training accuracy: 0.3577\n",
      "Validation loss: 1.9706, Validation accuracy: 0.2972\n",
      "\n",
      "Epoch 30:\n",
      "Training loss: 0.9648, Training accuracy: 0.3516\n",
      "Validation loss: 1.9091, Validation accuracy: 0.2988\n",
      "\n",
      "Epoch 31:\n",
      "Training loss: 0.9648, Training accuracy: 0.3523\n",
      "Validation loss: 1.8442, Validation accuracy: 0.3243\n",
      "\n",
      "Epoch 32:\n",
      "Training loss: 0.9622, Training accuracy: 0.3552\n",
      "Validation loss: 1.8427, Validation accuracy: 0.2907\n",
      "\n",
      "Epoch 33:\n",
      "Training loss: 0.9588, Training accuracy: 0.3589\n",
      "Validation loss: 2.1528, Validation accuracy: 0.2347\n",
      "\n",
      "Epoch 34:\n",
      "Training loss: 0.9658, Training accuracy: 0.3544\n",
      "Validation loss: 2.0473, Validation accuracy: 0.2382\n",
      "\n",
      "Epoch 35:\n",
      "Training loss: 0.9668, Training accuracy: 0.3490\n",
      "Validation loss: 1.8598, Validation accuracy: 0.2875\n",
      "\n",
      "Epoch 36:\n",
      "Training loss: 0.9660, Training accuracy: 0.3536\n",
      "Validation loss: 2.3874, Validation accuracy: 0.2190\n",
      "\n",
      "Epoch 37:\n",
      "Training loss: 0.9666, Training accuracy: 0.3527\n",
      "Validation loss: 2.1489, Validation accuracy: 0.2437\n",
      "\n",
      "Epoch 38:\n",
      "Training loss: 0.9627, Training accuracy: 0.3545\n",
      "Validation loss: 2.1494, Validation accuracy: 0.2375\n",
      "\n",
      "Epoch 39:\n",
      "Training loss: 0.9682, Training accuracy: 0.3533\n",
      "Validation loss: 2.0516, Validation accuracy: 0.2303\n",
      "\n",
      "Epoch 40:\n",
      "Training loss: 0.9688, Training accuracy: 0.3528\n",
      "Validation loss: 2.0430, Validation accuracy: 0.2642\n",
      "\n",
      "Epoch 41:\n",
      "Training loss: 0.9693, Training accuracy: 0.3525\n",
      "Validation loss: 1.9282, Validation accuracy: 0.2724\n",
      "\n",
      "Epoch 42:\n",
      "Training loss: 0.9721, Training accuracy: 0.3515\n",
      "Validation loss: 1.9406, Validation accuracy: 0.2519\n",
      "\n",
      "Epoch 43:\n",
      "Training loss: 0.9748, Training accuracy: 0.3465\n",
      "Validation loss: 2.0272, Validation accuracy: 0.2918\n",
      "\n",
      "Epoch 44:\n",
      "Training loss: 0.9732, Training accuracy: 0.3482\n",
      "Validation loss: 2.0574, Validation accuracy: 0.2573\n",
      "\n",
      "Epoch 45:\n",
      "Training loss: 0.9735, Training accuracy: 0.3465\n",
      "Validation loss: 2.2917, Validation accuracy: 0.1987\n",
      "\n",
      "Epoch 46:\n",
      "Training loss: 0.9724, Training accuracy: 0.3498\n",
      "Validation loss: 1.8936, Validation accuracy: 0.3005\n",
      "\n",
      "Epoch 47:\n",
      "Training loss: 0.9662, Training accuracy: 0.3544\n",
      "Validation loss: 1.7957, Validation accuracy: 0.3272\n",
      "\n",
      "Epoch 48:\n",
      "Training loss: 0.9689, Training accuracy: 0.3535\n",
      "Validation loss: 2.2866, Validation accuracy: 0.2254\n",
      "\n",
      "Epoch 49:\n",
      "Training loss: 0.9689, Training accuracy: 0.3503\n",
      "Validation loss: 1.7958, Validation accuracy: 0.3245\n",
      "\n",
      "Epoch 50:\n",
      "Training loss: 0.9722, Training accuracy: 0.3508\n",
      "Validation loss: 2.0564, Validation accuracy: 0.2586\n",
      "\n",
      "Epoch 51:\n",
      "Training loss: 0.9782, Training accuracy: 0.3459\n",
      "Validation loss: 1.9874, Validation accuracy: 0.2542\n",
      "\n",
      "Epoch 52:\n",
      "Training loss: 0.9763, Training accuracy: 0.3458\n",
      "Validation loss: 1.8559, Validation accuracy: 0.3289\n",
      "\n",
      "Epoch 53:\n",
      "Training loss: 0.9747, Training accuracy: 0.3494\n",
      "Validation loss: 2.2250, Validation accuracy: 0.2558\n",
      "\n",
      "Epoch 54:\n",
      "Training loss: 0.9754, Training accuracy: 0.3490\n",
      "Validation loss: 1.9977, Validation accuracy: 0.2576\n",
      "\n",
      "Epoch 55:\n",
      "Training loss: 0.9778, Training accuracy: 0.3457\n",
      "Validation loss: 2.0611, Validation accuracy: 0.2116\n",
      "\n",
      "Epoch 56:\n",
      "Training loss: 0.9849, Training accuracy: 0.3421\n",
      "Validation loss: 2.4874, Validation accuracy: 0.2061\n",
      "\n",
      "Epoch 57:\n",
      "Training loss: 0.9839, Training accuracy: 0.3402\n",
      "Validation loss: 2.0829, Validation accuracy: 0.2458\n",
      "\n",
      "Epoch 58:\n",
      "Training loss: 0.9876, Training accuracy: 0.3392\n",
      "Validation loss: 1.7904, Validation accuracy: 0.3132\n",
      "\n",
      "Epoch 59:\n",
      "Training loss: 0.9879, Training accuracy: 0.3376\n",
      "Validation loss: 2.0818, Validation accuracy: 0.2451\n",
      "\n",
      "Current learning rate has decayed to 0.010000\n",
      "Epoch 60:\n",
      "Training loss: 0.9035, Training accuracy: 0.4041\n",
      "Validation loss: 1.5310, Validation accuracy: 0.4237\n",
      "Saving ...\n",
      "\n",
      "Epoch 61:\n",
      "Training loss: 0.8763, Training accuracy: 0.4208\n",
      "Validation loss: 1.5838, Validation accuracy: 0.4052\n",
      "\n",
      "Epoch 62:\n",
      "Training loss: 0.8676, Training accuracy: 0.4324\n",
      "Validation loss: 1.4780, Validation accuracy: 0.4378\n",
      "Saving ...\n",
      "\n",
      "Epoch 63:\n",
      "Training loss: 0.8617, Training accuracy: 0.4359\n",
      "Validation loss: 1.6575, Validation accuracy: 0.3860\n",
      "\n",
      "Epoch 64:\n",
      "Training loss: 0.8542, Training accuracy: 0.4434\n",
      "Validation loss: 1.4845, Validation accuracy: 0.4477\n",
      "Saving ...\n",
      "\n",
      "Epoch 65:\n",
      "Training loss: 0.8550, Training accuracy: 0.4472\n",
      "Validation loss: 1.5146, Validation accuracy: 0.4395\n",
      "\n",
      "Epoch 66:\n",
      "Training loss: 0.8466, Training accuracy: 0.4561\n",
      "Validation loss: 1.5325, Validation accuracy: 0.4463\n",
      "\n",
      "Epoch 67:\n",
      "Training loss: 0.8438, Training accuracy: 0.4610\n",
      "Validation loss: 1.5841, Validation accuracy: 0.4266\n",
      "\n",
      "Epoch 68:\n",
      "Training loss: 0.8427, Training accuracy: 0.4637\n",
      "Validation loss: 1.5186, Validation accuracy: 0.4505\n",
      "Saving ...\n",
      "\n",
      "Epoch 69:\n",
      "Training loss: 0.8400, Training accuracy: 0.4673\n",
      "Validation loss: 1.4340, Validation accuracy: 0.4786\n",
      "Saving ...\n",
      "\n",
      "Epoch 70:\n",
      "Training loss: 0.8360, Training accuracy: 0.4767\n",
      "Validation loss: 1.4990, Validation accuracy: 0.4389\n",
      "\n",
      "Epoch 71:\n",
      "Training loss: 0.8336, Training accuracy: 0.4824\n",
      "Validation loss: 1.4177, Validation accuracy: 0.4799\n",
      "Saving ...\n",
      "\n",
      "Epoch 72:\n",
      "Training loss: 0.8305, Training accuracy: 0.4855\n",
      "Validation loss: 1.4671, Validation accuracy: 0.4773\n",
      "\n",
      "Epoch 73:\n",
      "Training loss: 0.8274, Training accuracy: 0.4873\n",
      "Validation loss: 1.5267, Validation accuracy: 0.4479\n",
      "\n",
      "Epoch 74:\n",
      "Training loss: 0.8301, Training accuracy: 0.4849\n",
      "Validation loss: 1.4767, Validation accuracy: 0.4651\n",
      "\n",
      "Epoch 75:\n",
      "Training loss: 0.8244, Training accuracy: 0.4928\n",
      "Validation loss: 1.3678, Validation accuracy: 0.5068\n",
      "Saving ...\n",
      "\n",
      "Epoch 76:\n",
      "Training loss: 0.8223, Training accuracy: 0.4939\n",
      "Validation loss: 1.5178, Validation accuracy: 0.4533\n",
      "\n",
      "Epoch 77:\n",
      "Training loss: 0.8205, Training accuracy: 0.4942\n",
      "Validation loss: 1.5293, Validation accuracy: 0.4537\n",
      "\n",
      "Epoch 78:\n",
      "Training loss: 0.8214, Training accuracy: 0.4953\n",
      "Validation loss: 1.3744, Validation accuracy: 0.5091\n",
      "Saving ...\n",
      "\n",
      "Epoch 79:\n",
      "Training loss: 0.8208, Training accuracy: 0.4955\n",
      "Validation loss: 1.5155, Validation accuracy: 0.4425\n",
      "\n",
      "Epoch 80:\n",
      "Training loss: 0.8201, Training accuracy: 0.4963\n",
      "Validation loss: 1.4171, Validation accuracy: 0.4875\n",
      "\n",
      "Epoch 81:\n",
      "Training loss: 0.8163, Training accuracy: 0.4985\n",
      "Validation loss: 1.4910, Validation accuracy: 0.4585\n",
      "\n",
      "Epoch 82:\n",
      "Training loss: 0.8193, Training accuracy: 0.4970\n",
      "Validation loss: 1.3835, Validation accuracy: 0.5182\n",
      "Saving ...\n",
      "\n",
      "Epoch 83:\n",
      "Training loss: 0.8176, Training accuracy: 0.5028\n",
      "Validation loss: 1.4691, Validation accuracy: 0.4688\n",
      "\n",
      "Epoch 84:\n",
      "Training loss: 0.8153, Training accuracy: 0.5025\n",
      "Validation loss: 1.4173, Validation accuracy: 0.4988\n",
      "\n",
      "Epoch 85:\n",
      "Training loss: 0.8147, Training accuracy: 0.5022\n",
      "Validation loss: 1.3913, Validation accuracy: 0.4998\n",
      "\n",
      "Epoch 86:\n",
      "Training loss: 0.8154, Training accuracy: 0.4996\n",
      "Validation loss: 1.4683, Validation accuracy: 0.4832\n",
      "\n",
      "Epoch 87:\n",
      "Training loss: 0.8132, Training accuracy: 0.5023\n",
      "Validation loss: 1.7150, Validation accuracy: 0.4000\n",
      "\n",
      "Epoch 88:\n",
      "Training loss: 0.8125, Training accuracy: 0.5041\n",
      "Validation loss: 1.4366, Validation accuracy: 0.4839\n",
      "\n",
      "Epoch 89:\n",
      "Training loss: 0.8138, Training accuracy: 0.5031\n",
      "Validation loss: 1.4325, Validation accuracy: 0.4958\n",
      "\n",
      "Epoch 90:\n",
      "Training loss: 0.8119, Training accuracy: 0.5032\n",
      "Validation loss: 1.4449, Validation accuracy: 0.4922\n",
      "\n",
      "Epoch 91:\n",
      "Training loss: 0.8115, Training accuracy: 0.5015\n",
      "Validation loss: 1.4839, Validation accuracy: 0.4748\n",
      "\n",
      "Epoch 92:\n",
      "Training loss: 0.8120, Training accuracy: 0.5028\n",
      "Validation loss: 1.4619, Validation accuracy: 0.4866\n",
      "\n",
      "Epoch 93:\n",
      "Training loss: 0.8104, Training accuracy: 0.5044\n",
      "Validation loss: 1.4266, Validation accuracy: 0.4885\n",
      "\n",
      "Epoch 94:\n",
      "Training loss: 0.8088, Training accuracy: 0.5055\n",
      "Validation loss: 1.4380, Validation accuracy: 0.4862\n",
      "\n",
      "Epoch 95:\n",
      "Training loss: 0.8054, Training accuracy: 0.5079\n",
      "Validation loss: 1.4241, Validation accuracy: 0.4958\n",
      "\n",
      "Epoch 96:\n",
      "Training loss: 0.8058, Training accuracy: 0.5083\n",
      "Validation loss: 1.4057, Validation accuracy: 0.5080\n",
      "\n",
      "Epoch 97:\n",
      "Training loss: 0.8029, Training accuracy: 0.5063\n",
      "Validation loss: 1.4821, Validation accuracy: 0.4704\n",
      "\n",
      "Epoch 98:\n",
      "Training loss: 0.8056, Training accuracy: 0.5065\n",
      "Validation loss: 1.3558, Validation accuracy: 0.5354\n",
      "Saving ...\n",
      "\n",
      "Epoch 99:\n",
      "Training loss: 0.8036, Training accuracy: 0.5079\n",
      "Validation loss: 1.3729, Validation accuracy: 0.5132\n",
      "\n",
      "Epoch 100:\n",
      "Training loss: 0.8038, Training accuracy: 0.5071\n",
      "Validation loss: 1.4118, Validation accuracy: 0.4830\n",
      "\n",
      "Epoch 101:\n",
      "Training loss: 0.8021, Training accuracy: 0.5083\n",
      "Validation loss: 1.8653, Validation accuracy: 0.3703\n",
      "\n",
      "Epoch 102:\n",
      "Training loss: 0.8021, Training accuracy: 0.5106\n",
      "Validation loss: 1.4897, Validation accuracy: 0.4625\n",
      "\n",
      "Epoch 103:\n",
      "Training loss: 0.7999, Training accuracy: 0.5114\n",
      "Validation loss: 1.4359, Validation accuracy: 0.4931\n",
      "\n",
      "Epoch 104:\n",
      "Training loss: 0.8006, Training accuracy: 0.5087\n",
      "Validation loss: 1.4637, Validation accuracy: 0.4790\n",
      "\n",
      "Epoch 105:\n",
      "Training loss: 0.8022, Training accuracy: 0.5100\n",
      "Validation loss: 1.4345, Validation accuracy: 0.4900\n",
      "\n",
      "Epoch 106:\n",
      "Training loss: 0.8013, Training accuracy: 0.5109\n",
      "Validation loss: 1.3987, Validation accuracy: 0.4945\n",
      "\n",
      "Epoch 107:\n",
      "Training loss: 0.7986, Training accuracy: 0.5131\n",
      "Validation loss: 1.4413, Validation accuracy: 0.4951\n",
      "\n",
      "Epoch 108:\n",
      "Training loss: 0.7974, Training accuracy: 0.5135\n",
      "Validation loss: 1.5310, Validation accuracy: 0.4578\n",
      "\n",
      "Epoch 109:\n",
      "Training loss: 0.8005, Training accuracy: 0.5122\n",
      "Validation loss: 1.6071, Validation accuracy: 0.4280\n",
      "\n",
      "Epoch 110:\n",
      "Training loss: 0.7995, Training accuracy: 0.5100\n",
      "Validation loss: 1.4546, Validation accuracy: 0.4772\n",
      "\n",
      "Epoch 111:\n",
      "Training loss: 0.7991, Training accuracy: 0.5100\n",
      "Validation loss: 1.3972, Validation accuracy: 0.5116\n",
      "\n",
      "Epoch 112:\n",
      "Training loss: 0.7984, Training accuracy: 0.5127\n",
      "Validation loss: 1.4325, Validation accuracy: 0.4941\n",
      "\n",
      "Epoch 113:\n",
      "Training loss: 0.7958, Training accuracy: 0.5159\n",
      "Validation loss: 1.4812, Validation accuracy: 0.4862\n",
      "\n",
      "Epoch 114:\n",
      "Training loss: 0.7987, Training accuracy: 0.5111\n",
      "Validation loss: 1.5241, Validation accuracy: 0.4532\n",
      "\n",
      "Epoch 115:\n",
      "Training loss: 0.7981, Training accuracy: 0.5145\n",
      "Validation loss: 1.3642, Validation accuracy: 0.5048\n",
      "\n",
      "Epoch 116:\n",
      "Training loss: 0.7998, Training accuracy: 0.5099\n",
      "Validation loss: 1.5073, Validation accuracy: 0.4593\n",
      "\n",
      "Epoch 117:\n",
      "Training loss: 0.7983, Training accuracy: 0.5127\n",
      "Validation loss: 1.3853, Validation accuracy: 0.5077\n",
      "\n",
      "Epoch 118:\n",
      "Training loss: 0.7986, Training accuracy: 0.5119\n",
      "Validation loss: 1.4033, Validation accuracy: 0.4983\n",
      "\n",
      "Epoch 119:\n",
      "Training loss: 0.7976, Training accuracy: 0.5133\n",
      "Validation loss: 1.4669, Validation accuracy: 0.4841\n",
      "\n",
      "Current learning rate has decayed to 0.001000\n",
      "Epoch 120:\n",
      "Training loss: 0.7525, Training accuracy: 0.5518\n",
      "Validation loss: 1.2255, Validation accuracy: 0.5751\n",
      "Saving ...\n",
      "\n",
      "Epoch 121:\n",
      "Training loss: 0.7404, Training accuracy: 0.5613\n",
      "Validation loss: 1.2404, Validation accuracy: 0.5752\n",
      "Saving ...\n",
      "\n",
      "Epoch 122:\n",
      "Training loss: 0.7357, Training accuracy: 0.5667\n",
      "Validation loss: 1.1911, Validation accuracy: 0.5844\n",
      "Saving ...\n",
      "\n",
      "Epoch 123:\n",
      "Training loss: 0.7331, Training accuracy: 0.5659\n",
      "Validation loss: 1.2052, Validation accuracy: 0.5828\n",
      "\n",
      "Epoch 124:\n",
      "Training loss: 0.7290, Training accuracy: 0.5706\n",
      "Validation loss: 1.2026, Validation accuracy: 0.5785\n",
      "\n",
      "Epoch 125:\n",
      "Training loss: 0.7276, Training accuracy: 0.5686\n",
      "Validation loss: 1.2019, Validation accuracy: 0.5858\n",
      "Saving ...\n",
      "\n",
      "Epoch 126:\n",
      "Training loss: 0.7267, Training accuracy: 0.5718\n",
      "Validation loss: 1.2003, Validation accuracy: 0.5790\n",
      "\n",
      "Epoch 127:\n",
      "Training loss: 0.7256, Training accuracy: 0.5715\n",
      "Validation loss: 1.1912, Validation accuracy: 0.5888\n",
      "Saving ...\n",
      "\n",
      "Epoch 128:\n",
      "Training loss: 0.7242, Training accuracy: 0.5749\n",
      "Validation loss: 1.1956, Validation accuracy: 0.5836\n",
      "\n",
      "Epoch 129:\n",
      "Training loss: 0.7234, Training accuracy: 0.5729\n",
      "Validation loss: 1.2046, Validation accuracy: 0.5804\n",
      "\n",
      "Epoch 130:\n",
      "Training loss: 0.7225, Training accuracy: 0.5722\n",
      "Validation loss: 1.1987, Validation accuracy: 0.5822\n",
      "\n",
      "Epoch 131:\n",
      "Training loss: 0.7239, Training accuracy: 0.5712\n",
      "Validation loss: 1.1917, Validation accuracy: 0.5866\n",
      "\n",
      "Epoch 132:\n",
      "Training loss: 0.7226, Training accuracy: 0.5718\n",
      "Validation loss: 1.1630, Validation accuracy: 0.5954\n",
      "Saving ...\n",
      "\n",
      "Epoch 133:\n",
      "Training loss: 0.7223, Training accuracy: 0.5704\n",
      "Validation loss: 1.2024, Validation accuracy: 0.5796\n",
      "\n",
      "Epoch 134:\n",
      "Training loss: 0.7223, Training accuracy: 0.5730\n",
      "Validation loss: 1.1842, Validation accuracy: 0.5881\n",
      "\n",
      "Epoch 135:\n",
      "Training loss: 0.7223, Training accuracy: 0.5715\n",
      "Validation loss: 1.2090, Validation accuracy: 0.5823\n",
      "\n",
      "Epoch 136:\n",
      "Training loss: 0.7216, Training accuracy: 0.5725\n",
      "Validation loss: 1.1847, Validation accuracy: 0.5828\n",
      "\n",
      "Epoch 137:\n",
      "Training loss: 0.7220, Training accuracy: 0.5705\n",
      "Validation loss: 1.1990, Validation accuracy: 0.5773\n",
      "\n",
      "Epoch 138:\n",
      "Training loss: 0.7205, Training accuracy: 0.5727\n",
      "Validation loss: 1.1881, Validation accuracy: 0.5902\n",
      "\n",
      "Epoch 139:\n",
      "Training loss: 0.7215, Training accuracy: 0.5734\n",
      "Validation loss: 1.1878, Validation accuracy: 0.5891\n",
      "\n",
      "Epoch 140:\n",
      "Training loss: 0.7194, Training accuracy: 0.5752\n",
      "Validation loss: 1.1949, Validation accuracy: 0.5818\n",
      "\n",
      "Epoch 141:\n"
     ]
    }
   ],
   "source": [
    "train(T=3,lamb=0.2,alpha=0.4,train_loader=train_loader,val_loader=val_loader,INITIAL_LR=0.1,DECAY_EPOCHS=[40,100,180],DECAY=0.1,EPOCHS=200,REG = 5e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Training starts!\n",
      "==================================================\n",
      "Epoch 0:\n",
      "Training loss: 1.6790, Training accuracy: 0.2840\n",
      "Validation loss: 1.5954, Validation accuracy: 0.3951\n",
      "Saving ...\n",
      "\n",
      "Epoch 1:\n",
      "Training loss: 1.1758, Training accuracy: 0.4591\n",
      "Validation loss: 1.3836, Validation accuracy: 0.4990\n",
      "Saving ...\n",
      "\n",
      "Epoch 2:\n",
      "Training loss: 1.0274, Training accuracy: 0.5286\n",
      "Validation loss: 1.4362, Validation accuracy: 0.4768\n",
      "\n",
      "Epoch 3:\n",
      "Training loss: 0.9258, Training accuracy: 0.5797\n",
      "Validation loss: 1.3440, Validation accuracy: 0.5389\n",
      "Saving ...\n",
      "\n",
      "Epoch 4:\n",
      "Training loss: 0.8661, Training accuracy: 0.6098\n",
      "Validation loss: 1.1956, Validation accuracy: 0.5925\n",
      "Saving ...\n",
      "\n",
      "Epoch 5:\n",
      "Training loss: 0.8287, Training accuracy: 0.6266\n",
      "Validation loss: 1.3217, Validation accuracy: 0.5501\n",
      "\n",
      "Epoch 6:\n",
      "Training loss: 0.8040, Training accuracy: 0.6423\n",
      "Validation loss: 1.0693, Validation accuracy: 0.6262\n",
      "Saving ...\n",
      "\n",
      "Epoch 7:\n",
      "Training loss: 0.7859, Training accuracy: 0.6481\n",
      "Validation loss: 1.1506, Validation accuracy: 0.6186\n",
      "\n",
      "Epoch 8:\n",
      "Training loss: 0.7702, Training accuracy: 0.6588\n",
      "Validation loss: 1.3087, Validation accuracy: 0.5678\n",
      "\n",
      "Epoch 9:\n",
      "Training loss: 0.7601, Training accuracy: 0.6622\n",
      "Validation loss: 1.0792, Validation accuracy: 0.6254\n",
      "\n",
      "Epoch 10:\n",
      "Training loss: 0.5118, Training accuracy: 0.6900\n",
      "Validation loss: 1.3182, Validation accuracy: 0.5589\n",
      "\n",
      "Epoch 11:\n",
      "Training loss: 0.5274, Training accuracy: 0.6811\n",
      "Validation loss: 1.1505, Validation accuracy: 0.6134\n",
      "\n",
      "Epoch 12:\n",
      "Training loss: 0.5287, Training accuracy: 0.6799\n",
      "Validation loss: 1.1341, Validation accuracy: 0.6147\n",
      "\n",
      "Epoch 13:\n",
      "Training loss: 0.5293, Training accuracy: 0.6815\n",
      "Validation loss: 1.6962, Validation accuracy: 0.4665\n",
      "\n",
      "Epoch 14:\n",
      "Training loss: 0.5235, Training accuracy: 0.6840\n",
      "Validation loss: 1.1534, Validation accuracy: 0.6098\n",
      "\n",
      "Epoch 15:\n",
      "Training loss: 0.5208, Training accuracy: 0.6877\n",
      "Validation loss: 1.2053, Validation accuracy: 0.5978\n",
      "\n",
      "Epoch 16:\n",
      "Training loss: 0.5181, Training accuracy: 0.6871\n",
      "Validation loss: 1.1688, Validation accuracy: 0.6103\n",
      "\n",
      "Epoch 17:\n",
      "Training loss: 0.5191, Training accuracy: 0.6881\n",
      "Validation loss: 0.9400, Validation accuracy: 0.6833\n",
      "Saving ...\n",
      "\n",
      "Epoch 18:\n",
      "Training loss: 0.5141, Training accuracy: 0.6908\n",
      "Validation loss: 1.2848, Validation accuracy: 0.5942\n",
      "\n",
      "Epoch 19:\n",
      "Training loss: 0.5139, Training accuracy: 0.6935\n",
      "Validation loss: 1.1133, Validation accuracy: 0.6227\n",
      "\n",
      "Epoch 20:\n",
      "Training loss: 0.5131, Training accuracy: 0.6918\n",
      "Validation loss: 1.1561, Validation accuracy: 0.6140\n",
      "\n",
      "Epoch 21:\n",
      "Training loss: 0.5126, Training accuracy: 0.6923\n",
      "Validation loss: 1.2697, Validation accuracy: 0.5759\n",
      "\n",
      "Epoch 22:\n",
      "Training loss: 0.5125, Training accuracy: 0.6934\n",
      "Validation loss: 1.2899, Validation accuracy: 0.5618\n",
      "\n",
      "Epoch 23:\n",
      "Training loss: 0.5122, Training accuracy: 0.6921\n",
      "Validation loss: 1.4336, Validation accuracy: 0.5599\n",
      "\n",
      "Epoch 24:\n",
      "Training loss: 0.5143, Training accuracy: 0.6910\n",
      "Validation loss: 1.0107, Validation accuracy: 0.6600\n",
      "\n",
      "Epoch 25:\n",
      "Training loss: 0.5137, Training accuracy: 0.6918\n",
      "Validation loss: 0.9750, Validation accuracy: 0.6667\n",
      "\n",
      "Epoch 26:\n",
      "Training loss: 0.5087, Training accuracy: 0.6945\n",
      "Validation loss: 1.0528, Validation accuracy: 0.6342\n",
      "\n",
      "Epoch 27:\n",
      "Training loss: 0.5080, Training accuracy: 0.6964\n",
      "Validation loss: 1.0460, Validation accuracy: 0.6462\n",
      "\n",
      "Epoch 28:\n",
      "Training loss: 0.5097, Training accuracy: 0.6948\n",
      "Validation loss: 1.4333, Validation accuracy: 0.5430\n",
      "\n",
      "Epoch 29:\n",
      "Training loss: 0.5051, Training accuracy: 0.6960\n",
      "Validation loss: 1.0610, Validation accuracy: 0.6351\n",
      "\n",
      "Epoch 30:\n",
      "Training loss: 0.5064, Training accuracy: 0.6978\n",
      "Validation loss: 1.0844, Validation accuracy: 0.6228\n",
      "\n",
      "Epoch 31:\n",
      "Training loss: 0.5054, Training accuracy: 0.6965\n",
      "Validation loss: 0.9752, Validation accuracy: 0.6609\n",
      "\n",
      "Epoch 32:\n",
      "Training loss: 0.5051, Training accuracy: 0.6981\n",
      "Validation loss: 1.1169, Validation accuracy: 0.6266\n",
      "\n",
      "Epoch 33:\n",
      "Training loss: 0.5072, Training accuracy: 0.6963\n",
      "Validation loss: 0.9975, Validation accuracy: 0.6580\n",
      "\n",
      "Epoch 34:\n",
      "Training loss: 0.5048, Training accuracy: 0.6981\n",
      "Validation loss: 1.4725, Validation accuracy: 0.5286\n",
      "\n",
      "Epoch 35:\n",
      "Training loss: 0.5067, Training accuracy: 0.6937\n",
      "Validation loss: 1.0131, Validation accuracy: 0.6590\n",
      "\n",
      "Epoch 36:\n",
      "Training loss: 0.5079, Training accuracy: 0.6946\n",
      "Validation loss: 0.9895, Validation accuracy: 0.6611\n",
      "\n",
      "Epoch 37:\n",
      "Training loss: 0.5065, Training accuracy: 0.6988\n",
      "Validation loss: 1.1278, Validation accuracy: 0.6182\n",
      "\n",
      "Epoch 38:\n",
      "Training loss: 0.5008, Training accuracy: 0.6994\n",
      "Validation loss: 1.0283, Validation accuracy: 0.6489\n",
      "\n",
      "Epoch 39:\n",
      "Training loss: 0.5062, Training accuracy: 0.6985\n",
      "Validation loss: 1.2434, Validation accuracy: 0.6002\n",
      "\n",
      "Current learning rate has decayed to 0.010000\n",
      "Epoch 40:\n",
      "Training loss: 0.3674, Training accuracy: 0.7885\n",
      "Validation loss: 0.5475, Validation accuracy: 0.8162\n",
      "Saving ...\n",
      "\n",
      "Epoch 41:\n",
      "Training loss: 0.3258, Training accuracy: 0.8101\n",
      "Validation loss: 0.5411, Validation accuracy: 0.8195\n",
      "Saving ...\n",
      "\n",
      "Epoch 42:\n",
      "Training loss: 0.3091, Training accuracy: 0.8229\n",
      "Validation loss: 0.5057, Validation accuracy: 0.8333\n",
      "Saving ...\n",
      "\n",
      "Epoch 43:\n",
      "Training loss: 0.3006, Training accuracy: 0.8261\n",
      "Validation loss: 0.5160, Validation accuracy: 0.8285\n",
      "\n",
      "Epoch 44:\n",
      "Training loss: 0.2922, Training accuracy: 0.8319\n",
      "Validation loss: 0.4905, Validation accuracy: 0.8360\n",
      "Saving ...\n",
      "\n",
      "Epoch 45:\n",
      "Training loss: 0.2898, Training accuracy: 0.8330\n",
      "Validation loss: 0.4974, Validation accuracy: 0.8293\n",
      "\n",
      "Epoch 46:\n",
      "Training loss: 0.2864, Training accuracy: 0.8368\n",
      "Validation loss: 0.5523, Validation accuracy: 0.8148\n",
      "\n",
      "Epoch 47:\n",
      "Training loss: 0.2831, Training accuracy: 0.8371\n",
      "Validation loss: 0.5228, Validation accuracy: 0.8216\n",
      "\n",
      "Epoch 48:\n",
      "Training loss: 0.2811, Training accuracy: 0.8387\n",
      "Validation loss: 0.4939, Validation accuracy: 0.8355\n",
      "\n",
      "Epoch 49:\n",
      "Training loss: 0.2800, Training accuracy: 0.8403\n",
      "Validation loss: 0.5192, Validation accuracy: 0.8259\n",
      "\n",
      "Epoch 50:\n",
      "Training loss: 0.2791, Training accuracy: 0.8399\n",
      "Validation loss: 0.5641, Validation accuracy: 0.8100\n",
      "\n",
      "Epoch 51:\n",
      "Training loss: 0.2771, Training accuracy: 0.8417\n",
      "Validation loss: 0.5395, Validation accuracy: 0.8191\n",
      "\n",
      "Epoch 52:\n",
      "Training loss: 0.2761, Training accuracy: 0.8424\n",
      "Validation loss: 0.5439, Validation accuracy: 0.8132\n",
      "\n",
      "Epoch 53:\n",
      "Training loss: 0.2740, Training accuracy: 0.8437\n",
      "Validation loss: 0.5058, Validation accuracy: 0.8269\n",
      "\n",
      "Epoch 54:\n",
      "Training loss: 0.2713, Training accuracy: 0.8449\n",
      "Validation loss: 0.5373, Validation accuracy: 0.8198\n",
      "\n",
      "Epoch 55:\n",
      "Training loss: 0.2691, Training accuracy: 0.8483\n",
      "Validation loss: 0.5367, Validation accuracy: 0.8190\n",
      "\n",
      "Epoch 56:\n",
      "Training loss: 0.2680, Training accuracy: 0.8468\n",
      "Validation loss: 0.5383, Validation accuracy: 0.8222\n",
      "\n",
      "Epoch 57:\n",
      "Training loss: 0.2668, Training accuracy: 0.8490\n",
      "Validation loss: 0.5230, Validation accuracy: 0.8204\n",
      "\n",
      "Epoch 58:\n",
      "Training loss: 0.2636, Training accuracy: 0.8502\n",
      "Validation loss: 0.4747, Validation accuracy: 0.8393\n",
      "Saving ...\n",
      "\n",
      "Epoch 59:\n",
      "Training loss: 0.2599, Training accuracy: 0.8523\n",
      "Validation loss: 0.4847, Validation accuracy: 0.8369\n",
      "\n",
      "Epoch 60:\n",
      "Training loss: 0.2643, Training accuracy: 0.8499\n",
      "Validation loss: 0.5632, Validation accuracy: 0.8085\n",
      "\n",
      "Epoch 61:\n",
      "Training loss: 0.2581, Training accuracy: 0.8542\n",
      "Validation loss: 0.5038, Validation accuracy: 0.8300\n",
      "\n",
      "Epoch 62:\n",
      "Training loss: 0.2591, Training accuracy: 0.8550\n",
      "Validation loss: 0.4860, Validation accuracy: 0.8353\n",
      "\n",
      "Epoch 63:\n",
      "Training loss: 0.2537, Training accuracy: 0.8547\n",
      "Validation loss: 0.5086, Validation accuracy: 0.8287\n",
      "\n",
      "Epoch 64:\n",
      "Training loss: 0.2573, Training accuracy: 0.8547\n",
      "Validation loss: 0.4912, Validation accuracy: 0.8344\n",
      "\n",
      "Epoch 65:\n",
      "Training loss: 0.2535, Training accuracy: 0.8576\n",
      "Validation loss: 0.4860, Validation accuracy: 0.8376\n",
      "\n",
      "Epoch 66:\n",
      "Training loss: 0.2524, Training accuracy: 0.8582\n",
      "Validation loss: 0.4752, Validation accuracy: 0.8401\n",
      "Saving ...\n",
      "\n",
      "Epoch 67:\n",
      "Training loss: 0.2542, Training accuracy: 0.8578\n",
      "Validation loss: 0.4729, Validation accuracy: 0.8422\n",
      "Saving ...\n",
      "\n",
      "Epoch 68:\n",
      "Training loss: 0.2488, Training accuracy: 0.8618\n",
      "Validation loss: 0.5142, Validation accuracy: 0.8295\n",
      "\n",
      "Epoch 69:\n",
      "Training loss: 0.2468, Training accuracy: 0.8612\n",
      "Validation loss: 0.4881, Validation accuracy: 0.8354\n",
      "\n",
      "Epoch 70:\n",
      "Training loss: 0.2476, Training accuracy: 0.8623\n",
      "Validation loss: 0.5282, Validation accuracy: 0.8244\n",
      "\n",
      "Epoch 71:\n",
      "Training loss: 0.2450, Training accuracy: 0.8631\n",
      "Validation loss: 0.5749, Validation accuracy: 0.8086\n",
      "\n",
      "Epoch 72:\n",
      "Training loss: 0.2442, Training accuracy: 0.8638\n",
      "Validation loss: 0.4907, Validation accuracy: 0.8347\n",
      "\n",
      "Epoch 73:\n",
      "Training loss: 0.2435, Training accuracy: 0.8638\n",
      "Validation loss: 0.5122, Validation accuracy: 0.8236\n",
      "\n",
      "Epoch 74:\n",
      "Training loss: 0.2418, Training accuracy: 0.8654\n",
      "Validation loss: 0.4744, Validation accuracy: 0.8398\n",
      "\n",
      "Epoch 75:\n",
      "Training loss: 0.2422, Training accuracy: 0.8650\n",
      "Validation loss: 0.5387, Validation accuracy: 0.8200\n",
      "\n",
      "Epoch 76:\n",
      "Training loss: 0.2418, Training accuracy: 0.8662\n",
      "Validation loss: 0.4872, Validation accuracy: 0.8359\n",
      "\n",
      "Epoch 77:\n",
      "Training loss: 0.2410, Training accuracy: 0.8664\n",
      "Validation loss: 0.5149, Validation accuracy: 0.8285\n",
      "\n",
      "Epoch 78:\n",
      "Training loss: 0.2387, Training accuracy: 0.8667\n",
      "Validation loss: 0.4869, Validation accuracy: 0.8351\n",
      "\n",
      "Epoch 79:\n",
      "Training loss: 0.2394, Training accuracy: 0.8674\n",
      "Validation loss: 0.4472, Validation accuracy: 0.8479\n",
      "Saving ...\n",
      "\n",
      "Epoch 80:\n",
      "Training loss: 0.2403, Training accuracy: 0.8662\n",
      "Validation loss: 0.4767, Validation accuracy: 0.8411\n",
      "\n",
      "Epoch 81:\n",
      "Training loss: 0.2355, Training accuracy: 0.8703\n",
      "Validation loss: 0.5110, Validation accuracy: 0.8291\n",
      "\n",
      "Epoch 82:\n",
      "Training loss: 0.2362, Training accuracy: 0.8683\n",
      "Validation loss: 0.4825, Validation accuracy: 0.8410\n",
      "\n",
      "Epoch 83:\n",
      "Training loss: 0.2343, Training accuracy: 0.8694\n",
      "Validation loss: 0.4791, Validation accuracy: 0.8442\n",
      "\n",
      "Epoch 84:\n",
      "Training loss: 0.2331, Training accuracy: 0.8709\n",
      "Validation loss: 0.4979, Validation accuracy: 0.8332\n",
      "\n",
      "Epoch 85:\n",
      "Training loss: 0.2334, Training accuracy: 0.8713\n",
      "Validation loss: 0.4632, Validation accuracy: 0.8466\n",
      "\n",
      "Epoch 86:\n",
      "Training loss: 0.2308, Training accuracy: 0.8717\n",
      "Validation loss: 0.4333, Validation accuracy: 0.8547\n",
      "Saving ...\n",
      "\n",
      "Epoch 87:\n",
      "Training loss: 0.2305, Training accuracy: 0.8723\n",
      "Validation loss: 0.5105, Validation accuracy: 0.8278\n",
      "\n",
      "Epoch 88:\n",
      "Training loss: 0.2324, Training accuracy: 0.8719\n",
      "Validation loss: 0.4969, Validation accuracy: 0.8347\n",
      "\n",
      "Epoch 89:\n",
      "Training loss: 0.2302, Training accuracy: 0.8722\n",
      "Validation loss: 0.5591, Validation accuracy: 0.8172\n",
      "\n",
      "Epoch 90:\n",
      "Training loss: 0.2294, Training accuracy: 0.8727\n",
      "Validation loss: 0.5063, Validation accuracy: 0.8310\n",
      "\n",
      "Epoch 91:\n",
      "Training loss: 0.2289, Training accuracy: 0.8737\n",
      "Validation loss: 0.5051, Validation accuracy: 0.8304\n",
      "\n",
      "Epoch 92:\n",
      "Training loss: 0.2286, Training accuracy: 0.8736\n",
      "Validation loss: 0.4673, Validation accuracy: 0.8463\n",
      "\n",
      "Epoch 93:\n",
      "Training loss: 0.2285, Training accuracy: 0.8735\n",
      "Validation loss: 0.5144, Validation accuracy: 0.8300\n",
      "\n",
      "Epoch 94:\n",
      "Training loss: 0.2265, Training accuracy: 0.8745\n",
      "Validation loss: 0.5091, Validation accuracy: 0.8310\n",
      "\n",
      "Epoch 95:\n",
      "Training loss: 0.2285, Training accuracy: 0.8718\n",
      "Validation loss: 0.5299, Validation accuracy: 0.8243\n",
      "\n",
      "Epoch 96:\n",
      "Training loss: 0.2231, Training accuracy: 0.8774\n",
      "Validation loss: 0.5196, Validation accuracy: 0.8232\n",
      "\n",
      "Epoch 97:\n",
      "Training loss: 0.2264, Training accuracy: 0.8762\n",
      "Validation loss: 0.5073, Validation accuracy: 0.8286\n",
      "\n",
      "Epoch 98:\n",
      "Training loss: 0.2257, Training accuracy: 0.8747\n",
      "Validation loss: 0.4635, Validation accuracy: 0.8445\n",
      "\n",
      "Epoch 99:\n",
      "Training loss: 0.2250, Training accuracy: 0.8765\n",
      "Validation loss: 0.4928, Validation accuracy: 0.8357\n",
      "\n",
      "Current learning rate has decayed to 0.001000\n",
      "Epoch 100:\n",
      "Training loss: 0.1617, Training accuracy: 0.9182\n",
      "Validation loss: 0.3284, Validation accuracy: 0.8909\n",
      "Saving ...\n",
      "\n",
      "Epoch 101:\n",
      "Training loss: 0.1402, Training accuracy: 0.9325\n",
      "Validation loss: 0.3239, Validation accuracy: 0.8915\n",
      "Saving ...\n",
      "\n",
      "Epoch 102:\n",
      "Training loss: 0.1316, Training accuracy: 0.9379\n",
      "Validation loss: 0.3150, Validation accuracy: 0.8975\n",
      "Saving ...\n",
      "\n",
      "Epoch 103:\n",
      "Training loss: 0.1245, Training accuracy: 0.9413\n",
      "Validation loss: 0.3153, Validation accuracy: 0.8969\n",
      "\n",
      "Epoch 104:\n",
      "Training loss: 0.1220, Training accuracy: 0.9454\n",
      "Validation loss: 0.3183, Validation accuracy: 0.8942\n",
      "\n",
      "Epoch 105:\n",
      "Training loss: 0.1178, Training accuracy: 0.9461\n",
      "Validation loss: 0.3124, Validation accuracy: 0.8985\n",
      "Saving ...\n",
      "\n",
      "Epoch 106:\n",
      "Training loss: 0.1151, Training accuracy: 0.9479\n",
      "Validation loss: 0.3162, Validation accuracy: 0.8978\n",
      "\n",
      "Epoch 107:\n",
      "Training loss: 0.1117, Training accuracy: 0.9500\n",
      "Validation loss: 0.3148, Validation accuracy: 0.8981\n",
      "\n",
      "Epoch 108:\n",
      "Training loss: 0.1083, Training accuracy: 0.9526\n",
      "Validation loss: 0.3149, Validation accuracy: 0.8946\n",
      "\n",
      "Epoch 109:\n",
      "Training loss: 0.1065, Training accuracy: 0.9549\n",
      "Validation loss: 0.3099, Validation accuracy: 0.8993\n",
      "Saving ...\n",
      "\n",
      "Epoch 110:\n",
      "Training loss: 0.1063, Training accuracy: 0.9539\n",
      "Validation loss: 0.3133, Validation accuracy: 0.8977\n",
      "\n",
      "Epoch 111:\n",
      "Training loss: 0.1013, Training accuracy: 0.9573\n",
      "Validation loss: 0.3176, Validation accuracy: 0.8966\n",
      "\n",
      "Epoch 112:\n",
      "Training loss: 0.1000, Training accuracy: 0.9580\n",
      "Validation loss: 0.3230, Validation accuracy: 0.8953\n",
      "\n",
      "Epoch 113:\n",
      "Training loss: 0.0991, Training accuracy: 0.9595\n",
      "Validation loss: 0.3167, Validation accuracy: 0.8963\n",
      "\n",
      "Epoch 114:\n",
      "Training loss: 0.0968, Training accuracy: 0.9593\n",
      "Validation loss: 0.3192, Validation accuracy: 0.8980\n",
      "\n",
      "Epoch 115:\n",
      "Training loss: 0.0973, Training accuracy: 0.9595\n",
      "Validation loss: 0.3220, Validation accuracy: 0.8966\n",
      "\n",
      "Epoch 116:\n",
      "Training loss: 0.0934, Training accuracy: 0.9618\n",
      "Validation loss: 0.3218, Validation accuracy: 0.8979\n",
      "\n",
      "Epoch 117:\n",
      "Training loss: 0.0920, Training accuracy: 0.9625\n",
      "Validation loss: 0.3225, Validation accuracy: 0.8969\n",
      "\n",
      "Epoch 118:\n",
      "Training loss: 0.0905, Training accuracy: 0.9633\n",
      "Validation loss: 0.3267, Validation accuracy: 0.8956\n",
      "\n",
      "Epoch 119:\n",
      "Training loss: 0.0906, Training accuracy: 0.9647\n",
      "Validation loss: 0.3172, Validation accuracy: 0.8987\n",
      "\n",
      "Epoch 120:\n",
      "Training loss: 0.0916, Training accuracy: 0.9625\n",
      "Validation loss: 0.3247, Validation accuracy: 0.8980\n",
      "\n",
      "Epoch 121:\n",
      "Training loss: 0.0881, Training accuracy: 0.9658\n",
      "Validation loss: 0.3212, Validation accuracy: 0.8984\n",
      "\n",
      "Epoch 122:\n",
      "Training loss: 0.0865, Training accuracy: 0.9667\n",
      "Validation loss: 0.3285, Validation accuracy: 0.8945\n",
      "\n",
      "Epoch 123:\n",
      "Training loss: 0.0849, Training accuracy: 0.9682\n",
      "Validation loss: 0.3341, Validation accuracy: 0.8929\n",
      "\n",
      "Epoch 124:\n",
      "Training loss: 0.0838, Training accuracy: 0.9691\n",
      "Validation loss: 0.3381, Validation accuracy: 0.8937\n",
      "\n",
      "Epoch 125:\n",
      "Training loss: 0.0852, Training accuracy: 0.9668\n",
      "Validation loss: 0.3267, Validation accuracy: 0.8971\n",
      "\n",
      "Epoch 126:\n",
      "Training loss: 0.0841, Training accuracy: 0.9679\n",
      "Validation loss: 0.3335, Validation accuracy: 0.8966\n",
      "\n",
      "Epoch 127:\n",
      "Training loss: 0.0821, Training accuracy: 0.9696\n",
      "Validation loss: 0.3296, Validation accuracy: 0.8980\n",
      "\n",
      "Epoch 128:\n",
      "Training loss: 0.0823, Training accuracy: 0.9692\n",
      "Validation loss: 0.3355, Validation accuracy: 0.8946\n",
      "\n",
      "Epoch 129:\n",
      "Training loss: 0.0809, Training accuracy: 0.9701\n",
      "Validation loss: 0.3249, Validation accuracy: 0.8987\n",
      "\n",
      "Epoch 130:\n",
      "Training loss: 0.0803, Training accuracy: 0.9705\n",
      "Validation loss: 0.3334, Validation accuracy: 0.8947\n",
      "\n",
      "Epoch 131:\n",
      "Training loss: 0.0801, Training accuracy: 0.9708\n",
      "Validation loss: 0.3393, Validation accuracy: 0.8965\n",
      "\n",
      "Epoch 132:\n",
      "Training loss: 0.0797, Training accuracy: 0.9707\n",
      "Validation loss: 0.3472, Validation accuracy: 0.8941\n",
      "\n",
      "Epoch 133:\n",
      "Training loss: 0.0798, Training accuracy: 0.9707\n",
      "Validation loss: 0.3411, Validation accuracy: 0.8938\n",
      "\n",
      "Epoch 134:\n",
      "Training loss: 0.0767, Training accuracy: 0.9728\n",
      "Validation loss: 0.3529, Validation accuracy: 0.8915\n",
      "\n",
      "Epoch 135:\n",
      "Training loss: 0.0771, Training accuracy: 0.9727\n",
      "Validation loss: 0.3473, Validation accuracy: 0.8929\n",
      "\n",
      "Epoch 136:\n",
      "Training loss: 0.0768, Training accuracy: 0.9726\n",
      "Validation loss: 0.3440, Validation accuracy: 0.8950\n",
      "\n",
      "Epoch 137:\n",
      "Training loss: 0.0770, Training accuracy: 0.9724\n",
      "Validation loss: 0.3514, Validation accuracy: 0.8909\n",
      "\n",
      "Epoch 138:\n",
      "Training loss: 0.0776, Training accuracy: 0.9717\n",
      "Validation loss: 0.3343, Validation accuracy: 0.8982\n",
      "\n",
      "Epoch 139:\n",
      "Training loss: 0.0769, Training accuracy: 0.9722\n",
      "Validation loss: 0.3474, Validation accuracy: 0.8922\n",
      "\n",
      "Epoch 140:\n",
      "Training loss: 0.0762, Training accuracy: 0.9724\n",
      "Validation loss: 0.3599, Validation accuracy: 0.8892\n",
      "\n",
      "Epoch 141:\n",
      "Training loss: 0.0744, Training accuracy: 0.9747\n",
      "Validation loss: 0.3541, Validation accuracy: 0.8927\n",
      "\n",
      "Epoch 142:\n",
      "Training loss: 0.0747, Training accuracy: 0.9738\n",
      "Validation loss: 0.3596, Validation accuracy: 0.8902\n",
      "\n",
      "Epoch 143:\n",
      "Training loss: 0.0737, Training accuracy: 0.9742\n",
      "Validation loss: 0.3524, Validation accuracy: 0.8910\n",
      "\n",
      "Epoch 144:\n",
      "Training loss: 0.0733, Training accuracy: 0.9752\n",
      "Validation loss: 0.3530, Validation accuracy: 0.8908\n",
      "\n",
      "Epoch 145:\n",
      "Training loss: 0.0736, Training accuracy: 0.9746\n",
      "Validation loss: 0.3529, Validation accuracy: 0.8942\n",
      "\n",
      "Epoch 146:\n",
      "Training loss: 0.0731, Training accuracy: 0.9744\n",
      "Validation loss: 0.3583, Validation accuracy: 0.8906\n",
      "\n",
      "Epoch 147:\n",
      "Training loss: 0.0724, Training accuracy: 0.9752\n",
      "Validation loss: 0.3549, Validation accuracy: 0.8912\n",
      "\n",
      "Epoch 148:\n",
      "Training loss: 0.0724, Training accuracy: 0.9751\n",
      "Validation loss: 0.3547, Validation accuracy: 0.8933\n",
      "\n",
      "Epoch 149:\n",
      "Training loss: 0.0735, Training accuracy: 0.9748\n",
      "Validation loss: 0.3801, Validation accuracy: 0.8841\n",
      "\n",
      "Epoch 150:\n",
      "Training loss: 0.0735, Training accuracy: 0.9740\n",
      "Validation loss: 0.3484, Validation accuracy: 0.8966\n",
      "\n",
      "Epoch 151:\n",
      "Training loss: 0.0720, Training accuracy: 0.9750\n",
      "Validation loss: 0.3599, Validation accuracy: 0.8890\n",
      "\n",
      "Epoch 152:\n",
      "Training loss: 0.0711, Training accuracy: 0.9761\n",
      "Validation loss: 0.3574, Validation accuracy: 0.8925\n",
      "\n",
      "Epoch 153:\n",
      "Training loss: 0.0723, Training accuracy: 0.9748\n",
      "Validation loss: 0.3664, Validation accuracy: 0.8869\n",
      "\n",
      "Epoch 154:\n",
      "Training loss: 0.0715, Training accuracy: 0.9755\n",
      "Validation loss: 0.3628, Validation accuracy: 0.8896\n",
      "\n",
      "Epoch 155:\n",
      "Training loss: 0.0712, Training accuracy: 0.9758\n",
      "Validation loss: 0.3603, Validation accuracy: 0.8891\n",
      "\n",
      "Epoch 156:\n",
      "Training loss: 0.0712, Training accuracy: 0.9762\n",
      "Validation loss: 0.3592, Validation accuracy: 0.8913\n",
      "\n",
      "Epoch 157:\n",
      "Training loss: 0.0711, Training accuracy: 0.9759\n",
      "Validation loss: 0.3639, Validation accuracy: 0.8908\n",
      "\n",
      "Epoch 158:\n",
      "Training loss: 0.0710, Training accuracy: 0.9757\n",
      "Validation loss: 0.3558, Validation accuracy: 0.8919\n",
      "\n",
      "Epoch 159:\n",
      "Training loss: 0.0732, Training accuracy: 0.9744\n",
      "Validation loss: 0.3626, Validation accuracy: 0.8886\n",
      "\n",
      "Epoch 160:\n",
      "Training loss: 0.0713, Training accuracy: 0.9759\n",
      "Validation loss: 0.3586, Validation accuracy: 0.8933\n",
      "\n",
      "Epoch 161:\n",
      "Training loss: 0.0706, Training accuracy: 0.9755\n",
      "Validation loss: 0.3871, Validation accuracy: 0.8819\n",
      "\n",
      "Epoch 162:\n",
      "Training loss: 0.0704, Training accuracy: 0.9769\n",
      "Validation loss: 0.3707, Validation accuracy: 0.8900\n",
      "\n",
      "Epoch 163:\n",
      "Training loss: 0.0694, Training accuracy: 0.9768\n",
      "Validation loss: 0.3689, Validation accuracy: 0.8885\n",
      "\n",
      "Epoch 164:\n",
      "Training loss: 0.0716, Training accuracy: 0.9751\n",
      "Validation loss: 0.3648, Validation accuracy: 0.8875\n",
      "\n",
      "Epoch 165:\n",
      "Training loss: 0.0700, Training accuracy: 0.9765\n",
      "Validation loss: 0.3865, Validation accuracy: 0.8823\n",
      "\n",
      "Epoch 166:\n",
      "Training loss: 0.0711, Training accuracy: 0.9751\n",
      "Validation loss: 0.3771, Validation accuracy: 0.8860\n",
      "\n",
      "Epoch 167:\n",
      "Training loss: 0.0701, Training accuracy: 0.9764\n",
      "Validation loss: 0.3805, Validation accuracy: 0.8831\n",
      "\n",
      "Epoch 168:\n",
      "Training loss: 0.0687, Training accuracy: 0.9770\n",
      "Validation loss: 0.3880, Validation accuracy: 0.8829\n",
      "\n",
      "Epoch 169:\n",
      "Training loss: 0.0713, Training accuracy: 0.9753\n",
      "Validation loss: 0.3728, Validation accuracy: 0.8881\n",
      "\n",
      "Epoch 170:\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_166/2408592979.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlamb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mval_loader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mINITIAL_LR\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mDECAY_EPOCHS\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m180\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mDECAY\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mREG\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m8e-4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_166/795005321.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(T, lamb, alpha, train_loader, val_loader, INITIAL_LR, DECAY_EPOCHS, DECAY, EPOCHS, REG)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# compute the output and loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0mfeature\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlamb\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmse_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmse_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmse_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_166/376220637.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, is_eval)\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresnet50\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0mfeature2\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneck2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mfeature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownsample\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m             \u001b[0midentity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownsample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0midentity\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/torch/nn/modules/batchnorm.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    166\u001b[0m         \u001b[0mused\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mnormalization\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0;32min\u001b[0m \u001b[0meval\u001b[0m \u001b[0mmode\u001b[0m \u001b[0mwhen\u001b[0m \u001b[0mbuffers\u001b[0m \u001b[0mare\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m         \"\"\"\n\u001b[0;32m--> 168\u001b[0;31m         return F.batch_norm(\n\u001b[0m\u001b[1;32m    169\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m             \u001b[0;31m# If buffers are not to be tracked, ensure that they won't be updated\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   2280\u001b[0m         \u001b[0m_verify_batch_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2281\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2282\u001b[0;31m     return torch.batch_norm(\n\u001b[0m\u001b[1;32m   2283\u001b[0m         \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcudnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2284\u001b[0m     )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(T=3,lamb=0.2,alpha=0.4,train_loader=train_loader,val_loader=val_loader,INITIAL_LR=0.1,DECAY_EPOCHS=[40,100,180],DECAY=0.1,EPOCHS=200,REG = 8e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Training starts!\n",
      "==================================================\n",
      "Epoch 0:\n",
      "Training loss: 1.6696, Training accuracy: 0.3068\n",
      "Validation loss: 6.7633, Validation accuracy: 0.4206\n",
      "Saving ...\n",
      "\n",
      "Epoch 1:\n",
      "Training loss: 1.2285, Training accuracy: 0.4491\n",
      "Validation loss: 3.8490, Validation accuracy: 0.5173\n",
      "Saving ...\n",
      "\n",
      "Epoch 2:\n",
      "Training loss: 1.0419, Training accuracy: 0.5279\n",
      "Validation loss: 1.4442, Validation accuracy: 0.5666\n",
      "Saving ...\n",
      "\n",
      "Epoch 3:\n",
      "Training loss: 0.9242, Training accuracy: 0.5801\n",
      "Validation loss: 1.1496, Validation accuracy: 0.5949\n",
      "Saving ...\n",
      "\n",
      "Epoch 4:\n",
      "Training loss: 0.8377, Training accuracy: 0.6216\n",
      "Validation loss: 1.0826, Validation accuracy: 0.6309\n",
      "Saving ...\n",
      "\n",
      "Epoch 5:\n",
      "Training loss: 0.7692, Training accuracy: 0.6535\n",
      "Validation loss: 1.0714, Validation accuracy: 0.6267\n",
      "\n",
      "Epoch 6:\n",
      "Training loss: 0.7134, Training accuracy: 0.6761\n",
      "Validation loss: 0.9235, Validation accuracy: 0.6878\n",
      "Saving ...\n",
      "\n",
      "Epoch 7:\n",
      "Training loss: 0.6729, Training accuracy: 0.6991\n",
      "Validation loss: 0.8397, Validation accuracy: 0.7084\n",
      "Saving ...\n",
      "\n",
      "Epoch 8:\n",
      "Training loss: 0.6395, Training accuracy: 0.7143\n",
      "Validation loss: 0.8852, Validation accuracy: 0.6987\n",
      "\n",
      "Epoch 9:\n",
      "Training loss: 0.6169, Training accuracy: 0.7254\n",
      "Validation loss: 0.9414, Validation accuracy: 0.6856\n",
      "\n",
      "Epoch 10:\n",
      "Training loss: 0.4140, Training accuracy: 0.7548\n",
      "Validation loss: 0.7038, Validation accuracy: 0.7592\n",
      "Saving ...\n",
      "\n",
      "Epoch 11:\n",
      "Training loss: 0.4322, Training accuracy: 0.7383\n",
      "Validation loss: 0.7149, Validation accuracy: 0.7505\n",
      "\n",
      "Epoch 12:\n",
      "Training loss: 0.4009, Training accuracy: 0.7605\n",
      "Validation loss: 0.7326, Validation accuracy: 0.7457\n",
      "\n",
      "Epoch 13:\n",
      "Training loss: 0.3952, Training accuracy: 0.7629\n",
      "Validation loss: 0.7392, Validation accuracy: 0.7468\n",
      "\n",
      "Epoch 14:\n",
      "Training loss: 0.3953, Training accuracy: 0.7631\n",
      "Validation loss: 0.7249, Validation accuracy: 0.7479\n",
      "\n",
      "Epoch 15:\n",
      "Training loss: 0.3874, Training accuracy: 0.7694\n",
      "Validation loss: 0.7087, Validation accuracy: 0.7538\n",
      "\n",
      "Epoch 16:\n",
      "Training loss: 0.3816, Training accuracy: 0.7716\n",
      "Validation loss: 0.7402, Validation accuracy: 0.7425\n",
      "\n",
      "Epoch 17:\n",
      "Training loss: 0.3770, Training accuracy: 0.7767\n",
      "Validation loss: 0.7011, Validation accuracy: 0.7586\n",
      "\n",
      "Epoch 18:\n",
      "Training loss: 0.3734, Training accuracy: 0.7787\n",
      "Validation loss: 0.7850, Validation accuracy: 0.7340\n",
      "\n",
      "Epoch 19:\n",
      "Training loss: 0.3702, Training accuracy: 0.7789\n",
      "Validation loss: 0.7838, Validation accuracy: 0.7302\n",
      "\n",
      "Epoch 20:\n",
      "Training loss: 0.3651, Training accuracy: 0.7827\n",
      "Validation loss: 0.6956, Validation accuracy: 0.7602\n",
      "Saving ...\n",
      "\n",
      "Epoch 21:\n",
      "Training loss: 0.3594, Training accuracy: 0.7859\n",
      "Validation loss: 0.6515, Validation accuracy: 0.7718\n",
      "Saving ...\n",
      "\n",
      "Epoch 22:\n",
      "Training loss: 0.3596, Training accuracy: 0.7853\n",
      "Validation loss: 0.7453, Validation accuracy: 0.7496\n",
      "\n",
      "Epoch 23:\n",
      "Training loss: 0.3550, Training accuracy: 0.7897\n",
      "Validation loss: 0.7828, Validation accuracy: 0.7364\n",
      "\n",
      "Epoch 24:\n",
      "Training loss: 0.3543, Training accuracy: 0.7890\n",
      "Validation loss: 0.7248, Validation accuracy: 0.7556\n",
      "\n",
      "Epoch 25:\n",
      "Training loss: 0.3465, Training accuracy: 0.7956\n",
      "Validation loss: 0.6795, Validation accuracy: 0.7666\n",
      "\n",
      "Epoch 26:\n",
      "Training loss: 0.3459, Training accuracy: 0.7939\n",
      "Validation loss: 0.6784, Validation accuracy: 0.7680\n",
      "\n",
      "Epoch 27:\n",
      "Training loss: 0.3438, Training accuracy: 0.7970\n",
      "Validation loss: 0.7123, Validation accuracy: 0.7618\n",
      "\n",
      "Epoch 28:\n",
      "Training loss: 0.3394, Training accuracy: 0.8004\n",
      "Validation loss: 0.7204, Validation accuracy: 0.7588\n",
      "\n",
      "Epoch 29:\n",
      "Training loss: 0.3394, Training accuracy: 0.7996\n",
      "Validation loss: 0.6310, Validation accuracy: 0.7842\n",
      "Saving ...\n",
      "\n",
      "Epoch 30:\n",
      "Training loss: 0.3372, Training accuracy: 0.8006\n",
      "Validation loss: 0.6358, Validation accuracy: 0.7870\n",
      "Saving ...\n",
      "\n",
      "Epoch 31:\n",
      "Training loss: 0.3318, Training accuracy: 0.8058\n",
      "Validation loss: 0.6260, Validation accuracy: 0.7847\n",
      "\n",
      "Epoch 32:\n",
      "Training loss: 0.3350, Training accuracy: 0.8033\n",
      "Validation loss: 0.6531, Validation accuracy: 0.7756\n",
      "\n",
      "Epoch 33:\n",
      "Training loss: 0.3330, Training accuracy: 0.8022\n",
      "Validation loss: 0.6905, Validation accuracy: 0.7698\n",
      "\n",
      "Epoch 34:\n",
      "Training loss: 0.3310, Training accuracy: 0.8051\n",
      "Validation loss: 0.7943, Validation accuracy: 0.7426\n",
      "\n",
      "Epoch 35:\n",
      "Training loss: 0.3292, Training accuracy: 0.8090\n",
      "Validation loss: 0.7064, Validation accuracy: 0.7580\n",
      "\n",
      "Epoch 36:\n",
      "Training loss: 0.3272, Training accuracy: 0.8076\n",
      "Validation loss: 0.7914, Validation accuracy: 0.7383\n",
      "\n",
      "Epoch 37:\n",
      "Training loss: 0.3278, Training accuracy: 0.8069\n",
      "Validation loss: 0.5845, Validation accuracy: 0.7991\n",
      "Saving ...\n",
      "\n",
      "Epoch 38:\n",
      "Training loss: 0.3245, Training accuracy: 0.8099\n",
      "Validation loss: 0.5892, Validation accuracy: 0.7971\n",
      "\n",
      "Epoch 39:\n",
      "Training loss: 0.3232, Training accuracy: 0.8106\n",
      "Validation loss: 0.7062, Validation accuracy: 0.7714\n",
      "\n",
      "Current learning rate has decayed to 0.010000\n",
      "Epoch 40:\n",
      "Training loss: 0.2298, Training accuracy: 0.8690\n",
      "Validation loss: 0.3960, Validation accuracy: 0.8633\n",
      "Saving ...\n",
      "\n",
      "Epoch 41:\n",
      "Training loss: 0.2014, Training accuracy: 0.8856\n",
      "Validation loss: 0.3760, Validation accuracy: 0.8715\n",
      "Saving ...\n",
      "\n",
      "Epoch 42:\n",
      "Training loss: 0.1883, Training accuracy: 0.8924\n",
      "Validation loss: 0.3662, Validation accuracy: 0.8771\n",
      "Saving ...\n",
      "\n",
      "Epoch 43:\n",
      "Training loss: 0.1809, Training accuracy: 0.8983\n",
      "Validation loss: 0.3664, Validation accuracy: 0.8768\n",
      "\n",
      "Epoch 44:\n",
      "Training loss: 0.1728, Training accuracy: 0.9045\n",
      "Validation loss: 0.3694, Validation accuracy: 0.8728\n",
      "\n",
      "Epoch 45:\n",
      "Training loss: 0.1678, Training accuracy: 0.9072\n",
      "Validation loss: 0.3589, Validation accuracy: 0.8802\n",
      "Saving ...\n",
      "\n",
      "Epoch 46:\n",
      "Training loss: 0.1625, Training accuracy: 0.9112\n",
      "Validation loss: 0.3492, Validation accuracy: 0.8797\n",
      "\n",
      "Epoch 47:\n",
      "Training loss: 0.1576, Training accuracy: 0.9140\n",
      "Validation loss: 0.3610, Validation accuracy: 0.8820\n",
      "Saving ...\n",
      "\n",
      "Epoch 48:\n",
      "Training loss: 0.1544, Training accuracy: 0.9161\n",
      "Validation loss: 0.3502, Validation accuracy: 0.8819\n",
      "\n",
      "Epoch 49:\n",
      "Training loss: 0.1501, Training accuracy: 0.9178\n",
      "Validation loss: 0.3546, Validation accuracy: 0.8805\n",
      "\n",
      "Epoch 50:\n",
      "Training loss: 0.1465, Training accuracy: 0.9211\n",
      "Validation loss: 0.3445, Validation accuracy: 0.8830\n",
      "Saving ...\n",
      "\n",
      "Epoch 51:\n",
      "Training loss: 0.1449, Training accuracy: 0.9218\n",
      "Validation loss: 0.3567, Validation accuracy: 0.8803\n",
      "\n",
      "Epoch 52:\n",
      "Training loss: 0.1401, Training accuracy: 0.9245\n",
      "Validation loss: 0.3570, Validation accuracy: 0.8797\n",
      "\n",
      "Epoch 53:\n",
      "Training loss: 0.1371, Training accuracy: 0.9270\n",
      "Validation loss: 0.3565, Validation accuracy: 0.8802\n",
      "\n",
      "Epoch 54:\n",
      "Training loss: 0.1359, Training accuracy: 0.9277\n",
      "Validation loss: 0.3576, Validation accuracy: 0.8800\n",
      "\n",
      "Epoch 55:\n",
      "Training loss: 0.1351, Training accuracy: 0.9265\n",
      "Validation loss: 0.3559, Validation accuracy: 0.8791\n",
      "\n",
      "Epoch 56:\n",
      "Training loss: 0.1305, Training accuracy: 0.9311\n",
      "Validation loss: 0.3449, Validation accuracy: 0.8819\n",
      "\n",
      "Epoch 57:\n",
      "Training loss: 0.1294, Training accuracy: 0.9323\n",
      "Validation loss: 0.3581, Validation accuracy: 0.8825\n",
      "\n",
      "Epoch 58:\n",
      "Training loss: 0.1266, Training accuracy: 0.9326\n",
      "Validation loss: 0.3573, Validation accuracy: 0.8834\n",
      "Saving ...\n",
      "\n",
      "Epoch 59:\n",
      "Training loss: 0.1283, Training accuracy: 0.9318\n",
      "Validation loss: 0.3597, Validation accuracy: 0.8815\n",
      "\n",
      "Epoch 60:\n",
      "Training loss: 0.1259, Training accuracy: 0.9341\n",
      "Validation loss: 0.3616, Validation accuracy: 0.8810\n",
      "\n",
      "Epoch 61:\n",
      "Training loss: 0.1252, Training accuracy: 0.9338\n",
      "Validation loss: 0.3589, Validation accuracy: 0.8803\n",
      "\n",
      "Epoch 62:\n",
      "Training loss: 0.1239, Training accuracy: 0.9351\n",
      "Validation loss: 0.3618, Validation accuracy: 0.8811\n",
      "\n",
      "Epoch 63:\n",
      "Training loss: 0.1219, Training accuracy: 0.9377\n",
      "Validation loss: 0.3529, Validation accuracy: 0.8836\n",
      "Saving ...\n",
      "\n",
      "Epoch 64:\n",
      "Training loss: 0.1223, Training accuracy: 0.9354\n",
      "Validation loss: 0.3612, Validation accuracy: 0.8793\n",
      "\n",
      "Epoch 65:\n",
      "Training loss: 0.1197, Training accuracy: 0.9382\n",
      "Validation loss: 0.3800, Validation accuracy: 0.8782\n",
      "\n",
      "Epoch 66:\n",
      "Training loss: 0.1181, Training accuracy: 0.9395\n",
      "Validation loss: 0.3589, Validation accuracy: 0.8814\n",
      "\n",
      "Epoch 67:\n",
      "Training loss: 0.1192, Training accuracy: 0.9373\n",
      "Validation loss: 0.3729, Validation accuracy: 0.8748\n",
      "\n",
      "Epoch 68:\n",
      "Training loss: 0.1169, Training accuracy: 0.9397\n",
      "Validation loss: 0.3707, Validation accuracy: 0.8790\n",
      "\n",
      "Epoch 69:\n",
      "Training loss: 0.1166, Training accuracy: 0.9408\n",
      "Validation loss: 0.3617, Validation accuracy: 0.8806\n",
      "\n",
      "Epoch 70:\n",
      "Training loss: 0.1162, Training accuracy: 0.9414\n",
      "Validation loss: 0.3653, Validation accuracy: 0.8804\n",
      "\n",
      "Epoch 71:\n",
      "Training loss: 0.1147, Training accuracy: 0.9419\n",
      "Validation loss: 0.3804, Validation accuracy: 0.8765\n",
      "\n",
      "Epoch 72:\n",
      "Training loss: 0.1159, Training accuracy: 0.9412\n",
      "Validation loss: 0.3769, Validation accuracy: 0.8775\n",
      "\n",
      "Epoch 73:\n",
      "Training loss: 0.1144, Training accuracy: 0.9422\n",
      "Validation loss: 0.3607, Validation accuracy: 0.8795\n",
      "\n",
      "Epoch 74:\n",
      "Training loss: 0.1135, Training accuracy: 0.9421\n",
      "Validation loss: 0.3810, Validation accuracy: 0.8778\n",
      "\n",
      "Epoch 75:\n",
      "Training loss: 0.1133, Training accuracy: 0.9422\n",
      "Validation loss: 0.3936, Validation accuracy: 0.8699\n",
      "\n",
      "Epoch 76:\n",
      "Training loss: 0.1122, Training accuracy: 0.9442\n",
      "Validation loss: 0.3820, Validation accuracy: 0.8738\n",
      "\n",
      "Epoch 77:\n",
      "Training loss: 0.1135, Training accuracy: 0.9424\n",
      "Validation loss: 0.3905, Validation accuracy: 0.8752\n",
      "\n",
      "Epoch 78:\n",
      "Training loss: 0.1126, Training accuracy: 0.9437\n",
      "Validation loss: 0.4002, Validation accuracy: 0.8658\n",
      "\n",
      "Epoch 79:\n",
      "Training loss: 0.1138, Training accuracy: 0.9420\n",
      "Validation loss: 0.3790, Validation accuracy: 0.8749\n",
      "\n",
      "Epoch 80:\n",
      "Training loss: 0.1125, Training accuracy: 0.9424\n",
      "Validation loss: 0.3724, Validation accuracy: 0.8809\n",
      "\n",
      "Epoch 81:\n",
      "Training loss: 0.1107, Training accuracy: 0.9441\n",
      "Validation loss: 0.3576, Validation accuracy: 0.8821\n",
      "\n",
      "Epoch 82:\n",
      "Training loss: 0.1082, Training accuracy: 0.9461\n",
      "Validation loss: 0.3785, Validation accuracy: 0.8772\n",
      "\n",
      "Epoch 83:\n",
      "Training loss: 0.1106, Training accuracy: 0.9442\n",
      "Validation loss: 0.3681, Validation accuracy: 0.8783\n",
      "\n",
      "Epoch 84:\n",
      "Training loss: 0.1102, Training accuracy: 0.9443\n",
      "Validation loss: 0.3832, Validation accuracy: 0.8783\n",
      "\n",
      "Epoch 85:\n",
      "Training loss: 0.1094, Training accuracy: 0.9449\n",
      "Validation loss: 0.3972, Validation accuracy: 0.8754\n",
      "\n",
      "Epoch 86:\n",
      "Training loss: 0.1093, Training accuracy: 0.9459\n",
      "Validation loss: 0.3919, Validation accuracy: 0.8695\n",
      "\n",
      "Epoch 87:\n",
      "Training loss: 0.1100, Training accuracy: 0.9442\n",
      "Validation loss: 0.3915, Validation accuracy: 0.8708\n",
      "\n",
      "Epoch 88:\n",
      "Training loss: 0.1083, Training accuracy: 0.9467\n",
      "Validation loss: 0.4506, Validation accuracy: 0.8574\n",
      "\n",
      "Epoch 89:\n",
      "Training loss: 0.1078, Training accuracy: 0.9464\n",
      "Validation loss: 0.3672, Validation accuracy: 0.8795\n",
      "\n",
      "Epoch 90:\n",
      "Training loss: 0.1073, Training accuracy: 0.9466\n",
      "Validation loss: 0.3825, Validation accuracy: 0.8751\n",
      "\n",
      "Epoch 91:\n",
      "Training loss: 0.1068, Training accuracy: 0.9472\n",
      "Validation loss: 0.3739, Validation accuracy: 0.8784\n",
      "\n",
      "Epoch 92:\n",
      "Training loss: 0.1080, Training accuracy: 0.9450\n",
      "Validation loss: 0.3649, Validation accuracy: 0.8802\n",
      "\n",
      "Epoch 93:\n",
      "Training loss: 0.1055, Training accuracy: 0.9465\n",
      "Validation loss: 0.3938, Validation accuracy: 0.8740\n",
      "\n",
      "Epoch 94:\n",
      "Training loss: 0.1054, Training accuracy: 0.9485\n",
      "Validation loss: 0.3853, Validation accuracy: 0.8772\n",
      "\n",
      "Epoch 95:\n",
      "Training loss: 0.1052, Training accuracy: 0.9480\n",
      "Validation loss: 0.3921, Validation accuracy: 0.8748\n",
      "\n",
      "Epoch 96:\n",
      "Training loss: 0.1046, Training accuracy: 0.9483\n",
      "Validation loss: 0.3912, Validation accuracy: 0.8758\n",
      "\n",
      "Epoch 97:\n",
      "Training loss: 0.1074, Training accuracy: 0.9470\n",
      "Validation loss: 0.3745, Validation accuracy: 0.8798\n",
      "\n",
      "Epoch 98:\n",
      "Training loss: 0.1055, Training accuracy: 0.9474\n",
      "Validation loss: 0.3885, Validation accuracy: 0.8769\n",
      "\n",
      "Epoch 99:\n",
      "Training loss: 0.1057, Training accuracy: 0.9470\n",
      "Validation loss: 0.3777, Validation accuracy: 0.8802\n",
      "\n",
      "Current learning rate has decayed to 0.001000\n",
      "Epoch 100:\n",
      "Training loss: 0.0730, Training accuracy: 0.9696\n",
      "Validation loss: 0.3226, Validation accuracy: 0.8979\n",
      "Saving ...\n",
      "\n",
      "Epoch 101:\n",
      "Training loss: 0.0610, Training accuracy: 0.9768\n",
      "Validation loss: 0.3209, Validation accuracy: 0.8980\n",
      "Saving ...\n",
      "\n",
      "Epoch 102:\n",
      "Training loss: 0.0561, Training accuracy: 0.9801\n",
      "Validation loss: 0.3203, Validation accuracy: 0.8980\n",
      "\n",
      "Epoch 103:\n",
      "Training loss: 0.0529, Training accuracy: 0.9826\n",
      "Validation loss: 0.3175, Validation accuracy: 0.8992\n",
      "Saving ...\n",
      "\n",
      "Epoch 104:\n",
      "Training loss: 0.0512, Training accuracy: 0.9838\n",
      "Validation loss: 0.3136, Validation accuracy: 0.9010\n",
      "Saving ...\n",
      "\n",
      "Epoch 105:\n",
      "Training loss: 0.0489, Training accuracy: 0.9851\n",
      "Validation loss: 0.3162, Validation accuracy: 0.9018\n",
      "Saving ...\n",
      "\n",
      "Epoch 106:\n",
      "Training loss: 0.0481, Training accuracy: 0.9847\n",
      "Validation loss: 0.3181, Validation accuracy: 0.9003\n",
      "\n",
      "Epoch 107:\n",
      "Training loss: 0.0457, Training accuracy: 0.9869\n",
      "Validation loss: 0.3176, Validation accuracy: 0.8994\n",
      "\n",
      "Epoch 108:\n",
      "Training loss: 0.0452, Training accuracy: 0.9870\n",
      "Validation loss: 0.3165, Validation accuracy: 0.9018\n",
      "\n",
      "Epoch 109:\n",
      "Training loss: 0.0442, Training accuracy: 0.9876\n",
      "Validation loss: 0.3152, Validation accuracy: 0.9032\n",
      "Saving ...\n",
      "\n",
      "Epoch 110:\n",
      "Training loss: 0.0438, Training accuracy: 0.9873\n",
      "Validation loss: 0.3181, Validation accuracy: 0.9007\n",
      "\n",
      "Epoch 111:\n",
      "Training loss: 0.0427, Training accuracy: 0.9884\n",
      "Validation loss: 0.3234, Validation accuracy: 0.9001\n",
      "\n",
      "Epoch 112:\n",
      "Training loss: 0.0410, Training accuracy: 0.9894\n",
      "Validation loss: 0.3239, Validation accuracy: 0.9021\n",
      "\n",
      "Epoch 113:\n",
      "Training loss: 0.0418, Training accuracy: 0.9887\n",
      "Validation loss: 0.3233, Validation accuracy: 0.9009\n",
      "\n",
      "Epoch 114:\n",
      "Training loss: 0.0410, Training accuracy: 0.9890\n",
      "Validation loss: 0.3250, Validation accuracy: 0.9000\n",
      "\n",
      "Epoch 115:\n",
      "Training loss: 0.0398, Training accuracy: 0.9896\n",
      "Validation loss: 0.3207, Validation accuracy: 0.9035\n",
      "Saving ...\n",
      "\n",
      "Epoch 116:\n",
      "Training loss: 0.0396, Training accuracy: 0.9902\n",
      "Validation loss: 0.3215, Validation accuracy: 0.9030\n",
      "\n",
      "Epoch 117:\n",
      "Training loss: 0.0383, Training accuracy: 0.9910\n",
      "Validation loss: 0.3202, Validation accuracy: 0.9038\n",
      "Saving ...\n",
      "\n",
      "Epoch 118:\n",
      "Training loss: 0.0384, Training accuracy: 0.9908\n",
      "Validation loss: 0.3220, Validation accuracy: 0.9022\n",
      "\n",
      "Epoch 119:\n",
      "Training loss: 0.0379, Training accuracy: 0.9911\n",
      "Validation loss: 0.3271, Validation accuracy: 0.9024\n",
      "\n",
      "Epoch 120:\n",
      "Training loss: 0.0377, Training accuracy: 0.9908\n",
      "Validation loss: 0.3273, Validation accuracy: 0.9033\n",
      "\n",
      "Epoch 121:\n",
      "Training loss: 0.0376, Training accuracy: 0.9907\n",
      "Validation loss: 0.3253, Validation accuracy: 0.9036\n",
      "\n",
      "Epoch 122:\n",
      "Training loss: 0.0365, Training accuracy: 0.9915\n",
      "Validation loss: 0.3232, Validation accuracy: 0.9039\n",
      "Saving ...\n",
      "\n",
      "Epoch 123:\n",
      "Training loss: 0.0359, Training accuracy: 0.9918\n",
      "Validation loss: 0.3250, Validation accuracy: 0.9038\n",
      "\n",
      "Epoch 124:\n",
      "Training loss: 0.0359, Training accuracy: 0.9920\n",
      "Validation loss: 0.3278, Validation accuracy: 0.9035\n",
      "\n",
      "Epoch 125:\n",
      "Training loss: 0.0352, Training accuracy: 0.9922\n",
      "Validation loss: 0.3237, Validation accuracy: 0.9030\n",
      "\n",
      "Epoch 126:\n",
      "Training loss: 0.0351, Training accuracy: 0.9924\n",
      "Validation loss: 0.3253, Validation accuracy: 0.9038\n",
      "\n",
      "Epoch 127:\n",
      "Training loss: 0.0346, Training accuracy: 0.9928\n",
      "Validation loss: 0.3306, Validation accuracy: 0.9016\n",
      "\n",
      "Epoch 128:\n",
      "Training loss: 0.0345, Training accuracy: 0.9929\n",
      "Validation loss: 0.3321, Validation accuracy: 0.9012\n",
      "\n",
      "Epoch 129:\n",
      "Training loss: 0.0345, Training accuracy: 0.9930\n",
      "Validation loss: 0.3266, Validation accuracy: 0.9042\n",
      "Saving ...\n",
      "\n",
      "Epoch 130:\n",
      "Training loss: 0.0337, Training accuracy: 0.9928\n",
      "Validation loss: 0.3315, Validation accuracy: 0.9008\n",
      "\n",
      "Epoch 131:\n",
      "Training loss: 0.0332, Training accuracy: 0.9934\n",
      "Validation loss: 0.3295, Validation accuracy: 0.9034\n",
      "\n",
      "Epoch 132:\n",
      "Training loss: 0.0330, Training accuracy: 0.9933\n",
      "Validation loss: 0.3291, Validation accuracy: 0.9034\n",
      "\n",
      "Epoch 133:\n",
      "Training loss: 0.0326, Training accuracy: 0.9939\n",
      "Validation loss: 0.3249, Validation accuracy: 0.9011\n",
      "\n",
      "Epoch 134:\n",
      "Training loss: 0.0328, Training accuracy: 0.9934\n",
      "Validation loss: 0.3311, Validation accuracy: 0.9019\n",
      "\n",
      "Epoch 135:\n",
      "Training loss: 0.0328, Training accuracy: 0.9934\n",
      "Validation loss: 0.3276, Validation accuracy: 0.9025\n",
      "\n",
      "Epoch 136:\n",
      "Training loss: 0.0322, Training accuracy: 0.9938\n",
      "Validation loss: 0.3300, Validation accuracy: 0.9029\n",
      "\n",
      "Epoch 137:\n",
      "Training loss: 0.0319, Training accuracy: 0.9936\n",
      "Validation loss: 0.3277, Validation accuracy: 0.9031\n",
      "\n",
      "Epoch 138:\n",
      "Training loss: 0.0312, Training accuracy: 0.9942\n",
      "Validation loss: 0.3300, Validation accuracy: 0.9042\n",
      "\n",
      "Epoch 139:\n",
      "Training loss: 0.0317, Training accuracy: 0.9938\n",
      "Validation loss: 0.3334, Validation accuracy: 0.9039\n",
      "\n",
      "Epoch 140:\n",
      "Training loss: 0.0313, Training accuracy: 0.9942\n",
      "Validation loss: 0.3313, Validation accuracy: 0.9005\n",
      "\n",
      "Epoch 141:\n",
      "Training loss: 0.0309, Training accuracy: 0.9946\n",
      "Validation loss: 0.3254, Validation accuracy: 0.9034\n",
      "\n",
      "Epoch 142:\n",
      "Training loss: 0.0311, Training accuracy: 0.9936\n",
      "Validation loss: 0.3300, Validation accuracy: 0.9031\n",
      "\n",
      "Epoch 143:\n",
      "Training loss: 0.0305, Training accuracy: 0.9945\n",
      "Validation loss: 0.3294, Validation accuracy: 0.9031\n",
      "\n",
      "Epoch 144:\n",
      "Training loss: 0.0303, Training accuracy: 0.9944\n",
      "Validation loss: 0.3315, Validation accuracy: 0.9019\n",
      "\n",
      "Epoch 145:\n",
      "Training loss: 0.0302, Training accuracy: 0.9945\n",
      "Validation loss: 0.3304, Validation accuracy: 0.9029\n",
      "\n",
      "Epoch 146:\n",
      "Training loss: 0.0303, Training accuracy: 0.9947\n",
      "Validation loss: 0.3334, Validation accuracy: 0.9034\n",
      "\n",
      "Epoch 147:\n",
      "Training loss: 0.0296, Training accuracy: 0.9949\n",
      "Validation loss: 0.3354, Validation accuracy: 0.9019\n",
      "\n",
      "Epoch 148:\n",
      "Training loss: 0.0298, Training accuracy: 0.9946\n",
      "Validation loss: 0.3368, Validation accuracy: 0.9019\n",
      "\n",
      "Epoch 149:\n",
      "Training loss: 0.0284, Training accuracy: 0.9959\n",
      "Validation loss: 0.3340, Validation accuracy: 0.9045\n",
      "Saving ...\n",
      "\n",
      "Epoch 150:\n",
      "Training loss: 0.0289, Training accuracy: 0.9955\n",
      "Validation loss: 0.3380, Validation accuracy: 0.9021\n",
      "\n",
      "Epoch 151:\n",
      "Training loss: 0.0292, Training accuracy: 0.9949\n",
      "Validation loss: 0.3394, Validation accuracy: 0.9022\n",
      "\n",
      "Epoch 152:\n",
      "Training loss: 0.0291, Training accuracy: 0.9952\n",
      "Validation loss: 0.3345, Validation accuracy: 0.9051\n",
      "Saving ...\n",
      "\n",
      "Epoch 153:\n",
      "Training loss: 0.0288, Training accuracy: 0.9950\n",
      "Validation loss: 0.3341, Validation accuracy: 0.9020\n",
      "\n",
      "Epoch 154:\n",
      "Training loss: 0.0283, Training accuracy: 0.9956\n",
      "Validation loss: 0.3392, Validation accuracy: 0.9021\n",
      "\n",
      "Epoch 155:\n",
      "Training loss: 0.0289, Training accuracy: 0.9951\n",
      "Validation loss: 0.3330, Validation accuracy: 0.9038\n",
      "\n",
      "Epoch 156:\n",
      "Training loss: 0.0283, Training accuracy: 0.9956\n",
      "Validation loss: 0.3338, Validation accuracy: 0.9035\n",
      "\n",
      "Epoch 157:\n",
      "Training loss: 0.0285, Training accuracy: 0.9954\n",
      "Validation loss: 0.3386, Validation accuracy: 0.9022\n",
      "\n",
      "Epoch 158:\n",
      "Training loss: 0.0280, Training accuracy: 0.9959\n",
      "Validation loss: 0.3351, Validation accuracy: 0.9037\n",
      "\n",
      "Epoch 159:\n",
      "Training loss: 0.0275, Training accuracy: 0.9963\n",
      "Validation loss: 0.3332, Validation accuracy: 0.9043\n",
      "\n",
      "Epoch 160:\n",
      "Training loss: 0.0279, Training accuracy: 0.9958\n",
      "Validation loss: 0.3388, Validation accuracy: 0.9042\n",
      "\n",
      "Epoch 161:\n",
      "Training loss: 0.0278, Training accuracy: 0.9958\n",
      "Validation loss: 0.3365, Validation accuracy: 0.9029\n",
      "\n",
      "Epoch 162:\n",
      "Training loss: 0.0274, Training accuracy: 0.9959\n",
      "Validation loss: 0.3358, Validation accuracy: 0.9025\n",
      "\n",
      "Epoch 163:\n",
      "Training loss: 0.0273, Training accuracy: 0.9960\n",
      "Validation loss: 0.3371, Validation accuracy: 0.9029\n",
      "\n",
      "Epoch 164:\n",
      "Training loss: 0.0272, Training accuracy: 0.9959\n",
      "Validation loss: 0.3375, Validation accuracy: 0.9015\n",
      "\n",
      "Epoch 165:\n",
      "Training loss: 0.0271, Training accuracy: 0.9961\n",
      "Validation loss: 0.3379, Validation accuracy: 0.9024\n",
      "\n",
      "Epoch 166:\n",
      "Training loss: 0.0265, Training accuracy: 0.9965\n",
      "Validation loss: 0.3352, Validation accuracy: 0.9022\n",
      "\n",
      "Epoch 167:\n",
      "Training loss: 0.0266, Training accuracy: 0.9961\n",
      "Validation loss: 0.3359, Validation accuracy: 0.9011\n",
      "\n",
      "Epoch 168:\n",
      "Training loss: 0.0266, Training accuracy: 0.9959\n",
      "Validation loss: 0.3351, Validation accuracy: 0.9035\n",
      "\n",
      "Epoch 169:\n",
      "Training loss: 0.0265, Training accuracy: 0.9964\n",
      "Validation loss: 0.3368, Validation accuracy: 0.9021\n",
      "\n",
      "Epoch 170:\n",
      "Training loss: 0.0259, Training accuracy: 0.9962\n",
      "Validation loss: 0.3364, Validation accuracy: 0.9033\n",
      "\n",
      "Epoch 171:\n",
      "Training loss: 0.0261, Training accuracy: 0.9963\n",
      "Validation loss: 0.3378, Validation accuracy: 0.9024\n",
      "\n",
      "Epoch 172:\n",
      "Training loss: 0.0263, Training accuracy: 0.9962\n",
      "Validation loss: 0.3399, Validation accuracy: 0.9043\n",
      "\n",
      "Epoch 173:\n",
      "Training loss: 0.0264, Training accuracy: 0.9960\n",
      "Validation loss: 0.3400, Validation accuracy: 0.9027\n",
      "\n",
      "Epoch 174:\n",
      "Training loss: 0.0262, Training accuracy: 0.9962\n",
      "Validation loss: 0.3365, Validation accuracy: 0.9040\n",
      "\n",
      "Epoch 175:\n",
      "Training loss: 0.0260, Training accuracy: 0.9967\n",
      "Validation loss: 0.3415, Validation accuracy: 0.9020\n",
      "\n",
      "Epoch 176:\n",
      "Training loss: 0.0254, Training accuracy: 0.9967\n",
      "Validation loss: 0.3411, Validation accuracy: 0.9034\n",
      "\n",
      "Epoch 177:\n",
      "Training loss: 0.0257, Training accuracy: 0.9962\n",
      "Validation loss: 0.3376, Validation accuracy: 0.9036\n",
      "\n",
      "Epoch 178:\n",
      "Training loss: 0.0257, Training accuracy: 0.9963\n",
      "Validation loss: 0.3366, Validation accuracy: 0.9039\n",
      "\n",
      "Epoch 179:\n",
      "Training loss: 0.0261, Training accuracy: 0.9962\n",
      "Validation loss: 0.3397, Validation accuracy: 0.9025\n",
      "\n",
      "Current learning rate has decayed to 0.000100\n",
      "Epoch 180:\n",
      "Training loss: 0.0246, Training accuracy: 0.9970\n",
      "Validation loss: 0.3404, Validation accuracy: 0.9027\n",
      "\n",
      "Epoch 181:\n",
      "Training loss: 0.0241, Training accuracy: 0.9971\n",
      "Validation loss: 0.3378, Validation accuracy: 0.9048\n",
      "\n",
      "Epoch 182:\n",
      "Training loss: 0.0233, Training accuracy: 0.9977\n",
      "Validation loss: 0.3349, Validation accuracy: 0.9043\n",
      "\n",
      "Epoch 183:\n",
      "Training loss: 0.0237, Training accuracy: 0.9976\n",
      "Validation loss: 0.3350, Validation accuracy: 0.9039\n",
      "\n",
      "Epoch 184:\n",
      "Training loss: 0.0239, Training accuracy: 0.9971\n",
      "Validation loss: 0.3355, Validation accuracy: 0.9047\n",
      "\n",
      "Epoch 185:\n",
      "Training loss: 0.0235, Training accuracy: 0.9975\n",
      "Validation loss: 0.3363, Validation accuracy: 0.9052\n",
      "Saving ...\n",
      "\n",
      "Epoch 186:\n",
      "Training loss: 0.0233, Training accuracy: 0.9977\n",
      "Validation loss: 0.3359, Validation accuracy: 0.9044\n",
      "\n",
      "Epoch 187:\n",
      "Training loss: 0.0235, Training accuracy: 0.9976\n",
      "Validation loss: 0.3374, Validation accuracy: 0.9030\n",
      "\n",
      "Epoch 188:\n",
      "Training loss: 0.0234, Training accuracy: 0.9976\n",
      "Validation loss: 0.3376, Validation accuracy: 0.9040\n",
      "\n",
      "Epoch 189:\n",
      "Training loss: 0.0234, Training accuracy: 0.9973\n",
      "Validation loss: 0.3362, Validation accuracy: 0.9049\n",
      "\n",
      "Epoch 190:\n",
      "Training loss: 0.0236, Training accuracy: 0.9974\n",
      "Validation loss: 0.3382, Validation accuracy: 0.9043\n",
      "\n",
      "Epoch 191:\n",
      "Training loss: 0.0230, Training accuracy: 0.9977\n",
      "Validation loss: 0.3405, Validation accuracy: 0.9042\n",
      "\n",
      "Epoch 192:\n",
      "Training loss: 0.0233, Training accuracy: 0.9976\n",
      "Validation loss: 0.3400, Validation accuracy: 0.9049\n",
      "\n",
      "Epoch 193:\n",
      "Training loss: 0.0229, Training accuracy: 0.9977\n",
      "Validation loss: 0.3368, Validation accuracy: 0.9046\n",
      "\n",
      "Epoch 194:\n",
      "Training loss: 0.0230, Training accuracy: 0.9978\n",
      "Validation loss: 0.3359, Validation accuracy: 0.9044\n",
      "\n",
      "Epoch 195:\n",
      "Training loss: 0.0226, Training accuracy: 0.9981\n",
      "Validation loss: 0.3406, Validation accuracy: 0.9021\n",
      "\n",
      "Epoch 196:\n",
      "Training loss: 0.0229, Training accuracy: 0.9977\n",
      "Validation loss: 0.3366, Validation accuracy: 0.9044\n",
      "\n",
      "Epoch 197:\n",
      "Training loss: 0.0231, Training accuracy: 0.9977\n",
      "Validation loss: 0.3383, Validation accuracy: 0.9041\n",
      "\n",
      "Epoch 198:\n",
      "Training loss: 0.0224, Training accuracy: 0.9980\n",
      "Validation loss: 0.3371, Validation accuracy: 0.9038\n",
      "\n",
      "Epoch 199:\n",
      "Training loss: 0.0231, Training accuracy: 0.9975\n",
      "Validation loss: 0.3368, Validation accuracy: 0.9046\n",
      "\n",
      "==================================================\n",
      "==> Optimization finished! Best validation accuracy: 0.9052\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9052"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train(T=3,lamb=0.2,alpha=0.4,train_loader=train_loader,val_loader=val_loader,INITIAL_LR=0.1,DECAY_EPOCHS=[40,100,180],DECAY=0.1,EPOCHS=200,REG = 2e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Training starts!\n",
      "==================================================\n",
      "Epoch 0:\n",
      "Training loss: 1.8158, Training accuracy: 0.2633\n",
      "Validation loss: 14.3474, Validation accuracy: 0.3707\n",
      "Saving ...\n",
      "\n",
      "Epoch 1:\n",
      "Training loss: 1.3046, Training accuracy: 0.4183\n",
      "Validation loss: 1.9721, Validation accuracy: 0.4785\n",
      "Saving ...\n",
      "\n",
      "Epoch 2:\n",
      "Training loss: 1.1244, Training accuracy: 0.4933\n",
      "Validation loss: 1.5144, Validation accuracy: 0.5664\n",
      "Saving ...\n",
      "\n",
      "Epoch 3:\n",
      "Training loss: 1.0003, Training accuracy: 0.5471\n",
      "Validation loss: 1.1961, Validation accuracy: 0.5859\n",
      "Saving ...\n",
      "\n",
      "Epoch 4:\n",
      "Training loss: 0.9160, Training accuracy: 0.5849\n",
      "Validation loss: 1.0493, Validation accuracy: 0.6272\n",
      "Saving ...\n",
      "\n",
      "Epoch 5:\n",
      "Training loss: 0.8456, Training accuracy: 0.6163\n",
      "Validation loss: 1.0138, Validation accuracy: 0.6454\n",
      "Saving ...\n",
      "\n",
      "Epoch 6:\n",
      "Training loss: 0.7892, Training accuracy: 0.6397\n",
      "Validation loss: 0.9805, Validation accuracy: 0.6659\n",
      "Saving ...\n",
      "\n",
      "Epoch 7:\n",
      "Training loss: 0.7296, Training accuracy: 0.6705\n",
      "Validation loss: 0.9647, Validation accuracy: 0.6715\n",
      "Saving ...\n",
      "\n",
      "Epoch 8:\n",
      "Training loss: 0.6930, Training accuracy: 0.6902\n",
      "Validation loss: 0.8502, Validation accuracy: 0.7052\n",
      "Saving ...\n",
      "\n",
      "Epoch 9:\n",
      "Training loss: 0.6560, Training accuracy: 0.7043\n",
      "Validation loss: 1.5003, Validation accuracy: 0.5291\n",
      "\n",
      "Epoch 10:\n",
      "Training loss: 0.4841, Training accuracy: 0.7060\n",
      "Validation loss: 0.7922, Validation accuracy: 0.7197\n",
      "Saving ...\n",
      "\n",
      "Epoch 11:\n",
      "Training loss: 0.4265, Training accuracy: 0.7436\n",
      "Validation loss: 0.8095, Validation accuracy: 0.7161\n",
      "\n",
      "Epoch 12:\n",
      "Training loss: 0.4200, Training accuracy: 0.7488\n",
      "Validation loss: 0.7793, Validation accuracy: 0.7236\n",
      "Saving ...\n",
      "\n",
      "Epoch 13:\n",
      "Training loss: 0.4148, Training accuracy: 0.7512\n",
      "Validation loss: 0.7722, Validation accuracy: 0.7291\n",
      "Saving ...\n",
      "\n",
      "Epoch 14:\n",
      "Training loss: 0.4080, Training accuracy: 0.7564\n",
      "Validation loss: 0.7351, Validation accuracy: 0.7458\n",
      "Saving ...\n",
      "\n",
      "Epoch 15:\n",
      "Training loss: 0.4034, Training accuracy: 0.7574\n",
      "Validation loss: 0.7395, Validation accuracy: 0.7513\n",
      "Saving ...\n",
      "\n",
      "Epoch 16:\n",
      "Training loss: 0.3951, Training accuracy: 0.7638\n",
      "Validation loss: 0.6802, Validation accuracy: 0.7697\n",
      "Saving ...\n",
      "\n",
      "Epoch 17:\n",
      "Training loss: 0.3888, Training accuracy: 0.7697\n",
      "Validation loss: 0.7325, Validation accuracy: 0.7503\n",
      "\n",
      "Epoch 18:\n",
      "Training loss: 0.3831, Training accuracy: 0.7721\n",
      "Validation loss: 0.7100, Validation accuracy: 0.7526\n",
      "\n",
      "Epoch 19:\n",
      "Training loss: 0.3825, Training accuracy: 0.7717\n",
      "Validation loss: 0.7276, Validation accuracy: 0.7508\n",
      "\n",
      "Epoch 20:\n",
      "Training loss: 0.3748, Training accuracy: 0.7770\n",
      "Validation loss: 0.6878, Validation accuracy: 0.7668\n",
      "\n",
      "Epoch 21:\n",
      "Training loss: 0.3717, Training accuracy: 0.7798\n",
      "Validation loss: 0.7163, Validation accuracy: 0.7605\n",
      "\n",
      "Epoch 22:\n",
      "Training loss: 0.3665, Training accuracy: 0.7832\n",
      "Validation loss: 0.6579, Validation accuracy: 0.7765\n",
      "Saving ...\n",
      "\n",
      "Epoch 23:\n",
      "Training loss: 0.3625, Training accuracy: 0.7845\n",
      "Validation loss: 0.6612, Validation accuracy: 0.7723\n",
      "\n",
      "Epoch 24:\n",
      "Training loss: 0.3558, Training accuracy: 0.7894\n",
      "Validation loss: 0.7034, Validation accuracy: 0.7618\n",
      "\n",
      "Epoch 25:\n",
      "Training loss: 0.3579, Training accuracy: 0.7893\n",
      "Validation loss: 0.8259, Validation accuracy: 0.7254\n",
      "\n",
      "Epoch 26:\n",
      "Training loss: 0.3545, Training accuracy: 0.7910\n",
      "Validation loss: 0.6785, Validation accuracy: 0.7647\n",
      "\n",
      "Epoch 27:\n",
      "Training loss: 0.3526, Training accuracy: 0.7907\n",
      "Validation loss: 0.6549, Validation accuracy: 0.7728\n",
      "\n",
      "Epoch 28:\n",
      "Training loss: 0.3451, Training accuracy: 0.7967\n",
      "Validation loss: 0.7068, Validation accuracy: 0.7565\n",
      "\n",
      "Epoch 29:\n",
      "Training loss: 0.3426, Training accuracy: 0.7971\n",
      "Validation loss: 0.6722, Validation accuracy: 0.7708\n",
      "\n",
      "Epoch 30:\n",
      "Training loss: 0.3434, Training accuracy: 0.7988\n",
      "Validation loss: 0.6876, Validation accuracy: 0.7645\n",
      "\n",
      "Epoch 31:\n",
      "Training loss: 0.3407, Training accuracy: 0.7975\n",
      "Validation loss: 0.7101, Validation accuracy: 0.7593\n",
      "\n",
      "Epoch 32:\n",
      "Training loss: 0.3366, Training accuracy: 0.8008\n",
      "Validation loss: 0.6885, Validation accuracy: 0.7701\n",
      "\n",
      "Epoch 33:\n",
      "Training loss: 0.3364, Training accuracy: 0.8006\n",
      "Validation loss: 0.6136, Validation accuracy: 0.7864\n",
      "Saving ...\n",
      "\n",
      "Epoch 34:\n",
      "Training loss: 0.3333, Training accuracy: 0.8028\n",
      "Validation loss: 0.6120, Validation accuracy: 0.7884\n",
      "Saving ...\n",
      "\n",
      "Epoch 35:\n",
      "Training loss: 0.3302, Training accuracy: 0.8058\n",
      "Validation loss: 0.6841, Validation accuracy: 0.7673\n",
      "\n",
      "Epoch 36:\n",
      "Training loss: 0.3295, Training accuracy: 0.8090\n",
      "Validation loss: 0.6393, Validation accuracy: 0.7788\n",
      "\n",
      "Epoch 37:\n",
      "Training loss: 0.3285, Training accuracy: 0.8059\n",
      "Validation loss: 0.6473, Validation accuracy: 0.7832\n",
      "\n",
      "Epoch 38:\n",
      "Training loss: 0.3258, Training accuracy: 0.8077\n",
      "Validation loss: 0.5442, Validation accuracy: 0.8107\n",
      "Saving ...\n",
      "\n",
      "Epoch 39:\n",
      "Training loss: 0.3261, Training accuracy: 0.8104\n",
      "Validation loss: 0.6401, Validation accuracy: 0.7840\n",
      "\n",
      "Current learning rate has decayed to 0.010000\n",
      "Epoch 40:\n",
      "Training loss: 0.2328, Training accuracy: 0.8670\n",
      "Validation loss: 0.3963, Validation accuracy: 0.8652\n",
      "Saving ...\n",
      "\n",
      "Epoch 41:\n",
      "Training loss: 0.2026, Training accuracy: 0.8851\n",
      "Validation loss: 0.3758, Validation accuracy: 0.8714\n",
      "Saving ...\n",
      "\n",
      "Epoch 42:\n",
      "Training loss: 0.1899, Training accuracy: 0.8937\n",
      "Validation loss: 0.3657, Validation accuracy: 0.8744\n",
      "Saving ...\n",
      "\n",
      "Epoch 43:\n",
      "Training loss: 0.1825, Training accuracy: 0.8970\n",
      "Validation loss: 0.3620, Validation accuracy: 0.8736\n",
      "\n",
      "Epoch 44:\n",
      "Training loss: 0.1758, Training accuracy: 0.9014\n",
      "Validation loss: 0.3614, Validation accuracy: 0.8754\n",
      "Saving ...\n",
      "\n",
      "Epoch 45:\n",
      "Training loss: 0.1715, Training accuracy: 0.9041\n",
      "Validation loss: 0.3538, Validation accuracy: 0.8771\n",
      "Saving ...\n",
      "\n",
      "Epoch 46:\n",
      "Training loss: 0.1659, Training accuracy: 0.9087\n",
      "Validation loss: 0.3460, Validation accuracy: 0.8813\n",
      "Saving ...\n",
      "\n",
      "Epoch 47:\n",
      "Training loss: 0.1607, Training accuracy: 0.9120\n",
      "Validation loss: 0.3484, Validation accuracy: 0.8811\n",
      "\n",
      "Epoch 48:\n",
      "Training loss: 0.1557, Training accuracy: 0.9149\n",
      "Validation loss: 0.3516, Validation accuracy: 0.8774\n",
      "\n",
      "Epoch 49:\n",
      "Training loss: 0.1524, Training accuracy: 0.9178\n",
      "Validation loss: 0.3537, Validation accuracy: 0.8763\n",
      "\n",
      "Epoch 50:\n",
      "Training loss: 0.1498, Training accuracy: 0.9196\n",
      "Validation loss: 0.3452, Validation accuracy: 0.8801\n",
      "\n",
      "Epoch 51:\n",
      "Training loss: 0.1451, Training accuracy: 0.9208\n",
      "Validation loss: 0.3475, Validation accuracy: 0.8825\n",
      "Saving ...\n",
      "\n",
      "Epoch 52:\n",
      "Training loss: 0.1442, Training accuracy: 0.9232\n",
      "Validation loss: 0.3477, Validation accuracy: 0.8825\n",
      "\n",
      "Epoch 53:\n",
      "Training loss: 0.1407, Training accuracy: 0.9262\n",
      "Validation loss: 0.3600, Validation accuracy: 0.8783\n",
      "\n",
      "Epoch 54:\n",
      "Training loss: 0.1388, Training accuracy: 0.9266\n",
      "Validation loss: 0.3459, Validation accuracy: 0.8826\n",
      "Saving ...\n",
      "\n",
      "Epoch 55:\n",
      "Training loss: 0.1376, Training accuracy: 0.9275\n",
      "Validation loss: 0.3606, Validation accuracy: 0.8775\n",
      "\n",
      "Epoch 56:\n",
      "Training loss: 0.1339, Training accuracy: 0.9298\n",
      "Validation loss: 0.3669, Validation accuracy: 0.8757\n",
      "\n",
      "Epoch 57:\n",
      "Training loss: 0.1324, Training accuracy: 0.9301\n",
      "Validation loss: 0.3478, Validation accuracy: 0.8840\n",
      "Saving ...\n",
      "\n",
      "Epoch 58:\n",
      "Training loss: 0.1331, Training accuracy: 0.9303\n",
      "Validation loss: 0.3533, Validation accuracy: 0.8824\n",
      "\n",
      "Epoch 59:\n",
      "Training loss: 0.1324, Training accuracy: 0.9301\n",
      "Validation loss: 0.3453, Validation accuracy: 0.8849\n",
      "Saving ...\n",
      "\n",
      "Epoch 60:\n",
      "Training loss: 0.1294, Training accuracy: 0.9319\n",
      "Validation loss: 0.3647, Validation accuracy: 0.8797\n",
      "\n",
      "Epoch 61:\n",
      "Training loss: 0.1269, Training accuracy: 0.9341\n",
      "Validation loss: 0.3543, Validation accuracy: 0.8792\n",
      "\n",
      "Epoch 62:\n",
      "Training loss: 0.1258, Training accuracy: 0.9352\n",
      "Validation loss: 0.3529, Validation accuracy: 0.8820\n",
      "\n",
      "Epoch 63:\n",
      "Training loss: 0.1228, Training accuracy: 0.9365\n",
      "Validation loss: 0.3786, Validation accuracy: 0.8756\n",
      "\n",
      "Epoch 64:\n",
      "Training loss: 0.1249, Training accuracy: 0.9347\n",
      "Validation loss: 0.3710, Validation accuracy: 0.8760\n",
      "\n",
      "Epoch 65:\n",
      "Training loss: 0.1235, Training accuracy: 0.9370\n",
      "Validation loss: 0.3527, Validation accuracy: 0.8814\n",
      "\n",
      "Epoch 66:\n",
      "Training loss: 0.1242, Training accuracy: 0.9360\n",
      "Validation loss: 0.3658, Validation accuracy: 0.8769\n",
      "\n",
      "Epoch 67:\n",
      "Training loss: 0.1216, Training accuracy: 0.9365\n",
      "Validation loss: 0.3686, Validation accuracy: 0.8783\n",
      "\n",
      "Epoch 68:\n",
      "Training loss: 0.1213, Training accuracy: 0.9389\n",
      "Validation loss: 0.3709, Validation accuracy: 0.8781\n",
      "\n",
      "Epoch 69:\n",
      "Training loss: 0.1217, Training accuracy: 0.9370\n",
      "Validation loss: 0.3706, Validation accuracy: 0.8776\n",
      "\n",
      "Epoch 70:\n",
      "Training loss: 0.1202, Training accuracy: 0.9396\n",
      "Validation loss: 0.3694, Validation accuracy: 0.8769\n",
      "\n",
      "Epoch 71:\n",
      "Training loss: 0.1197, Training accuracy: 0.9393\n",
      "Validation loss: 0.3727, Validation accuracy: 0.8775\n",
      "\n",
      "Epoch 72:\n",
      "Training loss: 0.1194, Training accuracy: 0.9392\n",
      "Validation loss: 0.3547, Validation accuracy: 0.8828\n",
      "\n",
      "Epoch 73:\n",
      "Training loss: 0.1167, Training accuracy: 0.9408\n",
      "Validation loss: 0.3554, Validation accuracy: 0.8831\n",
      "\n",
      "Epoch 74:\n",
      "Training loss: 0.1190, Training accuracy: 0.9387\n",
      "Validation loss: 0.3639, Validation accuracy: 0.8804\n",
      "\n",
      "Epoch 75:\n",
      "Training loss: 0.1168, Training accuracy: 0.9414\n",
      "Validation loss: 0.3720, Validation accuracy: 0.8744\n",
      "\n",
      "Epoch 76:\n",
      "Training loss: 0.1175, Training accuracy: 0.9407\n",
      "Validation loss: 0.3625, Validation accuracy: 0.8804\n",
      "\n",
      "Epoch 77:\n",
      "Training loss: 0.1166, Training accuracy: 0.9418\n",
      "Validation loss: 0.3509, Validation accuracy: 0.8860\n",
      "Saving ...\n",
      "\n",
      "Epoch 78:\n",
      "Training loss: 0.1156, Training accuracy: 0.9424\n",
      "Validation loss: 0.3636, Validation accuracy: 0.8819\n",
      "\n",
      "Epoch 79:\n",
      "Training loss: 0.1154, Training accuracy: 0.9418\n",
      "Validation loss: 0.3750, Validation accuracy: 0.8774\n",
      "\n",
      "Current learning rate has decayed to 0.001000\n",
      "Epoch 80:\n",
      "Training loss: 0.0859, Training accuracy: 0.9611\n",
      "Validation loss: 0.3206, Validation accuracy: 0.8963\n",
      "Saving ...\n",
      "\n",
      "Epoch 81:\n",
      "Training loss: 0.0744, Training accuracy: 0.9698\n",
      "Validation loss: 0.3156, Validation accuracy: 0.8986\n",
      "Saving ...\n",
      "\n",
      "Epoch 82:\n",
      "Training loss: 0.0693, Training accuracy: 0.9729\n",
      "Validation loss: 0.3164, Validation accuracy: 0.8988\n",
      "Saving ...\n",
      "\n",
      "Epoch 83:\n",
      "Training loss: 0.0667, Training accuracy: 0.9749\n",
      "Validation loss: 0.3162, Validation accuracy: 0.8995\n",
      "Saving ...\n",
      "\n",
      "Epoch 84:\n",
      "Training loss: 0.0642, Training accuracy: 0.9755\n",
      "Validation loss: 0.3177, Validation accuracy: 0.8998\n",
      "Saving ...\n",
      "\n",
      "Epoch 85:\n",
      "Training loss: 0.0626, Training accuracy: 0.9770\n",
      "Validation loss: 0.3203, Validation accuracy: 0.8965\n",
      "\n",
      "Epoch 86:\n",
      "Training loss: 0.0607, Training accuracy: 0.9779\n",
      "Validation loss: 0.3196, Validation accuracy: 0.8992\n",
      "\n",
      "Epoch 87:\n",
      "Training loss: 0.0600, Training accuracy: 0.9788\n",
      "Validation loss: 0.3168, Validation accuracy: 0.9005\n",
      "Saving ...\n",
      "\n",
      "Epoch 88:\n",
      "Training loss: 0.0584, Training accuracy: 0.9801\n",
      "Validation loss: 0.3189, Validation accuracy: 0.9000\n",
      "\n",
      "Epoch 89:\n",
      "Training loss: 0.0576, Training accuracy: 0.9805\n",
      "Validation loss: 0.3193, Validation accuracy: 0.8988\n",
      "\n",
      "Epoch 90:\n",
      "Training loss: 0.0566, Training accuracy: 0.9811\n",
      "Validation loss: 0.3193, Validation accuracy: 0.9004\n",
      "\n",
      "Epoch 91:\n",
      "Training loss: 0.0562, Training accuracy: 0.9809\n",
      "Validation loss: 0.3208, Validation accuracy: 0.9006\n",
      "Saving ...\n",
      "\n",
      "Epoch 92:\n",
      "Training loss: 0.0547, Training accuracy: 0.9824\n",
      "Validation loss: 0.3218, Validation accuracy: 0.9018\n",
      "Saving ...\n",
      "\n",
      "Epoch 93:\n",
      "Training loss: 0.0541, Training accuracy: 0.9826\n",
      "Validation loss: 0.3215, Validation accuracy: 0.9011\n",
      "\n",
      "Epoch 94:\n",
      "Training loss: 0.0523, Training accuracy: 0.9839\n",
      "Validation loss: 0.3208, Validation accuracy: 0.8997\n",
      "\n",
      "Epoch 95:\n",
      "Training loss: 0.0525, Training accuracy: 0.9830\n",
      "Validation loss: 0.3273, Validation accuracy: 0.8985\n",
      "\n",
      "Epoch 96:\n",
      "Training loss: 0.0516, Training accuracy: 0.9841\n",
      "Validation loss: 0.3253, Validation accuracy: 0.8961\n",
      "\n",
      "Epoch 97:\n",
      "Training loss: 0.0507, Training accuracy: 0.9848\n",
      "Validation loss: 0.3239, Validation accuracy: 0.8989\n",
      "\n",
      "Epoch 98:\n",
      "Training loss: 0.0515, Training accuracy: 0.9839\n",
      "Validation loss: 0.3196, Validation accuracy: 0.9007\n",
      "\n",
      "Epoch 99:\n",
      "Training loss: 0.0500, Training accuracy: 0.9853\n",
      "Validation loss: 0.3210, Validation accuracy: 0.9007\n",
      "\n",
      "Epoch 100:\n",
      "Training loss: 0.0496, Training accuracy: 0.9848\n",
      "Validation loss: 0.3192, Validation accuracy: 0.9011\n",
      "\n",
      "Epoch 101:\n",
      "Training loss: 0.0488, Training accuracy: 0.9858\n",
      "Validation loss: 0.3210, Validation accuracy: 0.9012\n",
      "\n",
      "Epoch 102:\n",
      "Training loss: 0.0483, Training accuracy: 0.9861\n",
      "Validation loss: 0.3263, Validation accuracy: 0.8994\n",
      "\n",
      "Epoch 103:\n",
      "Training loss: 0.0478, Training accuracy: 0.9861\n",
      "Validation loss: 0.3273, Validation accuracy: 0.9016\n",
      "\n",
      "Epoch 104:\n",
      "Training loss: 0.0471, Training accuracy: 0.9870\n",
      "Validation loss: 0.3229, Validation accuracy: 0.9023\n",
      "Saving ...\n",
      "\n",
      "Epoch 105:\n",
      "Training loss: 0.0464, Training accuracy: 0.9867\n",
      "Validation loss: 0.3231, Validation accuracy: 0.9014\n",
      "\n",
      "Epoch 106:\n",
      "Training loss: 0.0476, Training accuracy: 0.9859\n",
      "Validation loss: 0.3279, Validation accuracy: 0.9011\n",
      "\n",
      "Epoch 107:\n",
      "Training loss: 0.0452, Training accuracy: 0.9882\n",
      "Validation loss: 0.3274, Validation accuracy: 0.8993\n",
      "\n",
      "Epoch 108:\n",
      "Training loss: 0.0455, Training accuracy: 0.9871\n",
      "Validation loss: 0.3306, Validation accuracy: 0.8994\n",
      "\n",
      "Epoch 109:\n",
      "Training loss: 0.0458, Training accuracy: 0.9876\n",
      "Validation loss: 0.3254, Validation accuracy: 0.9020\n",
      "\n",
      "Epoch 110:\n",
      "Training loss: 0.0448, Training accuracy: 0.9880\n",
      "Validation loss: 0.3288, Validation accuracy: 0.9004\n",
      "\n",
      "Epoch 111:\n",
      "Training loss: 0.0447, Training accuracy: 0.9874\n",
      "Validation loss: 0.3314, Validation accuracy: 0.8995\n",
      "\n",
      "Epoch 112:\n",
      "Training loss: 0.0441, Training accuracy: 0.9879\n",
      "Validation loss: 0.3301, Validation accuracy: 0.9011\n",
      "\n",
      "Epoch 113:\n",
      "Training loss: 0.0423, Training accuracy: 0.9898\n",
      "Validation loss: 0.3298, Validation accuracy: 0.9005\n",
      "\n",
      "Epoch 114:\n",
      "Training loss: 0.0431, Training accuracy: 0.9888\n",
      "Validation loss: 0.3293, Validation accuracy: 0.9013\n",
      "\n",
      "Epoch 115:\n",
      "Training loss: 0.0424, Training accuracy: 0.9892\n",
      "Validation loss: 0.3343, Validation accuracy: 0.8997\n",
      "\n",
      "Epoch 116:\n",
      "Training loss: 0.0432, Training accuracy: 0.9885\n",
      "Validation loss: 0.3323, Validation accuracy: 0.9005\n",
      "\n",
      "Epoch 117:\n",
      "Training loss: 0.0413, Training accuracy: 0.9896\n",
      "Validation loss: 0.3352, Validation accuracy: 0.8989\n",
      "\n",
      "Epoch 118:\n",
      "Training loss: 0.0417, Training accuracy: 0.9896\n",
      "Validation loss: 0.3312, Validation accuracy: 0.8979\n",
      "\n",
      "Epoch 119:\n",
      "Training loss: 0.0425, Training accuracy: 0.9886\n",
      "Validation loss: 0.3362, Validation accuracy: 0.8979\n",
      "\n",
      "Epoch 120:\n",
      "Training loss: 0.0415, Training accuracy: 0.9897\n",
      "Validation loss: 0.3333, Validation accuracy: 0.9000\n",
      "\n",
      "Epoch 121:\n",
      "Training loss: 0.0408, Training accuracy: 0.9902\n",
      "Validation loss: 0.3347, Validation accuracy: 0.8992\n",
      "\n",
      "Epoch 122:\n",
      "Training loss: 0.0406, Training accuracy: 0.9901\n",
      "Validation loss: 0.3314, Validation accuracy: 0.8988\n",
      "\n",
      "Epoch 123:\n",
      "Training loss: 0.0404, Training accuracy: 0.9906\n",
      "Validation loss: 0.3373, Validation accuracy: 0.8996\n",
      "\n",
      "Epoch 124:\n",
      "Training loss: 0.0397, Training accuracy: 0.9907\n",
      "Validation loss: 0.3302, Validation accuracy: 0.8985\n",
      "\n",
      "Epoch 125:\n",
      "Training loss: 0.0397, Training accuracy: 0.9908\n",
      "Validation loss: 0.3348, Validation accuracy: 0.9014\n",
      "\n",
      "Epoch 126:\n",
      "Training loss: 0.0395, Training accuracy: 0.9905\n",
      "Validation loss: 0.3292, Validation accuracy: 0.9015\n",
      "\n",
      "Epoch 127:\n",
      "Training loss: 0.0393, Training accuracy: 0.9908\n",
      "Validation loss: 0.3330, Validation accuracy: 0.8984\n",
      "\n",
      "Epoch 128:\n",
      "Training loss: 0.0388, Training accuracy: 0.9917\n",
      "Validation loss: 0.3358, Validation accuracy: 0.8990\n",
      "\n",
      "Epoch 129:\n",
      "Training loss: 0.0382, Training accuracy: 0.9914\n",
      "Validation loss: 0.3340, Validation accuracy: 0.9020\n",
      "\n",
      "Epoch 130:\n",
      "Training loss: 0.0384, Training accuracy: 0.9915\n",
      "Validation loss: 0.3385, Validation accuracy: 0.8984\n",
      "\n",
      "Epoch 131:\n",
      "Training loss: 0.0377, Training accuracy: 0.9920\n",
      "Validation loss: 0.3299, Validation accuracy: 0.9003\n",
      "\n",
      "Epoch 132:\n",
      "Training loss: 0.0378, Training accuracy: 0.9916\n",
      "Validation loss: 0.3361, Validation accuracy: 0.8986\n",
      "\n",
      "Epoch 133:\n",
      "Training loss: 0.0376, Training accuracy: 0.9911\n",
      "Validation loss: 0.3327, Validation accuracy: 0.9003\n",
      "\n",
      "Epoch 134:\n",
      "Training loss: 0.0368, Training accuracy: 0.9923\n",
      "Validation loss: 0.3342, Validation accuracy: 0.9014\n",
      "\n",
      "Epoch 135:\n",
      "Training loss: 0.0368, Training accuracy: 0.9923\n",
      "Validation loss: 0.3369, Validation accuracy: 0.8985\n",
      "\n",
      "Epoch 136:\n",
      "Training loss: 0.0364, Training accuracy: 0.9924\n",
      "Validation loss: 0.3384, Validation accuracy: 0.8994\n",
      "\n",
      "Epoch 137:\n",
      "Training loss: 0.0371, Training accuracy: 0.9919\n",
      "Validation loss: 0.3356, Validation accuracy: 0.9006\n",
      "\n",
      "Epoch 138:\n",
      "Training loss: 0.0363, Training accuracy: 0.9922\n",
      "Validation loss: 0.3424, Validation accuracy: 0.8980\n",
      "\n",
      "Epoch 139:\n",
      "Training loss: 0.0361, Training accuracy: 0.9922\n",
      "Validation loss: 0.3355, Validation accuracy: 0.9012\n",
      "\n",
      "Epoch 140:\n",
      "Training loss: 0.0361, Training accuracy: 0.9922\n",
      "Validation loss: 0.3376, Validation accuracy: 0.9013\n",
      "\n",
      "Epoch 141:\n",
      "Training loss: 0.0355, Training accuracy: 0.9926\n",
      "Validation loss: 0.3366, Validation accuracy: 0.8997\n",
      "\n",
      "Epoch 142:\n",
      "Training loss: 0.0356, Training accuracy: 0.9925\n",
      "Validation loss: 0.3418, Validation accuracy: 0.8995\n",
      "\n",
      "Epoch 143:\n",
      "Training loss: 0.0357, Training accuracy: 0.9926\n"
     ]
    }
   ],
   "source": [
    "train(T=3,lamb=0.4,alpha=0.4,train_loader=train_loader,val_loader=val_loader,INITIAL_LR=0.1,DECAY_EPOCHS=[40,80,180],DECAY=0.1,EPOCHS=200,REG = 2e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Training starts!\n",
      "==================================================\n",
      "Epoch 0:\n",
      "Training loss: 1.7158, Training accuracy: 0.2982\n",
      "Validation loss: 1.6268, Validation accuracy: 0.4093\n",
      "Saving ...\n",
      "\n",
      "Epoch 1:\n",
      "Training loss: 1.2613, Training accuracy: 0.4312\n",
      "Validation loss: 1.5897, Validation accuracy: 0.4996\n",
      "Saving ...\n",
      "\n",
      "Epoch 2:\n",
      "Training loss: 1.0727, Training accuracy: 0.5139\n",
      "Validation loss: 1.5931, Validation accuracy: 0.5360\n",
      "Saving ...\n",
      "\n",
      "Epoch 3:\n",
      "Training loss: 0.9597, Training accuracy: 0.5671\n",
      "Validation loss: 1.1323, Validation accuracy: 0.6010\n",
      "Saving ...\n",
      "\n",
      "Epoch 4:\n",
      "Training loss: 0.8729, Training accuracy: 0.6057\n",
      "Validation loss: 1.2780, Validation accuracy: 0.6470\n",
      "Saving ...\n",
      "\n",
      "Epoch 5:\n",
      "Training loss: 0.8068, Training accuracy: 0.6373\n",
      "Validation loss: 1.0624, Validation accuracy: 0.6702\n",
      "Saving ...\n",
      "\n",
      "Epoch 6:\n",
      "Training loss: 0.7460, Training accuracy: 0.6690\n",
      "Validation loss: 1.1666, Validation accuracy: 0.6683\n",
      "\n",
      "Epoch 7:\n",
      "Training loss: 0.7031, Training accuracy: 0.6828\n",
      "Validation loss: 1.2306, Validation accuracy: 0.6770\n",
      "Saving ...\n",
      "\n",
      "Epoch 8:\n",
      "Training loss: 0.6627, Training accuracy: 0.7012\n",
      "Validation loss: 0.8818, Validation accuracy: 0.7058\n",
      "Saving ...\n",
      "\n",
      "Epoch 9:\n",
      "Training loss: 0.6381, Training accuracy: 0.7121\n",
      "Validation loss: 0.9041, Validation accuracy: 0.6965\n",
      "\n",
      "Epoch 10:\n",
      "Training loss: 0.4526, Training accuracy: 0.7288\n",
      "Validation loss: 0.6923, Validation accuracy: 0.7645\n",
      "Saving ...\n",
      "\n",
      "Epoch 11:\n",
      "Training loss: 0.4134, Training accuracy: 0.7531\n",
      "Validation loss: 0.7492, Validation accuracy: 0.7433\n",
      "\n",
      "Epoch 12:\n",
      "Training loss: 0.4113, Training accuracy: 0.7542\n",
      "Validation loss: 0.7949, Validation accuracy: 0.7310\n",
      "\n",
      "Epoch 13:\n",
      "Training loss: 0.3996, Training accuracy: 0.7630\n",
      "Validation loss: 0.7117, Validation accuracy: 0.7599\n",
      "\n",
      "Epoch 14:\n",
      "Training loss: 0.3982, Training accuracy: 0.7619\n",
      "Validation loss: 0.7127, Validation accuracy: 0.7590\n",
      "\n",
      "Epoch 15:\n",
      "Training loss: 0.3919, Training accuracy: 0.7656\n",
      "Validation loss: 0.7066, Validation accuracy: 0.7602\n",
      "\n",
      "Epoch 16:\n",
      "Training loss: 0.3858, Training accuracy: 0.7692\n",
      "Validation loss: 0.7130, Validation accuracy: 0.7504\n",
      "\n",
      "Epoch 17:\n",
      "Training loss: 0.3835, Training accuracy: 0.7710\n",
      "Validation loss: 0.8054, Validation accuracy: 0.7286\n",
      "\n",
      "Epoch 18:\n",
      "Training loss: 0.3811, Training accuracy: 0.7734\n",
      "Validation loss: 0.8387, Validation accuracy: 0.7141\n",
      "\n",
      "Epoch 19:\n",
      "Training loss: 0.3736, Training accuracy: 0.7767\n",
      "Validation loss: 0.6707, Validation accuracy: 0.7687\n",
      "Saving ...\n",
      "\n",
      "Epoch 20:\n",
      "Training loss: 0.3691, Training accuracy: 0.7806\n",
      "Validation loss: 0.6552, Validation accuracy: 0.7758\n",
      "Saving ...\n",
      "\n",
      "Epoch 21:\n",
      "Training loss: 0.3655, Training accuracy: 0.7831\n",
      "Validation loss: 0.7436, Validation accuracy: 0.7519\n",
      "\n",
      "Epoch 22:\n",
      "Training loss: 0.3627, Training accuracy: 0.7846\n",
      "Validation loss: 0.7490, Validation accuracy: 0.7511\n",
      "\n",
      "Epoch 23:\n",
      "Training loss: 0.3589, Training accuracy: 0.7879\n",
      "Validation loss: 0.7147, Validation accuracy: 0.7548\n",
      "\n",
      "Epoch 24:\n",
      "Training loss: 0.3534, Training accuracy: 0.7909\n",
      "Validation loss: 0.6651, Validation accuracy: 0.7696\n",
      "\n",
      "Epoch 25:\n",
      "Training loss: 0.3516, Training accuracy: 0.7911\n",
      "Validation loss: 0.6555, Validation accuracy: 0.7736\n",
      "\n",
      "Epoch 26:\n",
      "Training loss: 0.3471, Training accuracy: 0.7941\n",
      "Validation loss: 0.7841, Validation accuracy: 0.7393\n",
      "\n",
      "Epoch 27:\n",
      "Training loss: 0.3433, Training accuracy: 0.7979\n",
      "Validation loss: 0.6558, Validation accuracy: 0.7788\n",
      "Saving ...\n",
      "\n",
      "Epoch 28:\n",
      "Training loss: 0.3452, Training accuracy: 0.7964\n",
      "Validation loss: 0.6277, Validation accuracy: 0.7899\n",
      "Saving ...\n",
      "\n",
      "Epoch 29:\n",
      "Training loss: 0.3389, Training accuracy: 0.7986\n",
      "Validation loss: 0.6962, Validation accuracy: 0.7606\n",
      "\n",
      "Epoch 30:\n",
      "Training loss: 0.3371, Training accuracy: 0.8006\n",
      "Validation loss: 0.6245, Validation accuracy: 0.7890\n",
      "\n",
      "Epoch 31:\n",
      "Training loss: 0.3325, Training accuracy: 0.8028\n",
      "Validation loss: 0.7296, Validation accuracy: 0.7556\n",
      "\n",
      "Epoch 32:\n",
      "Training loss: 0.3315, Training accuracy: 0.8036\n",
      "Validation loss: 0.5878, Validation accuracy: 0.8006\n",
      "Saving ...\n",
      "\n",
      "Epoch 33:\n",
      "Training loss: 0.3319, Training accuracy: 0.8034\n",
      "Validation loss: 0.7094, Validation accuracy: 0.7621\n",
      "\n",
      "Epoch 34:\n",
      "Training loss: 0.3296, Training accuracy: 0.8051\n",
      "Validation loss: 0.6442, Validation accuracy: 0.7782\n",
      "\n",
      "Epoch 35:\n",
      "Training loss: 0.3281, Training accuracy: 0.8066\n",
      "Validation loss: 0.6555, Validation accuracy: 0.7772\n",
      "\n",
      "Epoch 36:\n",
      "Training loss: 0.3245, Training accuracy: 0.8095\n",
      "Validation loss: 0.6642, Validation accuracy: 0.7738\n",
      "\n",
      "Epoch 37:\n",
      "Training loss: 0.3294, Training accuracy: 0.8061\n",
      "Validation loss: 0.6223, Validation accuracy: 0.7858\n",
      "\n",
      "Epoch 38:\n",
      "Training loss: 0.3242, Training accuracy: 0.8090\n",
      "Validation loss: 0.6554, Validation accuracy: 0.7780\n",
      "\n",
      "Epoch 39:\n",
      "Training loss: 0.3234, Training accuracy: 0.8091\n",
      "Validation loss: 0.7208, Validation accuracy: 0.7656\n",
      "\n",
      "Current learning rate has decayed to 0.010000\n",
      "Epoch 40:\n",
      "Training loss: 0.2300, Training accuracy: 0.8674\n",
      "Validation loss: 0.3910, Validation accuracy: 0.8647\n",
      "Saving ...\n",
      "\n",
      "Epoch 41:\n",
      "Training loss: 0.2003, Training accuracy: 0.8848\n",
      "Validation loss: 0.3752, Validation accuracy: 0.8710\n",
      "Saving ...\n",
      "\n",
      "Epoch 42:\n",
      "Training loss: 0.1869, Training accuracy: 0.8937\n",
      "Validation loss: 0.3633, Validation accuracy: 0.8763\n",
      "Saving ...\n",
      "\n",
      "Epoch 43:\n",
      "Training loss: 0.1789, Training accuracy: 0.9002\n",
      "Validation loss: 0.3666, Validation accuracy: 0.8744\n",
      "\n",
      "Epoch 44:\n",
      "Training loss: 0.1713, Training accuracy: 0.9039\n",
      "Validation loss: 0.3469, Validation accuracy: 0.8822\n",
      "Saving ...\n",
      "\n",
      "Epoch 45:\n",
      "Training loss: 0.1666, Training accuracy: 0.9056\n",
      "Validation loss: 0.3498, Validation accuracy: 0.8831\n",
      "Saving ...\n",
      "\n",
      "Epoch 46:\n",
      "Training loss: 0.1624, Training accuracy: 0.9101\n",
      "Validation loss: 0.3498, Validation accuracy: 0.8808\n",
      "\n",
      "Epoch 47:\n",
      "Training loss: 0.1584, Training accuracy: 0.9123\n",
      "Validation loss: 0.3418, Validation accuracy: 0.8837\n",
      "Saving ...\n",
      "\n",
      "Epoch 48:\n",
      "Training loss: 0.1533, Training accuracy: 0.9163\n",
      "Validation loss: 0.3422, Validation accuracy: 0.8815\n",
      "\n",
      "Epoch 49:\n",
      "Training loss: 0.1494, Training accuracy: 0.9188\n",
      "Validation loss: 0.3516, Validation accuracy: 0.8808\n",
      "\n",
      "Epoch 50:\n",
      "Training loss: 0.1458, Training accuracy: 0.9205\n",
      "Validation loss: 0.3462, Validation accuracy: 0.8810\n",
      "\n",
      "Epoch 51:\n",
      "Training loss: 0.1438, Training accuracy: 0.9219\n",
      "Validation loss: 0.3456, Validation accuracy: 0.8852\n",
      "Saving ...\n",
      "\n",
      "Epoch 52:\n",
      "Training loss: 0.1424, Training accuracy: 0.9216\n",
      "Validation loss: 0.3455, Validation accuracy: 0.8844\n",
      "\n",
      "Epoch 53:\n",
      "Training loss: 0.1386, Training accuracy: 0.9260\n",
      "Validation loss: 0.3521, Validation accuracy: 0.8856\n",
      "Saving ...\n",
      "\n",
      "Epoch 54:\n",
      "Training loss: 0.1369, Training accuracy: 0.9259\n",
      "Validation loss: 0.3509, Validation accuracy: 0.8846\n",
      "\n",
      "Epoch 55:\n",
      "Training loss: 0.1329, Training accuracy: 0.9301\n",
      "Validation loss: 0.3518, Validation accuracy: 0.8811\n",
      "\n",
      "Epoch 56:\n",
      "Training loss: 0.1317, Training accuracy: 0.9303\n",
      "Validation loss: 0.3439, Validation accuracy: 0.8853\n",
      "\n",
      "Epoch 57:\n",
      "Training loss: 0.1315, Training accuracy: 0.9298\n",
      "Validation loss: 0.3538, Validation accuracy: 0.8814\n",
      "\n",
      "Epoch 58:\n",
      "Training loss: 0.1293, Training accuracy: 0.9318\n",
      "Validation loss: 0.3497, Validation accuracy: 0.8840\n",
      "\n",
      "Epoch 59:\n",
      "Training loss: 0.1265, Training accuracy: 0.9325\n",
      "Validation loss: 0.3478, Validation accuracy: 0.8841\n",
      "\n",
      "Epoch 60:\n",
      "Training loss: 0.1251, Training accuracy: 0.9337\n",
      "Validation loss: 0.3457, Validation accuracy: 0.8852\n",
      "\n",
      "Epoch 61:\n",
      "Training loss: 0.1248, Training accuracy: 0.9341\n",
      "Validation loss: 0.3599, Validation accuracy: 0.8791\n",
      "\n",
      "Epoch 62:\n",
      "Training loss: 0.1209, Training accuracy: 0.9382\n",
      "Validation loss: 0.3658, Validation accuracy: 0.8799\n",
      "\n",
      "Epoch 63:\n",
      "Training loss: 0.1233, Training accuracy: 0.9358\n",
      "Validation loss: 0.3512, Validation accuracy: 0.8830\n",
      "\n",
      "Epoch 64:\n",
      "Training loss: 0.1230, Training accuracy: 0.9360\n",
      "Validation loss: 0.3625, Validation accuracy: 0.8806\n",
      "\n",
      "Epoch 65:\n",
      "Training loss: 0.1200, Training accuracy: 0.9379\n",
      "Validation loss: 0.3610, Validation accuracy: 0.8816\n",
      "\n",
      "Epoch 66:\n",
      "Training loss: 0.1220, Training accuracy: 0.9368\n",
      "Validation loss: 0.3599, Validation accuracy: 0.8820\n",
      "\n",
      "Epoch 67:\n",
      "Training loss: 0.1205, Training accuracy: 0.9377\n",
      "Validation loss: 0.3655, Validation accuracy: 0.8809\n",
      "\n",
      "Epoch 68:\n",
      "Training loss: 0.1166, Training accuracy: 0.9406\n",
      "Validation loss: 0.3903, Validation accuracy: 0.8739\n",
      "\n",
      "Epoch 69:\n",
      "Training loss: 0.1188, Training accuracy: 0.9392\n",
      "Validation loss: 0.3749, Validation accuracy: 0.8780\n",
      "\n",
      "Epoch 70:\n",
      "Training loss: 0.1184, Training accuracy: 0.9401\n",
      "Validation loss: 0.3606, Validation accuracy: 0.8824\n",
      "\n",
      "Epoch 71:\n",
      "Training loss: 0.1156, Training accuracy: 0.9419\n",
      "Validation loss: 0.3969, Validation accuracy: 0.8706\n",
      "\n",
      "Epoch 72:\n",
      "Training loss: 0.1179, Training accuracy: 0.9386\n",
      "Validation loss: 0.3761, Validation accuracy: 0.8773\n",
      "\n",
      "Epoch 73:\n",
      "Training loss: 0.1169, Training accuracy: 0.9393\n",
      "Validation loss: 0.3831, Validation accuracy: 0.8776\n",
      "\n",
      "Epoch 74:\n",
      "Training loss: 0.1148, Training accuracy: 0.9408\n",
      "Validation loss: 0.3653, Validation accuracy: 0.8815\n",
      "\n",
      "Epoch 75:\n",
      "Training loss: 0.1159, Training accuracy: 0.9403\n",
      "Validation loss: 0.3762, Validation accuracy: 0.8800\n",
      "\n",
      "Epoch 76:\n",
      "Training loss: 0.1127, Training accuracy: 0.9430\n",
      "Validation loss: 0.3665, Validation accuracy: 0.8807\n",
      "\n",
      "Epoch 77:\n",
      "Training loss: 0.1133, Training accuracy: 0.9425\n",
      "Validation loss: 0.3621, Validation accuracy: 0.8835\n",
      "\n",
      "Epoch 78:\n",
      "Training loss: 0.1112, Training accuracy: 0.9437\n",
      "Validation loss: 0.3623, Validation accuracy: 0.8821\n",
      "\n",
      "Epoch 79:\n",
      "Training loss: 0.1135, Training accuracy: 0.9431\n",
      "Validation loss: 0.4055, Validation accuracy: 0.8715\n",
      "\n",
      "Current learning rate has decayed to 0.001000\n",
      "Epoch 80:\n",
      "Training loss: 0.0825, Training accuracy: 0.9634\n",
      "Validation loss: 0.3325, Validation accuracy: 0.8924\n",
      "Saving ...\n",
      "\n",
      "Epoch 81:\n",
      "Training loss: 0.0717, Training accuracy: 0.9706\n",
      "Validation loss: 0.3250, Validation accuracy: 0.8955\n",
      "Saving ...\n",
      "\n",
      "Epoch 82:\n",
      "Training loss: 0.0692, Training accuracy: 0.9716\n",
      "Validation loss: 0.3214, Validation accuracy: 0.8972\n",
      "Saving ...\n",
      "\n",
      "Epoch 83:\n",
      "Training loss: 0.0652, Training accuracy: 0.9740\n",
      "Validation loss: 0.3220, Validation accuracy: 0.8971\n",
      "\n",
      "Epoch 84:\n",
      "Training loss: 0.0631, Training accuracy: 0.9763\n",
      "Validation loss: 0.3193, Validation accuracy: 0.8976\n",
      "Saving ...\n",
      "\n",
      "Epoch 85:\n",
      "Training loss: 0.0608, Training accuracy: 0.9777\n",
      "Validation loss: 0.3171, Validation accuracy: 0.8993\n",
      "Saving ...\n",
      "\n",
      "Epoch 86:\n",
      "Training loss: 0.0598, Training accuracy: 0.9776\n",
      "Validation loss: 0.3191, Validation accuracy: 0.8990\n",
      "\n",
      "Epoch 87:\n",
      "Training loss: 0.0579, Training accuracy: 0.9790\n",
      "Validation loss: 0.3184, Validation accuracy: 0.8991\n",
      "\n",
      "Epoch 88:\n",
      "Training loss: 0.0565, Training accuracy: 0.9800\n",
      "Validation loss: 0.3186, Validation accuracy: 0.8994\n",
      "Saving ...\n",
      "\n",
      "Epoch 89:\n",
      "Training loss: 0.0562, Training accuracy: 0.9804\n",
      "Validation loss: 0.3210, Validation accuracy: 0.9000\n",
      "Saving ...\n",
      "\n",
      "Epoch 90:\n",
      "Training loss: 0.0545, Training accuracy: 0.9811\n",
      "Validation loss: 0.3216, Validation accuracy: 0.8990\n",
      "\n",
      "Epoch 91:\n",
      "Training loss: 0.0534, Training accuracy: 0.9824\n",
      "Validation loss: 0.3207, Validation accuracy: 0.8981\n",
      "\n",
      "Epoch 92:\n",
      "Training loss: 0.0529, Training accuracy: 0.9826\n",
      "Validation loss: 0.3189, Validation accuracy: 0.9003\n",
      "Saving ...\n",
      "\n",
      "Epoch 93:\n",
      "Training loss: 0.0519, Training accuracy: 0.9833\n",
      "Validation loss: 0.3213, Validation accuracy: 0.9011\n",
      "Saving ...\n",
      "\n",
      "Epoch 94:\n",
      "Training loss: 0.0512, Training accuracy: 0.9835\n",
      "Validation loss: 0.3226, Validation accuracy: 0.9005\n",
      "\n",
      "Epoch 95:\n",
      "Training loss: 0.0507, Training accuracy: 0.9836\n",
      "Validation loss: 0.3219, Validation accuracy: 0.8995\n",
      "\n",
      "Epoch 96:\n",
      "Training loss: 0.0504, Training accuracy: 0.9838\n",
      "Validation loss: 0.3224, Validation accuracy: 0.8998\n",
      "\n",
      "Epoch 97:\n",
      "Training loss: 0.0500, Training accuracy: 0.9844\n",
      "Validation loss: 0.3275, Validation accuracy: 0.8985\n",
      "\n",
      "Epoch 98:\n",
      "Training loss: 0.0495, Training accuracy: 0.9844\n",
      "Validation loss: 0.3244, Validation accuracy: 0.8969\n",
      "\n",
      "Epoch 99:\n",
      "Training loss: 0.0482, Training accuracy: 0.9852\n",
      "Validation loss: 0.3233, Validation accuracy: 0.8984\n",
      "\n",
      "Epoch 100:\n",
      "Training loss: 0.0480, Training accuracy: 0.9847\n",
      "Validation loss: 0.3219, Validation accuracy: 0.8997\n",
      "\n",
      "Epoch 101:\n",
      "Training loss: 0.0472, Training accuracy: 0.9860\n",
      "Validation loss: 0.3239, Validation accuracy: 0.8983\n",
      "\n",
      "Epoch 102:\n",
      "Training loss: 0.0472, Training accuracy: 0.9856\n",
      "Validation loss: 0.3249, Validation accuracy: 0.8985\n",
      "\n",
      "Epoch 103:\n",
      "Training loss: 0.0460, Training accuracy: 0.9868\n",
      "Validation loss: 0.3287, Validation accuracy: 0.8986\n",
      "\n",
      "Epoch 104:\n",
      "Training loss: 0.0455, Training accuracy: 0.9867\n",
      "Validation loss: 0.3286, Validation accuracy: 0.8977\n",
      "\n",
      "Epoch 105:\n",
      "Training loss: 0.0454, Training accuracy: 0.9868\n",
      "Validation loss: 0.3281, Validation accuracy: 0.8994\n",
      "\n",
      "Epoch 106:\n",
      "Training loss: 0.0442, Training accuracy: 0.9878\n",
      "Validation loss: 0.3220, Validation accuracy: 0.8999\n",
      "\n",
      "Epoch 107:\n",
      "Training loss: 0.0438, Training accuracy: 0.9878\n",
      "Validation loss: 0.3289, Validation accuracy: 0.9001\n",
      "\n",
      "Epoch 108:\n",
      "Training loss: 0.0442, Training accuracy: 0.9876\n",
      "Validation loss: 0.3283, Validation accuracy: 0.8996\n",
      "\n",
      "Epoch 109:\n",
      "Training loss: 0.0435, Training accuracy: 0.9883\n",
      "Validation loss: 0.3283, Validation accuracy: 0.8988\n",
      "\n",
      "Epoch 110:\n",
      "Training loss: 0.0429, Training accuracy: 0.9889\n",
      "Validation loss: 0.3298, Validation accuracy: 0.8993\n",
      "\n",
      "Epoch 111:\n",
      "Training loss: 0.0428, Training accuracy: 0.9888\n",
      "Validation loss: 0.3280, Validation accuracy: 0.8988\n",
      "\n",
      "Epoch 112:\n",
      "Training loss: 0.0430, Training accuracy: 0.9880\n",
      "Validation loss: 0.3268, Validation accuracy: 0.8994\n",
      "\n",
      "Epoch 113:\n",
      "Training loss: 0.0420, Training accuracy: 0.9889\n",
      "Validation loss: 0.3323, Validation accuracy: 0.8985\n",
      "\n",
      "Epoch 114:\n",
      "Training loss: 0.0420, Training accuracy: 0.9889\n",
      "Validation loss: 0.3306, Validation accuracy: 0.8993\n",
      "\n",
      "Epoch 115:\n",
      "Training loss: 0.0412, Training accuracy: 0.9896\n",
      "Validation loss: 0.3308, Validation accuracy: 0.8984\n",
      "\n",
      "Epoch 116:\n",
      "Training loss: 0.0409, Training accuracy: 0.9894\n",
      "Validation loss: 0.3310, Validation accuracy: 0.8990\n",
      "\n",
      "Epoch 117:\n",
      "Training loss: 0.0404, Training accuracy: 0.9903\n",
      "Validation loss: 0.3337, Validation accuracy: 0.8995\n",
      "\n",
      "Epoch 118:\n",
      "Training loss: 0.0405, Training accuracy: 0.9894\n",
      "Validation loss: 0.3317, Validation accuracy: 0.8973\n",
      "\n",
      "Epoch 119:\n",
      "Training loss: 0.0401, Training accuracy: 0.9902\n",
      "Validation loss: 0.3351, Validation accuracy: 0.8979\n",
      "\n",
      "Epoch 120:\n",
      "Training loss: 0.0401, Training accuracy: 0.9897\n",
      "Validation loss: 0.3370, Validation accuracy: 0.9010\n",
      "\n",
      "Epoch 121:\n",
      "Training loss: 0.0388, Training accuracy: 0.9909\n",
      "Validation loss: 0.3316, Validation accuracy: 0.9002\n",
      "\n",
      "Epoch 122:\n",
      "Training loss: 0.0387, Training accuracy: 0.9906\n",
      "Validation loss: 0.3360, Validation accuracy: 0.8984\n",
      "\n",
      "Epoch 123:\n",
      "Training loss: 0.0385, Training accuracy: 0.9912\n",
      "Validation loss: 0.3344, Validation accuracy: 0.8987\n",
      "\n",
      "Epoch 124:\n",
      "Training loss: 0.0386, Training accuracy: 0.9912\n",
      "Validation loss: 0.3367, Validation accuracy: 0.8988\n",
      "\n",
      "Epoch 125:\n",
      "Training loss: 0.0381, Training accuracy: 0.9911\n",
      "Validation loss: 0.3339, Validation accuracy: 0.8998\n",
      "\n",
      "Epoch 126:\n",
      "Training loss: 0.0376, Training accuracy: 0.9918\n",
      "Validation loss: 0.3362, Validation accuracy: 0.8974\n",
      "\n",
      "Epoch 127:\n",
      "Training loss: 0.0375, Training accuracy: 0.9916\n",
      "Validation loss: 0.3392, Validation accuracy: 0.8985\n",
      "\n",
      "Epoch 128:\n",
      "Training loss: 0.0373, Training accuracy: 0.9915\n",
      "Validation loss: 0.3348, Validation accuracy: 0.8994\n",
      "\n",
      "Epoch 129:\n",
      "Training loss: 0.0374, Training accuracy: 0.9920\n",
      "Validation loss: 0.3350, Validation accuracy: 0.9000\n",
      "\n",
      "Epoch 130:\n",
      "Training loss: 0.0372, Training accuracy: 0.9918\n",
      "Validation loss: 0.3391, Validation accuracy: 0.8997\n",
      "\n",
      "Epoch 131:\n",
      "Training loss: 0.0369, Training accuracy: 0.9918\n",
      "Validation loss: 0.3382, Validation accuracy: 0.8993\n",
      "\n",
      "Epoch 132:\n",
      "Training loss: 0.0364, Training accuracy: 0.9923\n",
      "Validation loss: 0.3376, Validation accuracy: 0.8994\n",
      "\n",
      "Epoch 133:\n",
      "Training loss: 0.0367, Training accuracy: 0.9918\n",
      "Validation loss: 0.3348, Validation accuracy: 0.8996\n",
      "\n",
      "Epoch 134:\n",
      "Training loss: 0.0357, Training accuracy: 0.9922\n",
      "Validation loss: 0.3353, Validation accuracy: 0.9008\n",
      "\n",
      "Epoch 135:\n",
      "Training loss: 0.0354, Training accuracy: 0.9923\n",
      "Validation loss: 0.3390, Validation accuracy: 0.9000\n",
      "\n",
      "Epoch 136:\n",
      "Training loss: 0.0352, Training accuracy: 0.9926\n",
      "Validation loss: 0.3373, Validation accuracy: 0.9006\n",
      "\n",
      "Epoch 137:\n",
      "Training loss: 0.0351, Training accuracy: 0.9926\n",
      "Validation loss: 0.3356, Validation accuracy: 0.9014\n",
      "Saving ...\n",
      "\n",
      "Epoch 138:\n",
      "Training loss: 0.0350, Training accuracy: 0.9928\n",
      "Validation loss: 0.3392, Validation accuracy: 0.8997\n",
      "\n",
      "Epoch 139:\n",
      "Training loss: 0.0356, Training accuracy: 0.9920\n",
      "Validation loss: 0.3386, Validation accuracy: 0.9001\n",
      "\n",
      "Epoch 140:\n",
      "Training loss: 0.0343, Training accuracy: 0.9929\n",
      "Validation loss: 0.3424, Validation accuracy: 0.8975\n",
      "\n",
      "Epoch 141:\n",
      "Training loss: 0.0333, Training accuracy: 0.9942\n",
      "Validation loss: 0.3393, Validation accuracy: 0.8981\n",
      "\n",
      "Epoch 142:\n",
      "Training loss: 0.0340, Training accuracy: 0.9932\n",
      "Validation loss: 0.3388, Validation accuracy: 0.8983\n",
      "\n",
      "Epoch 143:\n",
      "Training loss: 0.0334, Training accuracy: 0.9936\n",
      "Validation loss: 0.3401, Validation accuracy: 0.8984\n",
      "\n",
      "Epoch 144:\n",
      "Training loss: 0.0337, Training accuracy: 0.9932\n",
      "Validation loss: 0.3405, Validation accuracy: 0.8993\n",
      "\n",
      "Epoch 145:\n",
      "Training loss: 0.0341, Training accuracy: 0.9930\n",
      "Validation loss: 0.3405, Validation accuracy: 0.8987\n",
      "\n",
      "Epoch 146:\n",
      "Training loss: 0.0336, Training accuracy: 0.9932\n",
      "Validation loss: 0.3377, Validation accuracy: 0.8993\n",
      "\n",
      "Epoch 147:\n",
      "Training loss: 0.0332, Training accuracy: 0.9935\n",
      "Validation loss: 0.3423, Validation accuracy: 0.8999\n",
      "\n",
      "Epoch 148:\n",
      "Training loss: 0.0333, Training accuracy: 0.9935\n",
      "Validation loss: 0.3435, Validation accuracy: 0.8987\n",
      "\n",
      "Epoch 149:\n",
      "Training loss: 0.0325, Training accuracy: 0.9940\n",
      "Validation loss: 0.3433, Validation accuracy: 0.8986\n",
      "\n",
      "Epoch 150:\n",
      "Training loss: 0.0321, Training accuracy: 0.9942\n",
      "Validation loss: 0.3405, Validation accuracy: 0.8993\n",
      "\n",
      "Epoch 151:\n",
      "Training loss: 0.0328, Training accuracy: 0.9938\n",
      "Validation loss: 0.3428, Validation accuracy: 0.9011\n",
      "\n",
      "Epoch 152:\n",
      "Training loss: 0.0324, Training accuracy: 0.9938\n",
      "Validation loss: 0.3412, Validation accuracy: 0.8986\n",
      "\n",
      "Epoch 153:\n",
      "Training loss: 0.0325, Training accuracy: 0.9934\n",
      "Validation loss: 0.3369, Validation accuracy: 0.9005\n",
      "\n",
      "Epoch 154:\n",
      "Training loss: 0.0324, Training accuracy: 0.9939\n",
      "Validation loss: 0.3495, Validation accuracy: 0.8979\n",
      "\n",
      "Epoch 155:\n",
      "Training loss: 0.0325, Training accuracy: 0.9934\n",
      "Validation loss: 0.3420, Validation accuracy: 0.9000\n",
      "\n",
      "Epoch 156:\n",
      "Training loss: 0.0328, Training accuracy: 0.9938\n",
      "Validation loss: 0.3427, Validation accuracy: 0.9014\n",
      "\n",
      "Epoch 157:\n",
      "Training loss: 0.0319, Training accuracy: 0.9942\n",
      "Validation loss: 0.3402, Validation accuracy: 0.9011\n",
      "\n",
      "Epoch 158:\n",
      "Training loss: 0.0316, Training accuracy: 0.9941\n",
      "Validation loss: 0.3383, Validation accuracy: 0.9008\n",
      "\n",
      "Epoch 159:\n",
      "Training loss: 0.0313, Training accuracy: 0.9947\n",
      "Validation loss: 0.3412, Validation accuracy: 0.9014\n",
      "\n",
      "Epoch 160:\n",
      "Training loss: 0.0310, Training accuracy: 0.9949\n",
      "Validation loss: 0.3405, Validation accuracy: 0.9012\n",
      "\n",
      "Epoch 161:\n",
      "Training loss: 0.0319, Training accuracy: 0.9937\n",
      "Validation loss: 0.3388, Validation accuracy: 0.9007\n",
      "\n",
      "Epoch 162:\n",
      "Training loss: 0.0299, Training accuracy: 0.9952\n",
      "Validation loss: 0.3431, Validation accuracy: 0.9017\n",
      "Saving ...\n",
      "\n",
      "Epoch 163:\n",
      "Training loss: 0.0306, Training accuracy: 0.9947\n",
      "Validation loss: 0.3435, Validation accuracy: 0.9020\n",
      "Saving ...\n",
      "\n",
      "Epoch 164:\n",
      "Training loss: 0.0299, Training accuracy: 0.9951\n",
      "Validation loss: 0.3429, Validation accuracy: 0.8999\n",
      "\n",
      "Epoch 165:\n",
      "Training loss: 0.0303, Training accuracy: 0.9949\n",
      "Validation loss: 0.3413, Validation accuracy: 0.9011\n",
      "\n",
      "Epoch 166:\n",
      "Training loss: 0.0308, Training accuracy: 0.9945\n",
      "Validation loss: 0.3491, Validation accuracy: 0.8975\n",
      "\n",
      "Epoch 167:\n",
      "Training loss: 0.0306, Training accuracy: 0.9946\n",
      "Validation loss: 0.3483, Validation accuracy: 0.8973\n",
      "\n",
      "Epoch 168:\n",
      "Training loss: 0.0300, Training accuracy: 0.9947\n",
      "Validation loss: 0.3424, Validation accuracy: 0.9019\n",
      "\n",
      "Epoch 169:\n",
      "Training loss: 0.0301, Training accuracy: 0.9951\n",
      "Validation loss: 0.3421, Validation accuracy: 0.9002\n",
      "\n",
      "Epoch 170:\n",
      "Training loss: 0.0299, Training accuracy: 0.9949\n",
      "Validation loss: 0.3398, Validation accuracy: 0.9018\n",
      "\n",
      "Epoch 171:\n",
      "Training loss: 0.0298, Training accuracy: 0.9948\n",
      "Validation loss: 0.3412, Validation accuracy: 0.9012\n",
      "\n",
      "Epoch 172:\n",
      "Training loss: 0.0301, Training accuracy: 0.9947\n",
      "Validation loss: 0.3475, Validation accuracy: 0.9001\n",
      "\n",
      "Epoch 173:\n",
      "Training loss: 0.0297, Training accuracy: 0.9949\n",
      "Validation loss: 0.3467, Validation accuracy: 0.8999\n",
      "\n",
      "Epoch 174:\n",
      "Training loss: 0.0292, Training accuracy: 0.9955\n",
      "Validation loss: 0.3467, Validation accuracy: 0.9011\n",
      "\n",
      "Epoch 175:\n",
      "Training loss: 0.0294, Training accuracy: 0.9955\n",
      "Validation loss: 0.3511, Validation accuracy: 0.8996\n",
      "\n",
      "Epoch 176:\n",
      "Training loss: 0.0285, Training accuracy: 0.9955\n",
      "Validation loss: 0.3459, Validation accuracy: 0.8999\n",
      "\n",
      "Epoch 177:\n",
      "Training loss: 0.0298, Training accuracy: 0.9947\n",
      "Validation loss: 0.3476, Validation accuracy: 0.9000\n",
      "\n",
      "Epoch 178:\n",
      "Training loss: 0.0289, Training accuracy: 0.9957\n",
      "Validation loss: 0.3418, Validation accuracy: 0.8998\n",
      "\n",
      "Epoch 179:\n",
      "Training loss: 0.0286, Training accuracy: 0.9954\n",
      "Validation loss: 0.3464, Validation accuracy: 0.8978\n",
      "\n",
      "Current learning rate has decayed to 0.000100\n",
      "Epoch 180:\n",
      "Training loss: 0.0276, Training accuracy: 0.9961\n",
      "Validation loss: 0.3423, Validation accuracy: 0.9002\n",
      "\n",
      "Epoch 181:\n",
      "Training loss: 0.0270, Training accuracy: 0.9960\n",
      "Validation loss: 0.3420, Validation accuracy: 0.9014\n",
      "\n",
      "Epoch 182:\n",
      "Training loss: 0.0266, Training accuracy: 0.9964\n",
      "Validation loss: 0.3407, Validation accuracy: 0.9005\n",
      "\n",
      "Epoch 183:\n",
      "Training loss: 0.0262, Training accuracy: 0.9963\n",
      "Validation loss: 0.3422, Validation accuracy: 0.9005\n",
      "\n",
      "Epoch 184:\n",
      "Training loss: 0.0263, Training accuracy: 0.9965\n",
      "Validation loss: 0.3423, Validation accuracy: 0.9005\n",
      "\n",
      "Epoch 185:\n",
      "Training loss: 0.0261, Training accuracy: 0.9967\n",
      "Validation loss: 0.3419, Validation accuracy: 0.9016\n",
      "\n",
      "Epoch 186:\n",
      "Training loss: 0.0259, Training accuracy: 0.9966\n",
      "Validation loss: 0.3425, Validation accuracy: 0.8990\n",
      "\n",
      "Epoch 187:\n",
      "Training loss: 0.0260, Training accuracy: 0.9965\n",
      "Validation loss: 0.3435, Validation accuracy: 0.8998\n",
      "\n",
      "Epoch 188:\n",
      "Training loss: 0.0257, Training accuracy: 0.9972\n",
      "Validation loss: 0.3436, Validation accuracy: 0.9014\n",
      "\n",
      "Epoch 189:\n",
      "Training loss: 0.0255, Training accuracy: 0.9970\n",
      "Validation loss: 0.3427, Validation accuracy: 0.9019\n",
      "\n",
      "Epoch 190:\n",
      "Training loss: 0.0258, Training accuracy: 0.9968\n",
      "Validation loss: 0.3401, Validation accuracy: 0.9010\n",
      "\n",
      "Epoch 191:\n",
      "Training loss: 0.0260, Training accuracy: 0.9965\n",
      "Validation loss: 0.3416, Validation accuracy: 0.9019\n",
      "\n",
      "Epoch 192:\n",
      "Training loss: 0.0255, Training accuracy: 0.9971\n",
      "Validation loss: 0.3450, Validation accuracy: 0.9021\n",
      "Saving ...\n",
      "\n",
      "Epoch 193:\n",
      "Training loss: 0.0254, Training accuracy: 0.9974\n",
      "Validation loss: 0.3451, Validation accuracy: 0.9018\n",
      "\n",
      "Epoch 194:\n",
      "Training loss: 0.0252, Training accuracy: 0.9973\n",
      "Validation loss: 0.3426, Validation accuracy: 0.9019\n",
      "\n",
      "Epoch 195:\n",
      "Training loss: 0.0255, Training accuracy: 0.9969\n",
      "Validation loss: 0.3428, Validation accuracy: 0.9019\n",
      "\n",
      "Epoch 196:\n",
      "Training loss: 0.0260, Training accuracy: 0.9964\n",
      "Validation loss: 0.3420, Validation accuracy: 0.9029\n",
      "Saving ...\n",
      "\n",
      "Epoch 197:\n",
      "Training loss: 0.0256, Training accuracy: 0.9970\n",
      "Validation loss: 0.3426, Validation accuracy: 0.9033\n",
      "Saving ...\n",
      "\n",
      "Epoch 198:\n",
      "Training loss: 0.0254, Training accuracy: 0.9966\n",
      "Validation loss: 0.3418, Validation accuracy: 0.9019\n",
      "\n",
      "Epoch 199:\n",
      "Training loss: 0.0254, Training accuracy: 0.9971\n",
      "Validation loss: 0.3439, Validation accuracy: 0.9007\n",
      "\n",
      "==================================================\n",
      "==> Optimization finished! Best validation accuracy: 0.9033\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9033"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train(T=3,lamb=0.6,alpha=0.4,train_loader=train_loader,val_loader=val_loader,INITIAL_LR=0.1,DECAY_EPOCHS=[40,80,180],DECAY=0.1,EPOCHS=200,REG = 2e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Training starts!\n",
      "==================================================\n",
      "Epoch 0:\n",
      "Training loss: 1.8225, Training accuracy: 0.2777\n",
      "Validation loss: 5.8094, Validation accuracy: 0.4109\n",
      "Saving ...\n",
      "\n",
      "Epoch 1:\n",
      "Training loss: 1.2512, Training accuracy: 0.4368\n",
      "Validation loss: 6.3970, Validation accuracy: 0.4567\n",
      "Saving ...\n",
      "\n",
      "Epoch 2:\n",
      "Training loss: 1.1004, Training accuracy: 0.5017\n",
      "Validation loss: 1.3469, Validation accuracy: 0.5337\n",
      "Saving ...\n",
      "\n",
      "Epoch 3:\n",
      "Training loss: 0.9639, Training accuracy: 0.5640\n",
      "Validation loss: 1.6171, Validation accuracy: 0.5424\n",
      "Saving ...\n",
      "\n",
      "Epoch 4:\n",
      "Training loss: 0.8887, Training accuracy: 0.6002\n",
      "Validation loss: 1.1405, Validation accuracy: 0.6203\n",
      "Saving ...\n",
      "\n",
      "Epoch 5:\n",
      "Training loss: 0.8315, Training accuracy: 0.6264\n",
      "Validation loss: 1.3211, Validation accuracy: 0.6123\n",
      "\n",
      "Epoch 6:\n",
      "Training loss: 0.7846, Training accuracy: 0.6492\n",
      "Validation loss: 1.0721, Validation accuracy: 0.6378\n",
      "Saving ...\n",
      "\n",
      "Epoch 7:\n",
      "Training loss: 0.7387, Training accuracy: 0.6692\n",
      "Validation loss: 1.0491, Validation accuracy: 0.6565\n",
      "Saving ...\n",
      "\n",
      "Epoch 8:\n",
      "Training loss: 0.6986, Training accuracy: 0.6833\n",
      "Validation loss: 1.0484, Validation accuracy: 0.6781\n",
      "Saving ...\n",
      "\n",
      "Epoch 9:\n",
      "Training loss: 0.6628, Training accuracy: 0.7022\n",
      "Validation loss: 0.8481, Validation accuracy: 0.7097\n",
      "Saving ...\n",
      "\n",
      "Epoch 10:\n",
      "Training loss: 0.5126, Training accuracy: 0.6870\n",
      "Validation loss: 1.7741, Validation accuracy: 0.3522\n",
      "\n",
      "Epoch 11:\n",
      "Training loss: 0.7687, Training accuracy: 0.5051\n",
      "Validation loss: 1.1884, Validation accuracy: 0.5854\n",
      "\n",
      "Epoch 12:\n",
      "Training loss: 0.5757, Training accuracy: 0.6441\n",
      "Validation loss: 1.0658, Validation accuracy: 0.6279\n",
      "\n",
      "Epoch 13:\n",
      "Training loss: 0.5107, Training accuracy: 0.6876\n",
      "Validation loss: 0.8194, Validation accuracy: 0.7112\n",
      "Saving ...\n",
      "\n",
      "Epoch 14:\n",
      "Training loss: 0.4748, Training accuracy: 0.7125\n",
      "Validation loss: 0.8601, Validation accuracy: 0.7046\n",
      "\n",
      "Epoch 15:\n",
      "Training loss: 0.4507, Training accuracy: 0.7259\n",
      "Validation loss: 0.7947, Validation accuracy: 0.7202\n",
      "Saving ...\n",
      "\n",
      "Epoch 16:\n",
      "Training loss: 0.4359, Training accuracy: 0.7362\n",
      "Validation loss: 0.7592, Validation accuracy: 0.7357\n",
      "Saving ...\n",
      "\n",
      "Epoch 17:\n",
      "Training loss: 0.4240, Training accuracy: 0.7439\n",
      "Validation loss: 0.8028, Validation accuracy: 0.7225\n",
      "\n",
      "Epoch 18:\n",
      "Training loss: 0.4146, Training accuracy: 0.7515\n",
      "Validation loss: 0.7914, Validation accuracy: 0.7310\n",
      "\n",
      "Epoch 19:\n",
      "Training loss: 0.4042, Training accuracy: 0.7577\n",
      "Validation loss: 0.7035, Validation accuracy: 0.7568\n",
      "Saving ...\n",
      "\n",
      "Epoch 20:\n",
      "Training loss: 0.3947, Training accuracy: 0.7659\n",
      "Validation loss: 0.8306, Validation accuracy: 0.7128\n",
      "\n",
      "Epoch 21:\n",
      "Training loss: 0.3923, Training accuracy: 0.7642\n",
      "Validation loss: 0.7790, Validation accuracy: 0.7340\n",
      "\n",
      "Epoch 22:\n",
      "Training loss: 0.3852, Training accuracy: 0.7694\n",
      "Validation loss: 0.7283, Validation accuracy: 0.7562\n",
      "\n",
      "Epoch 23:\n",
      "Training loss: 0.3788, Training accuracy: 0.7740\n",
      "Validation loss: 0.7940, Validation accuracy: 0.7311\n",
      "\n",
      "Epoch 24:\n",
      "Training loss: 0.3723, Training accuracy: 0.7778\n",
      "Validation loss: 0.7009, Validation accuracy: 0.7580\n",
      "Saving ...\n",
      "\n",
      "Epoch 25:\n",
      "Training loss: 0.3683, Training accuracy: 0.7814\n",
      "Validation loss: 0.7030, Validation accuracy: 0.7603\n",
      "Saving ...\n",
      "\n",
      "Epoch 26:\n",
      "Training loss: 0.3658, Training accuracy: 0.7834\n",
      "Validation loss: 0.6558, Validation accuracy: 0.7756\n",
      "Saving ...\n",
      "\n",
      "Epoch 27:\n",
      "Training loss: 0.3605, Training accuracy: 0.7859\n",
      "Validation loss: 0.7342, Validation accuracy: 0.7504\n",
      "\n",
      "Epoch 28:\n",
      "Training loss: 0.3594, Training accuracy: 0.7867\n",
      "Validation loss: 0.6737, Validation accuracy: 0.7701\n",
      "\n",
      "Epoch 29:\n",
      "Training loss: 0.3574, Training accuracy: 0.7877\n",
      "Validation loss: 0.7421, Validation accuracy: 0.7500\n",
      "\n",
      "Epoch 30:\n",
      "Training loss: 0.3511, Training accuracy: 0.7908\n",
      "Validation loss: 0.7957, Validation accuracy: 0.7363\n",
      "\n",
      "Epoch 31:\n",
      "Training loss: 0.3521, Training accuracy: 0.7902\n",
      "Validation loss: 0.7201, Validation accuracy: 0.7616\n",
      "\n",
      "Epoch 32:\n",
      "Training loss: 0.3472, Training accuracy: 0.7937\n",
      "Validation loss: 0.6704, Validation accuracy: 0.7754\n",
      "\n",
      "Epoch 33:\n",
      "Training loss: 0.3466, Training accuracy: 0.7936\n",
      "Validation loss: 0.6496, Validation accuracy: 0.7782\n",
      "Saving ...\n",
      "\n",
      "Epoch 34:\n",
      "Training loss: 0.3444, Training accuracy: 0.7975\n",
      "Validation loss: 0.7194, Validation accuracy: 0.7509\n",
      "\n",
      "Epoch 35:\n",
      "Training loss: 0.3421, Training accuracy: 0.7988\n",
      "Validation loss: 0.6189, Validation accuracy: 0.7914\n",
      "Saving ...\n",
      "\n",
      "Epoch 36:\n",
      "Training loss: 0.3382, Training accuracy: 0.8020\n",
      "Validation loss: 0.6625, Validation accuracy: 0.7737\n",
      "\n",
      "Epoch 37:\n",
      "Training loss: 0.3395, Training accuracy: 0.7987\n",
      "Validation loss: 0.6542, Validation accuracy: 0.7797\n",
      "\n",
      "Epoch 38:\n",
      "Training loss: 0.3373, Training accuracy: 0.8000\n",
      "Validation loss: 0.6439, Validation accuracy: 0.7800\n",
      "\n",
      "Epoch 39:\n",
      "Training loss: 0.3360, Training accuracy: 0.8016\n",
      "Validation loss: 0.6553, Validation accuracy: 0.7790\n",
      "\n",
      "Current learning rate has decayed to 0.010000\n",
      "Epoch 40:\n",
      "Training loss: 0.2444, Training accuracy: 0.8599\n",
      "Validation loss: 0.4176, Validation accuracy: 0.8568\n",
      "Saving ...\n",
      "\n",
      "Epoch 41:\n",
      "Training loss: 0.2144, Training accuracy: 0.8786\n",
      "Validation loss: 0.4067, Validation accuracy: 0.8591\n",
      "Saving ...\n",
      "\n",
      "Epoch 42:\n",
      "Training loss: 0.2014, Training accuracy: 0.8858\n",
      "Validation loss: 0.3822, Validation accuracy: 0.8672\n",
      "Saving ...\n",
      "\n",
      "Epoch 43:\n",
      "Training loss: 0.1945, Training accuracy: 0.8898\n",
      "Validation loss: 0.3816, Validation accuracy: 0.8691\n",
      "Saving ...\n",
      "\n",
      "Epoch 44:\n",
      "Training loss: 0.1871, Training accuracy: 0.8948\n",
      "Validation loss: 0.3798, Validation accuracy: 0.8713\n",
      "Saving ...\n",
      "\n",
      "Epoch 45:\n",
      "Training loss: 0.1802, Training accuracy: 0.8982\n",
      "Validation loss: 0.3741, Validation accuracy: 0.8721\n",
      "Saving ...\n",
      "\n",
      "Epoch 46:\n",
      "Training loss: 0.1770, Training accuracy: 0.9018\n",
      "Validation loss: 0.3722, Validation accuracy: 0.8699\n",
      "\n",
      "Epoch 47:\n",
      "Training loss: 0.1730, Training accuracy: 0.9040\n",
      "Validation loss: 0.3643, Validation accuracy: 0.8738\n",
      "Saving ...\n",
      "\n",
      "Epoch 48:\n",
      "Training loss: 0.1682, Training accuracy: 0.9065\n",
      "Validation loss: 0.3721, Validation accuracy: 0.8754\n",
      "Saving ...\n",
      "\n",
      "Epoch 49:\n",
      "Training loss: 0.1654, Training accuracy: 0.9091\n",
      "Validation loss: 0.3649, Validation accuracy: 0.8766\n",
      "Saving ...\n",
      "\n",
      "Epoch 50:\n",
      "Training loss: 0.1614, Training accuracy: 0.9110\n",
      "Validation loss: 0.3824, Validation accuracy: 0.8723\n",
      "\n",
      "Epoch 51:\n",
      "Training loss: 0.1582, Training accuracy: 0.9129\n",
      "Validation loss: 0.3732, Validation accuracy: 0.8750\n",
      "\n",
      "Epoch 52:\n",
      "Training loss: 0.1572, Training accuracy: 0.9129\n",
      "Validation loss: 0.3666, Validation accuracy: 0.8736\n",
      "\n",
      "Epoch 53:\n",
      "Training loss: 0.1517, Training accuracy: 0.9184\n",
      "Validation loss: 0.3724, Validation accuracy: 0.8763\n",
      "\n",
      "Epoch 54:\n",
      "Training loss: 0.1500, Training accuracy: 0.9186\n",
      "Validation loss: 0.3663, Validation accuracy: 0.8768\n",
      "Saving ...\n",
      "\n",
      "Epoch 55:\n",
      "Training loss: 0.1491, Training accuracy: 0.9185\n",
      "Validation loss: 0.3656, Validation accuracy: 0.8767\n",
      "\n",
      "Epoch 56:\n",
      "Training loss: 0.1470, Training accuracy: 0.9200\n",
      "Validation loss: 0.3682, Validation accuracy: 0.8759\n",
      "\n",
      "Epoch 57:\n",
      "Training loss: 0.1446, Training accuracy: 0.9221\n",
      "Validation loss: 0.3569, Validation accuracy: 0.8793\n",
      "Saving ...\n",
      "\n",
      "Epoch 58:\n",
      "Training loss: 0.1412, Training accuracy: 0.9245\n",
      "Validation loss: 0.3740, Validation accuracy: 0.8757\n",
      "\n",
      "Epoch 59:\n",
      "Training loss: 0.1398, Training accuracy: 0.9269\n",
      "Validation loss: 0.3676, Validation accuracy: 0.8763\n",
      "\n",
      "Epoch 60:\n",
      "Training loss: 0.1393, Training accuracy: 0.9251\n",
      "Validation loss: 0.3937, Validation accuracy: 0.8679\n",
      "\n",
      "Epoch 61:\n",
      "Training loss: 0.1368, Training accuracy: 0.9281\n",
      "Validation loss: 0.3688, Validation accuracy: 0.8746\n",
      "\n",
      "Epoch 62:\n",
      "Training loss: 0.1371, Training accuracy: 0.9279\n",
      "Validation loss: 0.3697, Validation accuracy: 0.8750\n",
      "\n",
      "Epoch 63:\n",
      "Training loss: 0.1369, Training accuracy: 0.9265\n",
      "Validation loss: 0.3775, Validation accuracy: 0.8746\n",
      "\n",
      "Epoch 64:\n",
      "Training loss: 0.1350, Training accuracy: 0.9276\n",
      "Validation loss: 0.3831, Validation accuracy: 0.8740\n",
      "\n",
      "Epoch 65:\n",
      "Training loss: 0.1313, Training accuracy: 0.9314\n",
      "Validation loss: 0.3882, Validation accuracy: 0.8709\n",
      "\n",
      "Epoch 66:\n",
      "Training loss: 0.1314, Training accuracy: 0.9315\n",
      "Validation loss: 0.3922, Validation accuracy: 0.8687\n",
      "\n",
      "Epoch 67:\n",
      "Training loss: 0.1298, Training accuracy: 0.9320\n",
      "Validation loss: 0.3792, Validation accuracy: 0.8762\n",
      "\n",
      "Epoch 68:\n",
      "Training loss: 0.1311, Training accuracy: 0.9298\n",
      "Validation loss: 0.3755, Validation accuracy: 0.8757\n",
      "\n",
      "Epoch 69:\n",
      "Training loss: 0.1297, Training accuracy: 0.9341\n",
      "Validation loss: 0.3880, Validation accuracy: 0.8739\n",
      "\n",
      "Epoch 70:\n",
      "Training loss: 0.1285, Training accuracy: 0.9327\n",
      "Validation loss: 0.3962, Validation accuracy: 0.8694\n",
      "\n",
      "Epoch 71:\n",
      "Training loss: 0.1297, Training accuracy: 0.9320\n",
      "Validation loss: 0.3717, Validation accuracy: 0.8775\n",
      "\n",
      "Epoch 72:\n",
      "Training loss: 0.1273, Training accuracy: 0.9334\n",
      "Validation loss: 0.3904, Validation accuracy: 0.8721\n",
      "\n",
      "Epoch 73:\n",
      "Training loss: 0.1263, Training accuracy: 0.9348\n",
      "Validation loss: 0.3885, Validation accuracy: 0.8739\n",
      "\n",
      "Epoch 74:\n",
      "Training loss: 0.1266, Training accuracy: 0.9342\n",
      "Validation loss: 0.3960, Validation accuracy: 0.8703\n",
      "\n",
      "Epoch 75:\n",
      "Training loss: 0.1269, Training accuracy: 0.9355\n",
      "Validation loss: 0.3822, Validation accuracy: 0.8741\n",
      "\n",
      "Epoch 76:\n",
      "Training loss: 0.1249, Training accuracy: 0.9364\n",
      "Validation loss: 0.3883, Validation accuracy: 0.8746\n",
      "\n",
      "Epoch 77:\n",
      "Training loss: 0.1244, Training accuracy: 0.9357\n",
      "Validation loss: 0.3803, Validation accuracy: 0.8767\n",
      "\n",
      "Epoch 78:\n",
      "Training loss: 0.1225, Training accuracy: 0.9373\n",
      "Validation loss: 0.3819, Validation accuracy: 0.8770\n",
      "\n",
      "Epoch 79:\n",
      "Training loss: 0.1225, Training accuracy: 0.9375\n",
      "Validation loss: 0.3667, Validation accuracy: 0.8760\n",
      "\n",
      "Current learning rate has decayed to 0.001000\n",
      "Epoch 80:\n",
      "Training loss: 0.0914, Training accuracy: 0.9587\n",
      "Validation loss: 0.3320, Validation accuracy: 0.8909\n",
      "Saving ...\n",
      "\n",
      "Epoch 81:\n",
      "Training loss: 0.0813, Training accuracy: 0.9654\n",
      "Validation loss: 0.3300, Validation accuracy: 0.8919\n",
      "Saving ...\n",
      "\n",
      "Epoch 82:\n",
      "Training loss: 0.0762, Training accuracy: 0.9683\n",
      "Validation loss: 0.3249, Validation accuracy: 0.8944\n",
      "Saving ...\n",
      "\n",
      "Epoch 83:\n",
      "Training loss: 0.0729, Training accuracy: 0.9707\n",
      "Validation loss: 0.3282, Validation accuracy: 0.8955\n",
      "Saving ...\n",
      "\n",
      "Epoch 84:\n",
      "Training loss: 0.0699, Training accuracy: 0.9727\n",
      "Validation loss: 0.3266, Validation accuracy: 0.8958\n",
      "Saving ...\n",
      "\n",
      "Epoch 85:\n",
      "Training loss: 0.0676, Training accuracy: 0.9738\n",
      "Validation loss: 0.3306, Validation accuracy: 0.8934\n",
      "\n",
      "Epoch 86:\n",
      "Training loss: 0.0679, Training accuracy: 0.9741\n",
      "Validation loss: 0.3308, Validation accuracy: 0.8928\n",
      "\n",
      "Epoch 87:\n",
      "Training loss: 0.0655, Training accuracy: 0.9759\n",
      "Validation loss: 0.3317, Validation accuracy: 0.8937\n",
      "\n",
      "Epoch 88:\n",
      "Training loss: 0.0642, Training accuracy: 0.9770\n",
      "Validation loss: 0.3319, Validation accuracy: 0.8960\n",
      "Saving ...\n",
      "\n",
      "Epoch 89:\n",
      "Training loss: 0.0637, Training accuracy: 0.9763\n",
      "Validation loss: 0.3298, Validation accuracy: 0.8954\n",
      "\n",
      "Epoch 90:\n",
      "Training loss: 0.0617, Training accuracy: 0.9779\n",
      "Validation loss: 0.3284, Validation accuracy: 0.8978\n",
      "Saving ...\n",
      "\n",
      "Epoch 91:\n",
      "Training loss: 0.0612, Training accuracy: 0.9788\n",
      "Validation loss: 0.3305, Validation accuracy: 0.8951\n",
      "\n",
      "Epoch 92:\n",
      "Training loss: 0.0605, Training accuracy: 0.9790\n",
      "Validation loss: 0.3288, Validation accuracy: 0.8967\n",
      "\n",
      "Epoch 93:\n",
      "Training loss: 0.0597, Training accuracy: 0.9793\n",
      "Validation loss: 0.3311, Validation accuracy: 0.8959\n",
      "\n",
      "Epoch 94:\n",
      "Training loss: 0.0583, Training accuracy: 0.9800\n",
      "Validation loss: 0.3296, Validation accuracy: 0.8958\n",
      "\n",
      "Epoch 95:\n",
      "Training loss: 0.0572, Training accuracy: 0.9814\n",
      "Validation loss: 0.3294, Validation accuracy: 0.8979\n",
      "Saving ...\n",
      "\n",
      "Epoch 96:\n",
      "Training loss: 0.0566, Training accuracy: 0.9811\n",
      "Validation loss: 0.3323, Validation accuracy: 0.8956\n",
      "\n",
      "Epoch 97:\n",
      "Training loss: 0.0554, Training accuracy: 0.9819\n",
      "Validation loss: 0.3321, Validation accuracy: 0.8959\n",
      "\n",
      "Epoch 98:\n",
      "Training loss: 0.0553, Training accuracy: 0.9820\n",
      "Validation loss: 0.3300, Validation accuracy: 0.8961\n",
      "\n",
      "Epoch 99:\n",
      "Training loss: 0.0548, Training accuracy: 0.9822\n",
      "Validation loss: 0.3320, Validation accuracy: 0.8958\n",
      "\n",
      "Epoch 100:\n",
      "Training loss: 0.0553, Training accuracy: 0.9818\n",
      "Validation loss: 0.3309, Validation accuracy: 0.8977\n",
      "\n",
      "Epoch 101:\n",
      "Training loss: 0.0538, Training accuracy: 0.9825\n",
      "Validation loss: 0.3324, Validation accuracy: 0.8958\n",
      "\n",
      "Epoch 102:\n",
      "Training loss: 0.0523, Training accuracy: 0.9845\n",
      "Validation loss: 0.3295, Validation accuracy: 0.8965\n",
      "\n",
      "Epoch 103:\n",
      "Training loss: 0.0521, Training accuracy: 0.9838\n",
      "Validation loss: 0.3323, Validation accuracy: 0.8954\n",
      "\n",
      "Epoch 104:\n",
      "Training loss: 0.0537, Training accuracy: 0.9833\n",
      "Validation loss: 0.3324, Validation accuracy: 0.8967\n",
      "\n",
      "Epoch 105:\n",
      "Training loss: 0.0514, Training accuracy: 0.9849\n",
      "Validation loss: 0.3379, Validation accuracy: 0.8971\n",
      "\n",
      "Epoch 106:\n",
      "Training loss: 0.0513, Training accuracy: 0.9848\n",
      "Validation loss: 0.3339, Validation accuracy: 0.8957\n",
      "\n",
      "Epoch 107:\n",
      "Training loss: 0.0503, Training accuracy: 0.9849\n",
      "Validation loss: 0.3351, Validation accuracy: 0.8967\n",
      "\n",
      "Epoch 108:\n",
      "Training loss: 0.0499, Training accuracy: 0.9850\n",
      "Validation loss: 0.3340, Validation accuracy: 0.8976\n",
      "\n",
      "Epoch 109:\n",
      "Training loss: 0.0487, Training accuracy: 0.9866\n",
      "Validation loss: 0.3341, Validation accuracy: 0.8971\n",
      "\n",
      "Epoch 110:\n",
      "Training loss: 0.0485, Training accuracy: 0.9866\n",
      "Validation loss: 0.3366, Validation accuracy: 0.8967\n",
      "\n",
      "Epoch 111:\n",
      "Training loss: 0.0489, Training accuracy: 0.9861\n",
      "Validation loss: 0.3355, Validation accuracy: 0.8971\n",
      "\n",
      "Epoch 112:\n",
      "Training loss: 0.0484, Training accuracy: 0.9860\n",
      "Validation loss: 0.3378, Validation accuracy: 0.8970\n",
      "\n",
      "Epoch 113:\n",
      "Training loss: 0.0472, Training accuracy: 0.9878\n",
      "Validation loss: 0.3380, Validation accuracy: 0.8955\n",
      "\n",
      "Epoch 114:\n",
      "Training loss: 0.0471, Training accuracy: 0.9867\n",
      "Validation loss: 0.3340, Validation accuracy: 0.8991\n",
      "Saving ...\n",
      "\n",
      "Epoch 115:\n",
      "Training loss: 0.0468, Training accuracy: 0.9876\n",
      "Validation loss: 0.3341, Validation accuracy: 0.8982\n",
      "\n",
      "Epoch 116:\n",
      "Training loss: 0.0468, Training accuracy: 0.9872\n",
      "Validation loss: 0.3351, Validation accuracy: 0.8978\n",
      "\n",
      "Epoch 117:\n",
      "Training loss: 0.0458, Training accuracy: 0.9879\n",
      "Validation loss: 0.3357, Validation accuracy: 0.8972\n",
      "\n",
      "Epoch 118:\n",
      "Training loss: 0.0452, Training accuracy: 0.9885\n",
      "Validation loss: 0.3327, Validation accuracy: 0.8996\n",
      "Saving ...\n",
      "\n",
      "Epoch 119:\n",
      "Training loss: 0.0452, Training accuracy: 0.9888\n",
      "Validation loss: 0.3445, Validation accuracy: 0.8968\n",
      "\n",
      "Epoch 120:\n",
      "Training loss: 0.0451, Training accuracy: 0.9880\n",
      "Validation loss: 0.3380, Validation accuracy: 0.8962\n",
      "\n",
      "Epoch 121:\n",
      "Training loss: 0.0447, Training accuracy: 0.9883\n",
      "Validation loss: 0.3438, Validation accuracy: 0.8965\n",
      "\n",
      "Epoch 122:\n",
      "Training loss: 0.0446, Training accuracy: 0.9885\n",
      "Validation loss: 0.3383, Validation accuracy: 0.8967\n",
      "\n",
      "Epoch 123:\n",
      "Training loss: 0.0434, Training accuracy: 0.9896\n",
      "Validation loss: 0.3413, Validation accuracy: 0.8968\n",
      "\n",
      "Epoch 124:\n",
      "Training loss: 0.0429, Training accuracy: 0.9892\n",
      "Validation loss: 0.3377, Validation accuracy: 0.8986\n",
      "\n",
      "Epoch 125:\n",
      "Training loss: 0.0440, Training accuracy: 0.9889\n",
      "Validation loss: 0.3444, Validation accuracy: 0.8964\n",
      "\n",
      "Epoch 126:\n",
      "Training loss: 0.0423, Training accuracy: 0.9908\n",
      "Validation loss: 0.3452, Validation accuracy: 0.8961\n",
      "\n",
      "Epoch 127:\n",
      "Training loss: 0.0422, Training accuracy: 0.9897\n",
      "Validation loss: 0.3397, Validation accuracy: 0.8995\n",
      "\n",
      "Epoch 128:\n",
      "Training loss: 0.0417, Training accuracy: 0.9903\n",
      "Validation loss: 0.3461, Validation accuracy: 0.8968\n",
      "\n",
      "Epoch 129:\n",
      "Training loss: 0.0419, Training accuracy: 0.9891\n",
      "Validation loss: 0.3439, Validation accuracy: 0.8976\n",
      "\n",
      "Epoch 130:\n",
      "Training loss: 0.0420, Training accuracy: 0.9895\n",
      "Validation loss: 0.3411, Validation accuracy: 0.8994\n",
      "\n",
      "Epoch 131:\n",
      "Training loss: 0.0419, Training accuracy: 0.9893\n",
      "Validation loss: 0.3445, Validation accuracy: 0.8967\n",
      "\n",
      "Epoch 132:\n",
      "Training loss: 0.0422, Training accuracy: 0.9897\n",
      "Validation loss: 0.3432, Validation accuracy: 0.8978\n",
      "\n",
      "Epoch 133:\n",
      "Training loss: 0.0403, Training accuracy: 0.9912\n",
      "Validation loss: 0.3441, Validation accuracy: 0.8967\n",
      "\n",
      "Epoch 134:\n",
      "Training loss: 0.0403, Training accuracy: 0.9907\n",
      "Validation loss: 0.3479, Validation accuracy: 0.8970\n",
      "\n",
      "Epoch 135:\n",
      "Training loss: 0.0407, Training accuracy: 0.9909\n",
      "Validation loss: 0.3422, Validation accuracy: 0.8973\n",
      "\n",
      "Epoch 136:\n",
      "Training loss: 0.0400, Training accuracy: 0.9911\n",
      "Validation loss: 0.3453, Validation accuracy: 0.8973\n",
      "\n",
      "Epoch 137:\n",
      "Training loss: 0.0399, Training accuracy: 0.9907\n",
      "Validation loss: 0.3439, Validation accuracy: 0.8976\n",
      "\n",
      "Epoch 138:\n",
      "Training loss: 0.0398, Training accuracy: 0.9909\n",
      "Validation loss: 0.3448, Validation accuracy: 0.8990\n",
      "\n",
      "Epoch 139:\n",
      "Training loss: 0.0399, Training accuracy: 0.9909\n",
      "Validation loss: 0.3475, Validation accuracy: 0.8958\n",
      "\n",
      "Epoch 140:\n",
      "Training loss: 0.0384, Training accuracy: 0.9918\n",
      "Validation loss: 0.3465, Validation accuracy: 0.8964\n",
      "\n",
      "Epoch 141:\n",
      "Training loss: 0.0381, Training accuracy: 0.9918\n",
      "Validation loss: 0.3510, Validation accuracy: 0.8952\n",
      "\n",
      "Epoch 142:\n",
      "Training loss: 0.0376, Training accuracy: 0.9927\n",
      "Validation loss: 0.3503, Validation accuracy: 0.8961\n",
      "\n",
      "Epoch 143:\n",
      "Training loss: 0.0378, Training accuracy: 0.9917\n",
      "Validation loss: 0.3485, Validation accuracy: 0.8978\n",
      "\n",
      "Epoch 144:\n",
      "Training loss: 0.0381, Training accuracy: 0.9917\n",
      "Validation loss: 0.3471, Validation accuracy: 0.9000\n",
      "Saving ...\n",
      "\n",
      "Epoch 145:\n",
      "Training loss: 0.0384, Training accuracy: 0.9918\n",
      "Validation loss: 0.3435, Validation accuracy: 0.8989\n",
      "\n",
      "Epoch 146:\n",
      "Training loss: 0.0382, Training accuracy: 0.9909\n",
      "Validation loss: 0.3501, Validation accuracy: 0.8958\n",
      "\n",
      "Epoch 147:\n",
      "Training loss: 0.0374, Training accuracy: 0.9926\n",
      "Validation loss: 0.3544, Validation accuracy: 0.8991\n",
      "\n",
      "Epoch 148:\n",
      "Training loss: 0.0364, Training accuracy: 0.9932\n",
      "Validation loss: 0.3444, Validation accuracy: 0.8982\n",
      "\n",
      "Epoch 149:\n",
      "Training loss: 0.0371, Training accuracy: 0.9923\n",
      "Validation loss: 0.3518, Validation accuracy: 0.8974\n",
      "\n",
      "Epoch 150:\n",
      "Training loss: 0.0364, Training accuracy: 0.9932\n",
      "Validation loss: 0.3489, Validation accuracy: 0.8978\n",
      "\n",
      "Epoch 151:\n",
      "Training loss: 0.0367, Training accuracy: 0.9929\n",
      "Validation loss: 0.3525, Validation accuracy: 0.8983\n",
      "\n",
      "Epoch 152:\n",
      "Training loss: 0.0361, Training accuracy: 0.9928\n",
      "Validation loss: 0.3501, Validation accuracy: 0.8973\n",
      "\n",
      "Epoch 153:\n",
      "Training loss: 0.0366, Training accuracy: 0.9930\n",
      "Validation loss: 0.3524, Validation accuracy: 0.8951\n",
      "\n",
      "Epoch 154:\n",
      "Training loss: 0.0363, Training accuracy: 0.9925\n",
      "Validation loss: 0.3507, Validation accuracy: 0.8978\n",
      "\n",
      "Epoch 155:\n",
      "Training loss: 0.0355, Training accuracy: 0.9930\n",
      "Validation loss: 0.3496, Validation accuracy: 0.8975\n",
      "\n",
      "Epoch 156:\n",
      "Training loss: 0.0362, Training accuracy: 0.9924\n",
      "Validation loss: 0.3516, Validation accuracy: 0.8958\n",
      "\n",
      "Epoch 157:\n",
      "Training loss: 0.0359, Training accuracy: 0.9930\n",
      "Validation loss: 0.3565, Validation accuracy: 0.8953\n",
      "\n",
      "Epoch 158:\n",
      "Training loss: 0.0346, Training accuracy: 0.9935\n",
      "Validation loss: 0.3505, Validation accuracy: 0.8974\n",
      "\n",
      "Epoch 159:\n",
      "Training loss: 0.0347, Training accuracy: 0.9936\n",
      "Validation loss: 0.3538, Validation accuracy: 0.8962\n",
      "\n",
      "Epoch 160:\n",
      "Training loss: 0.0345, Training accuracy: 0.9939\n",
      "Validation loss: 0.3552, Validation accuracy: 0.8977\n",
      "\n",
      "Epoch 161:\n",
      "Training loss: 0.0355, Training accuracy: 0.9929\n",
      "Validation loss: 0.3558, Validation accuracy: 0.8962\n",
      "\n",
      "Epoch 162:\n",
      "Training loss: 0.0343, Training accuracy: 0.9938\n",
      "Validation loss: 0.3535, Validation accuracy: 0.8964\n",
      "\n",
      "Epoch 163:\n",
      "Training loss: 0.0342, Training accuracy: 0.9940\n",
      "Validation loss: 0.3539, Validation accuracy: 0.8981\n",
      "\n",
      "Epoch 164:\n",
      "Training loss: 0.0347, Training accuracy: 0.9931\n",
      "Validation loss: 0.3552, Validation accuracy: 0.8978\n",
      "\n",
      "Epoch 165:\n",
      "Training loss: 0.0344, Training accuracy: 0.9937\n",
      "Validation loss: 0.3532, Validation accuracy: 0.8978\n",
      "\n",
      "Epoch 166:\n",
      "Training loss: 0.0336, Training accuracy: 0.9942\n",
      "Validation loss: 0.3582, Validation accuracy: 0.8972\n",
      "\n",
      "Epoch 167:\n",
      "Training loss: 0.0336, Training accuracy: 0.9940\n",
      "Validation loss: 0.3577, Validation accuracy: 0.8974\n",
      "\n",
      "Epoch 168:\n",
      "Training loss: 0.0337, Training accuracy: 0.9938\n",
      "Validation loss: 0.3542, Validation accuracy: 0.8967\n",
      "\n",
      "Epoch 169:\n",
      "Training loss: 0.0340, Training accuracy: 0.9934\n",
      "Validation loss: 0.3598, Validation accuracy: 0.8971\n",
      "\n",
      "Epoch 170:\n",
      "Training loss: 0.0331, Training accuracy: 0.9938\n",
      "Validation loss: 0.3557, Validation accuracy: 0.8950\n",
      "\n",
      "Epoch 171:\n",
      "Training loss: 0.0326, Training accuracy: 0.9944\n",
      "Validation loss: 0.3690, Validation accuracy: 0.8940\n",
      "\n",
      "Epoch 172:\n",
      "Training loss: 0.0329, Training accuracy: 0.9945\n",
      "Validation loss: 0.3617, Validation accuracy: 0.8958\n",
      "\n",
      "Epoch 173:\n",
      "Training loss: 0.0330, Training accuracy: 0.9938\n",
      "Validation loss: 0.3615, Validation accuracy: 0.8964\n",
      "\n",
      "Epoch 174:\n",
      "Training loss: 0.0328, Training accuracy: 0.9941\n",
      "Validation loss: 0.3635, Validation accuracy: 0.8944\n",
      "\n",
      "Epoch 175:\n",
      "Training loss: 0.0323, Training accuracy: 0.9947\n",
      "Validation loss: 0.3638, Validation accuracy: 0.8952\n",
      "\n",
      "Epoch 176:\n",
      "Training loss: 0.0335, Training accuracy: 0.9935\n",
      "Validation loss: 0.3623, Validation accuracy: 0.8953\n",
      "\n",
      "Epoch 177:\n",
      "Training loss: 0.0322, Training accuracy: 0.9947\n",
      "Validation loss: 0.3664, Validation accuracy: 0.8932\n",
      "\n",
      "Epoch 178:\n",
      "Training loss: 0.0320, Training accuracy: 0.9947\n",
      "Validation loss: 0.3649, Validation accuracy: 0.8955\n",
      "\n",
      "Epoch 179:\n",
      "Training loss: 0.0321, Training accuracy: 0.9948\n",
      "Validation loss: 0.3607, Validation accuracy: 0.8961\n",
      "\n",
      "Current learning rate has decayed to 0.000100\n",
      "Epoch 180:\n",
      "Training loss: 0.0306, Training accuracy: 0.9952\n",
      "Validation loss: 0.3598, Validation accuracy: 0.8960\n",
      "\n",
      "Epoch 181:\n",
      "Training loss: 0.0295, Training accuracy: 0.9958\n",
      "Validation loss: 0.3587, Validation accuracy: 0.8974\n",
      "\n",
      "Epoch 182:\n",
      "Training loss: 0.0295, Training accuracy: 0.9961\n",
      "Validation loss: 0.3574, Validation accuracy: 0.8965\n",
      "\n",
      "Epoch 183:\n",
      "Training loss: 0.0293, Training accuracy: 0.9959\n",
      "Validation loss: 0.3589, Validation accuracy: 0.8967\n",
      "\n",
      "Epoch 184:\n",
      "Training loss: 0.0293, Training accuracy: 0.9957\n",
      "Validation loss: 0.3595, Validation accuracy: 0.8969\n",
      "\n",
      "Epoch 185:\n",
      "Training loss: 0.0290, Training accuracy: 0.9958\n",
      "Validation loss: 0.3595, Validation accuracy: 0.8971\n",
      "\n",
      "Epoch 186:\n",
      "Training loss: 0.0289, Training accuracy: 0.9964\n",
      "Validation loss: 0.3573, Validation accuracy: 0.8965\n",
      "\n",
      "Epoch 187:\n",
      "Training loss: 0.0282, Training accuracy: 0.9965\n",
      "Validation loss: 0.3579, Validation accuracy: 0.8969\n",
      "\n",
      "Epoch 188:\n",
      "Training loss: 0.0283, Training accuracy: 0.9964\n",
      "Validation loss: 0.3568, Validation accuracy: 0.8961\n",
      "\n",
      "Epoch 189:\n",
      "Training loss: 0.0280, Training accuracy: 0.9965\n",
      "Validation loss: 0.3584, Validation accuracy: 0.8972\n",
      "\n",
      "Epoch 190:\n",
      "Training loss: 0.0286, Training accuracy: 0.9959\n",
      "Validation loss: 0.3568, Validation accuracy: 0.8968\n",
      "\n",
      "Epoch 191:\n",
      "Training loss: 0.0281, Training accuracy: 0.9966\n",
      "Validation loss: 0.3591, Validation accuracy: 0.8968\n",
      "\n",
      "Epoch 192:\n",
      "Training loss: 0.0283, Training accuracy: 0.9962\n",
      "Validation loss: 0.3568, Validation accuracy: 0.8969\n",
      "\n",
      "Epoch 193:\n",
      "Training loss: 0.0282, Training accuracy: 0.9966\n",
      "Validation loss: 0.3598, Validation accuracy: 0.8968\n",
      "\n",
      "Epoch 194:\n",
      "Training loss: 0.0280, Training accuracy: 0.9962\n",
      "Validation loss: 0.3557, Validation accuracy: 0.8984\n",
      "\n",
      "Epoch 195:\n",
      "Training loss: 0.0284, Training accuracy: 0.9964\n",
      "Validation loss: 0.3565, Validation accuracy: 0.8991\n",
      "\n",
      "Epoch 196:\n",
      "Training loss: 0.0280, Training accuracy: 0.9968\n",
      "Validation loss: 0.3573, Validation accuracy: 0.9000\n",
      "\n",
      "Epoch 197:\n",
      "Training loss: 0.0282, Training accuracy: 0.9964\n",
      "Validation loss: 0.3570, Validation accuracy: 0.8995\n",
      "\n",
      "Epoch 198:\n",
      "Training loss: 0.0284, Training accuracy: 0.9966\n",
      "Validation loss: 0.3565, Validation accuracy: 0.8995\n",
      "\n",
      "Epoch 199:\n",
      "Training loss: 0.0278, Training accuracy: 0.9970\n",
      "Validation loss: 0.3568, Validation accuracy: 0.8998\n",
      "\n",
      "==================================================\n",
      "==> Optimization finished! Best validation accuracy: 0.9000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train(T=3,lamb=0.8,alpha=0.4,train_loader=train_loader,val_loader=val_loader,INITIAL_LR=0.1,DECAY_EPOCHS=[40,80,180],DECAY=0.1,EPOCHS=200,REG = 2e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Training starts!\n",
      "==================================================\n",
      "Epoch 0:\n",
      "Training loss: 1.7610, Training accuracy: 0.3007\n",
      "Validation loss: 2.4393, Validation accuracy: 0.4025\n",
      "Saving ...\n",
      "\n",
      "Epoch 1:\n",
      "Training loss: 1.2247, Training accuracy: 0.4485\n",
      "Validation loss: 2.4373, Validation accuracy: 0.5173\n",
      "Saving ...\n",
      "\n",
      "Epoch 2:\n",
      "Training loss: 1.0490, Training accuracy: 0.5260\n",
      "Validation loss: 1.5810, Validation accuracy: 0.5090\n",
      "\n",
      "Epoch 3:\n",
      "Training loss: 0.9566, Training accuracy: 0.5682\n",
      "Validation loss: 1.3258, Validation accuracy: 0.6096\n",
      "Saving ...\n",
      "\n",
      "Epoch 4:\n",
      "Training loss: 0.8622, Training accuracy: 0.6088\n",
      "Validation loss: 1.0559, Validation accuracy: 0.6330\n",
      "Saving ...\n",
      "\n",
      "Epoch 5:\n",
      "Training loss: 0.7854, Training accuracy: 0.6442\n",
      "Validation loss: 1.0209, Validation accuracy: 0.6530\n",
      "Saving ...\n",
      "\n",
      "Epoch 6:\n",
      "Training loss: 0.7350, Training accuracy: 0.6713\n",
      "Validation loss: 1.0118, Validation accuracy: 0.6522\n",
      "\n",
      "Epoch 7:\n",
      "Training loss: 0.7030, Training accuracy: 0.6859\n",
      "Validation loss: 0.9704, Validation accuracy: 0.6704\n",
      "Saving ...\n",
      "\n",
      "Epoch 8:\n",
      "Training loss: 0.6815, Training accuracy: 0.6967\n",
      "Validation loss: 0.9324, Validation accuracy: 0.6804\n",
      "Saving ...\n",
      "\n",
      "Epoch 9:\n",
      "Training loss: 0.6629, Training accuracy: 0.7048\n",
      "Validation loss: 1.2813, Validation accuracy: 0.5963\n",
      "\n",
      "Epoch 10:\n",
      "Training loss: 0.4413, Training accuracy: 0.7369\n",
      "Validation loss: 0.7885, Validation accuracy: 0.7314\n",
      "Saving ...\n",
      "\n",
      "Epoch 11:\n",
      "Training loss: 0.4428, Training accuracy: 0.7343\n",
      "Validation loss: 0.9803, Validation accuracy: 0.6639\n",
      "\n",
      "Epoch 12:\n",
      "Training loss: 0.4473, Training accuracy: 0.7326\n",
      "Validation loss: 0.8261, Validation accuracy: 0.7169\n",
      "\n",
      "Epoch 13:\n",
      "Training loss: 0.4460, Training accuracy: 0.7341\n",
      "Validation loss: 0.9498, Validation accuracy: 0.6724\n",
      "\n",
      "Epoch 14:\n",
      "Training loss: 0.4435, Training accuracy: 0.7372\n",
      "Validation loss: 0.9656, Validation accuracy: 0.6764\n",
      "\n",
      "Epoch 15:\n",
      "Training loss: 0.4388, Training accuracy: 0.7381\n",
      "Validation loss: 0.7759, Validation accuracy: 0.7342\n",
      "Saving ...\n",
      "\n",
      "Epoch 16:\n",
      "Training loss: 0.4354, Training accuracy: 0.7389\n",
      "Validation loss: 0.9066, Validation accuracy: 0.6938\n",
      "\n",
      "Epoch 17:\n",
      "Training loss: 0.4309, Training accuracy: 0.7429\n",
      "Validation loss: 0.7232, Validation accuracy: 0.7504\n",
      "Saving ...\n",
      "\n",
      "Epoch 18:\n",
      "Training loss: 0.4327, Training accuracy: 0.7417\n",
      "Validation loss: 0.8139, Validation accuracy: 0.7220\n",
      "\n",
      "Epoch 19:\n",
      "Training loss: 0.4268, Training accuracy: 0.7453\n",
      "Validation loss: 0.9895, Validation accuracy: 0.6647\n",
      "\n",
      "Epoch 20:\n",
      "Training loss: 0.4269, Training accuracy: 0.7449\n",
      "Validation loss: 1.1016, Validation accuracy: 0.6452\n",
      "\n",
      "Epoch 21:\n",
      "Training loss: 0.4227, Training accuracy: 0.7492\n",
      "Validation loss: 0.9757, Validation accuracy: 0.6796\n",
      "\n",
      "Epoch 22:\n",
      "Training loss: 0.4176, Training accuracy: 0.7523\n",
      "Validation loss: 0.9281, Validation accuracy: 0.6924\n",
      "\n",
      "Epoch 23:\n",
      "Training loss: 0.4171, Training accuracy: 0.7527\n",
      "Validation loss: 0.8236, Validation accuracy: 0.7209\n",
      "\n",
      "Epoch 24:\n",
      "Training loss: 0.4164, Training accuracy: 0.7515\n",
      "Validation loss: 0.8102, Validation accuracy: 0.7282\n",
      "\n",
      "Epoch 25:\n",
      "Training loss: 0.4121, Training accuracy: 0.7565\n",
      "Validation loss: 0.7700, Validation accuracy: 0.7434\n",
      "\n",
      "Epoch 26:\n",
      "Training loss: 0.4135, Training accuracy: 0.7539\n",
      "Validation loss: 0.8995, Validation accuracy: 0.6969\n",
      "\n",
      "Epoch 27:\n",
      "Training loss: 0.4132, Training accuracy: 0.7538\n",
      "Validation loss: 0.7374, Validation accuracy: 0.7478\n",
      "\n",
      "Epoch 28:\n",
      "Training loss: 0.4109, Training accuracy: 0.7546\n",
      "Validation loss: 1.0063, Validation accuracy: 0.6687\n",
      "\n",
      "Epoch 29:\n",
      "Training loss: 0.4127, Training accuracy: 0.7548\n",
      "Validation loss: 0.8576, Validation accuracy: 0.7118\n",
      "\n",
      "Epoch 30:\n",
      "Training loss: 0.4074, Training accuracy: 0.7582\n",
      "Validation loss: 0.9331, Validation accuracy: 0.6806\n",
      "\n",
      "Epoch 31:\n",
      "Training loss: 0.4083, Training accuracy: 0.7580\n",
      "Validation loss: 0.8316, Validation accuracy: 0.7162\n",
      "\n",
      "Epoch 32:\n",
      "Training loss: 0.4043, Training accuracy: 0.7580\n",
      "Validation loss: 0.7825, Validation accuracy: 0.7322\n",
      "\n",
      "Epoch 33:\n",
      "Training loss: 0.4037, Training accuracy: 0.7607\n",
      "Validation loss: 0.7860, Validation accuracy: 0.7320\n",
      "\n",
      "Epoch 34:\n",
      "Training loss: 0.4035, Training accuracy: 0.7618\n",
      "Validation loss: 0.9170, Validation accuracy: 0.6938\n",
      "\n",
      "Epoch 35:\n",
      "Training loss: 0.4051, Training accuracy: 0.7607\n",
      "Validation loss: 0.7670, Validation accuracy: 0.7384\n",
      "\n",
      "Epoch 36:\n",
      "Training loss: 0.4040, Training accuracy: 0.7615\n",
      "Validation loss: 0.8128, Validation accuracy: 0.7215\n",
      "\n",
      "Epoch 37:\n",
      "Training loss: 0.4015, Training accuracy: 0.7618\n",
      "Validation loss: 0.7366, Validation accuracy: 0.7490\n",
      "\n",
      "Epoch 38:\n",
      "Training loss: 0.3993, Training accuracy: 0.7634\n",
      "Validation loss: 0.7909, Validation accuracy: 0.7326\n",
      "\n",
      "Epoch 39:\n",
      "Training loss: 0.4044, Training accuracy: 0.7609\n",
      "Validation loss: 0.8451, Validation accuracy: 0.7038\n",
      "\n",
      "Current learning rate has decayed to 0.010000\n",
      "Epoch 40:\n",
      "Training loss: 0.2871, Training accuracy: 0.8344\n",
      "Validation loss: 0.4458, Validation accuracy: 0.8488\n",
      "Saving ...\n",
      "\n",
      "Epoch 41:\n",
      "Training loss: 0.2514, Training accuracy: 0.8553\n",
      "Validation loss: 0.4413, Validation accuracy: 0.8498\n",
      "Saving ...\n",
      "\n",
      "Epoch 42:\n",
      "Training loss: 0.2379, Training accuracy: 0.8654\n",
      "Validation loss: 0.4229, Validation accuracy: 0.8558\n",
      "Saving ...\n",
      "\n",
      "Epoch 43:\n",
      "Training loss: 0.2276, Training accuracy: 0.8686\n",
      "Validation loss: 0.4160, Validation accuracy: 0.8581\n",
      "Saving ...\n",
      "\n",
      "Epoch 44:\n",
      "Training loss: 0.2193, Training accuracy: 0.8756\n",
      "Validation loss: 0.4081, Validation accuracy: 0.8614\n",
      "Saving ...\n",
      "\n",
      "Epoch 45:\n",
      "Training loss: 0.2150, Training accuracy: 0.8769\n",
      "Validation loss: 0.4190, Validation accuracy: 0.8572\n",
      "\n",
      "Epoch 46:\n",
      "Training loss: 0.2108, Training accuracy: 0.8800\n",
      "Validation loss: 0.4028, Validation accuracy: 0.8619\n",
      "Saving ...\n",
      "\n",
      "Epoch 47:\n",
      "Training loss: 0.2021, Training accuracy: 0.8865\n",
      "Validation loss: 0.4018, Validation accuracy: 0.8627\n",
      "Saving ...\n",
      "\n",
      "Epoch 48:\n",
      "Training loss: 0.2017, Training accuracy: 0.8861\n",
      "Validation loss: 0.3878, Validation accuracy: 0.8673\n",
      "Saving ...\n",
      "\n",
      "Epoch 49:\n",
      "Training loss: 0.1986, Training accuracy: 0.8895\n",
      "Validation loss: 0.3894, Validation accuracy: 0.8679\n",
      "Saving ...\n",
      "\n",
      "Epoch 50:\n",
      "Training loss: 0.1952, Training accuracy: 0.8904\n",
      "Validation loss: 0.4071, Validation accuracy: 0.8644\n",
      "\n",
      "Epoch 51:\n",
      "Training loss: 0.1944, Training accuracy: 0.8918\n",
      "Validation loss: 0.4203, Validation accuracy: 0.8566\n",
      "\n",
      "Epoch 52:\n",
      "Training loss: 0.1928, Training accuracy: 0.8910\n",
      "Validation loss: 0.4044, Validation accuracy: 0.8633\n",
      "\n",
      "Epoch 53:\n",
      "Training loss: 0.1907, Training accuracy: 0.8930\n",
      "Validation loss: 0.4056, Validation accuracy: 0.8624\n",
      "\n",
      "Epoch 54:\n",
      "Training loss: 0.1923, Training accuracy: 0.8923\n",
      "Validation loss: 0.4051, Validation accuracy: 0.8605\n",
      "\n",
      "Epoch 55:\n",
      "Training loss: 0.1887, Training accuracy: 0.8946\n",
      "Validation loss: 0.4172, Validation accuracy: 0.8601\n",
      "\n",
      "Epoch 56:\n",
      "Training loss: 0.1879, Training accuracy: 0.8956\n",
      "Validation loss: 0.4228, Validation accuracy: 0.8577\n",
      "\n",
      "Epoch 57:\n",
      "Training loss: 0.1846, Training accuracy: 0.8974\n",
      "Validation loss: 0.4342, Validation accuracy: 0.8552\n",
      "\n",
      "Epoch 58:\n",
      "Training loss: 0.1875, Training accuracy: 0.8959\n",
      "Validation loss: 0.4041, Validation accuracy: 0.8683\n",
      "Saving ...\n",
      "\n",
      "Epoch 59:\n",
      "Training loss: 0.1840, Training accuracy: 0.8982\n",
      "Validation loss: 0.4200, Validation accuracy: 0.8561\n",
      "\n",
      "Epoch 60:\n",
      "Training loss: 0.1838, Training accuracy: 0.8983\n",
      "Validation loss: 0.4343, Validation accuracy: 0.8522\n",
      "\n",
      "Epoch 61:\n",
      "Training loss: 0.1831, Training accuracy: 0.8985\n",
      "Validation loss: 0.3910, Validation accuracy: 0.8683\n",
      "\n",
      "Epoch 62:\n",
      "Training loss: 0.1803, Training accuracy: 0.9011\n",
      "Validation loss: 0.4458, Validation accuracy: 0.8501\n",
      "\n",
      "Epoch 63:\n",
      "Training loss: 0.1802, Training accuracy: 0.9013\n",
      "Validation loss: 0.4165, Validation accuracy: 0.8586\n",
      "\n",
      "Epoch 64:\n",
      "Training loss: 0.1782, Training accuracy: 0.9031\n",
      "Validation loss: 0.3968, Validation accuracy: 0.8684\n",
      "Saving ...\n",
      "\n",
      "Epoch 65:\n",
      "Training loss: 0.1799, Training accuracy: 0.9008\n",
      "Validation loss: 0.4065, Validation accuracy: 0.8653\n",
      "\n",
      "Epoch 66:\n",
      "Training loss: 0.1793, Training accuracy: 0.9013\n",
      "Validation loss: 0.4082, Validation accuracy: 0.8629\n",
      "\n",
      "Epoch 67:\n",
      "Training loss: 0.1803, Training accuracy: 0.9007\n",
      "Validation loss: 0.4167, Validation accuracy: 0.8585\n",
      "\n",
      "Epoch 68:\n",
      "Training loss: 0.1761, Training accuracy: 0.9033\n",
      "Validation loss: 0.4429, Validation accuracy: 0.8505\n",
      "\n",
      "Epoch 69:\n",
      "Training loss: 0.1765, Training accuracy: 0.9044\n",
      "Validation loss: 0.4070, Validation accuracy: 0.8643\n",
      "\n",
      "Epoch 70:\n",
      "Training loss: 0.1754, Training accuracy: 0.9040\n",
      "Validation loss: 0.4136, Validation accuracy: 0.8624\n",
      "\n",
      "Epoch 71:\n",
      "Training loss: 0.1754, Training accuracy: 0.9049\n",
      "Validation loss: 0.3969, Validation accuracy: 0.8660\n",
      "\n",
      "Epoch 72:\n",
      "Training loss: 0.1724, Training accuracy: 0.9051\n",
      "Validation loss: 0.4116, Validation accuracy: 0.8630\n",
      "\n",
      "Epoch 73:\n",
      "Training loss: 0.1707, Training accuracy: 0.9068\n",
      "Validation loss: 0.4226, Validation accuracy: 0.8601\n",
      "\n",
      "Epoch 74:\n",
      "Training loss: 0.1711, Training accuracy: 0.9078\n",
      "Validation loss: 0.4037, Validation accuracy: 0.8665\n",
      "\n",
      "Epoch 75:\n",
      "Training loss: 0.1713, Training accuracy: 0.9063\n",
      "Validation loss: 0.4032, Validation accuracy: 0.8662\n",
      "\n",
      "Epoch 76:\n",
      "Training loss: 0.1701, Training accuracy: 0.9060\n",
      "Validation loss: 0.4190, Validation accuracy: 0.8602\n",
      "\n",
      "Epoch 77:\n",
      "Training loss: 0.1677, Training accuracy: 0.9091\n",
      "Validation loss: 0.3994, Validation accuracy: 0.8674\n",
      "\n",
      "Epoch 78:\n",
      "Training loss: 0.1687, Training accuracy: 0.9079\n",
      "Validation loss: 0.4276, Validation accuracy: 0.8582\n",
      "\n",
      "Epoch 79:\n",
      "Training loss: 0.1693, Training accuracy: 0.9079\n",
      "Validation loss: 0.4007, Validation accuracy: 0.8654\n",
      "\n",
      "Current learning rate has decayed to 0.001000\n",
      "Epoch 80:\n",
      "Training loss: 0.1199, Training accuracy: 0.9410\n",
      "Validation loss: 0.3130, Validation accuracy: 0.8989\n",
      "Saving ...\n",
      "\n",
      "Epoch 81:\n",
      "Training loss: 0.1042, Training accuracy: 0.9506\n",
      "Validation loss: 0.3084, Validation accuracy: 0.8980\n",
      "\n",
      "Epoch 82:\n",
      "Training loss: 0.0963, Training accuracy: 0.9577\n",
      "Validation loss: 0.3061, Validation accuracy: 0.8999\n",
      "Saving ...\n",
      "\n",
      "Epoch 83:\n",
      "Training loss: 0.0928, Training accuracy: 0.9596\n",
      "Validation loss: 0.3010, Validation accuracy: 0.8992\n",
      "\n",
      "Epoch 84:\n",
      "Training loss: 0.0887, Training accuracy: 0.9612\n",
      "Validation loss: 0.3043, Validation accuracy: 0.8992\n",
      "\n",
      "Epoch 85:\n",
      "Training loss: 0.0878, Training accuracy: 0.9621\n",
      "Validation loss: 0.3001, Validation accuracy: 0.8996\n",
      "\n",
      "Epoch 86:\n",
      "Training loss: 0.0845, Training accuracy: 0.9651\n",
      "Validation loss: 0.3030, Validation accuracy: 0.9000\n",
      "Saving ...\n",
      "\n",
      "Epoch 87:\n",
      "Training loss: 0.0827, Training accuracy: 0.9657\n",
      "Validation loss: 0.3000, Validation accuracy: 0.9010\n",
      "Saving ...\n",
      "\n",
      "Epoch 88:\n",
      "Training loss: 0.0815, Training accuracy: 0.9660\n",
      "Validation loss: 0.3004, Validation accuracy: 0.9001\n",
      "\n",
      "Epoch 89:\n",
      "Training loss: 0.0789, Training accuracy: 0.9675\n",
      "Validation loss: 0.3001, Validation accuracy: 0.9046\n",
      "Saving ...\n",
      "\n",
      "Epoch 90:\n",
      "Training loss: 0.0775, Training accuracy: 0.9689\n",
      "Validation loss: 0.3038, Validation accuracy: 0.8990\n",
      "\n",
      "Epoch 91:\n",
      "Training loss: 0.0751, Training accuracy: 0.9709\n",
      "Validation loss: 0.3012, Validation accuracy: 0.9021\n",
      "\n",
      "Epoch 92:\n",
      "Training loss: 0.0742, Training accuracy: 0.9705\n",
      "Validation loss: 0.3037, Validation accuracy: 0.9029\n",
      "\n",
      "Epoch 93:\n",
      "Training loss: 0.0738, Training accuracy: 0.9711\n",
      "Validation loss: 0.3006, Validation accuracy: 0.9037\n",
      "\n",
      "Epoch 94:\n",
      "Training loss: 0.0723, Training accuracy: 0.9719\n",
      "Validation loss: 0.3010, Validation accuracy: 0.9048\n",
      "Saving ...\n",
      "\n",
      "Epoch 95:\n",
      "Training loss: 0.0714, Training accuracy: 0.9728\n",
      "Validation loss: 0.3031, Validation accuracy: 0.9007\n",
      "\n",
      "Epoch 96:\n",
      "Training loss: 0.0698, Training accuracy: 0.9738\n",
      "Validation loss: 0.3078, Validation accuracy: 0.9027\n",
      "\n",
      "Epoch 97:\n",
      "Training loss: 0.0689, Training accuracy: 0.9743\n",
      "Validation loss: 0.3074, Validation accuracy: 0.9025\n",
      "\n",
      "Epoch 98:\n",
      "Training loss: 0.0670, Training accuracy: 0.9761\n",
      "Validation loss: 0.3043, Validation accuracy: 0.9017\n",
      "\n",
      "Epoch 99:\n",
      "Training loss: 0.0663, Training accuracy: 0.9767\n",
      "Validation loss: 0.3034, Validation accuracy: 0.9023\n",
      "\n",
      "Epoch 100:\n",
      "Training loss: 0.0655, Training accuracy: 0.9766\n",
      "Validation loss: 0.3031, Validation accuracy: 0.9056\n",
      "Saving ...\n",
      "\n",
      "Epoch 101:\n",
      "Training loss: 0.0644, Training accuracy: 0.9773\n",
      "Validation loss: 0.3046, Validation accuracy: 0.9046\n",
      "\n",
      "Epoch 102:\n",
      "Training loss: 0.0642, Training accuracy: 0.9778\n",
      "Validation loss: 0.3093, Validation accuracy: 0.9017\n",
      "\n",
      "Epoch 103:\n",
      "Training loss: 0.0624, Training accuracy: 0.9788\n",
      "Validation loss: 0.3120, Validation accuracy: 0.9052\n",
      "\n",
      "Epoch 104:\n",
      "Training loss: 0.0613, Training accuracy: 0.9793\n",
      "Validation loss: 0.3057, Validation accuracy: 0.9033\n",
      "\n",
      "Epoch 105:\n",
      "Training loss: 0.0616, Training accuracy: 0.9792\n",
      "Validation loss: 0.3093, Validation accuracy: 0.9029\n",
      "\n",
      "Epoch 106:\n",
      "Training loss: 0.0604, Training accuracy: 0.9805\n",
      "Validation loss: 0.3103, Validation accuracy: 0.9042\n",
      "\n",
      "Epoch 107:\n",
      "Training loss: 0.0620, Training accuracy: 0.9792\n",
      "Validation loss: 0.3063, Validation accuracy: 0.9047\n",
      "\n",
      "Epoch 108:\n",
      "Training loss: 0.0603, Training accuracy: 0.9791\n",
      "Validation loss: 0.3121, Validation accuracy: 0.9029\n",
      "\n",
      "Epoch 109:\n",
      "Training loss: 0.0591, Training accuracy: 0.9806\n",
      "Validation loss: 0.3086, Validation accuracy: 0.9028\n",
      "\n",
      "Epoch 110:\n",
      "Training loss: 0.0567, Training accuracy: 0.9828\n",
      "Validation loss: 0.3108, Validation accuracy: 0.9037\n",
      "\n",
      "Epoch 111:\n",
      "Training loss: 0.0560, Training accuracy: 0.9830\n",
      "Validation loss: 0.3111, Validation accuracy: 0.9057\n",
      "Saving ...\n",
      "\n",
      "Epoch 112:\n",
      "Training loss: 0.0568, Training accuracy: 0.9817\n",
      "Validation loss: 0.3111, Validation accuracy: 0.9045\n",
      "\n",
      "Epoch 113:\n",
      "Training loss: 0.0566, Training accuracy: 0.9823\n",
      "Validation loss: 0.3121, Validation accuracy: 0.9028\n",
      "\n",
      "Epoch 114:\n",
      "Training loss: 0.0556, Training accuracy: 0.9831\n",
      "Validation loss: 0.3172, Validation accuracy: 0.9014\n",
      "\n",
      "Epoch 115:\n",
      "Training loss: 0.0551, Training accuracy: 0.9839\n",
      "Validation loss: 0.3160, Validation accuracy: 0.9030\n",
      "\n",
      "Epoch 116:\n",
      "Training loss: 0.0543, Training accuracy: 0.9840\n",
      "Validation loss: 0.3181, Validation accuracy: 0.9029\n",
      "\n",
      "Epoch 117:\n",
      "Training loss: 0.0545, Training accuracy: 0.9839\n",
      "Validation loss: 0.3142, Validation accuracy: 0.9036\n",
      "\n",
      "Epoch 118:\n",
      "Training loss: 0.0527, Training accuracy: 0.9849\n",
      "Validation loss: 0.3180, Validation accuracy: 0.9047\n",
      "\n",
      "Epoch 119:\n",
      "Training loss: 0.0516, Training accuracy: 0.9851\n",
      "Validation loss: 0.3126, Validation accuracy: 0.9046\n",
      "\n",
      "Epoch 120:\n",
      "Training loss: 0.0514, Training accuracy: 0.9859\n",
      "Validation loss: 0.3174, Validation accuracy: 0.9045\n",
      "\n",
      "Epoch 121:\n",
      "Training loss: 0.0521, Training accuracy: 0.9850\n",
      "Validation loss: 0.3199, Validation accuracy: 0.9003\n",
      "\n",
      "Epoch 122:\n",
      "Training loss: 0.0517, Training accuracy: 0.9854\n",
      "Validation loss: 0.3184, Validation accuracy: 0.9022\n",
      "\n",
      "Epoch 123:\n",
      "Training loss: 0.0503, Training accuracy: 0.9865\n",
      "Validation loss: 0.3178, Validation accuracy: 0.9040\n",
      "\n",
      "Epoch 124:\n",
      "Training loss: 0.0500, Training accuracy: 0.9863\n",
      "Validation loss: 0.3275, Validation accuracy: 0.9010\n",
      "\n",
      "Epoch 125:\n",
      "Training loss: 0.0501, Training accuracy: 0.9860\n",
      "Validation loss: 0.3283, Validation accuracy: 0.9008\n",
      "\n",
      "Epoch 126:\n",
      "Training loss: 0.0501, Training accuracy: 0.9860\n",
      "Validation loss: 0.3269, Validation accuracy: 0.9014\n",
      "\n",
      "Epoch 127:\n",
      "Training loss: 0.0498, Training accuracy: 0.9865\n",
      "Validation loss: 0.3301, Validation accuracy: 0.9012\n",
      "\n",
      "Epoch 128:\n",
      "Training loss: 0.0491, Training accuracy: 0.9871\n",
      "Validation loss: 0.3253, Validation accuracy: 0.9040\n",
      "\n",
      "Epoch 129:\n",
      "Training loss: 0.0475, Training accuracy: 0.9877\n",
      "Validation loss: 0.3278, Validation accuracy: 0.9020\n",
      "\n",
      "Epoch 130:\n",
      "Training loss: 0.0478, Training accuracy: 0.9873\n",
      "Validation loss: 0.3287, Validation accuracy: 0.9014\n",
      "\n",
      "Epoch 131:\n",
      "Training loss: 0.0479, Training accuracy: 0.9874\n",
      "Validation loss: 0.3258, Validation accuracy: 0.9029\n",
      "\n",
      "Epoch 132:\n",
      "Training loss: 0.0475, Training accuracy: 0.9874\n",
      "Validation loss: 0.3209, Validation accuracy: 0.9025\n",
      "\n",
      "Epoch 133:\n",
      "Training loss: 0.0469, Training accuracy: 0.9874\n",
      "Validation loss: 0.3231, Validation accuracy: 0.9040\n",
      "\n",
      "Epoch 134:\n",
      "Training loss: 0.0473, Training accuracy: 0.9882\n",
      "Validation loss: 0.3319, Validation accuracy: 0.9012\n",
      "\n",
      "Epoch 135:\n",
      "Training loss: 0.0465, Training accuracy: 0.9877\n",
      "Validation loss: 0.3249, Validation accuracy: 0.9013\n",
      "\n",
      "Epoch 136:\n",
      "Training loss: 0.0466, Training accuracy: 0.9878\n",
      "Validation loss: 0.3278, Validation accuracy: 0.9021\n",
      "\n",
      "Epoch 137:\n",
      "Training loss: 0.0458, Training accuracy: 0.9883\n",
      "Validation loss: 0.3333, Validation accuracy: 0.9011\n",
      "\n",
      "Epoch 138:\n",
      "Training loss: 0.0460, Training accuracy: 0.9884\n",
      "Validation loss: 0.3261, Validation accuracy: 0.9039\n",
      "\n",
      "Epoch 139:\n",
      "Training loss: 0.0449, Training accuracy: 0.9892\n",
      "Validation loss: 0.3376, Validation accuracy: 0.9032\n",
      "\n",
      "Epoch 140:\n",
      "Training loss: 0.0449, Training accuracy: 0.9889\n",
      "Validation loss: 0.3347, Validation accuracy: 0.9014\n",
      "\n",
      "Epoch 141:\n",
      "Training loss: 0.0458, Training accuracy: 0.9879\n",
      "Validation loss: 0.3315, Validation accuracy: 0.9002\n",
      "\n",
      "Epoch 142:\n",
      "Training loss: 0.0453, Training accuracy: 0.9887\n",
      "Validation loss: 0.3317, Validation accuracy: 0.9020\n",
      "\n",
      "Epoch 143:\n",
      "Training loss: 0.0452, Training accuracy: 0.9882\n",
      "Validation loss: 0.3285, Validation accuracy: 0.9030\n",
      "\n",
      "Epoch 144:\n",
      "Training loss: 0.0434, Training accuracy: 0.9901\n",
      "Validation loss: 0.3386, Validation accuracy: 0.9004\n",
      "\n",
      "Epoch 145:\n",
      "Training loss: 0.0432, Training accuracy: 0.9900\n",
      "Validation loss: 0.3367, Validation accuracy: 0.9006\n",
      "\n",
      "Epoch 146:\n",
      "Training loss: 0.0437, Training accuracy: 0.9896\n",
      "Validation loss: 0.3364, Validation accuracy: 0.9017\n",
      "\n",
      "Epoch 147:\n",
      "Training loss: 0.0440, Training accuracy: 0.9898\n",
      "Validation loss: 0.3351, Validation accuracy: 0.9020\n",
      "\n",
      "Epoch 148:\n",
      "Training loss: 0.0431, Training accuracy: 0.9898\n",
      "Validation loss: 0.3398, Validation accuracy: 0.8986\n",
      "\n",
      "Epoch 149:\n",
      "Training loss: 0.0422, Training accuracy: 0.9905\n",
      "Validation loss: 0.3380, Validation accuracy: 0.9008\n",
      "\n",
      "Epoch 150:\n",
      "Training loss: 0.0430, Training accuracy: 0.9899\n",
      "Validation loss: 0.3340, Validation accuracy: 0.9008\n",
      "\n",
      "Epoch 151:\n",
      "Training loss: 0.0422, Training accuracy: 0.9898\n",
      "Validation loss: 0.3344, Validation accuracy: 0.9022\n",
      "\n",
      "Epoch 152:\n",
      "Training loss: 0.0414, Training accuracy: 0.9908\n",
      "Validation loss: 0.3430, Validation accuracy: 0.9011\n",
      "\n",
      "Epoch 153:\n",
      "Training loss: 0.0425, Training accuracy: 0.9900\n",
      "Validation loss: 0.3423, Validation accuracy: 0.9015\n",
      "\n",
      "Epoch 154:\n",
      "Training loss: 0.0429, Training accuracy: 0.9897\n",
      "Validation loss: 0.3441, Validation accuracy: 0.9013\n",
      "\n",
      "Epoch 155:\n",
      "Training loss: 0.0413, Training accuracy: 0.9911\n",
      "Validation loss: 0.3371, Validation accuracy: 0.9013\n",
      "\n",
      "Epoch 156:\n",
      "Training loss: 0.0416, Training accuracy: 0.9903\n",
      "Validation loss: 0.3427, Validation accuracy: 0.9006\n",
      "\n",
      "Epoch 157:\n",
      "Training loss: 0.0412, Training accuracy: 0.9903\n",
      "Validation loss: 0.3367, Validation accuracy: 0.9005\n",
      "\n",
      "Epoch 158:\n",
      "Training loss: 0.0416, Training accuracy: 0.9904\n",
      "Validation loss: 0.3391, Validation accuracy: 0.9009\n",
      "\n",
      "Epoch 159:\n",
      "Training loss: 0.0419, Training accuracy: 0.9899\n",
      "Validation loss: 0.3395, Validation accuracy: 0.9010\n",
      "\n",
      "Current learning rate has decayed to 0.000100\n",
      "Epoch 160:\n",
      "Training loss: 0.0367, Training accuracy: 0.9929\n",
      "Validation loss: 0.3271, Validation accuracy: 0.9035\n",
      "\n",
      "Epoch 161:\n",
      "Training loss: 0.0356, Training accuracy: 0.9938\n",
      "Validation loss: 0.3297, Validation accuracy: 0.9044\n",
      "\n",
      "Epoch 162:\n",
      "Training loss: 0.0344, Training accuracy: 0.9943\n",
      "Validation loss: 0.3293, Validation accuracy: 0.9026\n",
      "\n",
      "Epoch 163:\n",
      "Training loss: 0.0336, Training accuracy: 0.9948\n",
      "Validation loss: 0.3289, Validation accuracy: 0.9033\n",
      "\n",
      "Epoch 164:\n",
      "Training loss: 0.0342, Training accuracy: 0.9943\n",
      "Validation loss: 0.3297, Validation accuracy: 0.9035\n",
      "\n",
      "Epoch 165:\n",
      "Training loss: 0.0333, Training accuracy: 0.9949\n",
      "Validation loss: 0.3262, Validation accuracy: 0.9054\n",
      "\n",
      "Epoch 166:\n",
      "Training loss: 0.0331, Training accuracy: 0.9949\n",
      "Validation loss: 0.3259, Validation accuracy: 0.9054\n",
      "\n",
      "Epoch 167:\n",
      "Training loss: 0.0328, Training accuracy: 0.9950\n",
      "Validation loss: 0.3262, Validation accuracy: 0.9038\n",
      "\n",
      "Epoch 168:\n",
      "Training loss: 0.0329, Training accuracy: 0.9951\n",
      "Validation loss: 0.3285, Validation accuracy: 0.9044\n",
      "\n",
      "Epoch 169:\n",
      "Training loss: 0.0323, Training accuracy: 0.9957\n",
      "Validation loss: 0.3294, Validation accuracy: 0.9043\n",
      "\n",
      "Epoch 170:\n",
      "Training loss: 0.0326, Training accuracy: 0.9950\n",
      "Validation loss: 0.3287, Validation accuracy: 0.9048\n",
      "\n",
      "Epoch 171:\n",
      "Training loss: 0.0322, Training accuracy: 0.9954\n",
      "Validation loss: 0.3283, Validation accuracy: 0.9041\n",
      "\n",
      "Epoch 172:\n",
      "Training loss: 0.0320, Training accuracy: 0.9953\n",
      "Validation loss: 0.3282, Validation accuracy: 0.9051\n",
      "\n",
      "Epoch 173:\n",
      "Training loss: 0.0321, Training accuracy: 0.9956\n",
      "Validation loss: 0.3278, Validation accuracy: 0.9033\n",
      "\n",
      "Epoch 174:\n",
      "Training loss: 0.0319, Training accuracy: 0.9956\n",
      "Validation loss: 0.3294, Validation accuracy: 0.9054\n",
      "\n",
      "Epoch 175:\n",
      "Training loss: 0.0314, Training accuracy: 0.9957\n",
      "Validation loss: 0.3272, Validation accuracy: 0.9055\n",
      "\n",
      "Epoch 176:\n",
      "Training loss: 0.0313, Training accuracy: 0.9961\n",
      "Validation loss: 0.3280, Validation accuracy: 0.9059\n",
      "Saving ...\n",
      "\n",
      "Epoch 177:\n",
      "Training loss: 0.0313, Training accuracy: 0.9959\n",
      "Validation loss: 0.3304, Validation accuracy: 0.9047\n",
      "\n",
      "Epoch 178:\n",
      "Training loss: 0.0314, Training accuracy: 0.9959\n",
      "Validation loss: 0.3307, Validation accuracy: 0.9051\n",
      "\n",
      "Epoch 179:\n",
      "Training loss: 0.0313, Training accuracy: 0.9961\n",
      "Validation loss: 0.3249, Validation accuracy: 0.9062\n",
      "Saving ...\n",
      "\n",
      "Epoch 180:\n",
      "Training loss: 0.0312, Training accuracy: 0.9958\n",
      "Validation loss: 0.3264, Validation accuracy: 0.9063\n",
      "Saving ...\n",
      "\n",
      "Epoch 181:\n",
      "Training loss: 0.0307, Training accuracy: 0.9965\n",
      "Validation loss: 0.3265, Validation accuracy: 0.9053\n",
      "\n",
      "Epoch 182:\n",
      "Training loss: 0.0311, Training accuracy: 0.9958\n",
      "Validation loss: 0.3327, Validation accuracy: 0.9041\n",
      "\n",
      "Epoch 183:\n",
      "Training loss: 0.0305, Training accuracy: 0.9963\n",
      "Validation loss: 0.3295, Validation accuracy: 0.9061\n",
      "\n",
      "Epoch 184:\n",
      "Training loss: 0.0311, Training accuracy: 0.9959\n",
      "Validation loss: 0.3278, Validation accuracy: 0.9067\n",
      "Saving ...\n",
      "\n",
      "Epoch 185:\n",
      "Training loss: 0.0303, Training accuracy: 0.9965\n",
      "Validation loss: 0.3282, Validation accuracy: 0.9066\n",
      "\n",
      "Epoch 186:\n",
      "Training loss: 0.0303, Training accuracy: 0.9967\n",
      "Validation loss: 0.3288, Validation accuracy: 0.9056\n",
      "\n",
      "Epoch 187:\n",
      "Training loss: 0.0308, Training accuracy: 0.9961\n",
      "Validation loss: 0.3297, Validation accuracy: 0.9061\n",
      "\n",
      "Epoch 188:\n",
      "Training loss: 0.0309, Training accuracy: 0.9961\n",
      "Validation loss: 0.3289, Validation accuracy: 0.9041\n",
      "\n",
      "Epoch 189:\n",
      "Training loss: 0.0306, Training accuracy: 0.9961\n",
      "Validation loss: 0.3319, Validation accuracy: 0.9042\n",
      "\n",
      "Epoch 190:\n",
      "Training loss: 0.0305, Training accuracy: 0.9966\n",
      "Validation loss: 0.3299, Validation accuracy: 0.9057\n",
      "\n",
      "Epoch 191:\n",
      "Training loss: 0.0303, Training accuracy: 0.9966\n",
      "Validation loss: 0.3304, Validation accuracy: 0.9038\n",
      "\n",
      "Epoch 192:\n",
      "Training loss: 0.0301, Training accuracy: 0.9968\n",
      "Validation loss: 0.3317, Validation accuracy: 0.9046\n",
      "\n",
      "Epoch 193:\n",
      "Training loss: 0.0297, Training accuracy: 0.9964\n",
      "Validation loss: 0.3312, Validation accuracy: 0.9047\n",
      "\n",
      "Epoch 194:\n",
      "Training loss: 0.0301, Training accuracy: 0.9964\n",
      "Validation loss: 0.3310, Validation accuracy: 0.9051\n",
      "\n",
      "Epoch 195:\n",
      "Training loss: 0.0304, Training accuracy: 0.9963\n",
      "Validation loss: 0.3305, Validation accuracy: 0.9054\n",
      "\n",
      "Epoch 196:\n",
      "Training loss: 0.0303, Training accuracy: 0.9963\n",
      "Validation loss: 0.3286, Validation accuracy: 0.9051\n",
      "\n",
      "Epoch 197:\n",
      "Training loss: 0.0299, Training accuracy: 0.9967\n",
      "Validation loss: 0.3274, Validation accuracy: 0.9050\n",
      "\n",
      "Epoch 198:\n",
      "Training loss: 0.0300, Training accuracy: 0.9962\n",
      "Validation loss: 0.3309, Validation accuracy: 0.9048\n",
      "\n",
      "Epoch 199:\n",
      "Training loss: 0.0298, Training accuracy: 0.9966\n",
      "Validation loss: 0.3292, Validation accuracy: 0.9060\n",
      "\n",
      "==================================================\n",
      "==> Optimization finished! Best validation accuracy: 0.9067\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9067"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train(T=3,lamb=0.6,alpha=0.4,train_loader=train_loader,val_loader=val_loader,INITIAL_LR=0.1,DECAY_EPOCHS=[40,80,160],DECAY=0.1,EPOCHS=200,REG = 4e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Training starts!\n",
      "==================================================\n",
      "Epoch 0:\n",
      "Training loss: 1.6560, Training accuracy: 0.3239\n",
      "Validation loss: 3.1435, Validation accuracy: 0.4412\n",
      "Saving ...\n",
      "\n",
      "Epoch 1:\n",
      "Training loss: 1.1971, Training accuracy: 0.4550\n",
      "Validation loss: 15.7055, Validation accuracy: 0.4792\n",
      "Saving ...\n",
      "\n",
      "Epoch 2:\n",
      "Training loss: 1.0471, Training accuracy: 0.5249\n",
      "Validation loss: 1.3090, Validation accuracy: 0.5506\n",
      "Saving ...\n",
      "\n",
      "Epoch 3:\n",
      "Training loss: 0.9522, Training accuracy: 0.5690\n",
      "Validation loss: 1.2610, Validation accuracy: 0.5732\n",
      "Saving ...\n",
      "\n",
      "Epoch 4:\n",
      "Training loss: 0.8725, Training accuracy: 0.6038\n",
      "Validation loss: 1.0510, Validation accuracy: 0.6388\n",
      "Saving ...\n",
      "\n",
      "Epoch 5:\n",
      "Training loss: 0.8173, Training accuracy: 0.6320\n",
      "Validation loss: 1.2445, Validation accuracy: 0.5831\n",
      "\n",
      "Epoch 6:\n",
      "Training loss: 0.7792, Training accuracy: 0.6509\n",
      "Validation loss: 1.0436, Validation accuracy: 0.6381\n",
      "\n",
      "Epoch 7:\n",
      "Training loss: 0.7497, Training accuracy: 0.6648\n",
      "Validation loss: 1.1303, Validation accuracy: 0.6205\n",
      "\n",
      "Epoch 8:\n",
      "Training loss: 0.7318, Training accuracy: 0.6744\n",
      "Validation loss: 0.9908, Validation accuracy: 0.6647\n",
      "Saving ...\n",
      "\n",
      "Epoch 9:\n",
      "Training loss: 0.7170, Training accuracy: 0.6809\n",
      "Validation loss: 1.0489, Validation accuracy: 0.6526\n",
      "\n",
      "Epoch 10:\n",
      "Training loss: 0.4814, Training accuracy: 0.7105\n",
      "Validation loss: 1.0135, Validation accuracy: 0.6545\n",
      "\n",
      "Epoch 11:\n",
      "Training loss: 0.4924, Training accuracy: 0.7023\n",
      "Validation loss: 1.0243, Validation accuracy: 0.6661\n",
      "Saving ...\n",
      "\n",
      "Epoch 12:\n",
      "Training loss: 0.4969, Training accuracy: 0.7022\n",
      "Validation loss: 0.9714, Validation accuracy: 0.6681\n",
      "Saving ...\n",
      "\n",
      "Epoch 13:\n",
      "Training loss: 0.4891, Training accuracy: 0.7047\n",
      "Validation loss: 1.1383, Validation accuracy: 0.6325\n",
      "\n",
      "Epoch 14:\n",
      "Training loss: 0.4897, Training accuracy: 0.7054\n",
      "Validation loss: 0.9200, Validation accuracy: 0.6800\n",
      "Saving ...\n",
      "\n",
      "Epoch 15:\n",
      "Training loss: 0.4880, Training accuracy: 0.7081\n",
      "Validation loss: 1.0710, Validation accuracy: 0.6491\n",
      "\n",
      "Epoch 16:\n",
      "Training loss: 0.4828, Training accuracy: 0.7107\n",
      "Validation loss: 1.1547, Validation accuracy: 0.6142\n",
      "\n",
      "Epoch 17:\n",
      "Training loss: 0.4838, Training accuracy: 0.7099\n",
      "Validation loss: 0.8663, Validation accuracy: 0.7066\n",
      "Saving ...\n",
      "\n",
      "Epoch 18:\n",
      "Training loss: 0.4800, Training accuracy: 0.7120\n",
      "Validation loss: 0.9688, Validation accuracy: 0.6741\n",
      "\n",
      "Epoch 19:\n",
      "Training loss: 0.4781, Training accuracy: 0.7154\n",
      "Validation loss: 0.9864, Validation accuracy: 0.6680\n",
      "\n",
      "Epoch 20:\n",
      "Training loss: 0.4743, Training accuracy: 0.7170\n",
      "Validation loss: 0.9458, Validation accuracy: 0.6722\n",
      "\n",
      "Epoch 21:\n",
      "Training loss: 0.4726, Training accuracy: 0.7172\n",
      "Validation loss: 0.9203, Validation accuracy: 0.6869\n",
      "\n",
      "Epoch 22:\n",
      "Training loss: 0.4707, Training accuracy: 0.7185\n",
      "Validation loss: 0.9823, Validation accuracy: 0.6690\n",
      "\n",
      "Epoch 23:\n",
      "Training loss: 0.4703, Training accuracy: 0.7187\n",
      "Validation loss: 1.0343, Validation accuracy: 0.6456\n",
      "\n",
      "Epoch 24:\n",
      "Training loss: 0.4704, Training accuracy: 0.7193\n",
      "Validation loss: 0.9074, Validation accuracy: 0.6939\n",
      "\n",
      "Epoch 25:\n",
      "Training loss: 0.4694, Training accuracy: 0.7204\n",
      "Validation loss: 0.9258, Validation accuracy: 0.6842\n",
      "\n",
      "Epoch 26:\n",
      "Training loss: 0.4682, Training accuracy: 0.7211\n",
      "Validation loss: 0.9040, Validation accuracy: 0.6901\n",
      "\n",
      "Epoch 27:\n",
      "Training loss: 0.4669, Training accuracy: 0.7212\n",
      "Validation loss: 1.0678, Validation accuracy: 0.6364\n",
      "\n",
      "Epoch 28:\n",
      "Training loss: 0.4683, Training accuracy: 0.7213\n",
      "Validation loss: 1.0168, Validation accuracy: 0.6585\n",
      "\n",
      "Epoch 29:\n",
      "Training loss: 0.4666, Training accuracy: 0.7209\n",
      "Validation loss: 0.9240, Validation accuracy: 0.6856\n",
      "\n",
      "Epoch 30:\n",
      "Training loss: 0.4643, Training accuracy: 0.7229\n",
      "Validation loss: 1.0339, Validation accuracy: 0.6453\n",
      "\n",
      "Epoch 31:\n",
      "Training loss: 0.4660, Training accuracy: 0.7238\n",
      "Validation loss: 1.1702, Validation accuracy: 0.6142\n",
      "\n",
      "Epoch 32:\n",
      "Training loss: 0.4633, Training accuracy: 0.7236\n",
      "Validation loss: 0.9942, Validation accuracy: 0.6593\n",
      "\n",
      "Epoch 33:\n",
      "Training loss: 0.4628, Training accuracy: 0.7251\n",
      "Validation loss: 0.9793, Validation accuracy: 0.6622\n",
      "\n",
      "Epoch 34:\n",
      "Training loss: 0.4617, Training accuracy: 0.7230\n",
      "Validation loss: 0.9292, Validation accuracy: 0.6828\n",
      "\n",
      "Epoch 35:\n",
      "Training loss: 0.4618, Training accuracy: 0.7261\n",
      "Validation loss: 0.9704, Validation accuracy: 0.6647\n",
      "\n",
      "Epoch 36:\n",
      "Training loss: 0.4641, Training accuracy: 0.7237\n",
      "Validation loss: 1.0462, Validation accuracy: 0.6575\n",
      "\n",
      "Epoch 37:\n",
      "Training loss: 0.4644, Training accuracy: 0.7240\n",
      "Validation loss: 1.1059, Validation accuracy: 0.6319\n",
      "\n",
      "Epoch 38:\n",
      "Training loss: 0.4582, Training accuracy: 0.7252\n",
      "Validation loss: 0.9809, Validation accuracy: 0.6643\n",
      "\n",
      "Epoch 39:\n",
      "Training loss: 0.4561, Training accuracy: 0.7261\n",
      "Validation loss: 0.8017, Validation accuracy: 0.7277\n",
      "Saving ...\n",
      "\n",
      "Current learning rate has decayed to 0.010000\n",
      "Epoch 40:\n",
      "Training loss: 0.3293, Training accuracy: 0.8076\n",
      "Validation loss: 0.5057, Validation accuracy: 0.8288\n",
      "Saving ...\n",
      "\n",
      "Epoch 41:\n",
      "Training loss: 0.2933, Training accuracy: 0.8308\n",
      "Validation loss: 0.4865, Validation accuracy: 0.8350\n",
      "Saving ...\n",
      "\n",
      "Epoch 42:\n",
      "Training loss: 0.2791, Training accuracy: 0.8382\n",
      "Validation loss: 0.4629, Validation accuracy: 0.8461\n",
      "Saving ...\n",
      "\n",
      "Epoch 43:\n",
      "Training loss: 0.2660, Training accuracy: 0.8461\n",
      "Validation loss: 0.4778, Validation accuracy: 0.8347\n",
      "\n",
      "Epoch 44:\n",
      "Training loss: 0.2592, Training accuracy: 0.8511\n",
      "Validation loss: 0.4461, Validation accuracy: 0.8498\n",
      "Saving ...\n",
      "\n",
      "Epoch 45:\n",
      "Training loss: 0.2543, Training accuracy: 0.8532\n",
      "Validation loss: 0.4453, Validation accuracy: 0.8491\n",
      "\n",
      "Epoch 46:\n",
      "Training loss: 0.2510, Training accuracy: 0.8559\n",
      "Validation loss: 0.4738, Validation accuracy: 0.8413\n",
      "\n",
      "Epoch 47:\n",
      "Training loss: 0.2463, Training accuracy: 0.8610\n",
      "Validation loss: 0.4568, Validation accuracy: 0.8452\n",
      "\n",
      "Epoch 48:\n",
      "Training loss: 0.2472, Training accuracy: 0.8592\n",
      "Validation loss: 0.4265, Validation accuracy: 0.8556\n",
      "Saving ...\n",
      "\n",
      "Epoch 49:\n",
      "Training loss: 0.2418, Training accuracy: 0.8629\n",
      "Validation loss: 0.4589, Validation accuracy: 0.8461\n",
      "\n",
      "Epoch 50:\n",
      "Training loss: 0.2422, Training accuracy: 0.8600\n",
      "Validation loss: 0.4365, Validation accuracy: 0.8549\n",
      "\n",
      "Epoch 51:\n",
      "Training loss: 0.2410, Training accuracy: 0.8624\n",
      "Validation loss: 0.4637, Validation accuracy: 0.8461\n",
      "\n",
      "Epoch 52:\n",
      "Training loss: 0.2368, Training accuracy: 0.8670\n",
      "Validation loss: 0.4705, Validation accuracy: 0.8382\n",
      "\n",
      "Epoch 53:\n",
      "Training loss: 0.2383, Training accuracy: 0.8656\n",
      "Validation loss: 0.4737, Validation accuracy: 0.8420\n",
      "\n",
      "Epoch 54:\n",
      "Training loss: 0.2363, Training accuracy: 0.8655\n",
      "Validation loss: 0.4536, Validation accuracy: 0.8460\n",
      "\n",
      "Epoch 55:\n",
      "Training loss: 0.2364, Training accuracy: 0.8673\n",
      "Validation loss: 0.4604, Validation accuracy: 0.8450\n",
      "\n",
      "Epoch 56:\n",
      "Training loss: 0.2347, Training accuracy: 0.8680\n",
      "Validation loss: 0.4549, Validation accuracy: 0.8425\n",
      "\n",
      "Epoch 57:\n",
      "Training loss: 0.2326, Training accuracy: 0.8696\n",
      "Validation loss: 0.4580, Validation accuracy: 0.8450\n",
      "\n",
      "Epoch 58:\n",
      "Training loss: 0.2288, Training accuracy: 0.8720\n",
      "Validation loss: 0.4765, Validation accuracy: 0.8383\n",
      "\n",
      "Epoch 59:\n",
      "Training loss: 0.2306, Training accuracy: 0.8705\n",
      "Validation loss: 0.4685, Validation accuracy: 0.8429\n",
      "\n",
      "Epoch 60:\n",
      "Training loss: 0.2304, Training accuracy: 0.8694\n",
      "Validation loss: 0.4647, Validation accuracy: 0.8427\n",
      "\n",
      "Epoch 61:\n",
      "Training loss: 0.2298, Training accuracy: 0.8699\n",
      "Validation loss: 0.4986, Validation accuracy: 0.8308\n",
      "\n",
      "Epoch 62:\n",
      "Training loss: 0.2251, Training accuracy: 0.8757\n",
      "Validation loss: 0.4739, Validation accuracy: 0.8395\n",
      "\n",
      "Epoch 63:\n",
      "Training loss: 0.2247, Training accuracy: 0.8747\n",
      "Validation loss: 0.4727, Validation accuracy: 0.8395\n",
      "\n",
      "Epoch 64:\n",
      "Training loss: 0.2233, Training accuracy: 0.8744\n",
      "Validation loss: 0.4447, Validation accuracy: 0.8492\n",
      "\n",
      "Epoch 65:\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_454/364160503.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlamb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.6\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mval_loader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mINITIAL_LR\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mDECAY_EPOCHS\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m80\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m160\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mDECAY\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mREG\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m6e-4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_454/795005321.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(T, lamb, alpha, train_loader, val_loader, INITIAL_LR, DECAY_EPOCHS, DECAY, EPOCHS, REG)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# compute the output and loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0mfeature\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlamb\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmse_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmse_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmse_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_454/376220637.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, is_eval)\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresnet50\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresnet50\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaxpool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresnet50\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m         \u001b[0mfeature1\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneck1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mfeature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownsample\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/torch/nn/modules/batchnorm.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    166\u001b[0m         \u001b[0mused\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mnormalization\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0;32min\u001b[0m \u001b[0meval\u001b[0m \u001b[0mmode\u001b[0m \u001b[0mwhen\u001b[0m \u001b[0mbuffers\u001b[0m \u001b[0mare\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m         \"\"\"\n\u001b[0;32m--> 168\u001b[0;31m         return F.batch_norm(\n\u001b[0m\u001b[1;32m    169\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m             \u001b[0;31m# If buffers are not to be tracked, ensure that they won't be updated\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   2280\u001b[0m         \u001b[0m_verify_batch_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2281\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2282\u001b[0;31m     return torch.batch_norm(\n\u001b[0m\u001b[1;32m   2283\u001b[0m         \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcudnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2284\u001b[0m     )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(T=3,lamb=0.6,alpha=0.4,train_loader=train_loader,val_loader=val_loader,INITIAL_LR=0.1,DECAY_EPOCHS=[40,80,160],DECAY=0.1,EPOCHS=200,REG = 6e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Training starts!\n",
      "==================================================\n",
      "Epoch 0:\n",
      "Training loss: 1.7486, Training accuracy: 0.3017\n",
      "Validation loss: 4.0329, Validation accuracy: 0.3838\n",
      "Saving ...\n",
      "\n",
      "Epoch 1:\n",
      "Training loss: 1.2260, Training accuracy: 0.4524\n",
      "Validation loss: 1.4453, Validation accuracy: 0.5103\n",
      "Saving ...\n",
      "\n",
      "Epoch 2:\n",
      "Training loss: 1.0623, Training accuracy: 0.5177\n",
      "Validation loss: 1.2197, Validation accuracy: 0.5626\n",
      "Saving ...\n",
      "\n",
      "Epoch 3:\n",
      "Training loss: 0.9551, Training accuracy: 0.5694\n",
      "Validation loss: 1.5025, Validation accuracy: 0.5047\n",
      "\n",
      "Epoch 4:\n",
      "Training loss: 0.8880, Training accuracy: 0.5966\n",
      "Validation loss: 1.0447, Validation accuracy: 0.6363\n",
      "Saving ...\n",
      "\n",
      "Epoch 5:\n",
      "Training loss: 0.7960, Training accuracy: 0.6396\n",
      "Validation loss: 1.1691, Validation accuracy: 0.5998\n",
      "\n",
      "Epoch 6:\n",
      "Training loss: 0.7477, Training accuracy: 0.6674\n",
      "Validation loss: 1.1461, Validation accuracy: 0.6127\n",
      "\n",
      "Epoch 7:\n",
      "Training loss: 0.7150, Training accuracy: 0.6811\n",
      "Validation loss: 1.0447, Validation accuracy: 0.6468\n",
      "Saving ...\n",
      "\n",
      "Epoch 8:\n",
      "Training loss: 0.6902, Training accuracy: 0.6924\n",
      "Validation loss: 1.0026, Validation accuracy: 0.6658\n",
      "Saving ...\n",
      "\n",
      "Epoch 9:\n",
      "Training loss: 0.6724, Training accuracy: 0.7022\n",
      "Validation loss: 0.8967, Validation accuracy: 0.6913\n",
      "Saving ...\n",
      "\n",
      "Epoch 10:\n",
      "Training loss: 0.4448, Training accuracy: 0.7272\n",
      "Validation loss: 0.8774, Validation accuracy: 0.7007\n",
      "Saving ...\n",
      "\n",
      "Epoch 11:\n",
      "Training loss: 0.4465, Training accuracy: 0.7268\n",
      "Validation loss: 0.9484, Validation accuracy: 0.6759\n",
      "\n",
      "Epoch 12:\n",
      "Training loss: 0.4472, Training accuracy: 0.7281\n",
      "Validation loss: 1.1088, Validation accuracy: 0.6220\n",
      "\n",
      "Epoch 13:\n",
      "Training loss: 0.4464, Training accuracy: 0.7282\n",
      "Validation loss: 0.8758, Validation accuracy: 0.7050\n",
      "Saving ...\n",
      "\n",
      "Epoch 14:\n",
      "Training loss: 0.4426, Training accuracy: 0.7311\n",
      "Validation loss: 1.1646, Validation accuracy: 0.6201\n",
      "\n",
      "Epoch 15:\n",
      "Training loss: 0.4385, Training accuracy: 0.7316\n",
      "Validation loss: 0.8678, Validation accuracy: 0.7077\n",
      "Saving ...\n",
      "\n",
      "Epoch 16:\n",
      "Training loss: 0.4321, Training accuracy: 0.7369\n",
      "Validation loss: 0.8392, Validation accuracy: 0.7167\n",
      "Saving ...\n",
      "\n",
      "Epoch 17:\n",
      "Training loss: 0.4291, Training accuracy: 0.7391\n",
      "Validation loss: 0.8555, Validation accuracy: 0.7032\n",
      "\n",
      "Epoch 18:\n",
      "Training loss: 0.4248, Training accuracy: 0.7415\n",
      "Validation loss: 0.8233, Validation accuracy: 0.7235\n",
      "Saving ...\n",
      "\n",
      "Epoch 19:\n",
      "Training loss: 0.4226, Training accuracy: 0.7436\n",
      "Validation loss: 0.9048, Validation accuracy: 0.6942\n",
      "\n",
      "Epoch 20:\n",
      "Training loss: 0.4226, Training accuracy: 0.7430\n",
      "Validation loss: 0.9677, Validation accuracy: 0.6730\n",
      "\n",
      "Epoch 21:\n",
      "Training loss: 0.4183, Training accuracy: 0.7462\n",
      "Validation loss: 0.8057, Validation accuracy: 0.7263\n",
      "Saving ...\n",
      "\n",
      "Epoch 22:\n",
      "Training loss: 0.4207, Training accuracy: 0.7452\n",
      "Validation loss: 0.8461, Validation accuracy: 0.7085\n",
      "\n",
      "Epoch 23:\n",
      "Training loss: 0.4159, Training accuracy: 0.7494\n",
      "Validation loss: 0.9321, Validation accuracy: 0.6823\n",
      "\n",
      "Epoch 24:\n",
      "Training loss: 0.4149, Training accuracy: 0.7481\n",
      "Validation loss: 0.8161, Validation accuracy: 0.7230\n",
      "\n",
      "Epoch 25:\n",
      "Training loss: 0.4113, Training accuracy: 0.7517\n",
      "Validation loss: 0.7963, Validation accuracy: 0.7270\n",
      "Saving ...\n",
      "\n",
      "Epoch 26:\n",
      "Training loss: 0.4124, Training accuracy: 0.7483\n",
      "Validation loss: 0.7586, Validation accuracy: 0.7344\n",
      "Saving ...\n",
      "\n",
      "Epoch 27:\n",
      "Training loss: 0.4094, Training accuracy: 0.7518\n",
      "Validation loss: 0.9197, Validation accuracy: 0.6893\n",
      "\n",
      "Epoch 28:\n",
      "Training loss: 0.4116, Training accuracy: 0.7506\n",
      "Validation loss: 0.8040, Validation accuracy: 0.7305\n",
      "\n",
      "Epoch 29:\n",
      "Training loss: 0.4052, Training accuracy: 0.7538\n",
      "Validation loss: 1.0126, Validation accuracy: 0.6647\n",
      "\n",
      "Epoch 30:\n",
      "Training loss: 0.4105, Training accuracy: 0.7503\n",
      "Validation loss: 0.7875, Validation accuracy: 0.7346\n",
      "Saving ...\n",
      "\n",
      "Epoch 31:\n",
      "Training loss: 0.4044, Training accuracy: 0.7557\n",
      "Validation loss: 0.7656, Validation accuracy: 0.7409\n",
      "Saving ...\n",
      "\n",
      "Epoch 32:\n",
      "Training loss: 0.4045, Training accuracy: 0.7547\n",
      "Validation loss: 0.8503, Validation accuracy: 0.7072\n",
      "\n",
      "Epoch 33:\n",
      "Training loss: 0.4023, Training accuracy: 0.7563\n",
      "Validation loss: 0.9853, Validation accuracy: 0.6617\n",
      "\n",
      "Epoch 34:\n",
      "Training loss: 0.4044, Training accuracy: 0.7553\n",
      "Validation loss: 1.2227, Validation accuracy: 0.6216\n",
      "\n",
      "Epoch 35:\n",
      "Training loss: 0.3992, Training accuracy: 0.7590\n",
      "Validation loss: 0.8953, Validation accuracy: 0.6967\n",
      "\n",
      "Epoch 36:\n",
      "Training loss: 0.4043, Training accuracy: 0.7562\n",
      "Validation loss: 0.8603, Validation accuracy: 0.7127\n",
      "\n",
      "Epoch 37:\n",
      "Training loss: 0.3998, Training accuracy: 0.7561\n",
      "Validation loss: 0.9456, Validation accuracy: 0.6814\n",
      "\n",
      "Epoch 38:\n",
      "Training loss: 0.4007, Training accuracy: 0.7572\n",
      "Validation loss: 1.0567, Validation accuracy: 0.6700\n",
      "\n",
      "Epoch 39:\n",
      "Training loss: 0.3984, Training accuracy: 0.7602\n",
      "Validation loss: 0.7415, Validation accuracy: 0.7486\n",
      "Saving ...\n",
      "\n",
      "Current learning rate has decayed to 0.010000\n",
      "Epoch 40:\n",
      "Training loss: 0.2819, Training accuracy: 0.8351\n",
      "Validation loss: 0.4491, Validation accuracy: 0.8464\n",
      "Saving ...\n",
      "\n",
      "Epoch 41:\n",
      "Training loss: 0.2489, Training accuracy: 0.8540\n",
      "Validation loss: 0.4265, Validation accuracy: 0.8546\n",
      "Saving ...\n",
      "\n",
      "Epoch 42:\n",
      "Training loss: 0.2331, Training accuracy: 0.8623\n",
      "Validation loss: 0.4198, Validation accuracy: 0.8580\n",
      "Saving ...\n",
      "\n",
      "Epoch 43:\n",
      "Training loss: 0.2239, Training accuracy: 0.8682\n",
      "Validation loss: 0.4150, Validation accuracy: 0.8618\n",
      "Saving ...\n",
      "\n",
      "Epoch 44:\n",
      "Training loss: 0.2163, Training accuracy: 0.8734\n",
      "Validation loss: 0.4201, Validation accuracy: 0.8587\n",
      "\n",
      "Epoch 45:\n",
      "Training loss: 0.2097, Training accuracy: 0.8780\n",
      "Validation loss: 0.3950, Validation accuracy: 0.8658\n",
      "Saving ...\n",
      "\n",
      "Epoch 46:\n",
      "Training loss: 0.2028, Training accuracy: 0.8807\n",
      "Validation loss: 0.4076, Validation accuracy: 0.8607\n",
      "\n",
      "Epoch 47:\n",
      "Training loss: 0.2004, Training accuracy: 0.8821\n",
      "Validation loss: 0.4172, Validation accuracy: 0.8601\n",
      "\n",
      "Epoch 48:\n",
      "Training loss: 0.1995, Training accuracy: 0.8835\n",
      "Validation loss: 0.3991, Validation accuracy: 0.8677\n",
      "Saving ...\n",
      "\n",
      "Epoch 49:\n",
      "Training loss: 0.1947, Training accuracy: 0.8861\n",
      "Validation loss: 0.3989, Validation accuracy: 0.8665\n",
      "\n",
      "Epoch 50:\n",
      "Training loss: 0.1910, Training accuracy: 0.8880\n",
      "Validation loss: 0.4141, Validation accuracy: 0.8587\n",
      "\n",
      "Epoch 51:\n",
      "Training loss: 0.1914, Training accuracy: 0.8877\n",
      "Validation loss: 0.4427, Validation accuracy: 0.8507\n",
      "\n",
      "Epoch 52:\n",
      "Training loss: 0.1870, Training accuracy: 0.8906\n",
      "Validation loss: 0.4120, Validation accuracy: 0.8633\n",
      "\n",
      "Epoch 53:\n",
      "Training loss: 0.1871, Training accuracy: 0.8912\n",
      "Validation loss: 0.4253, Validation accuracy: 0.8583\n",
      "\n",
      "Epoch 54:\n",
      "Training loss: 0.1845, Training accuracy: 0.8948\n",
      "Validation loss: 0.4275, Validation accuracy: 0.8576\n",
      "\n",
      "Epoch 55:\n",
      "Training loss: 0.1839, Training accuracy: 0.8935\n",
      "Validation loss: 0.4072, Validation accuracy: 0.8672\n",
      "\n",
      "Epoch 56:\n",
      "Training loss: 0.1834, Training accuracy: 0.8918\n",
      "Validation loss: 0.4228, Validation accuracy: 0.8585\n",
      "\n",
      "Epoch 57:\n",
      "Training loss: 0.1822, Training accuracy: 0.8935\n",
      "Validation loss: 0.4346, Validation accuracy: 0.8562\n",
      "\n",
      "Epoch 58:\n",
      "Training loss: 0.1812, Training accuracy: 0.8942\n",
      "Validation loss: 0.4265, Validation accuracy: 0.8580\n",
      "\n",
      "Epoch 59:\n",
      "Training loss: 0.1822, Training accuracy: 0.8931\n",
      "Validation loss: 0.4200, Validation accuracy: 0.8597\n",
      "\n",
      "Epoch 60:\n",
      "Training loss: 0.1787, Training accuracy: 0.8939\n",
      "Validation loss: 0.4147, Validation accuracy: 0.8623\n",
      "\n",
      "Epoch 61:\n",
      "Training loss: 0.1813, Training accuracy: 0.8941\n",
      "Validation loss: 0.4396, Validation accuracy: 0.8536\n",
      "\n",
      "Epoch 62:\n",
      "Training loss: 0.1803, Training accuracy: 0.8945\n",
      "Validation loss: 0.4283, Validation accuracy: 0.8584\n",
      "\n",
      "Epoch 63:\n",
      "Training loss: 0.1783, Training accuracy: 0.8965\n",
      "Validation loss: 0.4270, Validation accuracy: 0.8616\n",
      "\n",
      "Epoch 64:\n",
      "Training loss: 0.1795, Training accuracy: 0.8952\n",
      "Validation loss: 0.4277, Validation accuracy: 0.8600\n",
      "\n",
      "Epoch 65:\n",
      "Training loss: 0.1761, Training accuracy: 0.8973\n",
      "Validation loss: 0.4080, Validation accuracy: 0.8628\n",
      "\n",
      "Epoch 66:\n",
      "Training loss: 0.1741, Training accuracy: 0.8983\n",
      "Validation loss: 0.4190, Validation accuracy: 0.8619\n",
      "\n",
      "Epoch 67:\n",
      "Training loss: 0.1737, Training accuracy: 0.8995\n",
      "Validation loss: 0.4104, Validation accuracy: 0.8627\n",
      "\n",
      "Epoch 68:\n",
      "Training loss: 0.1746, Training accuracy: 0.8982\n",
      "Validation loss: 0.4059, Validation accuracy: 0.8653\n",
      "\n",
      "Epoch 69:\n",
      "Training loss: 0.1707, Training accuracy: 0.9002\n",
      "Validation loss: 0.4049, Validation accuracy: 0.8642\n",
      "\n",
      "Epoch 70:\n",
      "Training loss: 0.1713, Training accuracy: 0.9009\n",
      "Validation loss: 0.4337, Validation accuracy: 0.8572\n",
      "\n",
      "Epoch 71:\n",
      "Training loss: 0.1693, Training accuracy: 0.9016\n",
      "Validation loss: 0.3956, Validation accuracy: 0.8706\n",
      "Saving ...\n",
      "\n",
      "Epoch 72:\n",
      "Training loss: 0.1716, Training accuracy: 0.8996\n",
      "Validation loss: 0.4327, Validation accuracy: 0.8570\n",
      "\n",
      "Epoch 73:\n",
      "Training loss: 0.1690, Training accuracy: 0.9011\n",
      "Validation loss: 0.4187, Validation accuracy: 0.8627\n",
      "\n",
      "Epoch 74:\n",
      "Training loss: 0.1659, Training accuracy: 0.9039\n",
      "Validation loss: 0.4146, Validation accuracy: 0.8666\n",
      "\n",
      "Epoch 75:\n",
      "Training loss: 0.1682, Training accuracy: 0.9027\n",
      "Validation loss: 0.4174, Validation accuracy: 0.8620\n",
      "\n",
      "Epoch 76:\n",
      "Training loss: 0.1660, Training accuracy: 0.9041\n",
      "Validation loss: 0.4258, Validation accuracy: 0.8604\n",
      "\n",
      "Epoch 77:\n",
      "Training loss: 0.1648, Training accuracy: 0.9041\n",
      "Validation loss: 0.4083, Validation accuracy: 0.8634\n",
      "\n",
      "Epoch 78:\n",
      "Training loss: 0.1637, Training accuracy: 0.9045\n",
      "Validation loss: 0.4156, Validation accuracy: 0.8627\n",
      "\n",
      "Epoch 79:\n",
      "Training loss: 0.1652, Training accuracy: 0.9038\n",
      "Validation loss: 0.4782, Validation accuracy: 0.8412\n",
      "\n",
      "Current learning rate has decayed to 0.001000\n",
      "Epoch 80:\n",
      "Training loss: 0.1155, Training accuracy: 0.9378\n",
      "Validation loss: 0.3203, Validation accuracy: 0.8946\n",
      "Saving ...\n",
      "\n",
      "Epoch 81:\n",
      "Training loss: 0.0974, Training accuracy: 0.9497\n",
      "Validation loss: 0.3177, Validation accuracy: 0.8937\n",
      "\n",
      "Epoch 82:\n",
      "Training loss: 0.0905, Training accuracy: 0.9536\n",
      "Validation loss: 0.3188, Validation accuracy: 0.8953\n",
      "Saving ...\n",
      "\n",
      "Epoch 83:\n",
      "Training loss: 0.0858, Training accuracy: 0.9564\n",
      "Validation loss: 0.3182, Validation accuracy: 0.8971\n",
      "Saving ...\n",
      "\n",
      "Epoch 84:\n",
      "Training loss: 0.0826, Training accuracy: 0.9588\n",
      "Validation loss: 0.3154, Validation accuracy: 0.8994\n",
      "Saving ...\n",
      "\n",
      "Epoch 85:\n",
      "Training loss: 0.0804, Training accuracy: 0.9601\n",
      "Validation loss: 0.3143, Validation accuracy: 0.8989\n",
      "\n",
      "Epoch 86:\n",
      "Training loss: 0.0767, Training accuracy: 0.9620\n",
      "Validation loss: 0.3225, Validation accuracy: 0.8988\n",
      "\n",
      "Epoch 87:\n",
      "Training loss: 0.0747, Training accuracy: 0.9629\n",
      "Validation loss: 0.3202, Validation accuracy: 0.9002\n",
      "Saving ...\n",
      "\n",
      "Epoch 88:\n",
      "Training loss: 0.0736, Training accuracy: 0.9634\n",
      "Validation loss: 0.3215, Validation accuracy: 0.8984\n",
      "\n",
      "Epoch 89:\n",
      "Training loss: 0.0713, Training accuracy: 0.9651\n",
      "Validation loss: 0.3222, Validation accuracy: 0.9007\n",
      "Saving ...\n",
      "\n",
      "Epoch 90:\n",
      "Training loss: 0.0696, Training accuracy: 0.9666\n",
      "Validation loss: 0.3219, Validation accuracy: 0.9016\n",
      "Saving ...\n",
      "\n",
      "Epoch 91:\n",
      "Training loss: 0.0692, Training accuracy: 0.9675\n",
      "Validation loss: 0.3211, Validation accuracy: 0.9011\n",
      "\n",
      "Epoch 92:\n",
      "Training loss: 0.0654, Training accuracy: 0.9696\n",
      "Validation loss: 0.3261, Validation accuracy: 0.8994\n",
      "\n",
      "Epoch 93:\n",
      "Training loss: 0.0650, Training accuracy: 0.9702\n",
      "Validation loss: 0.3308, Validation accuracy: 0.8993\n",
      "\n",
      "Epoch 94:\n",
      "Training loss: 0.0628, Training accuracy: 0.9712\n",
      "Validation loss: 0.3284, Validation accuracy: 0.8991\n",
      "\n",
      "Epoch 95:\n",
      "Training loss: 0.0623, Training accuracy: 0.9710\n",
      "Validation loss: 0.3336, Validation accuracy: 0.8984\n",
      "\n",
      "Epoch 96:\n",
      "Training loss: 0.0610, Training accuracy: 0.9719\n",
      "Validation loss: 0.3309, Validation accuracy: 0.9004\n",
      "\n",
      "Epoch 97:\n",
      "Training loss: 0.0610, Training accuracy: 0.9716\n",
      "Validation loss: 0.3369, Validation accuracy: 0.8991\n",
      "\n",
      "Epoch 98:\n",
      "Training loss: 0.0593, Training accuracy: 0.9732\n",
      "Validation loss: 0.3297, Validation accuracy: 0.8997\n",
      "\n",
      "Epoch 99:\n",
      "Training loss: 0.0563, Training accuracy: 0.9754\n",
      "Validation loss: 0.3399, Validation accuracy: 0.8971\n",
      "\n",
      "Epoch 100:\n",
      "Training loss: 0.0555, Training accuracy: 0.9755\n",
      "Validation loss: 0.3393, Validation accuracy: 0.8990\n",
      "\n",
      "Epoch 101:\n",
      "Training loss: 0.0544, Training accuracy: 0.9765\n",
      "Validation loss: 0.3379, Validation accuracy: 0.9003\n",
      "\n",
      "Epoch 102:\n",
      "Training loss: 0.0560, Training accuracy: 0.9747\n",
      "Validation loss: 0.3426, Validation accuracy: 0.9022\n",
      "Saving ...\n",
      "\n",
      "Epoch 103:\n",
      "Training loss: 0.0530, Training accuracy: 0.9771\n",
      "Validation loss: 0.3449, Validation accuracy: 0.8987\n",
      "\n",
      "Epoch 104:\n",
      "Training loss: 0.0533, Training accuracy: 0.9771\n",
      "Validation loss: 0.3479, Validation accuracy: 0.9009\n",
      "\n",
      "Epoch 105:\n",
      "Training loss: 0.0516, Training accuracy: 0.9775\n",
      "Validation loss: 0.3515, Validation accuracy: 0.8998\n",
      "\n",
      "Epoch 106:\n",
      "Training loss: 0.0519, Training accuracy: 0.9773\n",
      "Validation loss: 0.3478, Validation accuracy: 0.8975\n",
      "\n",
      "Epoch 107:\n",
      "Training loss: 0.0499, Training accuracy: 0.9792\n",
      "Validation loss: 0.3544, Validation accuracy: 0.8978\n",
      "\n",
      "Epoch 108:\n",
      "Training loss: 0.0494, Training accuracy: 0.9802\n",
      "Validation loss: 0.3546, Validation accuracy: 0.8978\n",
      "\n",
      "Epoch 109:\n",
      "Training loss: 0.0492, Training accuracy: 0.9798\n",
      "Validation loss: 0.3523, Validation accuracy: 0.8971\n",
      "\n",
      "Epoch 110:\n",
      "Training loss: 0.0491, Training accuracy: 0.9793\n",
      "Validation loss: 0.3496, Validation accuracy: 0.9018\n",
      "\n",
      "Epoch 111:\n",
      "Training loss: 0.0489, Training accuracy: 0.9794\n",
      "Validation loss: 0.3592, Validation accuracy: 0.8975\n",
      "\n",
      "Epoch 112:\n",
      "Training loss: 0.0465, Training accuracy: 0.9807\n",
      "Validation loss: 0.3507, Validation accuracy: 0.8990\n",
      "\n",
      "Epoch 113:\n",
      "Training loss: 0.0460, Training accuracy: 0.9811\n",
      "Validation loss: 0.3544, Validation accuracy: 0.8990\n",
      "\n",
      "Epoch 114:\n",
      "Training loss: 0.0453, Training accuracy: 0.9811\n",
      "Validation loss: 0.3549, Validation accuracy: 0.9002\n",
      "\n",
      "Epoch 115:\n",
      "Training loss: 0.0453, Training accuracy: 0.9808\n",
      "Validation loss: 0.3584, Validation accuracy: 0.8978\n",
      "\n",
      "Epoch 116:\n",
      "Training loss: 0.0455, Training accuracy: 0.9814\n",
      "Validation loss: 0.3597, Validation accuracy: 0.8995\n",
      "\n",
      "Epoch 117:\n",
      "Training loss: 0.0448, Training accuracy: 0.9817\n",
      "Validation loss: 0.3640, Validation accuracy: 0.8986\n",
      "\n",
      "Epoch 118:\n",
      "Training loss: 0.0443, Training accuracy: 0.9822\n",
      "Validation loss: 0.3675, Validation accuracy: 0.8968\n",
      "\n",
      "Epoch 119:\n",
      "Training loss: 0.0444, Training accuracy: 0.9819\n",
      "Validation loss: 0.3703, Validation accuracy: 0.8966\n",
      "\n",
      "Epoch 120:\n",
      "Training loss: 0.0416, Training accuracy: 0.9840\n",
      "Validation loss: 0.3714, Validation accuracy: 0.8981\n",
      "\n",
      "Epoch 121:\n",
      "Training loss: 0.0437, Training accuracy: 0.9819\n",
      "Validation loss: 0.3634, Validation accuracy: 0.8983\n",
      "\n",
      "Epoch 122:\n",
      "Training loss: 0.0422, Training accuracy: 0.9829\n",
      "Validation loss: 0.3608, Validation accuracy: 0.9002\n",
      "\n",
      "Epoch 123:\n",
      "Training loss: 0.0422, Training accuracy: 0.9833\n",
      "Validation loss: 0.3652, Validation accuracy: 0.8981\n",
      "\n",
      "Epoch 124:\n",
      "Training loss: 0.0418, Training accuracy: 0.9832\n",
      "Validation loss: 0.3726, Validation accuracy: 0.8978\n",
      "\n",
      "Epoch 125:\n",
      "Training loss: 0.0410, Training accuracy: 0.9840\n",
      "Validation loss: 0.3609, Validation accuracy: 0.9003\n",
      "\n",
      "Epoch 126:\n",
      "Training loss: 0.0409, Training accuracy: 0.9837\n",
      "Validation loss: 0.3701, Validation accuracy: 0.8966\n",
      "\n",
      "Epoch 127:\n",
      "Training loss: 0.0424, Training accuracy: 0.9828\n",
      "Validation loss: 0.3695, Validation accuracy: 0.8978\n",
      "\n",
      "Epoch 128:\n",
      "Training loss: 0.0412, Training accuracy: 0.9829\n",
      "Validation loss: 0.3688, Validation accuracy: 0.8976\n",
      "\n",
      "Epoch 129:\n",
      "Training loss: 0.0404, Training accuracy: 0.9843\n",
      "Validation loss: 0.3649, Validation accuracy: 0.8982\n",
      "\n",
      "Epoch 130:\n",
      "Training loss: 0.0390, Training accuracy: 0.9841\n",
      "Validation loss: 0.3688, Validation accuracy: 0.8989\n",
      "\n",
      "Epoch 131:\n",
      "Training loss: 0.0388, Training accuracy: 0.9851\n",
      "Validation loss: 0.3731, Validation accuracy: 0.8963\n",
      "\n",
      "Epoch 132:\n",
      "Training loss: 0.0377, Training accuracy: 0.9862\n",
      "Validation loss: 0.3775, Validation accuracy: 0.8964\n",
      "\n",
      "Epoch 133:\n",
      "Training loss: 0.0382, Training accuracy: 0.9858\n",
      "Validation loss: 0.3806, Validation accuracy: 0.8975\n",
      "\n",
      "Epoch 134:\n",
      "Training loss: 0.0378, Training accuracy: 0.9854\n",
      "Validation loss: 0.3780, Validation accuracy: 0.8967\n",
      "\n",
      "Epoch 135:\n",
      "Training loss: 0.0397, Training accuracy: 0.9843\n",
      "Validation loss: 0.3703, Validation accuracy: 0.9010\n",
      "\n",
      "Epoch 136:\n",
      "Training loss: 0.0379, Training accuracy: 0.9852\n",
      "Validation loss: 0.3769, Validation accuracy: 0.8985\n",
      "\n",
      "Epoch 137:\n",
      "Training loss: 0.0384, Training accuracy: 0.9851\n",
      "Validation loss: 0.3718, Validation accuracy: 0.8997\n",
      "\n",
      "Epoch 138:\n",
      "Training loss: 0.0382, Training accuracy: 0.9853\n",
      "Validation loss: 0.3744, Validation accuracy: 0.8983\n",
      "\n",
      "Epoch 139:\n",
      "Training loss: 0.0374, Training accuracy: 0.9860\n",
      "Validation loss: 0.3718, Validation accuracy: 0.8988\n",
      "\n",
      "Epoch 140:\n",
      "Training loss: 0.0378, Training accuracy: 0.9855\n",
      "Validation loss: 0.3750, Validation accuracy: 0.8966\n",
      "\n",
      "Epoch 141:\n",
      "Training loss: 0.0368, Training accuracy: 0.9862\n",
      "Validation loss: 0.3808, Validation accuracy: 0.8965\n",
      "\n",
      "Epoch 142:\n",
      "Training loss: 0.0354, Training accuracy: 0.9865\n",
      "Validation loss: 0.3782, Validation accuracy: 0.8983\n",
      "\n",
      "Epoch 143:\n",
      "Training loss: 0.0353, Training accuracy: 0.9868\n",
      "Validation loss: 0.3818, Validation accuracy: 0.8969\n",
      "\n",
      "Epoch 144:\n",
      "Training loss: 0.0372, Training accuracy: 0.9851\n",
      "Validation loss: 0.3888, Validation accuracy: 0.8958\n",
      "\n",
      "Epoch 145:\n",
      "Training loss: 0.0384, Training accuracy: 0.9848\n",
      "Validation loss: 0.3849, Validation accuracy: 0.8989\n",
      "\n",
      "Epoch 146:\n",
      "Training loss: 0.0351, Training accuracy: 0.9871\n",
      "Validation loss: 0.3785, Validation accuracy: 0.9010\n",
      "\n",
      "Epoch 147:\n",
      "Training loss: 0.0366, Training accuracy: 0.9859\n",
      "Validation loss: 0.3805, Validation accuracy: 0.8990\n",
      "\n",
      "Epoch 148:\n",
      "Training loss: 0.0358, Training accuracy: 0.9868\n",
      "Validation loss: 0.3906, Validation accuracy: 0.8960\n",
      "\n",
      "Epoch 149:\n",
      "Training loss: 0.0342, Training accuracy: 0.9879\n",
      "Validation loss: 0.3871, Validation accuracy: 0.8958\n",
      "\n",
      "Epoch 150:\n",
      "Training loss: 0.0351, Training accuracy: 0.9874\n",
      "Validation loss: 0.3902, Validation accuracy: 0.8949\n",
      "\n",
      "Epoch 151:\n",
      "Training loss: 0.0356, Training accuracy: 0.9866\n",
      "Validation loss: 0.3935, Validation accuracy: 0.8929\n",
      "\n",
      "Epoch 152:\n",
      "Training loss: 0.0355, Training accuracy: 0.9866\n",
      "Validation loss: 0.3992, Validation accuracy: 0.8917\n",
      "\n",
      "Epoch 153:\n",
      "Training loss: 0.0348, Training accuracy: 0.9870\n",
      "Validation loss: 0.3921, Validation accuracy: 0.8960\n",
      "\n",
      "Epoch 154:\n",
      "Training loss: 0.0356, Training accuracy: 0.9866\n",
      "Validation loss: 0.3763, Validation accuracy: 0.8974\n",
      "\n",
      "Epoch 155:\n",
      "Training loss: 0.0348, Training accuracy: 0.9870\n",
      "Validation loss: 0.3913, Validation accuracy: 0.8948\n",
      "\n",
      "Epoch 156:\n",
      "Training loss: 0.0342, Training accuracy: 0.9876\n",
      "Validation loss: 0.3895, Validation accuracy: 0.8980\n",
      "\n",
      "Epoch 157:\n",
      "Training loss: 0.0338, Training accuracy: 0.9871\n",
      "Validation loss: 0.3912, Validation accuracy: 0.8986\n",
      "\n",
      "Epoch 158:\n",
      "Training loss: 0.0343, Training accuracy: 0.9874\n",
      "Validation loss: 0.3987, Validation accuracy: 0.8939\n",
      "\n",
      "Epoch 159:\n",
      "Training loss: 0.0342, Training accuracy: 0.9874\n",
      "Validation loss: 0.3925, Validation accuracy: 0.8972\n",
      "\n",
      "Current learning rate has decayed to 0.000100\n",
      "Epoch 160:\n",
      "Training loss: 0.0296, Training accuracy: 0.9898\n",
      "Validation loss: 0.3730, Validation accuracy: 0.9008\n",
      "\n",
      "Epoch 161:\n",
      "Training loss: 0.0256, Training accuracy: 0.9925\n",
      "Validation loss: 0.3738, Validation accuracy: 0.9002\n",
      "\n",
      "Epoch 162:\n",
      "Training loss: 0.0258, Training accuracy: 0.9923\n",
      "Validation loss: 0.3678, Validation accuracy: 0.9025\n",
      "Saving ...\n",
      "\n",
      "Epoch 163:\n",
      "Training loss: 0.0252, Training accuracy: 0.9929\n",
      "Validation loss: 0.3684, Validation accuracy: 0.9031\n",
      "Saving ...\n",
      "\n",
      "Epoch 164:\n",
      "Training loss: 0.0242, Training accuracy: 0.9934\n",
      "Validation loss: 0.3712, Validation accuracy: 0.9021\n",
      "\n",
      "Epoch 165:\n",
      "Training loss: 0.0228, Training accuracy: 0.9937\n",
      "Validation loss: 0.3729, Validation accuracy: 0.9028\n",
      "\n",
      "Epoch 166:\n",
      "Training loss: 0.0236, Training accuracy: 0.9938\n",
      "Validation loss: 0.3718, Validation accuracy: 0.9026\n",
      "\n",
      "Epoch 167:\n",
      "Training loss: 0.0225, Training accuracy: 0.9946\n",
      "Validation loss: 0.3713, Validation accuracy: 0.9041\n",
      "Saving ...\n",
      "\n",
      "Epoch 168:\n",
      "Training loss: 0.0230, Training accuracy: 0.9940\n",
      "Validation loss: 0.3740, Validation accuracy: 0.9032\n",
      "\n",
      "Epoch 169:\n",
      "Training loss: 0.0227, Training accuracy: 0.9943\n",
      "Validation loss: 0.3781, Validation accuracy: 0.9025\n",
      "\n",
      "Epoch 170:\n",
      "Training loss: 0.0214, Training accuracy: 0.9954\n",
      "Validation loss: 0.3727, Validation accuracy: 0.9039\n",
      "\n",
      "Epoch 171:\n",
      "Training loss: 0.0213, Training accuracy: 0.9950\n",
      "Validation loss: 0.3721, Validation accuracy: 0.9046\n",
      "Saving ...\n",
      "\n",
      "Epoch 172:\n",
      "Training loss: 0.0221, Training accuracy: 0.9943\n",
      "Validation loss: 0.3695, Validation accuracy: 0.9050\n",
      "Saving ...\n",
      "\n",
      "Epoch 173:\n",
      "Training loss: 0.0213, Training accuracy: 0.9952\n",
      "Validation loss: 0.3751, Validation accuracy: 0.9022\n",
      "\n",
      "Epoch 174:\n",
      "Training loss: 0.0212, Training accuracy: 0.9954\n",
      "Validation loss: 0.3708, Validation accuracy: 0.9033\n",
      "\n",
      "Epoch 175:\n",
      "Training loss: 0.0210, Training accuracy: 0.9952\n",
      "Validation loss: 0.3691, Validation accuracy: 0.9037\n",
      "\n",
      "Epoch 176:\n",
      "Training loss: 0.0204, Training accuracy: 0.9959\n",
      "Validation loss: 0.3724, Validation accuracy: 0.9033\n",
      "\n",
      "Epoch 177:\n",
      "Training loss: 0.0211, Training accuracy: 0.9951\n",
      "Validation loss: 0.3729, Validation accuracy: 0.9026\n",
      "\n",
      "Epoch 178:\n",
      "Training loss: 0.0206, Training accuracy: 0.9957\n",
      "Validation loss: 0.3771, Validation accuracy: 0.9025\n",
      "\n",
      "Epoch 179:\n",
      "Training loss: 0.0207, Training accuracy: 0.9961\n",
      "Validation loss: 0.3729, Validation accuracy: 0.9038\n",
      "\n",
      "Epoch 180:\n",
      "Training loss: 0.0206, Training accuracy: 0.9953\n",
      "Validation loss: 0.3746, Validation accuracy: 0.9035\n",
      "\n",
      "Epoch 181:\n",
      "Training loss: 0.0201, Training accuracy: 0.9956\n",
      "Validation loss: 0.3749, Validation accuracy: 0.9031\n",
      "\n",
      "Epoch 182:\n",
      "Training loss: 0.0196, Training accuracy: 0.9961\n",
      "Validation loss: 0.3786, Validation accuracy: 0.9017\n",
      "\n",
      "Epoch 183:\n",
      "Training loss: 0.0199, Training accuracy: 0.9961\n",
      "Validation loss: 0.3779, Validation accuracy: 0.9034\n",
      "\n",
      "Epoch 184:\n",
      "Training loss: 0.0200, Training accuracy: 0.9961\n",
      "Validation loss: 0.3764, Validation accuracy: 0.9039\n",
      "\n",
      "Epoch 185:\n",
      "Training loss: 0.0203, Training accuracy: 0.9957\n",
      "Validation loss: 0.3728, Validation accuracy: 0.9038\n",
      "\n",
      "Epoch 186:\n",
      "Training loss: 0.0198, Training accuracy: 0.9957\n",
      "Validation loss: 0.3747, Validation accuracy: 0.9038\n",
      "\n",
      "Epoch 187:\n",
      "Training loss: 0.0201, Training accuracy: 0.9956\n",
      "Validation loss: 0.3787, Validation accuracy: 0.9024\n",
      "\n",
      "Epoch 188:\n",
      "Training loss: 0.0195, Training accuracy: 0.9962\n",
      "Validation loss: 0.3763, Validation accuracy: 0.9036\n",
      "\n",
      "Epoch 189:\n",
      "Training loss: 0.0194, Training accuracy: 0.9962\n",
      "Validation loss: 0.3824, Validation accuracy: 0.9022\n",
      "\n",
      "Epoch 190:\n",
      "Training loss: 0.0197, Training accuracy: 0.9959\n",
      "Validation loss: 0.3774, Validation accuracy: 0.9043\n",
      "\n",
      "Epoch 191:\n",
      "Training loss: 0.0195, Training accuracy: 0.9961\n",
      "Validation loss: 0.3799, Validation accuracy: 0.9035\n",
      "\n",
      "Epoch 192:\n",
      "Training loss: 0.0193, Training accuracy: 0.9961\n",
      "Validation loss: 0.3833, Validation accuracy: 0.9029\n",
      "\n",
      "Epoch 193:\n",
      "Training loss: 0.0193, Training accuracy: 0.9960\n",
      "Validation loss: 0.3770, Validation accuracy: 0.9038\n",
      "\n",
      "Epoch 194:\n",
      "Training loss: 0.0189, Training accuracy: 0.9964\n",
      "Validation loss: 0.3777, Validation accuracy: 0.9033\n",
      "\n",
      "Epoch 195:\n",
      "Training loss: 0.0194, Training accuracy: 0.9961\n",
      "Validation loss: 0.3821, Validation accuracy: 0.9035\n",
      "\n",
      "Epoch 196:\n",
      "Training loss: 0.0193, Training accuracy: 0.9965\n",
      "Validation loss: 0.3836, Validation accuracy: 0.9013\n",
      "\n",
      "Epoch 197:\n",
      "Training loss: 0.0190, Training accuracy: 0.9964\n",
      "Validation loss: 0.3859, Validation accuracy: 0.9021\n",
      "\n",
      "Epoch 198:\n",
      "Training loss: 0.0187, Training accuracy: 0.9964\n",
      "Validation loss: 0.3833, Validation accuracy: 0.9030\n",
      "\n",
      "Epoch 199:\n",
      "Training loss: 0.0188, Training accuracy: 0.9969\n",
      "Validation loss: 0.3840, Validation accuracy: 0.9020\n",
      "\n",
      "==================================================\n",
      "==> Optimization finished! Best validation accuracy: 0.9050\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.905"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train(T=1,lamb=0.6,alpha=0.4,train_loader=train_loader,val_loader=val_loader,INITIAL_LR=0.1,DECAY_EPOCHS=[40,80,160],DECAY=0.1,EPOCHS=200,REG = 4e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Training starts!\n",
      "==================================================\n",
      "Epoch 0:\n",
      "Training loss: 1.7234, Training accuracy: 0.3044\n",
      "Validation loss: 1.5948, Validation accuracy: 0.4232\n",
      "Saving ...\n",
      "\n",
      "Epoch 1:\n",
      "Training loss: 1.2070, Training accuracy: 0.4560\n",
      "Validation loss: 2.2621, Validation accuracy: 0.4935\n",
      "Saving ...\n",
      "\n",
      "Epoch 2:\n",
      "Training loss: 1.0354, Training accuracy: 0.5335\n",
      "Validation loss: 1.3222, Validation accuracy: 0.5404\n",
      "Saving ...\n",
      "\n",
      "Epoch 3:\n",
      "Training loss: 0.9089, Training accuracy: 0.5901\n",
      "Validation loss: 1.5381, Validation accuracy: 0.5813\n",
      "Saving ...\n",
      "\n",
      "Epoch 4:\n",
      "Training loss: 0.8210, Training accuracy: 0.6293\n",
      "Validation loss: 1.1514, Validation accuracy: 0.6069\n",
      "Saving ...\n",
      "\n",
      "Epoch 5:\n",
      "Training loss: 0.7639, Training accuracy: 0.6538\n",
      "Validation loss: 1.0311, Validation accuracy: 0.6438\n",
      "Saving ...\n",
      "\n",
      "Epoch 6:\n",
      "Training loss: 0.7237, Training accuracy: 0.6762\n",
      "Validation loss: 1.1330, Validation accuracy: 0.6236\n",
      "\n",
      "Epoch 7:\n",
      "Training loss: 0.6948, Training accuracy: 0.6895\n",
      "Validation loss: 0.9606, Validation accuracy: 0.6723\n",
      "Saving ...\n",
      "\n",
      "Epoch 8:\n",
      "Training loss: 0.6784, Training accuracy: 0.6972\n",
      "Validation loss: 0.9661, Validation accuracy: 0.6781\n",
      "Saving ...\n",
      "\n",
      "Epoch 9:\n",
      "Training loss: 0.6642, Training accuracy: 0.7022\n",
      "Validation loss: 0.9011, Validation accuracy: 0.6814\n",
      "Saving ...\n",
      "\n",
      "Epoch 10:\n",
      "Training loss: 0.4442, Training accuracy: 0.7311\n",
      "Validation loss: 0.7946, Validation accuracy: 0.7256\n",
      "Saving ...\n",
      "\n",
      "Epoch 11:\n",
      "Training loss: 0.4428, Training accuracy: 0.7310\n",
      "Validation loss: 0.9062, Validation accuracy: 0.6868\n",
      "\n",
      "Epoch 12:\n",
      "Training loss: 0.4470, Training accuracy: 0.7307\n",
      "Validation loss: 0.8958, Validation accuracy: 0.6979\n",
      "\n",
      "Epoch 13:\n",
      "Training loss: 0.4448, Training accuracy: 0.7320\n",
      "Validation loss: 0.7893, Validation accuracy: 0.7280\n",
      "Saving ...\n",
      "\n",
      "Epoch 14:\n",
      "Training loss: 0.4421, Training accuracy: 0.7339\n",
      "Validation loss: 0.8286, Validation accuracy: 0.7194\n",
      "\n",
      "Epoch 15:\n",
      "Training loss: 0.4382, Training accuracy: 0.7381\n",
      "Validation loss: 0.7491, Validation accuracy: 0.7404\n",
      "Saving ...\n",
      "\n",
      "Epoch 16:\n",
      "Training loss: 0.4392, Training accuracy: 0.7347\n",
      "Validation loss: 0.7940, Validation accuracy: 0.7286\n",
      "\n",
      "Epoch 17:\n",
      "Training loss: 0.4303, Training accuracy: 0.7426\n",
      "Validation loss: 0.8498, Validation accuracy: 0.7066\n",
      "\n",
      "Epoch 18:\n",
      "Training loss: 0.4270, Training accuracy: 0.7428\n",
      "Validation loss: 0.7676, Validation accuracy: 0.7372\n",
      "\n",
      "Epoch 19:\n",
      "Training loss: 0.4230, Training accuracy: 0.7466\n",
      "Validation loss: 0.7947, Validation accuracy: 0.7274\n",
      "\n",
      "Epoch 20:\n",
      "Training loss: 0.4222, Training accuracy: 0.7484\n",
      "Validation loss: 0.8218, Validation accuracy: 0.7202\n",
      "\n",
      "Epoch 21:\n",
      "Training loss: 0.4202, Training accuracy: 0.7487\n",
      "Validation loss: 0.7912, Validation accuracy: 0.7329\n",
      "\n",
      "Epoch 22:\n",
      "Training loss: 0.4188, Training accuracy: 0.7507\n",
      "Validation loss: 0.9055, Validation accuracy: 0.7038\n",
      "\n",
      "Epoch 23:\n",
      "Training loss: 0.4164, Training accuracy: 0.7498\n",
      "Validation loss: 0.7518, Validation accuracy: 0.7422\n",
      "Saving ...\n",
      "\n",
      "Epoch 24:\n",
      "Training loss: 0.4158, Training accuracy: 0.7501\n",
      "Validation loss: 0.7324, Validation accuracy: 0.7531\n",
      "Saving ...\n",
      "\n",
      "Epoch 25:\n",
      "Training loss: 0.4126, Training accuracy: 0.7522\n",
      "Validation loss: 1.0988, Validation accuracy: 0.6623\n",
      "\n",
      "Epoch 26:\n",
      "Training loss: 0.4116, Training accuracy: 0.7557\n",
      "Validation loss: 0.8602, Validation accuracy: 0.7027\n",
      "\n",
      "Epoch 27:\n",
      "Training loss: 0.4099, Training accuracy: 0.7555\n",
      "Validation loss: 0.8742, Validation accuracy: 0.7058\n",
      "\n",
      "Epoch 28:\n",
      "Training loss: 0.4071, Training accuracy: 0.7566\n",
      "Validation loss: 1.5045, Validation accuracy: 0.5566\n",
      "\n",
      "Epoch 29:\n",
      "Training loss: 0.4095, Training accuracy: 0.7568\n",
      "Validation loss: 0.9182, Validation accuracy: 0.6941\n",
      "\n",
      "Epoch 30:\n",
      "Training loss: 0.4034, Training accuracy: 0.7595\n",
      "Validation loss: 0.8144, Validation accuracy: 0.7240\n",
      "\n",
      "Epoch 31:\n",
      "Training loss: 0.4094, Training accuracy: 0.7548\n",
      "Validation loss: 0.8215, Validation accuracy: 0.7232\n",
      "\n",
      "Epoch 32:\n",
      "Training loss: 0.4056, Training accuracy: 0.7578\n",
      "Validation loss: 0.7322, Validation accuracy: 0.7476\n",
      "\n",
      "Epoch 33:\n",
      "Training loss: 0.4026, Training accuracy: 0.7617\n",
      "Validation loss: 0.8634, Validation accuracy: 0.7055\n",
      "\n",
      "Epoch 34:\n",
      "Training loss: 0.4065, Training accuracy: 0.7574\n",
      "Validation loss: 0.7560, Validation accuracy: 0.7397\n",
      "\n",
      "Epoch 35:\n",
      "Training loss: 0.4024, Training accuracy: 0.7615\n",
      "Validation loss: 0.9377, Validation accuracy: 0.6867\n",
      "\n",
      "Epoch 36:\n",
      "Training loss: 0.4038, Training accuracy: 0.7592\n",
      "Validation loss: 0.8600, Validation accuracy: 0.7088\n",
      "\n",
      "Epoch 37:\n",
      "Training loss: 0.4004, Training accuracy: 0.7601\n",
      "Validation loss: 0.7930, Validation accuracy: 0.7253\n",
      "\n",
      "Epoch 38:\n",
      "Training loss: 0.4005, Training accuracy: 0.7632\n",
      "Validation loss: 0.8656, Validation accuracy: 0.7068\n",
      "\n",
      "Epoch 39:\n",
      "Training loss: 0.4001, Training accuracy: 0.7611\n",
      "Validation loss: 0.7960, Validation accuracy: 0.7205\n",
      "\n",
      "Current learning rate has decayed to 0.010000\n",
      "Epoch 40:\n",
      "Training loss: 0.2809, Training accuracy: 0.8369\n",
      "Validation loss: 0.4543, Validation accuracy: 0.8464\n",
      "Saving ...\n",
      "\n",
      "Epoch 41:\n",
      "Training loss: 0.2480, Training accuracy: 0.8577\n",
      "Validation loss: 0.4193, Validation accuracy: 0.8572\n",
      "Saving ...\n",
      "\n",
      "Epoch 42:\n",
      "Training loss: 0.2357, Training accuracy: 0.8642\n",
      "Validation loss: 0.4128, Validation accuracy: 0.8598\n",
      "Saving ...\n",
      "\n",
      "Epoch 43:\n",
      "Training loss: 0.2256, Training accuracy: 0.8695\n",
      "Validation loss: 0.4084, Validation accuracy: 0.8615\n",
      "Saving ...\n",
      "\n",
      "Epoch 44:\n",
      "Training loss: 0.2188, Training accuracy: 0.8730\n",
      "Validation loss: 0.4066, Validation accuracy: 0.8640\n",
      "Saving ...\n",
      "\n",
      "Epoch 45:\n",
      "Training loss: 0.2121, Training accuracy: 0.8773\n",
      "Validation loss: 0.3875, Validation accuracy: 0.8681\n",
      "Saving ...\n",
      "\n",
      "Epoch 46:\n",
      "Training loss: 0.2082, Training accuracy: 0.8821\n",
      "Validation loss: 0.4048, Validation accuracy: 0.8640\n",
      "\n",
      "Epoch 47:\n",
      "Training loss: 0.2018, Training accuracy: 0.8847\n",
      "Validation loss: 0.4117, Validation accuracy: 0.8636\n",
      "\n",
      "Epoch 48:\n",
      "Training loss: 0.2007, Training accuracy: 0.8856\n",
      "Validation loss: 0.3951, Validation accuracy: 0.8641\n",
      "\n",
      "Epoch 49:\n",
      "Training loss: 0.1963, Training accuracy: 0.8888\n",
      "Validation loss: 0.4092, Validation accuracy: 0.8632\n",
      "\n",
      "Epoch 50:\n",
      "Training loss: 0.1955, Training accuracy: 0.8877\n",
      "Validation loss: 0.3898, Validation accuracy: 0.8667\n",
      "\n",
      "Epoch 51:\n",
      "Training loss: 0.1918, Training accuracy: 0.8905\n",
      "Validation loss: 0.4353, Validation accuracy: 0.8563\n",
      "\n",
      "Epoch 52:\n",
      "Training loss: 0.1905, Training accuracy: 0.8917\n",
      "Validation loss: 0.4005, Validation accuracy: 0.8695\n",
      "Saving ...\n",
      "\n",
      "Epoch 53:\n",
      "Training loss: 0.1871, Training accuracy: 0.8952\n",
      "Validation loss: 0.3983, Validation accuracy: 0.8627\n",
      "\n",
      "Epoch 54:\n",
      "Training loss: 0.1865, Training accuracy: 0.8948\n",
      "Validation loss: 0.4018, Validation accuracy: 0.8658\n",
      "\n",
      "Epoch 55:\n",
      "Training loss: 0.1871, Training accuracy: 0.8946\n",
      "Validation loss: 0.4016, Validation accuracy: 0.8632\n",
      "\n",
      "Epoch 56:\n",
      "Training loss: 0.1875, Training accuracy: 0.8947\n",
      "Validation loss: 0.4179, Validation accuracy: 0.8617\n",
      "\n",
      "Epoch 57:\n",
      "Training loss: 0.1853, Training accuracy: 0.8951\n",
      "Validation loss: 0.4178, Validation accuracy: 0.8585\n",
      "\n",
      "Epoch 58:\n",
      "Training loss: 0.1835, Training accuracy: 0.8967\n",
      "Validation loss: 0.4033, Validation accuracy: 0.8638\n",
      "\n",
      "Epoch 59:\n",
      "Training loss: 0.1832, Training accuracy: 0.8955\n",
      "Validation loss: 0.4294, Validation accuracy: 0.8565\n",
      "\n",
      "Epoch 60:\n",
      "Training loss: 0.1836, Training accuracy: 0.8965\n",
      "Validation loss: 0.3816, Validation accuracy: 0.8702\n",
      "Saving ...\n",
      "\n",
      "Epoch 61:\n",
      "Training loss: 0.1821, Training accuracy: 0.8957\n",
      "Validation loss: 0.4141, Validation accuracy: 0.8598\n",
      "\n",
      "Epoch 62:\n",
      "Training loss: 0.1798, Training accuracy: 0.8985\n",
      "Validation loss: 0.4242, Validation accuracy: 0.8597\n",
      "\n",
      "Epoch 63:\n",
      "Training loss: 0.1804, Training accuracy: 0.8987\n",
      "Validation loss: 0.4138, Validation accuracy: 0.8615\n",
      "\n",
      "Epoch 64:\n",
      "Training loss: 0.1775, Training accuracy: 0.9006\n",
      "Validation loss: 0.4084, Validation accuracy: 0.8614\n",
      "\n",
      "Epoch 65:\n",
      "Training loss: 0.1762, Training accuracy: 0.9017\n",
      "Validation loss: 0.4665, Validation accuracy: 0.8441\n",
      "\n",
      "Epoch 66:\n",
      "Training loss: 0.1780, Training accuracy: 0.9000\n",
      "Validation loss: 0.4046, Validation accuracy: 0.8656\n",
      "\n",
      "Epoch 67:\n",
      "Training loss: 0.1772, Training accuracy: 0.9011\n",
      "Validation loss: 0.4372, Validation accuracy: 0.8546\n",
      "\n",
      "Epoch 68:\n",
      "Training loss: 0.1748, Training accuracy: 0.9032\n",
      "Validation loss: 0.4159, Validation accuracy: 0.8583\n",
      "\n",
      "Epoch 69:\n",
      "Training loss: 0.1739, Training accuracy: 0.9024\n",
      "Validation loss: 0.4172, Validation accuracy: 0.8615\n",
      "\n",
      "Epoch 70:\n",
      "Training loss: 0.1727, Training accuracy: 0.9036\n",
      "Validation loss: 0.4007, Validation accuracy: 0.8676\n",
      "\n",
      "Epoch 71:\n",
      "Training loss: 0.1722, Training accuracy: 0.9043\n",
      "Validation loss: 0.4068, Validation accuracy: 0.8632\n",
      "\n",
      "Epoch 72:\n",
      "Training loss: 0.1702, Training accuracy: 0.9040\n",
      "Validation loss: 0.3909, Validation accuracy: 0.8665\n",
      "\n",
      "Epoch 73:\n",
      "Training loss: 0.1716, Training accuracy: 0.9041\n",
      "Validation loss: 0.4303, Validation accuracy: 0.8559\n",
      "\n",
      "Epoch 74:\n",
      "Training loss: 0.1666, Training accuracy: 0.9089\n",
      "Validation loss: 0.3989, Validation accuracy: 0.8678\n",
      "\n",
      "Epoch 75:\n",
      "Training loss: 0.1695, Training accuracy: 0.9061\n",
      "Validation loss: 0.4021, Validation accuracy: 0.8659\n",
      "\n",
      "Epoch 76:\n",
      "Training loss: 0.1663, Training accuracy: 0.9071\n",
      "Validation loss: 0.4609, Validation accuracy: 0.8479\n",
      "\n",
      "Epoch 77:\n",
      "Training loss: 0.1678, Training accuracy: 0.9063\n",
      "Validation loss: 0.3920, Validation accuracy: 0.8673\n",
      "\n",
      "Epoch 78:\n",
      "Training loss: 0.1648, Training accuracy: 0.9080\n",
      "Validation loss: 0.3769, Validation accuracy: 0.8735\n",
      "Saving ...\n",
      "\n",
      "Epoch 79:\n",
      "Training loss: 0.1615, Training accuracy: 0.9104\n",
      "Validation loss: 0.4229, Validation accuracy: 0.8571\n",
      "\n",
      "Current learning rate has decayed to 0.001000\n",
      "Epoch 80:\n",
      "Training loss: 0.1178, Training accuracy: 0.9400\n",
      "Validation loss: 0.3115, Validation accuracy: 0.8954\n",
      "Saving ...\n",
      "\n",
      "Epoch 81:\n",
      "Training loss: 0.1011, Training accuracy: 0.9510\n",
      "Validation loss: 0.3056, Validation accuracy: 0.8961\n",
      "Saving ...\n",
      "\n",
      "Epoch 82:\n",
      "Training loss: 0.0935, Training accuracy: 0.9570\n",
      "Validation loss: 0.3065, Validation accuracy: 0.8980\n",
      "Saving ...\n",
      "\n",
      "Epoch 83:\n",
      "Training loss: 0.0895, Training accuracy: 0.9591\n",
      "Validation loss: 0.3028, Validation accuracy: 0.8981\n",
      "Saving ...\n",
      "\n",
      "Epoch 84:\n",
      "Training loss: 0.0854, Training accuracy: 0.9610\n",
      "Validation loss: 0.3034, Validation accuracy: 0.8994\n",
      "Saving ...\n",
      "\n",
      "Epoch 85:\n",
      "Training loss: 0.0828, Training accuracy: 0.9634\n",
      "Validation loss: 0.3084, Validation accuracy: 0.8985\n",
      "\n",
      "Epoch 86:\n",
      "Training loss: 0.0803, Training accuracy: 0.9649\n",
      "Validation loss: 0.3072, Validation accuracy: 0.8983\n",
      "\n",
      "Epoch 87:\n",
      "Training loss: 0.0789, Training accuracy: 0.9645\n",
      "Validation loss: 0.3059, Validation accuracy: 0.8973\n",
      "\n",
      "Epoch 88:\n",
      "Training loss: 0.0753, Training accuracy: 0.9676\n",
      "Validation loss: 0.3022, Validation accuracy: 0.8996\n",
      "Saving ...\n",
      "\n",
      "Epoch 89:\n",
      "Training loss: 0.0754, Training accuracy: 0.9681\n",
      "Validation loss: 0.3038, Validation accuracy: 0.9004\n",
      "Saving ...\n",
      "\n",
      "Epoch 90:\n",
      "Training loss: 0.0723, Training accuracy: 0.9694\n",
      "Validation loss: 0.3033, Validation accuracy: 0.8998\n",
      "\n",
      "Epoch 91:\n",
      "Training loss: 0.0718, Training accuracy: 0.9700\n",
      "Validation loss: 0.3039, Validation accuracy: 0.9006\n",
      "Saving ...\n",
      "\n",
      "Epoch 92:\n",
      "Training loss: 0.0703, Training accuracy: 0.9705\n",
      "Validation loss: 0.3041, Validation accuracy: 0.9007\n",
      "Saving ...\n",
      "\n",
      "Epoch 93:\n",
      "Training loss: 0.0678, Training accuracy: 0.9725\n",
      "Validation loss: 0.3077, Validation accuracy: 0.8988\n",
      "\n",
      "Epoch 94:\n",
      "Training loss: 0.0682, Training accuracy: 0.9721\n",
      "Validation loss: 0.3077, Validation accuracy: 0.8999\n",
      "\n",
      "Epoch 95:\n",
      "Training loss: 0.0655, Training accuracy: 0.9747\n",
      "Validation loss: 0.3083, Validation accuracy: 0.9001\n",
      "\n",
      "Epoch 96:\n",
      "Training loss: 0.0650, Training accuracy: 0.9745\n",
      "Validation loss: 0.3113, Validation accuracy: 0.8980\n",
      "\n",
      "Epoch 97:\n",
      "Training loss: 0.0638, Training accuracy: 0.9752\n",
      "Validation loss: 0.3151, Validation accuracy: 0.8964\n",
      "\n",
      "Epoch 98:\n",
      "Training loss: 0.0633, Training accuracy: 0.9762\n",
      "Validation loss: 0.3073, Validation accuracy: 0.9001\n",
      "\n",
      "Epoch 99:\n",
      "Training loss: 0.0623, Training accuracy: 0.9761\n",
      "Validation loss: 0.3118, Validation accuracy: 0.9008\n",
      "Saving ...\n",
      "\n",
      "Epoch 100:\n",
      "Training loss: 0.0601, Training accuracy: 0.9775\n",
      "Validation loss: 0.3179, Validation accuracy: 0.8986\n",
      "\n",
      "Epoch 101:\n",
      "Training loss: 0.0606, Training accuracy: 0.9773\n",
      "Validation loss: 0.3155, Validation accuracy: 0.9013\n",
      "Saving ...\n",
      "\n",
      "Epoch 102:\n",
      "Training loss: 0.0588, Training accuracy: 0.9783\n",
      "Validation loss: 0.3143, Validation accuracy: 0.9002\n",
      "\n",
      "Epoch 103:\n",
      "Training loss: 0.0570, Training accuracy: 0.9794\n",
      "Validation loss: 0.3148, Validation accuracy: 0.9004\n",
      "\n",
      "Epoch 104:\n",
      "Training loss: 0.0567, Training accuracy: 0.9798\n",
      "Validation loss: 0.3191, Validation accuracy: 0.8989\n",
      "\n",
      "Epoch 105:\n",
      "Training loss: 0.0568, Training accuracy: 0.9797\n",
      "Validation loss: 0.3118, Validation accuracy: 0.9018\n",
      "Saving ...\n",
      "\n",
      "Epoch 106:\n",
      "Training loss: 0.0560, Training accuracy: 0.9796\n",
      "Validation loss: 0.3169, Validation accuracy: 0.8994\n",
      "\n",
      "Epoch 107:\n",
      "Training loss: 0.0547, Training accuracy: 0.9816\n",
      "Validation loss: 0.3172, Validation accuracy: 0.9008\n",
      "\n",
      "Epoch 108:\n",
      "Training loss: 0.0542, Training accuracy: 0.9813\n",
      "Validation loss: 0.3197, Validation accuracy: 0.8973\n",
      "\n",
      "Epoch 109:\n",
      "Training loss: 0.0541, Training accuracy: 0.9808\n",
      "Validation loss: 0.3170, Validation accuracy: 0.9030\n",
      "Saving ...\n",
      "\n",
      "Epoch 110:\n",
      "Training loss: 0.0527, Training accuracy: 0.9821\n",
      "Validation loss: 0.3196, Validation accuracy: 0.9000\n",
      "\n",
      "Epoch 111:\n",
      "Training loss: 0.0534, Training accuracy: 0.9819\n",
      "Validation loss: 0.3199, Validation accuracy: 0.9011\n",
      "\n",
      "Epoch 112:\n",
      "Training loss: 0.0526, Training accuracy: 0.9821\n",
      "Validation loss: 0.3224, Validation accuracy: 0.8992\n",
      "\n",
      "Epoch 113:\n",
      "Training loss: 0.0500, Training accuracy: 0.9844\n",
      "Validation loss: 0.3191, Validation accuracy: 0.9016\n",
      "\n",
      "Epoch 114:\n",
      "Training loss: 0.0508, Training accuracy: 0.9830\n",
      "Validation loss: 0.3246, Validation accuracy: 0.8992\n",
      "\n",
      "Epoch 115:\n",
      "Training loss: 0.0511, Training accuracy: 0.9830\n",
      "Validation loss: 0.3261, Validation accuracy: 0.8988\n",
      "\n",
      "Epoch 116:\n",
      "Training loss: 0.0503, Training accuracy: 0.9835\n",
      "Validation loss: 0.3263, Validation accuracy: 0.8991\n",
      "\n",
      "Epoch 117:\n",
      "Training loss: 0.0502, Training accuracy: 0.9832\n",
      "Validation loss: 0.3241, Validation accuracy: 0.9000\n",
      "\n",
      "Epoch 118:\n",
      "Training loss: 0.0483, Training accuracy: 0.9847\n",
      "Validation loss: 0.3285, Validation accuracy: 0.9002\n",
      "\n",
      "Epoch 119:\n",
      "Training loss: 0.0486, Training accuracy: 0.9849\n",
      "Validation loss: 0.3273, Validation accuracy: 0.8994\n",
      "\n",
      "Epoch 120:\n",
      "Training loss: 0.0466, Training accuracy: 0.9856\n",
      "Validation loss: 0.3306, Validation accuracy: 0.8984\n",
      "\n",
      "Epoch 121:\n",
      "Training loss: 0.0463, Training accuracy: 0.9862\n",
      "Validation loss: 0.3283, Validation accuracy: 0.8990\n",
      "\n",
      "Epoch 122:\n",
      "Training loss: 0.0461, Training accuracy: 0.9856\n",
      "Validation loss: 0.3285, Validation accuracy: 0.9018\n",
      "\n",
      "Epoch 123:\n",
      "Training loss: 0.0447, Training accuracy: 0.9868\n",
      "Validation loss: 0.3337, Validation accuracy: 0.8986\n",
      "\n",
      "Epoch 124:\n",
      "Training loss: 0.0455, Training accuracy: 0.9863\n",
      "Validation loss: 0.3351, Validation accuracy: 0.8987\n",
      "\n",
      "Epoch 125:\n",
      "Training loss: 0.0442, Training accuracy: 0.9869\n",
      "Validation loss: 0.3351, Validation accuracy: 0.8981\n",
      "\n",
      "Epoch 126:\n",
      "Training loss: 0.0445, Training accuracy: 0.9867\n",
      "Validation loss: 0.3359, Validation accuracy: 0.8980\n",
      "\n",
      "Epoch 127:\n",
      "Training loss: 0.0454, Training accuracy: 0.9860\n",
      "Validation loss: 0.3278, Validation accuracy: 0.9005\n",
      "\n",
      "Epoch 128:\n",
      "Training loss: 0.0438, Training accuracy: 0.9873\n",
      "Validation loss: 0.3382, Validation accuracy: 0.8986\n",
      "\n",
      "Epoch 129:\n",
      "Training loss: 0.0439, Training accuracy: 0.9865\n",
      "Validation loss: 0.3340, Validation accuracy: 0.8995\n",
      "\n",
      "Epoch 130:\n",
      "Training loss: 0.0438, Training accuracy: 0.9876\n",
      "Validation loss: 0.3279, Validation accuracy: 0.9008\n",
      "\n",
      "Epoch 131:\n",
      "Training loss: 0.0430, Training accuracy: 0.9874\n",
      "Validation loss: 0.3315, Validation accuracy: 0.8980\n",
      "\n",
      "Epoch 132:\n",
      "Training loss: 0.0422, Training accuracy: 0.9879\n",
      "Validation loss: 0.3313, Validation accuracy: 0.8998\n",
      "\n",
      "Epoch 133:\n",
      "Training loss: 0.0419, Training accuracy: 0.9885\n",
      "Validation loss: 0.3368, Validation accuracy: 0.9004\n",
      "\n",
      "Epoch 134:\n",
      "Training loss: 0.0426, Training accuracy: 0.9873\n",
      "Validation loss: 0.3356, Validation accuracy: 0.8993\n",
      "\n",
      "Epoch 135:\n",
      "Training loss: 0.0419, Training accuracy: 0.9880\n",
      "Validation loss: 0.3395, Validation accuracy: 0.8976\n",
      "\n",
      "Epoch 136:\n",
      "Training loss: 0.0417, Training accuracy: 0.9879\n",
      "Validation loss: 0.3359, Validation accuracy: 0.8984\n",
      "\n",
      "Epoch 137:\n",
      "Training loss: 0.0415, Training accuracy: 0.9882\n",
      "Validation loss: 0.3347, Validation accuracy: 0.9019\n",
      "\n",
      "Epoch 138:\n",
      "Training loss: 0.0406, Training accuracy: 0.9894\n",
      "Validation loss: 0.3395, Validation accuracy: 0.8968\n",
      "\n",
      "Epoch 139:\n",
      "Training loss: 0.0409, Training accuracy: 0.9881\n",
      "Validation loss: 0.3519, Validation accuracy: 0.8973\n",
      "\n",
      "Epoch 140:\n",
      "Training loss: 0.0404, Training accuracy: 0.9885\n",
      "Validation loss: 0.3458, Validation accuracy: 0.8999\n",
      "\n",
      "Epoch 141:\n",
      "Training loss: 0.0391, Training accuracy: 0.9900\n",
      "Validation loss: 0.3494, Validation accuracy: 0.8970\n",
      "\n",
      "Epoch 142:\n",
      "Training loss: 0.0392, Training accuracy: 0.9893\n",
      "Validation loss: 0.3411, Validation accuracy: 0.8972\n",
      "\n",
      "Epoch 143:\n",
      "Training loss: 0.0405, Training accuracy: 0.9886\n",
      "Validation loss: 0.3481, Validation accuracy: 0.8985\n",
      "\n",
      "Epoch 144:\n",
      "Training loss: 0.0386, Training accuracy: 0.9899\n",
      "Validation loss: 0.3418, Validation accuracy: 0.8987\n",
      "\n",
      "Epoch 145:\n",
      "Training loss: 0.0386, Training accuracy: 0.9895\n",
      "Validation loss: 0.3483, Validation accuracy: 0.8987\n",
      "\n",
      "Epoch 146:\n",
      "Training loss: 0.0387, Training accuracy: 0.9901\n",
      "Validation loss: 0.3409, Validation accuracy: 0.9010\n",
      "\n",
      "Epoch 147:\n",
      "Training loss: 0.0398, Training accuracy: 0.9886\n",
      "Validation loss: 0.3412, Validation accuracy: 0.8991\n",
      "\n",
      "Epoch 148:\n",
      "Training loss: 0.0374, Training accuracy: 0.9902\n",
      "Validation loss: 0.3498, Validation accuracy: 0.8987\n",
      "\n",
      "Epoch 149:\n",
      "Training loss: 0.0380, Training accuracy: 0.9901\n",
      "Validation loss: 0.3512, Validation accuracy: 0.8997\n",
      "\n",
      "Epoch 150:\n",
      "Training loss: 0.0374, Training accuracy: 0.9910\n",
      "Validation loss: 0.3454, Validation accuracy: 0.9012\n",
      "\n",
      "Epoch 151:\n",
      "Training loss: 0.0371, Training accuracy: 0.9906\n",
      "Validation loss: 0.3474, Validation accuracy: 0.8988\n",
      "\n",
      "Epoch 152:\n",
      "Training loss: 0.0374, Training accuracy: 0.9906\n",
      "Validation loss: 0.3556, Validation accuracy: 0.8988\n",
      "\n",
      "Epoch 153:\n",
      "Training loss: 0.0377, Training accuracy: 0.9900\n",
      "Validation loss: 0.3495, Validation accuracy: 0.9001\n",
      "\n",
      "Epoch 154:\n",
      "Training loss: 0.0372, Training accuracy: 0.9901\n",
      "Validation loss: 0.3451, Validation accuracy: 0.8997\n",
      "\n",
      "Epoch 155:\n",
      "Training loss: 0.0370, Training accuracy: 0.9907\n",
      "Validation loss: 0.3485, Validation accuracy: 0.8995\n",
      "\n",
      "Epoch 156:\n",
      "Training loss: 0.0356, Training accuracy: 0.9914\n",
      "Validation loss: 0.3527, Validation accuracy: 0.8985\n",
      "\n",
      "Epoch 157:\n",
      "Training loss: 0.0367, Training accuracy: 0.9901\n",
      "Validation loss: 0.3530, Validation accuracy: 0.8986\n",
      "\n",
      "Epoch 158:\n",
      "Training loss: 0.0364, Training accuracy: 0.9911\n",
      "Validation loss: 0.3558, Validation accuracy: 0.8988\n",
      "\n",
      "Epoch 159:\n",
      "Training loss: 0.0359, Training accuracy: 0.9907\n",
      "Validation loss: 0.3526, Validation accuracy: 0.8981\n",
      "\n",
      "Current learning rate has decayed to 0.000100\n",
      "Epoch 160:\n",
      "Training loss: 0.0314, Training accuracy: 0.9931\n",
      "Validation loss: 0.3440, Validation accuracy: 0.8993\n",
      "\n",
      "Epoch 161:\n",
      "Training loss: 0.0304, Training accuracy: 0.9942\n",
      "Validation loss: 0.3417, Validation accuracy: 0.8995\n",
      "\n",
      "Epoch 162:\n",
      "Training loss: 0.0290, Training accuracy: 0.9950\n",
      "Validation loss: 0.3434, Validation accuracy: 0.9007\n",
      "\n",
      "Epoch 163:\n",
      "Training loss: 0.0285, Training accuracy: 0.9951\n",
      "Validation loss: 0.3412, Validation accuracy: 0.8995\n",
      "\n",
      "Epoch 164:\n",
      "Training loss: 0.0288, Training accuracy: 0.9951\n",
      "Validation loss: 0.3427, Validation accuracy: 0.8995\n",
      "\n",
      "Epoch 165:\n",
      "Training loss: 0.0290, Training accuracy: 0.9950\n",
      "Validation loss: 0.3410, Validation accuracy: 0.9023\n",
      "\n",
      "Epoch 166:\n",
      "Training loss: 0.0288, Training accuracy: 0.9947\n",
      "Validation loss: 0.3425, Validation accuracy: 0.9017\n",
      "\n",
      "Epoch 167:\n",
      "Training loss: 0.0273, Training accuracy: 0.9956\n",
      "Validation loss: 0.3429, Validation accuracy: 0.9003\n",
      "\n",
      "Epoch 168:\n",
      "Training loss: 0.0273, Training accuracy: 0.9957\n",
      "Validation loss: 0.3414, Validation accuracy: 0.9013\n",
      "\n",
      "Epoch 169:\n",
      "Training loss: 0.0275, Training accuracy: 0.9954\n",
      "Validation loss: 0.3378, Validation accuracy: 0.9033\n",
      "Saving ...\n",
      "\n",
      "Epoch 170:\n",
      "Training loss: 0.0276, Training accuracy: 0.9954\n",
      "Validation loss: 0.3413, Validation accuracy: 0.9030\n",
      "\n",
      "Epoch 171:\n",
      "Training loss: 0.0272, Training accuracy: 0.9957\n",
      "Validation loss: 0.3423, Validation accuracy: 0.9008\n",
      "\n",
      "Epoch 172:\n",
      "Training loss: 0.0270, Training accuracy: 0.9959\n",
      "Validation loss: 0.3419, Validation accuracy: 0.9028\n",
      "\n",
      "Epoch 173:\n",
      "Training loss: 0.0269, Training accuracy: 0.9956\n",
      "Validation loss: 0.3424, Validation accuracy: 0.9023\n",
      "\n",
      "Epoch 174:\n",
      "Training loss: 0.0268, Training accuracy: 0.9959\n",
      "Validation loss: 0.3403, Validation accuracy: 0.9024\n",
      "\n",
      "Epoch 175:\n",
      "Training loss: 0.0269, Training accuracy: 0.9958\n",
      "Validation loss: 0.3386, Validation accuracy: 0.9024\n",
      "\n",
      "Epoch 176:\n",
      "Training loss: 0.0260, Training accuracy: 0.9965\n",
      "Validation loss: 0.3409, Validation accuracy: 0.9033\n",
      "\n",
      "Epoch 177:\n",
      "Training loss: 0.0263, Training accuracy: 0.9961\n",
      "Validation loss: 0.3409, Validation accuracy: 0.9021\n",
      "\n",
      "Epoch 178:\n",
      "Training loss: 0.0268, Training accuracy: 0.9959\n",
      "Validation loss: 0.3398, Validation accuracy: 0.9038\n",
      "Saving ...\n",
      "\n",
      "Epoch 179:\n",
      "Training loss: 0.0262, Training accuracy: 0.9964\n",
      "Validation loss: 0.3399, Validation accuracy: 0.9030\n",
      "\n",
      "Epoch 180:\n",
      "Training loss: 0.0262, Training accuracy: 0.9964\n",
      "Validation loss: 0.3452, Validation accuracy: 0.9016\n",
      "\n",
      "Epoch 181:\n",
      "Training loss: 0.0267, Training accuracy: 0.9957\n",
      "Validation loss: 0.3432, Validation accuracy: 0.9025\n",
      "\n",
      "Epoch 182:\n",
      "Training loss: 0.0264, Training accuracy: 0.9961\n",
      "Validation loss: 0.3436, Validation accuracy: 0.9015\n",
      "\n",
      "Epoch 183:\n",
      "Training loss: 0.0259, Training accuracy: 0.9966\n",
      "Validation loss: 0.3418, Validation accuracy: 0.9029\n",
      "\n",
      "Epoch 184:\n",
      "Training loss: 0.0255, Training accuracy: 0.9967\n",
      "Validation loss: 0.3427, Validation accuracy: 0.9009\n",
      "\n",
      "Epoch 185:\n",
      "Training loss: 0.0260, Training accuracy: 0.9961\n",
      "Validation loss: 0.3420, Validation accuracy: 0.9019\n",
      "\n",
      "Epoch 186:\n",
      "Training loss: 0.0259, Training accuracy: 0.9964\n",
      "Validation loss: 0.3415, Validation accuracy: 0.9013\n",
      "\n",
      "Epoch 187:\n",
      "Training loss: 0.0261, Training accuracy: 0.9964\n",
      "Validation loss: 0.3410, Validation accuracy: 0.9021\n",
      "\n",
      "Epoch 188:\n",
      "Training loss: 0.0256, Training accuracy: 0.9965\n",
      "Validation loss: 0.3430, Validation accuracy: 0.9026\n",
      "\n",
      "Epoch 189:\n",
      "Training loss: 0.0256, Training accuracy: 0.9961\n",
      "Validation loss: 0.3453, Validation accuracy: 0.9011\n",
      "\n",
      "Epoch 190:\n",
      "Training loss: 0.0257, Training accuracy: 0.9967\n",
      "Validation loss: 0.3443, Validation accuracy: 0.9007\n",
      "\n",
      "Epoch 191:\n",
      "Training loss: 0.0259, Training accuracy: 0.9962\n",
      "Validation loss: 0.3429, Validation accuracy: 0.9024\n",
      "\n",
      "Epoch 192:\n",
      "Training loss: 0.0256, Training accuracy: 0.9962\n",
      "Validation loss: 0.3426, Validation accuracy: 0.9037\n",
      "\n",
      "Epoch 193:\n",
      "Training loss: 0.0254, Training accuracy: 0.9965\n",
      "Validation loss: 0.3422, Validation accuracy: 0.9024\n",
      "\n",
      "Epoch 194:\n",
      "Training loss: 0.0250, Training accuracy: 0.9970\n",
      "Validation loss: 0.3444, Validation accuracy: 0.9023\n",
      "\n",
      "Epoch 195:\n",
      "Training loss: 0.0255, Training accuracy: 0.9966\n",
      "Validation loss: 0.3412, Validation accuracy: 0.9020\n",
      "\n",
      "Epoch 196:\n",
      "Training loss: 0.0254, Training accuracy: 0.9965\n",
      "Validation loss: 0.3430, Validation accuracy: 0.9032\n",
      "\n",
      "Epoch 197:\n",
      "Training loss: 0.0253, Training accuracy: 0.9968\n",
      "Validation loss: 0.3446, Validation accuracy: 0.9023\n",
      "\n",
      "Epoch 198:\n",
      "Training loss: 0.0251, Training accuracy: 0.9967\n",
      "Validation loss: 0.3458, Validation accuracy: 0.9018\n",
      "\n",
      "Epoch 199:\n",
      "Training loss: 0.0254, Training accuracy: 0.9965\n",
      "Validation loss: 0.3450, Validation accuracy: 0.9030\n",
      "\n",
      "==================================================\n",
      "==> Optimization finished! Best validation accuracy: 0.9038\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9038"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train(T=2,lamb=0.6,alpha=0.4,train_loader=train_loader,val_loader=val_loader,INITIAL_LR=0.1,DECAY_EPOCHS=[40,80,160],DECAY=0.1,EPOCHS=200,REG = 4e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Training starts!\n",
      "==================================================\n",
      "Epoch 0:\n",
      "Training loss: 1.6047, Training accuracy: 0.3300\n",
      "Validation loss: 1.7521, Validation accuracy: 0.4322\n",
      "Saving ...\n",
      "\n",
      "Epoch 1:\n",
      "Training loss: 1.1887, Training accuracy: 0.4625\n",
      "Validation loss: 1.3359, Validation accuracy: 0.5349\n",
      "Saving ...\n",
      "\n",
      "Epoch 2:\n",
      "Training loss: 1.0125, Training accuracy: 0.5414\n",
      "Validation loss: 1.4947, Validation accuracy: 0.5702\n",
      "Saving ...\n",
      "\n",
      "Epoch 3:\n",
      "Training loss: 0.9082, Training accuracy: 0.5865\n",
      "Validation loss: 1.3701, Validation accuracy: 0.5515\n",
      "\n",
      "Epoch 4:\n",
      "Training loss: 0.8204, Training accuracy: 0.6298\n",
      "Validation loss: 1.1028, Validation accuracy: 0.6271\n",
      "Saving ...\n",
      "\n",
      "Epoch 5:\n",
      "Training loss: 0.7654, Training accuracy: 0.6551\n",
      "Validation loss: 1.0836, Validation accuracy: 0.6329\n",
      "Saving ...\n",
      "\n",
      "Epoch 6:\n",
      "Training loss: 0.7258, Training accuracy: 0.6757\n",
      "Validation loss: 0.9933, Validation accuracy: 0.6625\n",
      "Saving ...\n",
      "\n",
      "Epoch 7:\n",
      "Training loss: 0.6990, Training accuracy: 0.6873\n",
      "Validation loss: 1.0389, Validation accuracy: 0.6352\n",
      "\n",
      "Epoch 8:\n",
      "Training loss: 0.6778, Training accuracy: 0.6974\n",
      "Validation loss: 1.0415, Validation accuracy: 0.6561\n",
      "\n",
      "Epoch 9:\n",
      "Training loss: 0.6652, Training accuracy: 0.7043\n",
      "Validation loss: 0.9870, Validation accuracy: 0.6690\n",
      "Saving ...\n",
      "\n",
      "Epoch 10:\n",
      "Training loss: 0.4410, Training accuracy: 0.7339\n",
      "Validation loss: 0.8272, Validation accuracy: 0.7136\n",
      "Saving ...\n",
      "\n",
      "Epoch 11:\n",
      "Training loss: 0.4449, Training accuracy: 0.7322\n",
      "Validation loss: 0.8870, Validation accuracy: 0.6931\n",
      "\n",
      "Epoch 12:\n",
      "Training loss: 0.4472, Training accuracy: 0.7313\n",
      "Validation loss: 0.7727, Validation accuracy: 0.7331\n",
      "Saving ...\n",
      "\n",
      "Epoch 13:\n",
      "Training loss: 0.4466, Training accuracy: 0.7317\n",
      "Validation loss: 0.9810, Validation accuracy: 0.6618\n",
      "\n",
      "Epoch 14:\n",
      "Training loss: 0.4415, Training accuracy: 0.7361\n",
      "Validation loss: 1.0848, Validation accuracy: 0.6323\n",
      "\n",
      "Epoch 15:\n",
      "Training loss: 0.4407, Training accuracy: 0.7368\n",
      "Validation loss: 0.8011, Validation accuracy: 0.7262\n",
      "\n",
      "Epoch 16:\n",
      "Training loss: 0.4369, Training accuracy: 0.7390\n",
      "Validation loss: 1.0060, Validation accuracy: 0.6534\n",
      "\n",
      "Epoch 17:\n",
      "Training loss: 0.4297, Training accuracy: 0.7432\n",
      "Validation loss: 0.8605, Validation accuracy: 0.7107\n",
      "\n",
      "Epoch 18:\n",
      "Training loss: 0.4295, Training accuracy: 0.7441\n",
      "Validation loss: 0.7847, Validation accuracy: 0.7257\n",
      "\n",
      "Epoch 19:\n",
      "Training loss: 0.4273, Training accuracy: 0.7472\n",
      "Validation loss: 0.8816, Validation accuracy: 0.7039\n",
      "\n",
      "Epoch 20:\n",
      "Training loss: 0.4250, Training accuracy: 0.7460\n",
      "Validation loss: 1.0222, Validation accuracy: 0.6699\n",
      "\n",
      "Epoch 21:\n",
      "Training loss: 0.4225, Training accuracy: 0.7478\n",
      "Validation loss: 0.9190, Validation accuracy: 0.6949\n",
      "\n",
      "Epoch 22:\n",
      "Training loss: 0.4242, Training accuracy: 0.7477\n",
      "Validation loss: 0.9291, Validation accuracy: 0.6854\n",
      "\n",
      "Epoch 23:\n",
      "Training loss: 0.4205, Training accuracy: 0.7503\n",
      "Validation loss: 0.9513, Validation accuracy: 0.6849\n",
      "\n",
      "Epoch 24:\n",
      "Training loss: 0.4181, Training accuracy: 0.7511\n",
      "Validation loss: 0.9088, Validation accuracy: 0.6923\n",
      "\n",
      "Epoch 25:\n",
      "Training loss: 0.4171, Training accuracy: 0.7523\n",
      "Validation loss: 0.8359, Validation accuracy: 0.7138\n",
      "\n",
      "Epoch 26:\n",
      "Training loss: 0.4135, Training accuracy: 0.7542\n",
      "Validation loss: 0.8322, Validation accuracy: 0.7093\n",
      "\n",
      "Epoch 27:\n",
      "Training loss: 0.4113, Training accuracy: 0.7557\n",
      "Validation loss: 0.8967, Validation accuracy: 0.7000\n",
      "\n",
      "Epoch 28:\n",
      "Training loss: 0.4133, Training accuracy: 0.7541\n",
      "Validation loss: 0.7645, Validation accuracy: 0.7409\n",
      "Saving ...\n",
      "\n",
      "Epoch 29:\n",
      "Training loss: 0.4109, Training accuracy: 0.7545\n",
      "Validation loss: 1.0660, Validation accuracy: 0.6529\n",
      "\n",
      "Epoch 30:\n",
      "Training loss: 0.4082, Training accuracy: 0.7569\n",
      "Validation loss: 0.8572, Validation accuracy: 0.7121\n",
      "\n",
      "Epoch 31:\n",
      "Training loss: 0.4065, Training accuracy: 0.7578\n",
      "Validation loss: 0.7614, Validation accuracy: 0.7377\n",
      "\n",
      "Epoch 32:\n",
      "Training loss: 0.4064, Training accuracy: 0.7585\n",
      "Validation loss: 0.8149, Validation accuracy: 0.7186\n",
      "\n",
      "Epoch 33:\n",
      "Training loss: 0.4085, Training accuracy: 0.7564\n",
      "Validation loss: 0.8206, Validation accuracy: 0.7200\n",
      "\n",
      "Epoch 34:\n",
      "Training loss: 0.4035, Training accuracy: 0.7609\n",
      "Validation loss: 0.8040, Validation accuracy: 0.7278\n",
      "\n",
      "Epoch 35:\n",
      "Training loss: 0.4059, Training accuracy: 0.7590\n",
      "Validation loss: 1.0057, Validation accuracy: 0.6665\n",
      "\n",
      "Epoch 36:\n",
      "Training loss: 0.4030, Training accuracy: 0.7624\n",
      "Validation loss: 0.8229, Validation accuracy: 0.7218\n",
      "\n",
      "Epoch 37:\n",
      "Training loss: 0.4033, Training accuracy: 0.7610\n",
      "Validation loss: 0.7979, Validation accuracy: 0.7248\n",
      "\n",
      "Epoch 38:\n",
      "Training loss: 0.4024, Training accuracy: 0.7613\n",
      "Validation loss: 0.8115, Validation accuracy: 0.7235\n",
      "\n",
      "Epoch 39:\n",
      "Training loss: 0.4011, Training accuracy: 0.7611\n",
      "Validation loss: 0.8035, Validation accuracy: 0.7299\n",
      "\n",
      "Current learning rate has decayed to 0.010000\n",
      "Epoch 40:\n",
      "Training loss: 0.2837, Training accuracy: 0.8367\n",
      "Validation loss: 0.4436, Validation accuracy: 0.8482\n",
      "Saving ...\n",
      "\n",
      "Epoch 41:\n",
      "Training loss: 0.2522, Training accuracy: 0.8551\n",
      "Validation loss: 0.4233, Validation accuracy: 0.8544\n",
      "Saving ...\n",
      "\n",
      "Epoch 42:\n",
      "Training loss: 0.2367, Training accuracy: 0.8637\n",
      "Validation loss: 0.4173, Validation accuracy: 0.8603\n",
      "Saving ...\n",
      "\n",
      "Epoch 43:\n",
      "Training loss: 0.2273, Training accuracy: 0.8699\n",
      "Validation loss: 0.4068, Validation accuracy: 0.8619\n",
      "Saving ...\n",
      "\n",
      "Epoch 44:\n",
      "Training loss: 0.2202, Training accuracy: 0.8751\n",
      "Validation loss: 0.3977, Validation accuracy: 0.8668\n",
      "Saving ...\n",
      "\n",
      "Epoch 45:\n",
      "Training loss: 0.2136, Training accuracy: 0.8780\n",
      "Validation loss: 0.4064, Validation accuracy: 0.8608\n",
      "\n",
      "Epoch 46:\n",
      "Training loss: 0.2086, Training accuracy: 0.8829\n",
      "Validation loss: 0.3858, Validation accuracy: 0.8636\n",
      "\n",
      "Epoch 47:\n",
      "Training loss: 0.2032, Training accuracy: 0.8866\n",
      "Validation loss: 0.4167, Validation accuracy: 0.8612\n",
      "\n",
      "Epoch 48:\n",
      "Training loss: 0.2026, Training accuracy: 0.8854\n",
      "Validation loss: 0.3989, Validation accuracy: 0.8635\n",
      "\n",
      "Epoch 49:\n",
      "Training loss: 0.2003, Training accuracy: 0.8870\n",
      "Validation loss: 0.3937, Validation accuracy: 0.8684\n",
      "Saving ...\n",
      "\n",
      "Epoch 50:\n",
      "Training loss: 0.1952, Training accuracy: 0.8914\n",
      "Validation loss: 0.3939, Validation accuracy: 0.8649\n",
      "\n",
      "Epoch 51:\n",
      "Training loss: 0.1916, Training accuracy: 0.8938\n",
      "Validation loss: 0.3925, Validation accuracy: 0.8692\n",
      "Saving ...\n",
      "\n",
      "Epoch 52:\n",
      "Training loss: 0.1914, Training accuracy: 0.8943\n",
      "Validation loss: 0.4187, Validation accuracy: 0.8569\n",
      "\n",
      "Epoch 53:\n",
      "Training loss: 0.1915, Training accuracy: 0.8936\n",
      "Validation loss: 0.3950, Validation accuracy: 0.8633\n",
      "\n",
      "Epoch 54:\n",
      "Training loss: 0.1894, Training accuracy: 0.8955\n",
      "Validation loss: 0.4109, Validation accuracy: 0.8587\n",
      "\n",
      "Epoch 55:\n",
      "Training loss: 0.1882, Training accuracy: 0.8958\n",
      "Validation loss: 0.4148, Validation accuracy: 0.8631\n",
      "\n",
      "Epoch 56:\n",
      "Training loss: 0.1873, Training accuracy: 0.8954\n",
      "Validation loss: 0.4263, Validation accuracy: 0.8571\n",
      "\n",
      "Epoch 57:\n",
      "Training loss: 0.1847, Training accuracy: 0.8989\n",
      "Validation loss: 0.4384, Validation accuracy: 0.8520\n",
      "\n",
      "Epoch 58:\n",
      "Training loss: 0.1875, Training accuracy: 0.8954\n",
      "Validation loss: 0.3984, Validation accuracy: 0.8653\n",
      "\n",
      "Epoch 59:\n",
      "Training loss: 0.1845, Training accuracy: 0.8991\n",
      "Validation loss: 0.4429, Validation accuracy: 0.8510\n",
      "\n",
      "Epoch 60:\n",
      "Training loss: 0.1826, Training accuracy: 0.8982\n",
      "Validation loss: 0.4156, Validation accuracy: 0.8606\n",
      "\n",
      "Epoch 61:\n",
      "Training loss: 0.1836, Training accuracy: 0.8990\n",
      "Validation loss: 0.4045, Validation accuracy: 0.8647\n",
      "\n",
      "Epoch 62:\n",
      "Training loss: 0.1806, Training accuracy: 0.9005\n",
      "Validation loss: 0.4236, Validation accuracy: 0.8597\n",
      "\n",
      "Epoch 63:\n",
      "Training loss: 0.1819, Training accuracy: 0.8998\n",
      "Validation loss: 0.4462, Validation accuracy: 0.8510\n",
      "\n",
      "Epoch 64:\n",
      "Training loss: 0.1813, Training accuracy: 0.9011\n",
      "Validation loss: 0.4370, Validation accuracy: 0.8558\n",
      "\n",
      "Epoch 65:\n",
      "Training loss: 0.1773, Training accuracy: 0.9037\n",
      "Validation loss: 0.4423, Validation accuracy: 0.8524\n",
      "\n",
      "Epoch 66:\n",
      "Training loss: 0.1777, Training accuracy: 0.9027\n",
      "Validation loss: 0.4285, Validation accuracy: 0.8587\n",
      "\n",
      "Epoch 67:\n",
      "Training loss: 0.1774, Training accuracy: 0.9021\n",
      "Validation loss: 0.4118, Validation accuracy: 0.8647\n",
      "\n",
      "Epoch 68:\n",
      "Training loss: 0.1753, Training accuracy: 0.9045\n",
      "Validation loss: 0.4227, Validation accuracy: 0.8572\n",
      "\n",
      "Epoch 69:\n",
      "Training loss: 0.1778, Training accuracy: 0.9033\n",
      "Validation loss: 0.4028, Validation accuracy: 0.8661\n",
      "\n",
      "Epoch 70:\n",
      "Training loss: 0.1742, Training accuracy: 0.9061\n",
      "Validation loss: 0.4036, Validation accuracy: 0.8647\n",
      "\n",
      "Epoch 71:\n",
      "Training loss: 0.1734, Training accuracy: 0.9048\n",
      "Validation loss: 0.4396, Validation accuracy: 0.8566\n",
      "\n",
      "Epoch 72:\n",
      "Training loss: 0.1758, Training accuracy: 0.9042\n",
      "Validation loss: 0.4079, Validation accuracy: 0.8654\n",
      "\n",
      "Epoch 73:\n",
      "Training loss: 0.1722, Training accuracy: 0.9061\n",
      "Validation loss: 0.4140, Validation accuracy: 0.8596\n",
      "\n",
      "Epoch 74:\n",
      "Training loss: 0.1721, Training accuracy: 0.9075\n",
      "Validation loss: 0.4787, Validation accuracy: 0.8423\n",
      "\n",
      "Epoch 75:\n",
      "Training loss: 0.1711, Training accuracy: 0.9073\n",
      "Validation loss: 0.4513, Validation accuracy: 0.8494\n",
      "\n",
      "Epoch 76:\n",
      "Training loss: 0.1708, Training accuracy: 0.9075\n",
      "Validation loss: 0.3927, Validation accuracy: 0.8677\n",
      "\n",
      "Epoch 77:\n",
      "Training loss: 0.1684, Training accuracy: 0.9075\n",
      "Validation loss: 0.4058, Validation accuracy: 0.8658\n",
      "\n",
      "Epoch 78:\n",
      "Training loss: 0.1670, Training accuracy: 0.9084\n",
      "Validation loss: 0.4266, Validation accuracy: 0.8600\n",
      "\n",
      "Epoch 79:\n",
      "Training loss: 0.1672, Training accuracy: 0.9084\n",
      "Validation loss: 0.4312, Validation accuracy: 0.8579\n",
      "\n",
      "Current learning rate has decayed to 0.001000\n",
      "Epoch 80:\n",
      "Training loss: 0.1213, Training accuracy: 0.9401\n",
      "Validation loss: 0.3258, Validation accuracy: 0.8928\n",
      "Saving ...\n",
      "\n",
      "Epoch 81:\n",
      "Training loss: 0.1029, Training accuracy: 0.9517\n",
      "Validation loss: 0.3215, Validation accuracy: 0.8939\n",
      "Saving ...\n",
      "\n",
      "Epoch 82:\n",
      "Training loss: 0.0974, Training accuracy: 0.9557\n",
      "Validation loss: 0.3189, Validation accuracy: 0.8927\n",
      "\n",
      "Epoch 83:\n",
      "Training loss: 0.0924, Training accuracy: 0.9595\n",
      "Validation loss: 0.3176, Validation accuracy: 0.8950\n",
      "Saving ...\n",
      "\n",
      "Epoch 84:\n",
      "Training loss: 0.0884, Training accuracy: 0.9612\n",
      "Validation loss: 0.3184, Validation accuracy: 0.8944\n",
      "\n",
      "Epoch 85:\n",
      "Training loss: 0.0855, Training accuracy: 0.9633\n",
      "Validation loss: 0.3197, Validation accuracy: 0.8969\n",
      "Saving ...\n",
      "\n",
      "Epoch 86:\n",
      "Training loss: 0.0835, Training accuracy: 0.9650\n",
      "Validation loss: 0.3187, Validation accuracy: 0.8959\n",
      "\n",
      "Epoch 87:\n",
      "Training loss: 0.0814, Training accuracy: 0.9674\n",
      "Validation loss: 0.3207, Validation accuracy: 0.8954\n",
      "\n",
      "Epoch 88:\n",
      "Training loss: 0.0800, Training accuracy: 0.9676\n",
      "Validation loss: 0.3176, Validation accuracy: 0.8990\n",
      "Saving ...\n",
      "\n",
      "Epoch 89:\n",
      "Training loss: 0.0783, Training accuracy: 0.9680\n",
      "Validation loss: 0.3219, Validation accuracy: 0.8972\n",
      "\n",
      "Epoch 90:\n",
      "Training loss: 0.0766, Training accuracy: 0.9698\n",
      "Validation loss: 0.3203, Validation accuracy: 0.8954\n",
      "\n",
      "Epoch 91:\n",
      "Training loss: 0.0756, Training accuracy: 0.9703\n",
      "Validation loss: 0.3203, Validation accuracy: 0.8967\n",
      "\n",
      "Epoch 92:\n",
      "Training loss: 0.0737, Training accuracy: 0.9717\n",
      "Validation loss: 0.3180, Validation accuracy: 0.8986\n",
      "\n",
      "Epoch 93:\n",
      "Training loss: 0.0724, Training accuracy: 0.9721\n",
      "Validation loss: 0.3172, Validation accuracy: 0.8974\n",
      "\n",
      "Epoch 94:\n",
      "Training loss: 0.0704, Training accuracy: 0.9737\n",
      "Validation loss: 0.3281, Validation accuracy: 0.8954\n",
      "\n",
      "Epoch 95:\n",
      "Training loss: 0.0688, Training accuracy: 0.9744\n",
      "Validation loss: 0.3240, Validation accuracy: 0.8985\n",
      "\n",
      "Epoch 96:\n",
      "Training loss: 0.0692, Training accuracy: 0.9748\n",
      "Validation loss: 0.3248, Validation accuracy: 0.8942\n",
      "\n",
      "Epoch 97:\n",
      "Training loss: 0.0663, Training accuracy: 0.9764\n",
      "Validation loss: 0.3253, Validation accuracy: 0.8965\n",
      "\n",
      "Epoch 98:\n",
      "Training loss: 0.0679, Training accuracy: 0.9756\n",
      "Validation loss: 0.3220, Validation accuracy: 0.8981\n",
      "\n",
      "Epoch 99:\n",
      "Training loss: 0.0648, Training accuracy: 0.9772\n",
      "Validation loss: 0.3241, Validation accuracy: 0.8975\n",
      "\n",
      "Epoch 100:\n",
      "Training loss: 0.0636, Training accuracy: 0.9780\n",
      "Validation loss: 0.3309, Validation accuracy: 0.8956\n",
      "\n",
      "Epoch 101:\n",
      "Training loss: 0.0629, Training accuracy: 0.9786\n",
      "Validation loss: 0.3244, Validation accuracy: 0.8973\n",
      "\n",
      "Epoch 102:\n",
      "Training loss: 0.0630, Training accuracy: 0.9783\n",
      "Validation loss: 0.3317, Validation accuracy: 0.8972\n",
      "\n",
      "Epoch 103:\n",
      "Training loss: 0.0613, Training accuracy: 0.9803\n",
      "Validation loss: 0.3290, Validation accuracy: 0.8968\n",
      "\n",
      "Epoch 104:\n",
      "Training loss: 0.0608, Training accuracy: 0.9795\n",
      "Validation loss: 0.3358, Validation accuracy: 0.8973\n",
      "\n",
      "Epoch 105:\n",
      "Training loss: 0.0599, Training accuracy: 0.9804\n",
      "Validation loss: 0.3312, Validation accuracy: 0.8978\n",
      "\n",
      "Epoch 106:\n",
      "Training loss: 0.0597, Training accuracy: 0.9805\n",
      "Validation loss: 0.3274, Validation accuracy: 0.8991\n",
      "Saving ...\n",
      "\n",
      "Epoch 107:\n",
      "Training loss: 0.0590, Training accuracy: 0.9802\n",
      "Validation loss: 0.3295, Validation accuracy: 0.8999\n",
      "Saving ...\n",
      "\n",
      "Epoch 108:\n",
      "Training loss: 0.0583, Training accuracy: 0.9809\n",
      "Validation loss: 0.3300, Validation accuracy: 0.8978\n",
      "\n",
      "Epoch 109:\n",
      "Training loss: 0.0580, Training accuracy: 0.9822\n",
      "Validation loss: 0.3359, Validation accuracy: 0.8984\n",
      "\n",
      "Epoch 110:\n",
      "Training loss: 0.0556, Training accuracy: 0.9835\n",
      "Validation loss: 0.3332, Validation accuracy: 0.8973\n",
      "\n",
      "Epoch 111:\n",
      "Training loss: 0.0555, Training accuracy: 0.9832\n",
      "Validation loss: 0.3336, Validation accuracy: 0.8977\n",
      "\n",
      "Epoch 112:\n",
      "Training loss: 0.0565, Training accuracy: 0.9818\n",
      "Validation loss: 0.3329, Validation accuracy: 0.8978\n",
      "\n",
      "Epoch 113:\n",
      "Training loss: 0.0549, Training accuracy: 0.9835\n",
      "Validation loss: 0.3347, Validation accuracy: 0.8965\n",
      "\n",
      "Epoch 114:\n",
      "Training loss: 0.0545, Training accuracy: 0.9843\n",
      "Validation loss: 0.3354, Validation accuracy: 0.8964\n",
      "\n",
      "Epoch 115:\n",
      "Training loss: 0.0531, Training accuracy: 0.9846\n",
      "Validation loss: 0.3339, Validation accuracy: 0.8971\n",
      "\n",
      "Epoch 116:\n",
      "Training loss: 0.0520, Training accuracy: 0.9857\n",
      "Validation loss: 0.3375, Validation accuracy: 0.8958\n",
      "\n",
      "Epoch 117:\n",
      "Training loss: 0.0521, Training accuracy: 0.9851\n",
      "Validation loss: 0.3381, Validation accuracy: 0.8977\n",
      "\n",
      "Epoch 118:\n",
      "Training loss: 0.0524, Training accuracy: 0.9848\n",
      "Validation loss: 0.3354, Validation accuracy: 0.8987\n",
      "\n",
      "Epoch 119:\n",
      "Training loss: 0.0532, Training accuracy: 0.9840\n",
      "Validation loss: 0.3366, Validation accuracy: 0.8973\n",
      "\n",
      "Epoch 120:\n",
      "Training loss: 0.0507, Training accuracy: 0.9859\n",
      "Validation loss: 0.3361, Validation accuracy: 0.8979\n",
      "\n",
      "Epoch 121:\n",
      "Training loss: 0.0502, Training accuracy: 0.9866\n",
      "Validation loss: 0.3339, Validation accuracy: 0.8996\n",
      "\n",
      "Epoch 122:\n",
      "Training loss: 0.0499, Training accuracy: 0.9869\n",
      "Validation loss: 0.3409, Validation accuracy: 0.8985\n",
      "\n",
      "Epoch 123:\n",
      "Training loss: 0.0492, Training accuracy: 0.9866\n",
      "Validation loss: 0.3410, Validation accuracy: 0.8978\n",
      "\n",
      "Epoch 124:\n",
      "Training loss: 0.0502, Training accuracy: 0.9864\n",
      "Validation loss: 0.3427, Validation accuracy: 0.8959\n",
      "\n",
      "Epoch 125:\n",
      "Training loss: 0.0486, Training accuracy: 0.9873\n",
      "Validation loss: 0.3361, Validation accuracy: 0.9000\n",
      "Saving ...\n",
      "\n",
      "Epoch 126:\n",
      "Training loss: 0.0479, Training accuracy: 0.9876\n",
      "Validation loss: 0.3411, Validation accuracy: 0.9010\n",
      "Saving ...\n",
      "\n",
      "Epoch 127:\n",
      "Training loss: 0.0487, Training accuracy: 0.9865\n",
      "Validation loss: 0.3428, Validation accuracy: 0.8985\n",
      "\n",
      "Epoch 128:\n",
      "Training loss: 0.0490, Training accuracy: 0.9863\n",
      "Validation loss: 0.3548, Validation accuracy: 0.8942\n",
      "\n",
      "Epoch 129:\n",
      "Training loss: 0.0469, Training accuracy: 0.9881\n",
      "Validation loss: 0.3452, Validation accuracy: 0.8986\n",
      "\n",
      "Epoch 130:\n",
      "Training loss: 0.0470, Training accuracy: 0.9882\n",
      "Validation loss: 0.3450, Validation accuracy: 0.8950\n",
      "\n",
      "Epoch 131:\n",
      "Training loss: 0.0468, Training accuracy: 0.9878\n",
      "Validation loss: 0.3493, Validation accuracy: 0.8944\n",
      "\n",
      "Epoch 132:\n",
      "Training loss: 0.0464, Training accuracy: 0.9884\n",
      "Validation loss: 0.3479, Validation accuracy: 0.8952\n",
      "\n",
      "Epoch 133:\n",
      "Training loss: 0.0459, Training accuracy: 0.9887\n",
      "Validation loss: 0.3420, Validation accuracy: 0.8992\n",
      "\n",
      "Epoch 134:\n",
      "Training loss: 0.0442, Training accuracy: 0.9896\n",
      "Validation loss: 0.3494, Validation accuracy: 0.8967\n",
      "\n",
      "Epoch 135:\n",
      "Training loss: 0.0465, Training accuracy: 0.9883\n",
      "Validation loss: 0.3453, Validation accuracy: 0.8996\n",
      "\n",
      "Epoch 136:\n",
      "Training loss: 0.0454, Training accuracy: 0.9888\n",
      "Validation loss: 0.3475, Validation accuracy: 0.8958\n",
      "\n",
      "Epoch 137:\n",
      "Training loss: 0.0459, Training accuracy: 0.9885\n",
      "Validation loss: 0.3482, Validation accuracy: 0.8973\n",
      "\n",
      "Epoch 138:\n",
      "Training loss: 0.0454, Training accuracy: 0.9885\n",
      "Validation loss: 0.3497, Validation accuracy: 0.8953\n",
      "\n",
      "Epoch 139:\n",
      "Training loss: 0.0455, Training accuracy: 0.9890\n",
      "Validation loss: 0.3468, Validation accuracy: 0.8992\n",
      "\n",
      "Epoch 140:\n",
      "Training loss: 0.0449, Training accuracy: 0.9888\n",
      "Validation loss: 0.3470, Validation accuracy: 0.8990\n",
      "\n",
      "Epoch 141:\n",
      "Training loss: 0.0440, Training accuracy: 0.9895\n",
      "Validation loss: 0.3505, Validation accuracy: 0.8963\n",
      "\n",
      "Epoch 142:\n",
      "Training loss: 0.0438, Training accuracy: 0.9895\n",
      "Validation loss: 0.3481, Validation accuracy: 0.8981\n",
      "\n",
      "Epoch 143:\n",
      "Training loss: 0.0428, Training accuracy: 0.9897\n",
      "Validation loss: 0.3527, Validation accuracy: 0.8975\n",
      "\n",
      "Epoch 144:\n",
      "Training loss: 0.0434, Training accuracy: 0.9892\n",
      "Validation loss: 0.3518, Validation accuracy: 0.8975\n",
      "\n",
      "Epoch 145:\n",
      "Training loss: 0.0423, Training accuracy: 0.9905\n",
      "Validation loss: 0.3485, Validation accuracy: 0.9002\n",
      "\n",
      "Epoch 146:\n",
      "Training loss: 0.0426, Training accuracy: 0.9900\n",
      "Validation loss: 0.3555, Validation accuracy: 0.8961\n",
      "\n",
      "Epoch 147:\n",
      "Training loss: 0.0420, Training accuracy: 0.9909\n",
      "Validation loss: 0.3525, Validation accuracy: 0.8962\n",
      "\n",
      "Epoch 148:\n",
      "Training loss: 0.0419, Training accuracy: 0.9903\n",
      "Validation loss: 0.3536, Validation accuracy: 0.8959\n",
      "\n",
      "Epoch 149:\n",
      "Training loss: 0.0421, Training accuracy: 0.9898\n",
      "Validation loss: 0.3556, Validation accuracy: 0.8934\n",
      "\n",
      "Epoch 150:\n",
      "Training loss: 0.0424, Training accuracy: 0.9893\n",
      "Validation loss: 0.3573, Validation accuracy: 0.8962\n",
      "\n",
      "Epoch 151:\n",
      "Training loss: 0.0424, Training accuracy: 0.9901\n",
      "Validation loss: 0.3557, Validation accuracy: 0.8961\n",
      "\n",
      "Epoch 152:\n",
      "Training loss: 0.0426, Training accuracy: 0.9901\n",
      "Validation loss: 0.3555, Validation accuracy: 0.8955\n",
      "\n",
      "Epoch 153:\n",
      "Training loss: 0.0423, Training accuracy: 0.9898\n",
      "Validation loss: 0.3572, Validation accuracy: 0.8959\n",
      "\n",
      "Epoch 154:\n",
      "Training loss: 0.0423, Training accuracy: 0.9899\n",
      "Validation loss: 0.3613, Validation accuracy: 0.8940\n",
      "\n",
      "Epoch 155:\n",
      "Training loss: 0.0408, Training accuracy: 0.9906\n",
      "Validation loss: 0.3520, Validation accuracy: 0.8966\n",
      "\n",
      "Epoch 156:\n",
      "Training loss: 0.0399, Training accuracy: 0.9916\n",
      "Validation loss: 0.3612, Validation accuracy: 0.8949\n",
      "\n",
      "Epoch 157:\n",
      "Training loss: 0.0399, Training accuracy: 0.9912\n",
      "Validation loss: 0.3714, Validation accuracy: 0.8965\n",
      "\n",
      "Epoch 158:\n",
      "Training loss: 0.0413, Training accuracy: 0.9904\n",
      "Validation loss: 0.3533, Validation accuracy: 0.8975\n",
      "\n",
      "Epoch 159:\n",
      "Training loss: 0.0405, Training accuracy: 0.9907\n",
      "Validation loss: 0.3549, Validation accuracy: 0.8997\n",
      "\n",
      "Current learning rate has decayed to 0.000100\n",
      "Epoch 160:\n",
      "Training loss: 0.0363, Training accuracy: 0.9935\n",
      "Validation loss: 0.3491, Validation accuracy: 0.9003\n",
      "\n",
      "Epoch 161:\n",
      "Training loss: 0.0351, Training accuracy: 0.9941\n",
      "Validation loss: 0.3519, Validation accuracy: 0.8988\n",
      "\n",
      "Epoch 162:\n",
      "Training loss: 0.0331, Training accuracy: 0.9951\n",
      "Validation loss: 0.3480, Validation accuracy: 0.9012\n",
      "Saving ...\n",
      "\n",
      "Epoch 163:\n",
      "Training loss: 0.0332, Training accuracy: 0.9951\n",
      "Validation loss: 0.3468, Validation accuracy: 0.9018\n",
      "Saving ...\n",
      "\n",
      "Epoch 164:\n",
      "Training loss: 0.0329, Training accuracy: 0.9952\n",
      "Validation loss: 0.3483, Validation accuracy: 0.9013\n",
      "\n",
      "Epoch 165:\n",
      "Training loss: 0.0323, Training accuracy: 0.9954\n",
      "Validation loss: 0.3484, Validation accuracy: 0.9011\n",
      "\n",
      "Epoch 166:\n",
      "Training loss: 0.0322, Training accuracy: 0.9960\n",
      "Validation loss: 0.3465, Validation accuracy: 0.9013\n",
      "\n",
      "Epoch 167:\n",
      "Training loss: 0.0316, Training accuracy: 0.9958\n",
      "Validation loss: 0.3470, Validation accuracy: 0.9016\n",
      "\n",
      "Epoch 168:\n",
      "Training loss: 0.0323, Training accuracy: 0.9956\n",
      "Validation loss: 0.3478, Validation accuracy: 0.9019\n",
      "Saving ...\n",
      "\n",
      "Epoch 169:\n",
      "Training loss: 0.0314, Training accuracy: 0.9959\n",
      "Validation loss: 0.3466, Validation accuracy: 0.9028\n",
      "Saving ...\n",
      "\n",
      "Epoch 170:\n",
      "Training loss: 0.0316, Training accuracy: 0.9959\n",
      "Validation loss: 0.3445, Validation accuracy: 0.9019\n",
      "\n",
      "Epoch 171:\n",
      "Training loss: 0.0318, Training accuracy: 0.9955\n",
      "Validation loss: 0.3485, Validation accuracy: 0.9019\n",
      "\n",
      "Epoch 172:\n",
      "Training loss: 0.0315, Training accuracy: 0.9962\n",
      "Validation loss: 0.3502, Validation accuracy: 0.9017\n",
      "\n",
      "Epoch 173:\n",
      "Training loss: 0.0308, Training accuracy: 0.9962\n",
      "Validation loss: 0.3523, Validation accuracy: 0.8997\n",
      "\n",
      "Epoch 174:\n",
      "Training loss: 0.0312, Training accuracy: 0.9962\n",
      "Validation loss: 0.3484, Validation accuracy: 0.9017\n",
      "\n",
      "Epoch 175:\n",
      "Training loss: 0.0306, Training accuracy: 0.9965\n",
      "Validation loss: 0.3504, Validation accuracy: 0.9025\n",
      "\n",
      "Epoch 176:\n",
      "Training loss: 0.0308, Training accuracy: 0.9962\n",
      "Validation loss: 0.3509, Validation accuracy: 0.9014\n",
      "\n",
      "Epoch 177:\n",
      "Training loss: 0.0302, Training accuracy: 0.9967\n",
      "Validation loss: 0.3463, Validation accuracy: 0.9021\n",
      "\n",
      "Epoch 178:\n",
      "Training loss: 0.0298, Training accuracy: 0.9970\n",
      "Validation loss: 0.3469, Validation accuracy: 0.9017\n",
      "\n",
      "Epoch 179:\n",
      "Training loss: 0.0299, Training accuracy: 0.9969\n",
      "Validation loss: 0.3456, Validation accuracy: 0.9043\n",
      "Saving ...\n",
      "\n",
      "Epoch 180:\n",
      "Training loss: 0.0299, Training accuracy: 0.9969\n",
      "Validation loss: 0.3482, Validation accuracy: 0.9039\n",
      "\n",
      "Epoch 181:\n",
      "Training loss: 0.0306, Training accuracy: 0.9963\n",
      "Validation loss: 0.3482, Validation accuracy: 0.9029\n",
      "\n",
      "Epoch 182:\n",
      "Training loss: 0.0303, Training accuracy: 0.9967\n",
      "Validation loss: 0.3472, Validation accuracy: 0.9020\n",
      "\n",
      "Epoch 183:\n",
      "Training loss: 0.0297, Training accuracy: 0.9969\n",
      "Validation loss: 0.3475, Validation accuracy: 0.9018\n",
      "\n",
      "Epoch 184:\n",
      "Training loss: 0.0301, Training accuracy: 0.9971\n",
      "Validation loss: 0.3490, Validation accuracy: 0.9028\n",
      "\n",
      "Epoch 185:\n",
      "Training loss: 0.0297, Training accuracy: 0.9968\n",
      "Validation loss: 0.3484, Validation accuracy: 0.9034\n",
      "\n",
      "Epoch 186:\n",
      "Training loss: 0.0297, Training accuracy: 0.9968\n",
      "Validation loss: 0.3481, Validation accuracy: 0.9018\n",
      "\n",
      "Epoch 187:\n",
      "Training loss: 0.0303, Training accuracy: 0.9965\n",
      "Validation loss: 0.3540, Validation accuracy: 0.9018\n",
      "\n",
      "Epoch 188:\n",
      "Training loss: 0.0301, Training accuracy: 0.9967\n",
      "Validation loss: 0.3462, Validation accuracy: 0.9032\n",
      "\n",
      "Epoch 189:\n",
      "Training loss: 0.0293, Training accuracy: 0.9970\n",
      "Validation loss: 0.3487, Validation accuracy: 0.9036\n",
      "\n",
      "Epoch 190:\n",
      "Training loss: 0.0294, Training accuracy: 0.9969\n",
      "Validation loss: 0.3487, Validation accuracy: 0.9024\n",
      "\n",
      "Epoch 191:\n",
      "Training loss: 0.0296, Training accuracy: 0.9967\n",
      "Validation loss: 0.3497, Validation accuracy: 0.9019\n",
      "\n",
      "Epoch 192:\n",
      "Training loss: 0.0294, Training accuracy: 0.9967\n",
      "Validation loss: 0.3498, Validation accuracy: 0.9026\n",
      "\n",
      "Epoch 193:\n",
      "Training loss: 0.0298, Training accuracy: 0.9966\n",
      "Validation loss: 0.3501, Validation accuracy: 0.9030\n",
      "\n",
      "Epoch 194:\n",
      "Training loss: 0.0293, Training accuracy: 0.9967\n",
      "Validation loss: 0.3496, Validation accuracy: 0.9019\n",
      "\n",
      "Epoch 195:\n",
      "Training loss: 0.0292, Training accuracy: 0.9968\n",
      "Validation loss: 0.3523, Validation accuracy: 0.9010\n",
      "\n",
      "Epoch 196:\n",
      "Training loss: 0.0291, Training accuracy: 0.9969\n",
      "Validation loss: 0.3497, Validation accuracy: 0.9019\n",
      "\n",
      "Epoch 197:\n",
      "Training loss: 0.0287, Training accuracy: 0.9971\n",
      "Validation loss: 0.3468, Validation accuracy: 0.9029\n",
      "\n",
      "Epoch 198:\n",
      "Training loss: 0.0290, Training accuracy: 0.9967\n",
      "Validation loss: 0.3506, Validation accuracy: 0.9011\n",
      "\n",
      "Epoch 199:\n",
      "Training loss: 0.0290, Training accuracy: 0.9974\n",
      "Validation loss: 0.3519, Validation accuracy: 0.9010\n",
      "\n",
      "==================================================\n",
      "==> Optimization finished! Best validation accuracy: 0.9043\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9043"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train(T=4,lamb=0.6,alpha=0.4,train_loader=train_loader,val_loader=val_loader,INITIAL_LR=0.1,DECAY_EPOCHS=[40,80,160],DECAY=0.1,EPOCHS=200,REG = 4e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(T=8,lamb=0.6,alpha=0.4,train_loader=train_loader,val_loader=val_loader,INITIAL_LR=0.1,DECAY_EPOCHS=[40,80,160],DECAY=0.1,EPOCHS=200,REG = 4e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "55f20d8859a1a0149f7d957af872e078c8283691172f5ca78f1d0b16a2e38dc4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
