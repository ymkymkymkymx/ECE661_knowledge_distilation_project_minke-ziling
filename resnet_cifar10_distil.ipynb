{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os, sys\n",
    "import time\n",
    "import datetime\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Softloss(nn.Module):\n",
    "    def __init__(self,T=4,loss_portion=[1,0,0]) -> None:\n",
    "        '''\n",
    "        T: temperature\n",
    "        loss_portion: KLD, cosine, mse\n",
    "        '''\n",
    "        super(Softloss,self).__init__()\n",
    "        self.T=T\n",
    "        self.portion=loss_portion\n",
    "    def forward(self,x,y):\n",
    "        soft_x=F.log_softmax(x/self.T,dim=-1)\n",
    "        soft_y=F.softmax(y/self.T,dim=-1)\n",
    "        loss=self.portion[0]*F.kl_div(soft_x,soft_y,reduction=\"batchmean\")\\\n",
    "            +self.portion[1]*F.cosine_embedding_loss(soft_x,soft_y,torch.ones(soft_x.shape[0]).to(soft_x.device))\\\n",
    "            +self.portion[2]*F.mse_loss(soft_x,soft_y)\n",
    "        return loss*self.T*self.T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResBlock11(nn.Module):\n",
    "    def __init__(self,channel,filter_size=3):\n",
    "        super(ResBlock11, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(channel, channel, filter_size,padding=1,bias=False)\n",
    "        nn.init.kaiming_normal_(self.conv1.weight, mode='fan_in', nonlinearity='leaky_relu')\n",
    "        self.norm1 = nn.BatchNorm2d(channel)\n",
    "        self.norm3 = nn.BatchNorm2d(channel)\n",
    "    def forward(self,x):\n",
    "        out=F.leaky_relu(self.norm1(self.conv1(x)))\n",
    "        out=self.norm3(out+x)\n",
    "        return out\n",
    "\n",
    "class ResDownSampling11(nn.Module):\n",
    "    def __init__(self,channel,out_channel,filter_size=3):\n",
    "        super(ResDownSampling11, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(channel, out_channel, filter_size,stride=2,padding=1,bias=False)\n",
    "        nn.init.kaiming_normal_(self.conv1.weight, mode='fan_in', nonlinearity='leaky_relu')\n",
    "        self.norm1 = nn.BatchNorm2d(out_channel)\n",
    "        self.norm3 = nn.BatchNorm2d(out_channel)\n",
    "        self.conv3 = nn.Conv2d(channel,out_channel,kernel_size=1,stride=2,bias=False)\n",
    "        nn.init.kaiming_normal_(self.conv3.weight, mode='fan_in', nonlinearity='leaky_relu')\n",
    "        self.norm4 = nn.BatchNorm2d(out_channel)\n",
    "    def forward(self,x):\n",
    "        out=F.leaky_relu(self.norm1(self.conv1(x)))\n",
    "        x=F.leaky_relu(self.norm3(self.conv3(x)))\n",
    "        out=self.norm4(out+x)\n",
    "        return out\n",
    "class ResNetCIFAR11(nn.Module):\n",
    "    def __init__(self ):\n",
    "        super(ResNetCIFAR11, self).__init__()\n",
    "        self.inconv=nn.Conv2d(3, 16,3,padding=1,bias=False)\n",
    "        nn.init.xavier_normal_(self.inconv.weight)\n",
    "        self.res_block=nn.Sequential(self.inconv,\n",
    "                                    nn.BatchNorm2d(16),\n",
    "                                    nn.ReLU(),\n",
    "                                    ResBlock11(16),\n",
    "                                    ResBlock11(16),\n",
    "                                    ResBlock11(16),\n",
    "                                    ResDownSampling11(16,32),\n",
    "                                    ResBlock11(32),\n",
    "                                    ResBlock11(32),\n",
    "                                    ResDownSampling11(32,64),\n",
    "                                    ResBlock11(64),\n",
    "                                    ResBlock11(64),\n",
    "                                    nn.AvgPool2d(8),\n",
    "                                    nn.Flatten(),\n",
    "                                    nn.Linear(64*1*1,10))\n",
    "    def forward(self, x):\n",
    "        return self.res_block(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResBlock(nn.Module):\n",
    "    def __init__(self,channel,filter_size=3):\n",
    "        super(ResBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(channel, channel, filter_size,padding=1,bias=False)\n",
    "        nn.init.kaiming_normal_(self.conv1.weight, mode='fan_in', nonlinearity='leaky_relu')\n",
    "        self.norm1 = nn.BatchNorm2d(channel)\n",
    "        self.conv2 = nn.Conv2d(channel, channel, filter_size,padding=1,bias=False)\n",
    "        nn.init.kaiming_normal_(self.conv2.weight, mode='fan_in', nonlinearity='leaky_relu')\n",
    "        self.norm2 = nn.BatchNorm2d(channel)\n",
    "        self.norm3 = nn.BatchNorm2d(channel)\n",
    "    def forward(self,x):\n",
    "        out=F.leaky_relu(self.norm1(self.conv1(x)))\n",
    "        out=F.leaky_relu(self.norm2(self.conv2(out)))\n",
    "        out=self.norm3(out+x)\n",
    "        return out\n",
    "\n",
    "class ResDownSampling(nn.Module):\n",
    "    def __init__(self,channel,out_channel,filter_size=3):\n",
    "        super(ResDownSampling, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(channel, channel, filter_size,stride=2,padding=1,bias=False)\n",
    "        nn.init.kaiming_normal_(self.conv1.weight, mode='fan_in', nonlinearity='leaky_relu')\n",
    "        self.norm1 = nn.BatchNorm2d(channel)\n",
    "        self.conv2 = nn.Conv2d(channel, out_channel, filter_size,padding=1,bias=False)\n",
    "        nn.init.kaiming_normal_(self.conv2.weight, mode='fan_in', nonlinearity='leaky_relu')\n",
    "        self.norm2 = nn.BatchNorm2d(out_channel)\n",
    "        self.norm3 = nn.BatchNorm2d(out_channel)\n",
    "        self.conv3 = nn.Conv2d(channel,out_channel,kernel_size=1,stride=2,bias=False)\n",
    "        nn.init.kaiming_normal_(self.conv3.weight, mode='fan_in', nonlinearity='leaky_relu')\n",
    "        self.norm4 = nn.BatchNorm2d(out_channel)\n",
    "    def forward(self,x):\n",
    "        out=F.leaky_relu(self.norm1(self.conv1(x)))\n",
    "        out=F.leaky_relu(self.norm2(self.conv2(out)))\n",
    "        x=F.leaky_relu(self.norm3(self.conv3(x)))\n",
    "        out=self.norm4(out+x)\n",
    "        return out\n",
    "class ResNetCIFAR(nn.Module):\n",
    "    def __init__(self ):\n",
    "        super(ResNetCIFAR, self).__init__()\n",
    "        self.inconv=nn.Conv2d(3, 16,3,padding=1,bias=False)\n",
    "        nn.init.xavier_normal_(self.inconv.weight)\n",
    "        self.res_block=nn.Sequential(self.inconv,\n",
    "                                    nn.BatchNorm2d(16),\n",
    "                                    nn.ReLU(),\n",
    "                                    ResBlock(16),\n",
    "                                    ResBlock(16),\n",
    "                                    ResBlock(16),\n",
    "                                    ResDownSampling(16,32),\n",
    "                                    ResBlock(32),\n",
    "                                    ResBlock(32),\n",
    "                                    ResDownSampling(32,64),\n",
    "                                    ResBlock(64),\n",
    "                                    ResBlock(64),\n",
    "                                    nn.AvgPool2d(8),\n",
    "                                    nn.Flatten(),\n",
    "                                    nn.Linear(64*1*1,10))\n",
    "    def forward(self, x):\n",
    "        return self.res_block(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# useful libraries\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "#############################################\n",
    "# your code here\n",
    "# specify preprocessing function\n",
    "transform = transforms.Compose(\n",
    "    (\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "    )\n",
    ")\n",
    "transform_train = transforms.Compose(\n",
    "    (\n",
    "    \n",
    "    transforms.RandomCrop((32,32),padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    #transforms.RandomVerticalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "    \n",
    "    #\n",
    "    #transforms.ColorJitter(0.2,0,0)\n",
    "    \n",
    "    )\n",
    ")\n",
    "\n",
    "transform_val = transform\n",
    "#############################################\n",
    "# do NOT change these\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# a few arguments, do NOT change these\n",
    "DATA_ROOT = \"./data\"\n",
    "TRAIN_BATCH_SIZE = 128\n",
    "VAL_BATCH_SIZE = 100\n",
    "\n",
    "#############################################\n",
    "# your code here\n",
    "# construct dataset\n",
    "train_set = CIFAR10(\n",
    "    root=DATA_ROOT, \n",
    "    train=True, \n",
    "    download=True,\n",
    "    transform=transform_train    # your code\n",
    ")\n",
    "\n",
    "val_set = CIFAR10(\n",
    "    root=DATA_ROOT, \n",
    "    train=False, \n",
    "    download=True,\n",
    "    transform=transform_val    # your code\n",
    ")\n",
    "\n",
    "# construct dataloader\n",
    "train_loader = DataLoader(\n",
    "    train_set, \n",
    "    batch_size=TRAIN_BATCH_SIZE,  # your code\n",
    "    shuffle=True,     # your code\n",
    "    num_workers=2\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_set, \n",
    "    batch_size=VAL_BATCH_SIZE,  # your code\n",
    "    shuffle=False,     # your code\n",
    "    num_workers=2\n",
    ")\n",
    "#############################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "student=ResNetCIFAR11()\n",
    "student=student.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# hyperparameters, do NOT change right now\n",
    "# initial learning rate\n",
    "#INITIAL_LR = 0.0001\n",
    "\n",
    "# momentum for optimizer\n",
    "#MOMENTUM = 0.9\n",
    "\n",
    "# L2 regularization strength\n",
    "REG = 0.00\n",
    "\n",
    "#############################################\n",
    "# your code here\n",
    "# create loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Add optimizer\n",
    "optimizer = optim.Adam(student.parameters(),weight_decay=REG,amsgrad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher=ResNetCIFAR()\n",
    "state=torch.load(\"./saved_model/res20_9188.pth\")[\"state_dict\"]\n",
    "teacher.load_state_dict(state)\n",
    "teacher=teacher.to(device)\n",
    "state=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model,teacher,optimizer,criterion,T,portion,alpha,train_loader,val_loader,EPOCHS=200):\n",
    "    # some hyperparameters\n",
    "    # total number of training epochs\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    teacher.eval()\n",
    "    soft_criterion=Softloss(T,portion)\n",
    "    # the folder where the trained model is saved\n",
    "    CHECKPOINT_FOLDER = \"./saved_model\"\n",
    "    #DECAY_EPOCHS=5\n",
    "    #DECAY=0.75\n",
    "    # start the training/validation process\n",
    "    # the process should take about 5 minutes on a GTX 1070-Ti\n",
    "    # if the code is written efficiently.\n",
    "    best_val_acc = 0\n",
    "    #current_learning_rate = INITIAL_LR\n",
    "    \n",
    "    print(\"==> Training starts!\")\n",
    "    print(\"=\"*50)\n",
    "    for i in range(0, EPOCHS):\n",
    "        # handle the learning rate scheduler.\n",
    "        '''\n",
    "        if i % DECAY_EPOCHS == 0 and i != 0 :\n",
    "            current_learning_rate = current_learning_rate * DECAY\n",
    "        \n",
    "            for param_group in optimizer.param_groups:\n",
    "                param_group['lr'] = current_learning_rate\n",
    "            print(\"Current learning rate has decayed to %f\" %current_learning_rate)\n",
    "        '''\n",
    "        #######################\n",
    "        # your code here\n",
    "        # switch to train mode\n",
    "        model.train()\n",
    "        \n",
    "        #######################\n",
    "        \n",
    "        print(\"Epoch %d:\" %i)\n",
    "        # this help you compute the training accuracy\n",
    "        total_examples = 0\n",
    "        correct_examples = 0\n",
    "\n",
    "        train_loss = 0 # track training loss if you want\n",
    "        loader=train_loader\n",
    "        \n",
    "        # Train the model for 1 epoch.\n",
    "        for batch_idx, (inputs, targets) in enumerate(loader):\n",
    "            ####################################\n",
    "            # your code here\n",
    "            # copy inputs to device\n",
    "            inputs=inputs.to(device)\n",
    "            targets=targets.to(device).long()\n",
    "\n",
    "            \n",
    "            # compute the output and loss\n",
    "            out=model(inputs)\n",
    "            with torch.no_grad():\n",
    "                soft_target=teacher(inputs)\n",
    "            loss=(1-alpha)*criterion(out,targets)+alpha*soft_criterion(out,soft_target)\n",
    "            \n",
    "            # zero the gradient\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            # backpropagation\n",
    "            loss.backward()\n",
    "\n",
    "            \n",
    "            # apply gradient and update the weights\n",
    "            optimizer.step()\n",
    "            train_loss+=loss.item()\n",
    "            \n",
    "            # count the number of correctly predicted samples in the current batch\n",
    "            correct_examples+=torch.sum(out.argmax(-1)==targets).item()\n",
    "            ####################################\n",
    "        total_examples=len(train_loader.dataset)      \n",
    "        avg_loss = train_loss / len(train_loader)\n",
    "        avg_acc = correct_examples / total_examples\n",
    "        print(\"Training loss: %.4f, Training accuracy: %.4f\" %(avg_loss, avg_acc))\n",
    "\n",
    "        # Validate on the validation dataset\n",
    "        #######################\n",
    "        # your code here\n",
    "        # switch to eval mode\n",
    "        model.eval()\n",
    "        \n",
    "        #######################\n",
    "\n",
    "        # this help you compute the validation accuracy\n",
    "        total_examples = 0\n",
    "        correct_examples = 0\n",
    "        \n",
    "        val_loss = 0 # again, track the validation loss if you want\n",
    "\n",
    "        # disable gradient during validation, which can save GPU memory\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, (inputs, targets) in enumerate(val_loader):\n",
    "                ####################################\n",
    "                # your code here\n",
    "                # copy inputs to device\n",
    "                inputs=inputs.to(device)\n",
    "                targets=targets.to(device).long()\n",
    "                # compute the output and loss\n",
    "                out=model(inputs)\n",
    "                loss=criterion(out,targets)\n",
    "                # count the number of correctly predicted samples in the current batch\n",
    "                val_loss+=loss.item()\n",
    "                correct_examples+=torch.sum(out.argmax(-1)==targets).item()\n",
    "                \n",
    "                ####################################\n",
    "        total_examples=len(val_loader.dataset)\n",
    "        avg_loss = val_loss / len(val_loader)\n",
    "        avg_acc = correct_examples / total_examples\n",
    "        print(\"Validation loss: %.4f, Validation accuracy: %.4f\" % (avg_loss, avg_acc))\n",
    "        \n",
    "        # save the model checkpoint\n",
    "        if avg_acc > best_val_acc:\n",
    "            best_val_acc = avg_acc\n",
    "            if not os.path.exists(CHECKPOINT_FOLDER):\n",
    "                os.makedirs(CHECKPOINT_FOLDER)\n",
    "            print(\"Saving ...\")\n",
    "            state = {'state_dict': model.state_dict(),\n",
    "                    'epoch': i,\n",
    "                    }\n",
    "            torch.save(state, os.path.join(CHECKPOINT_FOLDER, 'distilled.pth'))\n",
    "            \n",
    "        print('')\n",
    "\n",
    "    print(\"=\"*50)\n",
    "    print(f\"==> Optimization finished! Best validation accuracy: {best_val_acc:.4f}\")\n",
    "    return best_val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Training starts!\n",
      "==================================================\n",
      "Epoch 0:\n",
      "Training loss: 1.3926, Training accuracy: 0.4149\n",
      "Validation loss: 1.3530, Validation accuracy: 0.5114\n",
      "Saving ...\n",
      "\n",
      "Epoch 1:\n",
      "Training loss: 1.0502, Training accuracy: 0.5635\n",
      "Validation loss: 1.0980, Validation accuracy: 0.6066\n",
      "Saving ...\n",
      "\n",
      "Epoch 2:\n",
      "Training loss: 0.9056, Training accuracy: 0.6254\n",
      "Validation loss: 0.9878, Validation accuracy: 0.6418\n",
      "Saving ...\n",
      "\n",
      "Epoch 3:\n",
      "Training loss: 0.8198, Training accuracy: 0.6604\n",
      "Validation loss: 0.9314, Validation accuracy: 0.6679\n",
      "Saving ...\n",
      "\n",
      "Epoch 4:\n",
      "Training loss: 0.7583, Training accuracy: 0.6873\n",
      "Validation loss: 0.8622, Validation accuracy: 0.7000\n",
      "Saving ...\n",
      "\n",
      "Epoch 5:\n",
      "Training loss: 0.7086, Training accuracy: 0.7081\n",
      "Validation loss: 0.8287, Validation accuracy: 0.7045\n",
      "Saving ...\n",
      "\n",
      "Epoch 6:\n",
      "Training loss: 0.6557, Training accuracy: 0.7299\n",
      "Validation loss: 0.7754, Validation accuracy: 0.7257\n",
      "Saving ...\n",
      "\n",
      "Epoch 7:\n",
      "Training loss: 0.6124, Training accuracy: 0.7482\n",
      "Validation loss: 0.7244, Validation accuracy: 0.7478\n",
      "Saving ...\n",
      "\n",
      "Epoch 8:\n",
      "Training loss: 0.5797, Training accuracy: 0.7616\n",
      "Validation loss: 0.6837, Validation accuracy: 0.7632\n",
      "Saving ...\n",
      "\n",
      "Epoch 9:\n",
      "Training loss: 0.5488, Training accuracy: 0.7760\n",
      "Validation loss: 0.6706, Validation accuracy: 0.7729\n",
      "Saving ...\n",
      "\n",
      "Epoch 10:\n",
      "Training loss: 0.5235, Training accuracy: 0.7862\n",
      "Validation loss: 0.6418, Validation accuracy: 0.7789\n",
      "Saving ...\n",
      "\n",
      "Epoch 11:\n",
      "Training loss: 0.5011, Training accuracy: 0.7939\n",
      "Validation loss: 0.6285, Validation accuracy: 0.7809\n",
      "Saving ...\n",
      "\n",
      "Epoch 12:\n",
      "Training loss: 0.4852, Training accuracy: 0.8031\n",
      "Validation loss: 0.6256, Validation accuracy: 0.7811\n",
      "Saving ...\n",
      "\n",
      "Epoch 13:\n",
      "Training loss: 0.4665, Training accuracy: 0.8109\n",
      "Validation loss: 0.5671, Validation accuracy: 0.8046\n",
      "Saving ...\n",
      "\n",
      "Epoch 14:\n",
      "Training loss: 0.4532, Training accuracy: 0.8144\n",
      "Validation loss: 0.5731, Validation accuracy: 0.8048\n",
      "Saving ...\n",
      "\n",
      "Epoch 15:\n",
      "Training loss: 0.4368, Training accuracy: 0.8223\n",
      "Validation loss: 0.5660, Validation accuracy: 0.8054\n",
      "Saving ...\n",
      "\n",
      "Epoch 16:\n",
      "Training loss: 0.4256, Training accuracy: 0.8261\n",
      "Validation loss: 0.5489, Validation accuracy: 0.8097\n",
      "Saving ...\n",
      "\n",
      "Epoch 17:\n",
      "Training loss: 0.4157, Training accuracy: 0.8300\n",
      "Validation loss: 0.5449, Validation accuracy: 0.8099\n",
      "Saving ...\n",
      "\n",
      "Epoch 18:\n",
      "Training loss: 0.4023, Training accuracy: 0.8379\n",
      "Validation loss: 0.5272, Validation accuracy: 0.8198\n",
      "Saving ...\n",
      "\n",
      "Epoch 19:\n",
      "Training loss: 0.3971, Training accuracy: 0.8409\n",
      "Validation loss: 0.5296, Validation accuracy: 0.8227\n",
      "Saving ...\n",
      "\n",
      "Epoch 20:\n",
      "Training loss: 0.3829, Training accuracy: 0.8442\n",
      "Validation loss: 0.5176, Validation accuracy: 0.8246\n",
      "Saving ...\n",
      "\n",
      "Epoch 21:\n",
      "Training loss: 0.3792, Training accuracy: 0.8466\n",
      "Validation loss: 0.5346, Validation accuracy: 0.8214\n",
      "\n",
      "Epoch 22:\n",
      "Training loss: 0.3719, Training accuracy: 0.8503\n",
      "Validation loss: 0.4991, Validation accuracy: 0.8330\n",
      "Saving ...\n",
      "\n",
      "Epoch 23:\n",
      "Training loss: 0.3656, Training accuracy: 0.8520\n",
      "Validation loss: 0.4891, Validation accuracy: 0.8295\n",
      "\n",
      "Epoch 24:\n",
      "Training loss: 0.3528, Training accuracy: 0.8565\n",
      "Validation loss: 0.5272, Validation accuracy: 0.8256\n",
      "\n",
      "Epoch 25:\n",
      "Training loss: 0.3502, Training accuracy: 0.8583\n",
      "Validation loss: 0.4814, Validation accuracy: 0.8349\n",
      "Saving ...\n",
      "\n",
      "Epoch 26:\n",
      "Training loss: 0.3437, Training accuracy: 0.8625\n",
      "Validation loss: 0.4833, Validation accuracy: 0.8327\n",
      "\n",
      "Epoch 27:\n",
      "Training loss: 0.3371, Training accuracy: 0.8650\n",
      "Validation loss: 0.4718, Validation accuracy: 0.8408\n",
      "Saving ...\n",
      "\n",
      "Epoch 28:\n",
      "Training loss: 0.3293, Training accuracy: 0.8675\n",
      "Validation loss: 0.4662, Validation accuracy: 0.8398\n",
      "\n",
      "Epoch 29:\n",
      "Training loss: 0.3272, Training accuracy: 0.8688\n",
      "Validation loss: 0.4642, Validation accuracy: 0.8400\n",
      "\n",
      "Epoch 30:\n",
      "Training loss: 0.3216, Training accuracy: 0.8722\n",
      "Validation loss: 0.4621, Validation accuracy: 0.8452\n",
      "Saving ...\n",
      "\n",
      "Epoch 31:\n",
      "Training loss: 0.3182, Training accuracy: 0.8717\n",
      "Validation loss: 0.4623, Validation accuracy: 0.8431\n",
      "\n",
      "Epoch 32:\n",
      "Training loss: 0.3114, Training accuracy: 0.8748\n",
      "Validation loss: 0.4479, Validation accuracy: 0.8462\n",
      "Saving ...\n",
      "\n",
      "Epoch 33:\n",
      "Training loss: 0.3089, Training accuracy: 0.8760\n",
      "Validation loss: 0.4514, Validation accuracy: 0.8457\n",
      "\n",
      "Epoch 34:\n",
      "Training loss: 0.3041, Training accuracy: 0.8781\n",
      "Validation loss: 0.4518, Validation accuracy: 0.8475\n",
      "Saving ...\n",
      "\n",
      "Epoch 35:\n",
      "Training loss: 0.2997, Training accuracy: 0.8804\n",
      "Validation loss: 0.4348, Validation accuracy: 0.8530\n",
      "Saving ...\n",
      "\n",
      "Epoch 36:\n",
      "Training loss: 0.2952, Training accuracy: 0.8847\n",
      "Validation loss: 0.4502, Validation accuracy: 0.8489\n",
      "\n",
      "Epoch 37:\n",
      "Training loss: 0.2923, Training accuracy: 0.8832\n",
      "Validation loss: 0.4369, Validation accuracy: 0.8490\n",
      "\n",
      "Epoch 38:\n",
      "Training loss: 0.2898, Training accuracy: 0.8850\n",
      "Validation loss: 0.4302, Validation accuracy: 0.8540\n",
      "Saving ...\n",
      "\n",
      "Epoch 39:\n",
      "Training loss: 0.2863, Training accuracy: 0.8863\n",
      "Validation loss: 0.4350, Validation accuracy: 0.8520\n",
      "\n",
      "Epoch 40:\n",
      "Training loss: 0.2835, Training accuracy: 0.8873\n",
      "Validation loss: 0.4252, Validation accuracy: 0.8549\n",
      "Saving ...\n",
      "\n",
      "Epoch 41:\n",
      "Training loss: 0.2816, Training accuracy: 0.8894\n",
      "Validation loss: 0.4189, Validation accuracy: 0.8585\n",
      "Saving ...\n",
      "\n",
      "Epoch 42:\n",
      "Training loss: 0.2749, Training accuracy: 0.8915\n",
      "Validation loss: 0.4285, Validation accuracy: 0.8549\n",
      "\n",
      "Epoch 43:\n",
      "Training loss: 0.2726, Training accuracy: 0.8935\n",
      "Validation loss: 0.4214, Validation accuracy: 0.8583\n",
      "\n",
      "Epoch 44:\n",
      "Training loss: 0.2681, Training accuracy: 0.8950\n",
      "Validation loss: 0.4275, Validation accuracy: 0.8527\n",
      "\n",
      "Epoch 45:\n",
      "Training loss: 0.2668, Training accuracy: 0.8945\n",
      "Validation loss: 0.4241, Validation accuracy: 0.8583\n",
      "\n",
      "Epoch 46:\n",
      "Training loss: 0.2629, Training accuracy: 0.8972\n",
      "Validation loss: 0.4076, Validation accuracy: 0.8656\n",
      "Saving ...\n",
      "\n",
      "Epoch 47:\n",
      "Training loss: 0.2630, Training accuracy: 0.8960\n",
      "Validation loss: 0.4126, Validation accuracy: 0.8617\n",
      "\n",
      "Epoch 48:\n",
      "Training loss: 0.2569, Training accuracy: 0.9001\n",
      "Validation loss: 0.4142, Validation accuracy: 0.8619\n",
      "\n",
      "Epoch 49:\n",
      "Training loss: 0.2563, Training accuracy: 0.9011\n",
      "Validation loss: 0.4071, Validation accuracy: 0.8664\n",
      "Saving ...\n",
      "\n",
      "Epoch 50:\n",
      "Training loss: 0.2528, Training accuracy: 0.9010\n",
      "Validation loss: 0.4078, Validation accuracy: 0.8643\n",
      "\n",
      "Epoch 51:\n",
      "Training loss: 0.2498, Training accuracy: 0.9035\n",
      "Validation loss: 0.4152, Validation accuracy: 0.8598\n",
      "\n",
      "Epoch 52:\n",
      "Training loss: 0.2488, Training accuracy: 0.9037\n",
      "Validation loss: 0.4057, Validation accuracy: 0.8660\n",
      "\n",
      "Epoch 53:\n",
      "Training loss: 0.2494, Training accuracy: 0.9039\n",
      "Validation loss: 0.4080, Validation accuracy: 0.8642\n",
      "\n",
      "Epoch 54:\n",
      "Training loss: 0.2475, Training accuracy: 0.9041\n",
      "Validation loss: 0.4027, Validation accuracy: 0.8689\n",
      "Saving ...\n",
      "\n",
      "Epoch 55:\n",
      "Training loss: 0.2427, Training accuracy: 0.9069\n",
      "Validation loss: 0.4240, Validation accuracy: 0.8553\n",
      "\n",
      "Epoch 56:\n",
      "Training loss: 0.2394, Training accuracy: 0.9074\n",
      "Validation loss: 0.4013, Validation accuracy: 0.8656\n",
      "\n",
      "Epoch 57:\n",
      "Training loss: 0.2389, Training accuracy: 0.9074\n",
      "Validation loss: 0.3918, Validation accuracy: 0.8671\n",
      "\n",
      "Epoch 58:\n",
      "Training loss: 0.2348, Training accuracy: 0.9102\n",
      "Validation loss: 0.4089, Validation accuracy: 0.8622\n",
      "\n",
      "Epoch 59:\n",
      "Training loss: 0.2358, Training accuracy: 0.9098\n",
      "Validation loss: 0.3940, Validation accuracy: 0.8684\n",
      "\n",
      "Epoch 60:\n",
      "Training loss: 0.2331, Training accuracy: 0.9106\n",
      "Validation loss: 0.3988, Validation accuracy: 0.8665\n",
      "\n",
      "Epoch 61:\n",
      "Training loss: 0.2314, Training accuracy: 0.9119\n",
      "Validation loss: 0.3947, Validation accuracy: 0.8696\n",
      "Saving ...\n",
      "\n",
      "Epoch 62:\n",
      "Training loss: 0.2280, Training accuracy: 0.9124\n",
      "Validation loss: 0.3916, Validation accuracy: 0.8694\n",
      "\n",
      "Epoch 63:\n",
      "Training loss: 0.2276, Training accuracy: 0.9127\n",
      "Validation loss: 0.3856, Validation accuracy: 0.8737\n",
      "Saving ...\n",
      "\n",
      "Epoch 64:\n",
      "Training loss: 0.2264, Training accuracy: 0.9140\n",
      "Validation loss: 0.3882, Validation accuracy: 0.8692\n",
      "\n",
      "Epoch 65:\n",
      "Training loss: 0.2244, Training accuracy: 0.9143\n",
      "Validation loss: 0.3779, Validation accuracy: 0.8738\n",
      "Saving ...\n",
      "\n",
      "Epoch 66:\n",
      "Training loss: 0.2235, Training accuracy: 0.9155\n",
      "Validation loss: 0.3834, Validation accuracy: 0.8721\n",
      "\n",
      "Epoch 67:\n",
      "Training loss: 0.2193, Training accuracy: 0.9169\n",
      "Validation loss: 0.3736, Validation accuracy: 0.8763\n",
      "Saving ...\n",
      "\n",
      "Epoch 68:\n",
      "Training loss: 0.2200, Training accuracy: 0.9181\n",
      "Validation loss: 0.3874, Validation accuracy: 0.8715\n",
      "\n",
      "Epoch 69:\n",
      "Training loss: 0.2184, Training accuracy: 0.9178\n",
      "Validation loss: 0.3828, Validation accuracy: 0.8743\n",
      "\n",
      "Epoch 70:\n",
      "Training loss: 0.2140, Training accuracy: 0.9194\n",
      "Validation loss: 0.3763, Validation accuracy: 0.8747\n",
      "\n",
      "Epoch 71:\n",
      "Training loss: 0.2142, Training accuracy: 0.9192\n",
      "Validation loss: 0.3769, Validation accuracy: 0.8755\n",
      "\n",
      "Epoch 72:\n",
      "Training loss: 0.2145, Training accuracy: 0.9202\n",
      "Validation loss: 0.3862, Validation accuracy: 0.8728\n",
      "\n",
      "Epoch 73:\n",
      "Training loss: 0.2132, Training accuracy: 0.9204\n",
      "Validation loss: 0.3857, Validation accuracy: 0.8725\n",
      "\n",
      "Epoch 74:\n",
      "Training loss: 0.2113, Training accuracy: 0.9214\n",
      "Validation loss: 0.3876, Validation accuracy: 0.8716\n",
      "\n",
      "Epoch 75:\n",
      "Training loss: 0.2078, Training accuracy: 0.9231\n",
      "Validation loss: 0.3820, Validation accuracy: 0.8747\n",
      "\n",
      "Epoch 76:\n",
      "Training loss: 0.2078, Training accuracy: 0.9223\n",
      "Validation loss: 0.3777, Validation accuracy: 0.8738\n",
      "\n",
      "Epoch 77:\n",
      "Training loss: 0.2058, Training accuracy: 0.9241\n",
      "Validation loss: 0.3757, Validation accuracy: 0.8739\n",
      "\n",
      "Epoch 78:\n",
      "Training loss: 0.2062, Training accuracy: 0.9241\n",
      "Validation loss: 0.3737, Validation accuracy: 0.8743\n",
      "\n",
      "Epoch 79:\n",
      "Training loss: 0.2058, Training accuracy: 0.9252\n",
      "Validation loss: 0.3778, Validation accuracy: 0.8730\n",
      "\n",
      "Epoch 80:\n",
      "Training loss: 0.2018, Training accuracy: 0.9268\n",
      "Validation loss: 0.3691, Validation accuracy: 0.8790\n",
      "Saving ...\n",
      "\n",
      "Epoch 81:\n",
      "Training loss: 0.2015, Training accuracy: 0.9264\n",
      "Validation loss: 0.3699, Validation accuracy: 0.8743\n",
      "\n",
      "Epoch 82:\n",
      "Training loss: 0.1991, Training accuracy: 0.9273\n",
      "Validation loss: 0.3669, Validation accuracy: 0.8798\n",
      "Saving ...\n",
      "\n",
      "Epoch 83:\n",
      "Training loss: 0.1988, Training accuracy: 0.9272\n",
      "Validation loss: 0.3656, Validation accuracy: 0.8823\n",
      "Saving ...\n",
      "\n",
      "Epoch 84:\n",
      "Training loss: 0.1970, Training accuracy: 0.9281\n",
      "Validation loss: 0.3733, Validation accuracy: 0.8764\n",
      "\n",
      "Epoch 85:\n",
      "Training loss: 0.1970, Training accuracy: 0.9282\n",
      "Validation loss: 0.3721, Validation accuracy: 0.8781\n",
      "\n",
      "Epoch 86:\n",
      "Training loss: 0.1955, Training accuracy: 0.9287\n",
      "Validation loss: 0.3658, Validation accuracy: 0.8789\n",
      "\n",
      "Epoch 87:\n",
      "Training loss: 0.1957, Training accuracy: 0.9285\n",
      "Validation loss: 0.3711, Validation accuracy: 0.8780\n",
      "\n",
      "Epoch 88:\n",
      "Training loss: 0.1943, Training accuracy: 0.9314\n",
      "Validation loss: 0.3613, Validation accuracy: 0.8815\n",
      "\n",
      "Epoch 89:\n",
      "Training loss: 0.1933, Training accuracy: 0.9304\n",
      "Validation loss: 0.3680, Validation accuracy: 0.8782\n",
      "\n",
      "Epoch 90:\n",
      "Training loss: 0.1898, Training accuracy: 0.9317\n",
      "Validation loss: 0.3691, Validation accuracy: 0.8783\n",
      "\n",
      "Epoch 91:\n",
      "Training loss: 0.1911, Training accuracy: 0.9300\n",
      "Validation loss: 0.3635, Validation accuracy: 0.8767\n",
      "\n",
      "Epoch 92:\n",
      "Training loss: 0.1889, Training accuracy: 0.9318\n",
      "Validation loss: 0.3686, Validation accuracy: 0.8779\n",
      "\n",
      "Epoch 93:\n",
      "Training loss: 0.1881, Training accuracy: 0.9324\n",
      "Validation loss: 0.3706, Validation accuracy: 0.8755\n",
      "\n",
      "Epoch 94:\n",
      "Training loss: 0.1881, Training accuracy: 0.9328\n",
      "Validation loss: 0.3737, Validation accuracy: 0.8763\n",
      "\n",
      "Epoch 95:\n",
      "Training loss: 0.1867, Training accuracy: 0.9335\n",
      "Validation loss: 0.3687, Validation accuracy: 0.8786\n",
      "\n",
      "Epoch 96:\n",
      "Training loss: 0.1883, Training accuracy: 0.9325\n",
      "Validation loss: 0.3657, Validation accuracy: 0.8777\n",
      "\n",
      "Epoch 97:\n",
      "Training loss: 0.1844, Training accuracy: 0.9337\n",
      "Validation loss: 0.3629, Validation accuracy: 0.8789\n",
      "\n",
      "Epoch 98:\n",
      "Training loss: 0.1831, Training accuracy: 0.9339\n",
      "Validation loss: 0.3621, Validation accuracy: 0.8790\n",
      "\n",
      "Epoch 99:\n",
      "Training loss: 0.1843, Training accuracy: 0.9342\n",
      "Validation loss: 0.3748, Validation accuracy: 0.8758\n",
      "\n",
      "Epoch 100:\n",
      "Training loss: 0.1828, Training accuracy: 0.9345\n",
      "Validation loss: 0.3597, Validation accuracy: 0.8828\n",
      "Saving ...\n",
      "\n",
      "Epoch 101:\n",
      "Training loss: 0.1809, Training accuracy: 0.9357\n",
      "Validation loss: 0.3596, Validation accuracy: 0.8813\n",
      "\n",
      "Epoch 102:\n",
      "Training loss: 0.1814, Training accuracy: 0.9368\n",
      "Validation loss: 0.3624, Validation accuracy: 0.8805\n",
      "\n",
      "Epoch 103:\n",
      "Training loss: 0.1787, Training accuracy: 0.9377\n",
      "Validation loss: 0.3637, Validation accuracy: 0.8798\n",
      "\n",
      "Epoch 104:\n",
      "Training loss: 0.1809, Training accuracy: 0.9374\n",
      "Validation loss: 0.3676, Validation accuracy: 0.8772\n",
      "\n",
      "Epoch 105:\n",
      "Training loss: 0.1795, Training accuracy: 0.9358\n",
      "Validation loss: 0.3718, Validation accuracy: 0.8758\n",
      "\n",
      "Epoch 106:\n",
      "Training loss: 0.1770, Training accuracy: 0.9377\n",
      "Validation loss: 0.3664, Validation accuracy: 0.8778\n",
      "\n",
      "Epoch 107:\n",
      "Training loss: 0.1774, Training accuracy: 0.9373\n",
      "Validation loss: 0.3609, Validation accuracy: 0.8838\n",
      "Saving ...\n",
      "\n",
      "Epoch 108:\n",
      "Training loss: 0.1778, Training accuracy: 0.9390\n",
      "Validation loss: 0.3581, Validation accuracy: 0.8831\n",
      "\n",
      "Epoch 109:\n",
      "Training loss: 0.1755, Training accuracy: 0.9386\n",
      "Validation loss: 0.3688, Validation accuracy: 0.8779\n",
      "\n",
      "Epoch 110:\n",
      "Training loss: 0.1741, Training accuracy: 0.9400\n",
      "Validation loss: 0.3582, Validation accuracy: 0.8822\n",
      "\n",
      "Epoch 111:\n",
      "Training loss: 0.1721, Training accuracy: 0.9415\n",
      "Validation loss: 0.3547, Validation accuracy: 0.8822\n",
      "\n",
      "Epoch 112:\n",
      "Training loss: 0.1740, Training accuracy: 0.9402\n",
      "Validation loss: 0.3580, Validation accuracy: 0.8818\n",
      "\n",
      "Epoch 113:\n",
      "Training loss: 0.1721, Training accuracy: 0.9413\n",
      "Validation loss: 0.3625, Validation accuracy: 0.8793\n",
      "\n",
      "Epoch 114:\n",
      "Training loss: 0.1732, Training accuracy: 0.9394\n",
      "Validation loss: 0.3556, Validation accuracy: 0.8851\n",
      "Saving ...\n",
      "\n",
      "Epoch 115:\n",
      "Training loss: 0.1738, Training accuracy: 0.9400\n",
      "Validation loss: 0.3628, Validation accuracy: 0.8821\n",
      "\n",
      "Epoch 116:\n",
      "Training loss: 0.1734, Training accuracy: 0.9399\n",
      "Validation loss: 0.3599, Validation accuracy: 0.8786\n",
      "\n",
      "Epoch 117:\n",
      "Training loss: 0.1703, Training accuracy: 0.9412\n",
      "Validation loss: 0.3610, Validation accuracy: 0.8793\n",
      "\n",
      "Epoch 118:\n",
      "Training loss: 0.1685, Training accuracy: 0.9429\n",
      "Validation loss: 0.3573, Validation accuracy: 0.8854\n",
      "Saving ...\n",
      "\n",
      "Epoch 119:\n",
      "Training loss: 0.1674, Training accuracy: 0.9434\n",
      "Validation loss: 0.3651, Validation accuracy: 0.8767\n",
      "\n",
      "Epoch 120:\n",
      "Training loss: 0.1666, Training accuracy: 0.9433\n",
      "Validation loss: 0.3550, Validation accuracy: 0.8830\n",
      "\n",
      "Epoch 121:\n",
      "Training loss: 0.1677, Training accuracy: 0.9437\n",
      "Validation loss: 0.3490, Validation accuracy: 0.8863\n",
      "Saving ...\n",
      "\n",
      "Epoch 122:\n",
      "Training loss: 0.1668, Training accuracy: 0.9437\n",
      "Validation loss: 0.3618, Validation accuracy: 0.8793\n",
      "\n",
      "Epoch 123:\n",
      "Training loss: 0.1665, Training accuracy: 0.9436\n",
      "Validation loss: 0.3610, Validation accuracy: 0.8799\n",
      "\n",
      "Epoch 124:\n",
      "Training loss: 0.1667, Training accuracy: 0.9425\n",
      "Validation loss: 0.3460, Validation accuracy: 0.8864\n",
      "Saving ...\n",
      "\n",
      "Epoch 125:\n",
      "Training loss: 0.1628, Training accuracy: 0.9446\n",
      "Validation loss: 0.3613, Validation accuracy: 0.8816\n",
      "\n",
      "Epoch 126:\n",
      "Training loss: 0.1659, Training accuracy: 0.9435\n",
      "Validation loss: 0.3580, Validation accuracy: 0.8822\n",
      "\n",
      "Epoch 127:\n",
      "Training loss: 0.1622, Training accuracy: 0.9463\n",
      "Validation loss: 0.3449, Validation accuracy: 0.8844\n",
      "\n",
      "Epoch 128:\n",
      "Training loss: 0.1636, Training accuracy: 0.9461\n",
      "Validation loss: 0.3569, Validation accuracy: 0.8809\n",
      "\n",
      "Epoch 129:\n",
      "Training loss: 0.1609, Training accuracy: 0.9474\n",
      "Validation loss: 0.3552, Validation accuracy: 0.8817\n",
      "\n",
      "Epoch 130:\n",
      "Training loss: 0.1626, Training accuracy: 0.9456\n",
      "Validation loss: 0.3499, Validation accuracy: 0.8848\n",
      "\n",
      "Epoch 131:\n",
      "Training loss: 0.1605, Training accuracy: 0.9464\n",
      "Validation loss: 0.3525, Validation accuracy: 0.8852\n",
      "\n",
      "Epoch 132:\n",
      "Training loss: 0.1610, Training accuracy: 0.9466\n",
      "Validation loss: 0.3635, Validation accuracy: 0.8819\n",
      "\n",
      "Epoch 133:\n",
      "Training loss: 0.1592, Training accuracy: 0.9475\n",
      "Validation loss: 0.3535, Validation accuracy: 0.8842\n",
      "\n",
      "Epoch 134:\n",
      "Training loss: 0.1574, Training accuracy: 0.9487\n",
      "Validation loss: 0.3650, Validation accuracy: 0.8782\n",
      "\n",
      "Epoch 135:\n",
      "Training loss: 0.1609, Training accuracy: 0.9481\n",
      "Validation loss: 0.3640, Validation accuracy: 0.8784\n",
      "\n",
      "Epoch 136:\n",
      "Training loss: 0.1590, Training accuracy: 0.9482\n",
      "Validation loss: 0.3599, Validation accuracy: 0.8833\n",
      "\n",
      "Epoch 137:\n",
      "Training loss: 0.1578, Training accuracy: 0.9472\n",
      "Validation loss: 0.3534, Validation accuracy: 0.8821\n",
      "\n",
      "Epoch 138:\n",
      "Training loss: 0.1561, Training accuracy: 0.9483\n",
      "Validation loss: 0.3562, Validation accuracy: 0.8812\n",
      "\n",
      "Epoch 139:\n",
      "Training loss: 0.1571, Training accuracy: 0.9477\n",
      "Validation loss: 0.3598, Validation accuracy: 0.8808\n",
      "\n",
      "Epoch 140:\n",
      "Training loss: 0.1569, Training accuracy: 0.9488\n",
      "Validation loss: 0.3467, Validation accuracy: 0.8884\n",
      "Saving ...\n",
      "\n",
      "Epoch 141:\n",
      "Training loss: 0.1577, Training accuracy: 0.9482\n",
      "Validation loss: 0.3617, Validation accuracy: 0.8802\n",
      "\n",
      "Epoch 142:\n",
      "Training loss: 0.1557, Training accuracy: 0.9488\n",
      "Validation loss: 0.3486, Validation accuracy: 0.8848\n",
      "\n",
      "Epoch 143:\n",
      "Training loss: 0.1562, Training accuracy: 0.9490\n",
      "Validation loss: 0.3593, Validation accuracy: 0.8820\n",
      "\n",
      "Epoch 144:\n",
      "Training loss: 0.1556, Training accuracy: 0.9485\n",
      "Validation loss: 0.3457, Validation accuracy: 0.8859\n",
      "\n",
      "Epoch 145:\n",
      "Training loss: 0.1521, Training accuracy: 0.9516\n",
      "Validation loss: 0.3609, Validation accuracy: 0.8814\n",
      "\n",
      "Epoch 146:\n",
      "Training loss: 0.1537, Training accuracy: 0.9504\n",
      "Validation loss: 0.3507, Validation accuracy: 0.8852\n",
      "\n",
      "Epoch 147:\n",
      "Training loss: 0.1525, Training accuracy: 0.9502\n",
      "Validation loss: 0.3556, Validation accuracy: 0.8840\n",
      "\n",
      "Epoch 148:\n",
      "Training loss: 0.1516, Training accuracy: 0.9510\n",
      "Validation loss: 0.3445, Validation accuracy: 0.8871\n",
      "\n",
      "Epoch 149:\n",
      "Training loss: 0.1532, Training accuracy: 0.9490\n",
      "Validation loss: 0.3456, Validation accuracy: 0.8874\n",
      "\n",
      "Epoch 150:\n",
      "Training loss: 0.1548, Training accuracy: 0.9489\n",
      "Validation loss: 0.3477, Validation accuracy: 0.8865\n",
      "\n",
      "Epoch 151:\n",
      "Training loss: 0.1505, Training accuracy: 0.9518\n",
      "Validation loss: 0.3496, Validation accuracy: 0.8860\n",
      "\n",
      "Epoch 152:\n",
      "Training loss: 0.1501, Training accuracy: 0.9521\n",
      "Validation loss: 0.3608, Validation accuracy: 0.8808\n",
      "\n",
      "Epoch 153:\n",
      "Training loss: 0.1514, Training accuracy: 0.9511\n",
      "Validation loss: 0.3408, Validation accuracy: 0.8877\n",
      "\n",
      "Epoch 154:\n",
      "Training loss: 0.1504, Training accuracy: 0.9521\n",
      "Validation loss: 0.3526, Validation accuracy: 0.8830\n",
      "\n",
      "Epoch 155:\n",
      "Training loss: 0.1523, Training accuracy: 0.9513\n",
      "Validation loss: 0.3505, Validation accuracy: 0.8861\n",
      "\n",
      "Epoch 156:\n",
      "Training loss: 0.1493, Training accuracy: 0.9528\n",
      "Validation loss: 0.3554, Validation accuracy: 0.8835\n",
      "\n",
      "Epoch 157:\n",
      "Training loss: 0.1492, Training accuracy: 0.9518\n",
      "Validation loss: 0.3558, Validation accuracy: 0.8845\n",
      "\n",
      "Epoch 158:\n",
      "Training loss: 0.1491, Training accuracy: 0.9530\n",
      "Validation loss: 0.3539, Validation accuracy: 0.8830\n",
      "\n",
      "Epoch 159:\n",
      "Training loss: 0.1472, Training accuracy: 0.9526\n",
      "Validation loss: 0.3515, Validation accuracy: 0.8839\n",
      "\n",
      "Epoch 160:\n",
      "Training loss: 0.1475, Training accuracy: 0.9522\n",
      "Validation loss: 0.3533, Validation accuracy: 0.8852\n",
      "\n",
      "Epoch 161:\n",
      "Training loss: 0.1461, Training accuracy: 0.9552\n",
      "Validation loss: 0.3535, Validation accuracy: 0.8835\n",
      "\n",
      "Epoch 162:\n",
      "Training loss: 0.1451, Training accuracy: 0.9545\n",
      "Validation loss: 0.3533, Validation accuracy: 0.8847\n",
      "\n",
      "Epoch 163:\n",
      "Training loss: 0.1470, Training accuracy: 0.9539\n",
      "Validation loss: 0.3438, Validation accuracy: 0.8887\n",
      "Saving ...\n",
      "\n",
      "Epoch 164:\n",
      "Training loss: 0.1463, Training accuracy: 0.9534\n",
      "Validation loss: 0.3483, Validation accuracy: 0.8865\n",
      "\n",
      "Epoch 165:\n",
      "Training loss: 0.1460, Training accuracy: 0.9541\n",
      "Validation loss: 0.3596, Validation accuracy: 0.8837\n",
      "\n",
      "Epoch 166:\n",
      "Training loss: 0.1437, Training accuracy: 0.9549\n",
      "Validation loss: 0.3552, Validation accuracy: 0.8831\n",
      "\n",
      "Epoch 167:\n",
      "Training loss: 0.1449, Training accuracy: 0.9544\n",
      "Validation loss: 0.3484, Validation accuracy: 0.8852\n",
      "\n",
      "Epoch 168:\n",
      "Training loss: 0.1444, Training accuracy: 0.9539\n",
      "Validation loss: 0.3423, Validation accuracy: 0.8897\n",
      "Saving ...\n",
      "\n",
      "Epoch 169:\n",
      "Training loss: 0.1423, Training accuracy: 0.9560\n",
      "Validation loss: 0.3537, Validation accuracy: 0.8841\n",
      "\n",
      "Epoch 170:\n",
      "Training loss: 0.1436, Training accuracy: 0.9556\n",
      "Validation loss: 0.3494, Validation accuracy: 0.8860\n",
      "\n",
      "Epoch 171:\n",
      "Training loss: 0.1423, Training accuracy: 0.9562\n",
      "Validation loss: 0.3502, Validation accuracy: 0.8855\n",
      "\n",
      "Epoch 172:\n",
      "Training loss: 0.1412, Training accuracy: 0.9566\n",
      "Validation loss: 0.3454, Validation accuracy: 0.8871\n",
      "\n",
      "Epoch 173:\n",
      "Training loss: 0.1437, Training accuracy: 0.9552\n",
      "Validation loss: 0.3615, Validation accuracy: 0.8838\n",
      "\n",
      "Epoch 174:\n",
      "Training loss: 0.1454, Training accuracy: 0.9544\n",
      "Validation loss: 0.3481, Validation accuracy: 0.8864\n",
      "\n",
      "Epoch 175:\n",
      "Training loss: 0.1446, Training accuracy: 0.9549\n",
      "Validation loss: 0.3545, Validation accuracy: 0.8842\n",
      "\n",
      "Epoch 176:\n",
      "Training loss: 0.1418, Training accuracy: 0.9567\n",
      "Validation loss: 0.3473, Validation accuracy: 0.8897\n",
      "\n",
      "Epoch 177:\n",
      "Training loss: 0.1414, Training accuracy: 0.9562\n",
      "Validation loss: 0.3574, Validation accuracy: 0.8835\n",
      "\n",
      "Epoch 178:\n",
      "Training loss: 0.1421, Training accuracy: 0.9555\n",
      "Validation loss: 0.3528, Validation accuracy: 0.8882\n",
      "\n",
      "Epoch 179:\n",
      "Training loss: 0.1410, Training accuracy: 0.9575\n",
      "Validation loss: 0.3484, Validation accuracy: 0.8854\n",
      "\n",
      "Epoch 180:\n",
      "Training loss: 0.1423, Training accuracy: 0.9554\n",
      "Validation loss: 0.3542, Validation accuracy: 0.8846\n",
      "\n",
      "Epoch 181:\n",
      "Training loss: 0.1410, Training accuracy: 0.9565\n",
      "Validation loss: 0.3449, Validation accuracy: 0.8875\n",
      "\n",
      "Epoch 182:\n",
      "Training loss: 0.1418, Training accuracy: 0.9568\n",
      "Validation loss: 0.3429, Validation accuracy: 0.8863\n",
      "\n",
      "Epoch 183:\n",
      "Training loss: 0.1396, Training accuracy: 0.9575\n",
      "Validation loss: 0.3547, Validation accuracy: 0.8842\n",
      "\n",
      "Epoch 184:\n",
      "Training loss: 0.1401, Training accuracy: 0.9566\n",
      "Validation loss: 0.3458, Validation accuracy: 0.8865\n",
      "\n",
      "Epoch 185:\n",
      "Training loss: 0.1388, Training accuracy: 0.9575\n",
      "Validation loss: 0.3603, Validation accuracy: 0.8840\n",
      "\n",
      "Epoch 186:\n",
      "Training loss: 0.1417, Training accuracy: 0.9558\n",
      "Validation loss: 0.3441, Validation accuracy: 0.8873\n",
      "\n",
      "Epoch 187:\n",
      "Training loss: 0.1384, Training accuracy: 0.9578\n",
      "Validation loss: 0.3495, Validation accuracy: 0.8874\n",
      "\n",
      "Epoch 188:\n",
      "Training loss: 0.1389, Training accuracy: 0.9586\n",
      "Validation loss: 0.3569, Validation accuracy: 0.8864\n",
      "\n",
      "Epoch 189:\n",
      "Training loss: 0.1378, Training accuracy: 0.9580\n",
      "Validation loss: 0.3536, Validation accuracy: 0.8857\n",
      "\n",
      "Epoch 190:\n",
      "Training loss: 0.1365, Training accuracy: 0.9583\n",
      "Validation loss: 0.3450, Validation accuracy: 0.8877\n",
      "\n",
      "Epoch 191:\n",
      "Training loss: 0.1390, Training accuracy: 0.9578\n",
      "Validation loss: 0.3522, Validation accuracy: 0.8825\n",
      "\n",
      "Epoch 192:\n",
      "Training loss: 0.1387, Training accuracy: 0.9581\n",
      "Validation loss: 0.3495, Validation accuracy: 0.8878\n",
      "\n",
      "Epoch 193:\n",
      "Training loss: 0.1365, Training accuracy: 0.9591\n",
      "Validation loss: 0.3467, Validation accuracy: 0.8880\n",
      "\n",
      "Epoch 194:\n",
      "Training loss: 0.1382, Training accuracy: 0.9584\n",
      "Validation loss: 0.3383, Validation accuracy: 0.8900\n",
      "Saving ...\n",
      "\n",
      "Epoch 195:\n",
      "Training loss: 0.1385, Training accuracy: 0.9585\n",
      "Validation loss: 0.3583, Validation accuracy: 0.8840\n",
      "\n",
      "Epoch 196:\n",
      "Training loss: 0.1362, Training accuracy: 0.9598\n",
      "Validation loss: 0.3539, Validation accuracy: 0.8842\n",
      "\n",
      "Epoch 197:\n",
      "Training loss: 0.1350, Training accuracy: 0.9597\n",
      "Validation loss: 0.3460, Validation accuracy: 0.8877\n",
      "\n",
      "Epoch 198:\n",
      "Training loss: 0.1366, Training accuracy: 0.9593\n",
      "Validation loss: 0.3418, Validation accuracy: 0.8875\n",
      "\n",
      "Epoch 199:\n",
      "Training loss: 0.1370, Training accuracy: 0.9574\n",
      "Validation loss: 0.3456, Validation accuracy: 0.8891\n",
      "\n",
      "==================================================\n",
      "==> Optimization finished! Best validation accuracy: 0.8900\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.89"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train(student,teacher,optimizer,criterion,1,[1,0,0],1,train_loader,val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Training starts!\n",
      "==================================================\n",
      "Epoch 0:\n",
      "Training loss: 2.5655, Training accuracy: 0.4233\n",
      "Validation loss: 1.3180, Validation accuracy: 0.5279\n",
      "Saving ...\n",
      "\n",
      "Epoch 1:\n",
      "Training loss: 1.9464, Training accuracy: 0.5716\n",
      "Validation loss: 1.1163, Validation accuracy: 0.6095\n",
      "Saving ...\n",
      "\n",
      "Epoch 2:\n",
      "Training loss: 1.6837, Training accuracy: 0.6352\n",
      "Validation loss: 1.0471, Validation accuracy: 0.6463\n",
      "Saving ...\n",
      "\n",
      "Epoch 3:\n",
      "Training loss: 1.5188, Training accuracy: 0.6716\n",
      "Validation loss: 0.9085, Validation accuracy: 0.6855\n",
      "Saving ...\n",
      "\n",
      "Epoch 4:\n",
      "Training loss: 1.4000, Training accuracy: 0.7055\n",
      "Validation loss: 0.8691, Validation accuracy: 0.6981\n",
      "Saving ...\n",
      "\n",
      "Epoch 5:\n",
      "Training loss: 1.3154, Training accuracy: 0.7224\n",
      "Validation loss: 0.8272, Validation accuracy: 0.7175\n",
      "Saving ...\n",
      "\n",
      "Epoch 6:\n",
      "Training loss: 1.2348, Training accuracy: 0.7404\n",
      "Validation loss: 0.8601, Validation accuracy: 0.7113\n",
      "\n",
      "Epoch 7:\n",
      "Training loss: 1.1705, Training accuracy: 0.7554\n",
      "Validation loss: 0.7240, Validation accuracy: 0.7535\n",
      "Saving ...\n",
      "\n",
      "Epoch 8:\n",
      "Training loss: 1.1213, Training accuracy: 0.7674\n",
      "Validation loss: 0.7227, Validation accuracy: 0.7540\n",
      "Saving ...\n",
      "\n",
      "Epoch 9:\n",
      "Training loss: 1.0657, Training accuracy: 0.7803\n",
      "Validation loss: 0.7105, Validation accuracy: 0.7622\n",
      "Saving ...\n",
      "\n",
      "Epoch 10:\n",
      "Training loss: 1.0410, Training accuracy: 0.7815\n",
      "Validation loss: 0.7035, Validation accuracy: 0.7643\n",
      "Saving ...\n",
      "\n",
      "Epoch 11:\n",
      "Training loss: 1.0007, Training accuracy: 0.7914\n",
      "Validation loss: 0.6269, Validation accuracy: 0.7871\n",
      "Saving ...\n",
      "\n",
      "Epoch 12:\n",
      "Training loss: 0.9719, Training accuracy: 0.7996\n",
      "Validation loss: 0.6443, Validation accuracy: 0.7803\n",
      "\n",
      "Epoch 13:\n",
      "Training loss: 0.9463, Training accuracy: 0.8068\n",
      "Validation loss: 0.6213, Validation accuracy: 0.7955\n",
      "Saving ...\n",
      "\n",
      "Epoch 14:\n",
      "Training loss: 0.9178, Training accuracy: 0.8105\n",
      "Validation loss: 0.5903, Validation accuracy: 0.8023\n",
      "Saving ...\n",
      "\n",
      "Epoch 15:\n",
      "Training loss: 0.8986, Training accuracy: 0.8164\n",
      "Validation loss: 0.5992, Validation accuracy: 0.7997\n",
      "\n",
      "Epoch 16:\n",
      "Training loss: 0.8785, Training accuracy: 0.8201\n",
      "Validation loss: 0.5600, Validation accuracy: 0.8121\n",
      "Saving ...\n",
      "\n",
      "Epoch 17:\n",
      "Training loss: 0.8614, Training accuracy: 0.8239\n",
      "Validation loss: 0.5846, Validation accuracy: 0.8031\n",
      "\n",
      "Epoch 18:\n",
      "Training loss: 0.8446, Training accuracy: 0.8266\n",
      "Validation loss: 0.5282, Validation accuracy: 0.8236\n",
      "Saving ...\n",
      "\n",
      "Epoch 19:\n",
      "Training loss: 0.8295, Training accuracy: 0.8296\n",
      "Validation loss: 0.5502, Validation accuracy: 0.8175\n",
      "\n",
      "Epoch 20:\n",
      "Training loss: 0.8162, Training accuracy: 0.8340\n",
      "Validation loss: 0.5541, Validation accuracy: 0.8121\n",
      "\n",
      "Epoch 21:\n",
      "Training loss: 0.7991, Training accuracy: 0.8366\n",
      "Validation loss: 0.5339, Validation accuracy: 0.8215\n",
      "\n",
      "Epoch 22:\n",
      "Training loss: 0.7954, Training accuracy: 0.8387\n",
      "Validation loss: 0.5387, Validation accuracy: 0.8221\n",
      "\n",
      "Epoch 23:\n",
      "Training loss: 0.7720, Training accuracy: 0.8429\n",
      "Validation loss: 0.5317, Validation accuracy: 0.8240\n",
      "Saving ...\n",
      "\n",
      "Epoch 24:\n",
      "Training loss: 0.7686, Training accuracy: 0.8453\n",
      "Validation loss: 0.5061, Validation accuracy: 0.8322\n",
      "Saving ...\n",
      "\n",
      "Epoch 25:\n",
      "Training loss: 0.7525, Training accuracy: 0.8483\n",
      "Validation loss: 0.5320, Validation accuracy: 0.8215\n",
      "\n",
      "Epoch 26:\n",
      "Training loss: 0.7463, Training accuracy: 0.8477\n",
      "Validation loss: 0.5242, Validation accuracy: 0.8298\n",
      "\n",
      "Epoch 27:\n",
      "Training loss: 0.7375, Training accuracy: 0.8518\n",
      "Validation loss: 0.5064, Validation accuracy: 0.8335\n",
      "Saving ...\n",
      "\n",
      "Epoch 28:\n",
      "Training loss: 0.7256, Training accuracy: 0.8543\n",
      "Validation loss: 0.4959, Validation accuracy: 0.8373\n",
      "Saving ...\n",
      "\n",
      "Epoch 29:\n",
      "Training loss: 0.7135, Training accuracy: 0.8547\n",
      "Validation loss: 0.5093, Validation accuracy: 0.8312\n",
      "\n",
      "Epoch 30:\n",
      "Training loss: 0.7098, Training accuracy: 0.8553\n",
      "Validation loss: 0.4811, Validation accuracy: 0.8417\n",
      "Saving ...\n",
      "\n",
      "Epoch 31:\n",
      "Training loss: 0.6984, Training accuracy: 0.8591\n",
      "Validation loss: 0.4872, Validation accuracy: 0.8396\n",
      "\n",
      "Epoch 32:\n",
      "Training loss: 0.6948, Training accuracy: 0.8616\n",
      "Validation loss: 0.4804, Validation accuracy: 0.8363\n",
      "\n",
      "Epoch 33:\n",
      "Training loss: 0.6885, Training accuracy: 0.8606\n",
      "Validation loss: 0.4694, Validation accuracy: 0.8430\n",
      "Saving ...\n",
      "\n",
      "Epoch 34:\n",
      "Training loss: 0.6753, Training accuracy: 0.8666\n",
      "Validation loss: 0.4719, Validation accuracy: 0.8430\n",
      "\n",
      "Epoch 35:\n",
      "Training loss: 0.6711, Training accuracy: 0.8636\n",
      "Validation loss: 0.4798, Validation accuracy: 0.8420\n",
      "\n",
      "Epoch 36:\n",
      "Training loss: 0.6603, Training accuracy: 0.8677\n",
      "Validation loss: 0.4636, Validation accuracy: 0.8475\n",
      "Saving ...\n",
      "\n",
      "Epoch 37:\n",
      "Training loss: 0.6552, Training accuracy: 0.8692\n",
      "Validation loss: 0.4751, Validation accuracy: 0.8394\n",
      "\n",
      "Epoch 38:\n",
      "Training loss: 0.6498, Training accuracy: 0.8693\n",
      "Validation loss: 0.4560, Validation accuracy: 0.8505\n",
      "Saving ...\n",
      "\n",
      "Epoch 39:\n",
      "Training loss: 0.6413, Training accuracy: 0.8705\n",
      "Validation loss: 0.4740, Validation accuracy: 0.8424\n",
      "\n",
      "Epoch 40:\n",
      "Training loss: 0.6387, Training accuracy: 0.8733\n",
      "Validation loss: 0.4429, Validation accuracy: 0.8548\n",
      "Saving ...\n",
      "\n",
      "Epoch 41:\n",
      "Training loss: 0.6280, Training accuracy: 0.8753\n",
      "Validation loss: 0.4729, Validation accuracy: 0.8402\n",
      "\n",
      "Epoch 42:\n",
      "Training loss: 0.6296, Training accuracy: 0.8751\n",
      "Validation loss: 0.4374, Validation accuracy: 0.8558\n",
      "Saving ...\n",
      "\n",
      "Epoch 43:\n",
      "Training loss: 0.6217, Training accuracy: 0.8764\n",
      "Validation loss: 0.4385, Validation accuracy: 0.8585\n",
      "Saving ...\n",
      "\n",
      "Epoch 44:\n",
      "Training loss: 0.6150, Training accuracy: 0.8774\n",
      "Validation loss: 0.4541, Validation accuracy: 0.8514\n",
      "\n",
      "Epoch 45:\n",
      "Training loss: 0.6094, Training accuracy: 0.8790\n",
      "Validation loss: 0.4422, Validation accuracy: 0.8557\n",
      "\n",
      "Epoch 46:\n",
      "Training loss: 0.6042, Training accuracy: 0.8788\n",
      "Validation loss: 0.4391, Validation accuracy: 0.8579\n",
      "\n",
      "Epoch 47:\n",
      "Training loss: 0.6028, Training accuracy: 0.8805\n",
      "Validation loss: 0.4386, Validation accuracy: 0.8564\n",
      "\n",
      "Epoch 48:\n",
      "Training loss: 0.5946, Training accuracy: 0.8832\n",
      "Validation loss: 0.4429, Validation accuracy: 0.8518\n",
      "\n",
      "Epoch 49:\n",
      "Training loss: 0.5910, Training accuracy: 0.8816\n",
      "Validation loss: 0.4328, Validation accuracy: 0.8586\n",
      "Saving ...\n",
      "\n",
      "Epoch 50:\n",
      "Training loss: 0.5855, Training accuracy: 0.8841\n",
      "Validation loss: 0.4272, Validation accuracy: 0.8575\n",
      "\n",
      "Epoch 51:\n",
      "Training loss: 0.5852, Training accuracy: 0.8844\n",
      "Validation loss: 0.4221, Validation accuracy: 0.8610\n",
      "Saving ...\n",
      "\n",
      "Epoch 52:\n",
      "Training loss: 0.5747, Training accuracy: 0.8889\n",
      "Validation loss: 0.4355, Validation accuracy: 0.8560\n",
      "\n",
      "Epoch 53:\n",
      "Training loss: 0.5756, Training accuracy: 0.8868\n",
      "Validation loss: 0.4208, Validation accuracy: 0.8613\n",
      "Saving ...\n",
      "\n",
      "Epoch 54:\n",
      "Training loss: 0.5778, Training accuracy: 0.8871\n",
      "Validation loss: 0.4246, Validation accuracy: 0.8581\n",
      "\n",
      "Epoch 55:\n",
      "Training loss: 0.5706, Training accuracy: 0.8871\n",
      "Validation loss: 0.4229, Validation accuracy: 0.8629\n",
      "Saving ...\n",
      "\n",
      "Epoch 56:\n",
      "Training loss: 0.5634, Training accuracy: 0.8882\n",
      "Validation loss: 0.4062, Validation accuracy: 0.8654\n",
      "Saving ...\n",
      "\n",
      "Epoch 57:\n",
      "Training loss: 0.5639, Training accuracy: 0.8902\n",
      "Validation loss: 0.4386, Validation accuracy: 0.8529\n",
      "\n",
      "Epoch 58:\n",
      "Training loss: 0.5615, Training accuracy: 0.8911\n",
      "Validation loss: 0.4484, Validation accuracy: 0.8537\n",
      "\n",
      "Epoch 59:\n",
      "Training loss: 0.5552, Training accuracy: 0.8921\n",
      "Validation loss: 0.4234, Validation accuracy: 0.8619\n",
      "\n",
      "Epoch 60:\n",
      "Training loss: 0.5546, Training accuracy: 0.8928\n",
      "Validation loss: 0.4053, Validation accuracy: 0.8606\n",
      "\n",
      "Epoch 61:\n",
      "Training loss: 0.5453, Training accuracy: 0.8938\n",
      "Validation loss: 0.4046, Validation accuracy: 0.8668\n",
      "Saving ...\n",
      "\n",
      "Epoch 62:\n",
      "Training loss: 0.5487, Training accuracy: 0.8941\n",
      "Validation loss: 0.4154, Validation accuracy: 0.8611\n",
      "\n",
      "Epoch 63:\n",
      "Training loss: 0.5444, Training accuracy: 0.8943\n",
      "Validation loss: 0.4340, Validation accuracy: 0.8591\n",
      "\n",
      "Epoch 64:\n",
      "Training loss: 0.5409, Training accuracy: 0.8940\n",
      "Validation loss: 0.4053, Validation accuracy: 0.8677\n",
      "Saving ...\n",
      "\n",
      "Epoch 65:\n",
      "Training loss: 0.5423, Training accuracy: 0.8956\n",
      "Validation loss: 0.4123, Validation accuracy: 0.8640\n",
      "\n",
      "Epoch 66:\n",
      "Training loss: 0.5308, Training accuracy: 0.8961\n",
      "Validation loss: 0.3969, Validation accuracy: 0.8684\n",
      "Saving ...\n",
      "\n",
      "Epoch 67:\n",
      "Training loss: 0.5290, Training accuracy: 0.8974\n",
      "Validation loss: 0.3955, Validation accuracy: 0.8742\n",
      "Saving ...\n",
      "\n",
      "Epoch 68:\n",
      "Training loss: 0.5287, Training accuracy: 0.8968\n",
      "Validation loss: 0.4179, Validation accuracy: 0.8614\n",
      "\n",
      "Epoch 69:\n",
      "Training loss: 0.5259, Training accuracy: 0.8984\n",
      "Validation loss: 0.4089, Validation accuracy: 0.8680\n",
      "\n",
      "Epoch 70:\n",
      "Training loss: 0.5233, Training accuracy: 0.9000\n",
      "Validation loss: 0.3997, Validation accuracy: 0.8687\n",
      "\n",
      "Epoch 71:\n",
      "Training loss: 0.5156, Training accuracy: 0.8995\n",
      "Validation loss: 0.3932, Validation accuracy: 0.8714\n",
      "\n",
      "Epoch 72:\n",
      "Training loss: 0.5186, Training accuracy: 0.8989\n",
      "Validation loss: 0.4134, Validation accuracy: 0.8629\n",
      "\n",
      "Epoch 73:\n",
      "Training loss: 0.5137, Training accuracy: 0.9006\n",
      "Validation loss: 0.3914, Validation accuracy: 0.8696\n",
      "\n",
      "Epoch 74:\n",
      "Training loss: 0.5098, Training accuracy: 0.9030\n",
      "Validation loss: 0.3942, Validation accuracy: 0.8720\n",
      "\n",
      "Epoch 75:\n",
      "Training loss: 0.5068, Training accuracy: 0.9033\n",
      "Validation loss: 0.4024, Validation accuracy: 0.8689\n",
      "\n",
      "Epoch 76:\n",
      "Training loss: 0.5059, Training accuracy: 0.9042\n",
      "Validation loss: 0.3969, Validation accuracy: 0.8708\n",
      "\n",
      "Epoch 77:\n",
      "Training loss: 0.5013, Training accuracy: 0.9024\n",
      "Validation loss: 0.3947, Validation accuracy: 0.8721\n",
      "\n",
      "Epoch 78:\n",
      "Training loss: 0.5050, Training accuracy: 0.9026\n",
      "Validation loss: 0.3857, Validation accuracy: 0.8730\n",
      "\n",
      "Epoch 79:\n",
      "Training loss: 0.4994, Training accuracy: 0.9045\n",
      "Validation loss: 0.3861, Validation accuracy: 0.8784\n",
      "Saving ...\n",
      "\n",
      "Epoch 80:\n",
      "Training loss: 0.4975, Training accuracy: 0.9036\n",
      "Validation loss: 0.4049, Validation accuracy: 0.8648\n",
      "\n",
      "Epoch 81:\n",
      "Training loss: 0.4897, Training accuracy: 0.9053\n",
      "Validation loss: 0.4080, Validation accuracy: 0.8670\n",
      "\n",
      "Epoch 82:\n",
      "Training loss: 0.4927, Training accuracy: 0.9064\n",
      "Validation loss: 0.3984, Validation accuracy: 0.8689\n",
      "\n",
      "Epoch 83:\n",
      "Training loss: 0.4922, Training accuracy: 0.9057\n",
      "Validation loss: 0.3946, Validation accuracy: 0.8691\n",
      "\n",
      "Epoch 84:\n",
      "Training loss: 0.4875, Training accuracy: 0.9063\n",
      "Validation loss: 0.3746, Validation accuracy: 0.8781\n",
      "\n",
      "Epoch 85:\n",
      "Training loss: 0.4853, Training accuracy: 0.9066\n",
      "Validation loss: 0.4014, Validation accuracy: 0.8706\n",
      "\n",
      "Epoch 86:\n",
      "Training loss: 0.4836, Training accuracy: 0.9070\n",
      "Validation loss: 0.3975, Validation accuracy: 0.8692\n",
      "\n",
      "Epoch 87:\n",
      "Training loss: 0.4861, Training accuracy: 0.9061\n",
      "Validation loss: 0.3907, Validation accuracy: 0.8713\n",
      "\n",
      "Epoch 88:\n",
      "Training loss: 0.4826, Training accuracy: 0.9067\n",
      "Validation loss: 0.3948, Validation accuracy: 0.8695\n",
      "\n",
      "Epoch 89:\n",
      "Training loss: 0.4768, Training accuracy: 0.9079\n",
      "Validation loss: 0.3839, Validation accuracy: 0.8752\n",
      "\n",
      "Epoch 90:\n",
      "Training loss: 0.4805, Training accuracy: 0.9080\n",
      "Validation loss: 0.3793, Validation accuracy: 0.8755\n",
      "\n",
      "Epoch 91:\n",
      "Training loss: 0.4766, Training accuracy: 0.9103\n",
      "Validation loss: 0.4055, Validation accuracy: 0.8652\n",
      "\n",
      "Epoch 92:\n",
      "Training loss: 0.4769, Training accuracy: 0.9100\n",
      "Validation loss: 0.3852, Validation accuracy: 0.8729\n",
      "\n",
      "Epoch 93:\n",
      "Training loss: 0.4713, Training accuracy: 0.9100\n",
      "Validation loss: 0.3725, Validation accuracy: 0.8769\n",
      "\n",
      "Epoch 94:\n",
      "Training loss: 0.4703, Training accuracy: 0.9104\n",
      "Validation loss: 0.3985, Validation accuracy: 0.8664\n",
      "\n",
      "Epoch 95:\n",
      "Training loss: 0.4654, Training accuracy: 0.9095\n",
      "Validation loss: 0.3823, Validation accuracy: 0.8736\n",
      "\n",
      "Epoch 96:\n",
      "Training loss: 0.4703, Training accuracy: 0.9099\n",
      "Validation loss: 0.4055, Validation accuracy: 0.8659\n",
      "\n",
      "Epoch 97:\n",
      "Training loss: 0.4644, Training accuracy: 0.9124\n",
      "Validation loss: 0.3767, Validation accuracy: 0.8777\n",
      "\n",
      "Epoch 98:\n",
      "Training loss: 0.4664, Training accuracy: 0.9106\n",
      "Validation loss: 0.3828, Validation accuracy: 0.8725\n",
      "\n",
      "Epoch 99:\n",
      "Training loss: 0.4570, Training accuracy: 0.9132\n",
      "Validation loss: 0.3857, Validation accuracy: 0.8734\n",
      "\n",
      "Epoch 100:\n",
      "Training loss: 0.4630, Training accuracy: 0.9111\n",
      "Validation loss: 0.3931, Validation accuracy: 0.8710\n",
      "\n",
      "Epoch 101:\n",
      "Training loss: 0.4613, Training accuracy: 0.9115\n",
      "Validation loss: 0.3774, Validation accuracy: 0.8766\n",
      "\n",
      "Epoch 102:\n",
      "Training loss: 0.4547, Training accuracy: 0.9130\n",
      "Validation loss: 0.3835, Validation accuracy: 0.8748\n",
      "\n",
      "Epoch 103:\n",
      "Training loss: 0.4576, Training accuracy: 0.9127\n",
      "Validation loss: 0.3709, Validation accuracy: 0.8789\n",
      "Saving ...\n",
      "\n",
      "Epoch 104:\n",
      "Training loss: 0.4470, Training accuracy: 0.9143\n",
      "Validation loss: 0.3758, Validation accuracy: 0.8794\n",
      "Saving ...\n",
      "\n",
      "Epoch 105:\n",
      "Training loss: 0.4507, Training accuracy: 0.9151\n",
      "Validation loss: 0.4362, Validation accuracy: 0.8587\n",
      "\n",
      "Epoch 106:\n",
      "Training loss: 0.4525, Training accuracy: 0.9145\n",
      "Validation loss: 0.3983, Validation accuracy: 0.8721\n",
      "\n",
      "Epoch 107:\n",
      "Training loss: 0.4477, Training accuracy: 0.9155\n",
      "Validation loss: 0.3740, Validation accuracy: 0.8768\n",
      "\n",
      "Epoch 108:\n",
      "Training loss: 0.4476, Training accuracy: 0.9163\n",
      "Validation loss: 0.3884, Validation accuracy: 0.8714\n",
      "\n",
      "Epoch 109:\n",
      "Training loss: 0.4473, Training accuracy: 0.9159\n",
      "Validation loss: 0.3852, Validation accuracy: 0.8768\n",
      "\n",
      "Epoch 110:\n",
      "Training loss: 0.4482, Training accuracy: 0.9153\n",
      "Validation loss: 0.3825, Validation accuracy: 0.8730\n",
      "\n",
      "Epoch 111:\n",
      "Training loss: 0.4457, Training accuracy: 0.9161\n",
      "Validation loss: 0.3893, Validation accuracy: 0.8751\n",
      "\n",
      "Epoch 112:\n",
      "Training loss: 0.4401, Training accuracy: 0.9164\n",
      "Validation loss: 0.3726, Validation accuracy: 0.8763\n",
      "\n",
      "Epoch 113:\n",
      "Training loss: 0.4398, Training accuracy: 0.9151\n",
      "Validation loss: 0.3694, Validation accuracy: 0.8793\n",
      "\n",
      "Epoch 114:\n",
      "Training loss: 0.4400, Training accuracy: 0.9163\n",
      "Validation loss: 0.3827, Validation accuracy: 0.8749\n",
      "\n",
      "Epoch 115:\n",
      "Training loss: 0.4334, Training accuracy: 0.9185\n",
      "Validation loss: 0.3825, Validation accuracy: 0.8763\n",
      "\n",
      "Epoch 116:\n",
      "Training loss: 0.4410, Training accuracy: 0.9175\n",
      "Validation loss: 0.3819, Validation accuracy: 0.8773\n",
      "\n",
      "Epoch 117:\n",
      "Training loss: 0.4337, Training accuracy: 0.9188\n",
      "Validation loss: 0.3781, Validation accuracy: 0.8760\n",
      "\n",
      "Epoch 118:\n",
      "Training loss: 0.4335, Training accuracy: 0.9174\n",
      "Validation loss: 0.3871, Validation accuracy: 0.8725\n",
      "\n",
      "Epoch 119:\n",
      "Training loss: 0.4330, Training accuracy: 0.9189\n",
      "Validation loss: 0.3756, Validation accuracy: 0.8788\n",
      "\n",
      "Epoch 120:\n",
      "Training loss: 0.4324, Training accuracy: 0.9185\n",
      "Validation loss: 0.3789, Validation accuracy: 0.8751\n",
      "\n",
      "Epoch 121:\n",
      "Training loss: 0.4301, Training accuracy: 0.9194\n",
      "Validation loss: 0.3766, Validation accuracy: 0.8758\n",
      "\n",
      "Epoch 122:\n",
      "Training loss: 0.4307, Training accuracy: 0.9196\n",
      "Validation loss: 0.3819, Validation accuracy: 0.8756\n",
      "\n",
      "Epoch 123:\n",
      "Training loss: 0.4263, Training accuracy: 0.9201\n",
      "Validation loss: 0.3784, Validation accuracy: 0.8750\n",
      "\n",
      "Epoch 124:\n",
      "Training loss: 0.4294, Training accuracy: 0.9198\n",
      "Validation loss: 0.3763, Validation accuracy: 0.8781\n",
      "\n",
      "Epoch 125:\n",
      "Training loss: 0.4233, Training accuracy: 0.9212\n",
      "Validation loss: 0.3620, Validation accuracy: 0.8809\n",
      "Saving ...\n",
      "\n",
      "Epoch 126:\n",
      "Training loss: 0.4283, Training accuracy: 0.9195\n",
      "Validation loss: 0.3789, Validation accuracy: 0.8744\n",
      "\n",
      "Epoch 127:\n",
      "Training loss: 0.4265, Training accuracy: 0.9196\n",
      "Validation loss: 0.3717, Validation accuracy: 0.8780\n",
      "\n",
      "Epoch 128:\n",
      "Training loss: 0.4212, Training accuracy: 0.9219\n",
      "Validation loss: 0.3668, Validation accuracy: 0.8816\n",
      "Saving ...\n",
      "\n",
      "Epoch 129:\n",
      "Training loss: 0.4226, Training accuracy: 0.9188\n",
      "Validation loss: 0.3874, Validation accuracy: 0.8766\n",
      "\n",
      "Epoch 130:\n",
      "Training loss: 0.4171, Training accuracy: 0.9212\n",
      "Validation loss: 0.3816, Validation accuracy: 0.8781\n",
      "\n",
      "Epoch 131:\n",
      "Training loss: 0.4201, Training accuracy: 0.9218\n",
      "Validation loss: 0.3747, Validation accuracy: 0.8799\n",
      "\n",
      "Epoch 132:\n",
      "Training loss: 0.4183, Training accuracy: 0.9202\n",
      "Validation loss: 0.3567, Validation accuracy: 0.8844\n",
      "Saving ...\n",
      "\n",
      "Epoch 133:\n",
      "Training loss: 0.4199, Training accuracy: 0.9217\n",
      "Validation loss: 0.3718, Validation accuracy: 0.8799\n",
      "\n",
      "Epoch 134:\n",
      "Training loss: 0.4171, Training accuracy: 0.9224\n",
      "Validation loss: 0.3738, Validation accuracy: 0.8804\n",
      "\n",
      "Epoch 135:\n",
      "Training loss: 0.4136, Training accuracy: 0.9232\n",
      "Validation loss: 0.3682, Validation accuracy: 0.8793\n",
      "\n",
      "Epoch 136:\n",
      "Training loss: 0.4102, Training accuracy: 0.9248\n",
      "Validation loss: 0.3771, Validation accuracy: 0.8767\n",
      "\n",
      "Epoch 137:\n",
      "Training loss: 0.4168, Training accuracy: 0.9236\n",
      "Validation loss: 0.4064, Validation accuracy: 0.8665\n",
      "\n",
      "Epoch 138:\n",
      "Training loss: 0.4085, Training accuracy: 0.9228\n",
      "Validation loss: 0.3693, Validation accuracy: 0.8817\n",
      "\n",
      "Epoch 139:\n",
      "Training loss: 0.4095, Training accuracy: 0.9244\n",
      "Validation loss: 0.3738, Validation accuracy: 0.8779\n",
      "\n",
      "Epoch 140:\n",
      "Training loss: 0.4081, Training accuracy: 0.9232\n",
      "Validation loss: 0.3646, Validation accuracy: 0.8816\n",
      "\n",
      "Epoch 141:\n",
      "Training loss: 0.4100, Training accuracy: 0.9246\n",
      "Validation loss: 0.3690, Validation accuracy: 0.8822\n",
      "\n",
      "Epoch 142:\n",
      "Training loss: 0.4056, Training accuracy: 0.9253\n",
      "Validation loss: 0.3741, Validation accuracy: 0.8805\n",
      "\n",
      "Epoch 143:\n",
      "Training loss: 0.4053, Training accuracy: 0.9246\n",
      "Validation loss: 0.3655, Validation accuracy: 0.8806\n",
      "\n",
      "Epoch 144:\n",
      "Training loss: 0.4044, Training accuracy: 0.9251\n",
      "Validation loss: 0.3631, Validation accuracy: 0.8831\n",
      "\n",
      "Epoch 145:\n",
      "Training loss: 0.4074, Training accuracy: 0.9249\n",
      "Validation loss: 0.3742, Validation accuracy: 0.8788\n",
      "\n",
      "Epoch 146:\n",
      "Training loss: 0.4055, Training accuracy: 0.9246\n",
      "Validation loss: 0.3609, Validation accuracy: 0.8824\n",
      "\n",
      "Epoch 147:\n",
      "Training loss: 0.4041, Training accuracy: 0.9265\n",
      "Validation loss: 0.3702, Validation accuracy: 0.8788\n",
      "\n",
      "Epoch 148:\n",
      "Training loss: 0.4000, Training accuracy: 0.9254\n",
      "Validation loss: 0.3656, Validation accuracy: 0.8815\n",
      "\n",
      "Epoch 149:\n",
      "Training loss: 0.3990, Training accuracy: 0.9263\n",
      "Validation loss: 0.3677, Validation accuracy: 0.8808\n",
      "\n",
      "Epoch 150:\n",
      "Training loss: 0.3999, Training accuracy: 0.9255\n",
      "Validation loss: 0.3745, Validation accuracy: 0.8794\n",
      "\n",
      "Epoch 151:\n",
      "Training loss: 0.4034, Training accuracy: 0.9254\n",
      "Validation loss: 0.3944, Validation accuracy: 0.8749\n",
      "\n",
      "Epoch 152:\n",
      "Training loss: 0.3995, Training accuracy: 0.9258\n",
      "Validation loss: 0.3577, Validation accuracy: 0.8837\n",
      "\n",
      "Epoch 153:\n",
      "Training loss: 0.3977, Training accuracy: 0.9268\n",
      "Validation loss: 0.3721, Validation accuracy: 0.8782\n",
      "\n",
      "Epoch 154:\n",
      "Training loss: 0.3973, Training accuracy: 0.9280\n",
      "Validation loss: 0.3662, Validation accuracy: 0.8793\n",
      "\n",
      "Epoch 155:\n",
      "Training loss: 0.3959, Training accuracy: 0.9261\n",
      "Validation loss: 0.3720, Validation accuracy: 0.8776\n",
      "\n",
      "Epoch 156:\n",
      "Training loss: 0.3948, Training accuracy: 0.9290\n",
      "Validation loss: 0.3604, Validation accuracy: 0.8837\n",
      "\n",
      "Epoch 157:\n",
      "Training loss: 0.3978, Training accuracy: 0.9269\n",
      "Validation loss: 0.3807, Validation accuracy: 0.8749\n",
      "\n",
      "Epoch 158:\n",
      "Training loss: 0.3941, Training accuracy: 0.9279\n",
      "Validation loss: 0.3778, Validation accuracy: 0.8803\n",
      "\n",
      "Epoch 159:\n",
      "Training loss: 0.3948, Training accuracy: 0.9288\n",
      "Validation loss: 0.3781, Validation accuracy: 0.8764\n",
      "\n",
      "Epoch 160:\n",
      "Training loss: 0.3948, Training accuracy: 0.9271\n",
      "Validation loss: 0.3730, Validation accuracy: 0.8809\n",
      "\n",
      "Epoch 161:\n",
      "Training loss: 0.3901, Training accuracy: 0.9273\n",
      "Validation loss: 0.3620, Validation accuracy: 0.8827\n",
      "\n",
      "Epoch 162:\n",
      "Training loss: 0.3948, Training accuracy: 0.9269\n",
      "Validation loss: 0.3622, Validation accuracy: 0.8839\n",
      "\n",
      "Epoch 163:\n",
      "Training loss: 0.3865, Training accuracy: 0.9289\n",
      "Validation loss: 0.3649, Validation accuracy: 0.8828\n",
      "\n",
      "Epoch 164:\n",
      "Training loss: 0.3913, Training accuracy: 0.9281\n",
      "Validation loss: 0.3617, Validation accuracy: 0.8827\n",
      "\n",
      "Epoch 165:\n",
      "Training loss: 0.3927, Training accuracy: 0.9270\n",
      "Validation loss: 0.3679, Validation accuracy: 0.8784\n",
      "\n",
      "Epoch 166:\n",
      "Training loss: 0.3879, Training accuracy: 0.9285\n",
      "Validation loss: 0.3538, Validation accuracy: 0.8832\n",
      "\n",
      "Epoch 167:\n",
      "Training loss: 0.3866, Training accuracy: 0.9291\n",
      "Validation loss: 0.3574, Validation accuracy: 0.8823\n",
      "\n",
      "Epoch 168:\n",
      "Training loss: 0.3841, Training accuracy: 0.9279\n",
      "Validation loss: 0.3859, Validation accuracy: 0.8743\n",
      "\n",
      "Epoch 169:\n",
      "Training loss: 0.3917, Training accuracy: 0.9296\n",
      "Validation loss: 0.3638, Validation accuracy: 0.8819\n",
      "\n",
      "Epoch 170:\n",
      "Training loss: 0.3847, Training accuracy: 0.9295\n",
      "Validation loss: 0.3839, Validation accuracy: 0.8758\n",
      "\n",
      "Epoch 171:\n",
      "Training loss: 0.3811, Training accuracy: 0.9300\n",
      "Validation loss: 0.3618, Validation accuracy: 0.8837\n",
      "\n",
      "Epoch 172:\n",
      "Training loss: 0.3839, Training accuracy: 0.9301\n",
      "Validation loss: 0.3795, Validation accuracy: 0.8802\n",
      "\n",
      "Epoch 173:\n",
      "Training loss: 0.3812, Training accuracy: 0.9310\n",
      "Validation loss: 0.3586, Validation accuracy: 0.8863\n",
      "Saving ...\n",
      "\n",
      "Epoch 174:\n",
      "Training loss: 0.3829, Training accuracy: 0.9293\n",
      "Validation loss: 0.3617, Validation accuracy: 0.8851\n",
      "\n",
      "Epoch 175:\n",
      "Training loss: 0.3833, Training accuracy: 0.9297\n",
      "Validation loss: 0.3742, Validation accuracy: 0.8775\n",
      "\n",
      "Epoch 176:\n",
      "Training loss: 0.3786, Training accuracy: 0.9311\n",
      "Validation loss: 0.3552, Validation accuracy: 0.8878\n",
      "Saving ...\n",
      "\n",
      "Epoch 177:\n",
      "Training loss: 0.3760, Training accuracy: 0.9311\n",
      "Validation loss: 0.3565, Validation accuracy: 0.8851\n",
      "\n",
      "Epoch 178:\n",
      "Training loss: 0.3790, Training accuracy: 0.9309\n",
      "Validation loss: 0.3645, Validation accuracy: 0.8818\n",
      "\n",
      "Epoch 179:\n",
      "Training loss: 0.3757, Training accuracy: 0.9317\n",
      "Validation loss: 0.3554, Validation accuracy: 0.8844\n",
      "\n",
      "Epoch 180:\n",
      "Training loss: 0.3777, Training accuracy: 0.9302\n",
      "Validation loss: 0.3626, Validation accuracy: 0.8824\n",
      "\n",
      "Epoch 181:\n",
      "Training loss: 0.3806, Training accuracy: 0.9301\n",
      "Validation loss: 0.3670, Validation accuracy: 0.8818\n",
      "\n",
      "Epoch 182:\n",
      "Training loss: 0.3765, Training accuracy: 0.9312\n",
      "Validation loss: 0.3662, Validation accuracy: 0.8790\n",
      "\n",
      "Epoch 183:\n",
      "Training loss: 0.3751, Training accuracy: 0.9322\n",
      "Validation loss: 0.3510, Validation accuracy: 0.8870\n",
      "\n",
      "Epoch 184:\n",
      "Training loss: 0.3774, Training accuracy: 0.9306\n",
      "Validation loss: 0.3498, Validation accuracy: 0.8873\n",
      "\n",
      "Epoch 185:\n",
      "Training loss: 0.3770, Training accuracy: 0.9313\n",
      "Validation loss: 0.3797, Validation accuracy: 0.8787\n",
      "\n",
      "Epoch 186:\n",
      "Training loss: 0.3733, Training accuracy: 0.9325\n",
      "Validation loss: 0.3586, Validation accuracy: 0.8856\n",
      "\n",
      "Epoch 187:\n",
      "Training loss: 0.3723, Training accuracy: 0.9322\n",
      "Validation loss: 0.3565, Validation accuracy: 0.8852\n",
      "\n",
      "Epoch 188:\n",
      "Training loss: 0.3714, Training accuracy: 0.9319\n",
      "Validation loss: 0.3830, Validation accuracy: 0.8778\n",
      "\n",
      "Epoch 189:\n",
      "Training loss: 0.3698, Training accuracy: 0.9331\n",
      "Validation loss: 0.3547, Validation accuracy: 0.8851\n",
      "\n",
      "Epoch 190:\n",
      "Training loss: 0.3690, Training accuracy: 0.9318\n",
      "Validation loss: 0.3614, Validation accuracy: 0.8837\n",
      "\n",
      "Epoch 191:\n",
      "Training loss: 0.3730, Training accuracy: 0.9313\n",
      "Validation loss: 0.3509, Validation accuracy: 0.8877\n",
      "\n",
      "Epoch 192:\n",
      "Training loss: 0.3699, Training accuracy: 0.9320\n",
      "Validation loss: 0.3679, Validation accuracy: 0.8793\n",
      "\n",
      "Epoch 193:\n",
      "Training loss: 0.3668, Training accuracy: 0.9338\n",
      "Validation loss: 0.3584, Validation accuracy: 0.8812\n",
      "\n",
      "Epoch 194:\n",
      "Training loss: 0.3688, Training accuracy: 0.9332\n",
      "Validation loss: 0.3737, Validation accuracy: 0.8795\n",
      "\n",
      "Epoch 195:\n",
      "Training loss: 0.3664, Training accuracy: 0.9339\n",
      "Validation loss: 0.3664, Validation accuracy: 0.8821\n",
      "\n",
      "Epoch 196:\n",
      "Training loss: 0.3694, Training accuracy: 0.9336\n",
      "Validation loss: 0.3799, Validation accuracy: 0.8783\n",
      "\n",
      "Epoch 197:\n",
      "Training loss: 0.3666, Training accuracy: 0.9309\n",
      "Validation loss: 0.3887, Validation accuracy: 0.8738\n",
      "\n",
      "Epoch 198:\n",
      "Training loss: 0.3687, Training accuracy: 0.9333\n",
      "Validation loss: 0.3821, Validation accuracy: 0.8802\n",
      "\n",
      "Epoch 199:\n",
      "Training loss: 0.3671, Training accuracy: 0.9337\n",
      "Validation loss: 0.3692, Validation accuracy: 0.8808\n",
      "\n",
      "==================================================\n",
      "==> Optimization finished! Best validation accuracy: 0.8878\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8878"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train(student,teacher,optimizer,criterion,2,[1,0,0],1,train_loader,val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Training starts!\n",
      "==================================================\n",
      "Epoch 0:\n",
      "Training loss: 2.1979, Training accuracy: 0.4179\n",
      "Validation loss: 1.4050, Validation accuracy: 0.4981\n",
      "Saving ...\n",
      "\n",
      "Epoch 1:\n",
      "Training loss: 1.7070, Training accuracy: 0.5686\n",
      "Validation loss: 1.2272, Validation accuracy: 0.5743\n",
      "Saving ...\n",
      "\n",
      "Epoch 2:\n",
      "Training loss: 1.4861, Training accuracy: 0.6276\n",
      "Validation loss: 1.0451, Validation accuracy: 0.6436\n",
      "Saving ...\n",
      "\n",
      "Epoch 3:\n",
      "Training loss: 1.3582, Training accuracy: 0.6641\n",
      "Validation loss: 0.9836, Validation accuracy: 0.6619\n",
      "Saving ...\n",
      "\n",
      "Epoch 4:\n",
      "Training loss: 1.2665, Training accuracy: 0.6885\n",
      "Validation loss: 0.9084, Validation accuracy: 0.6915\n",
      "Saving ...\n",
      "\n",
      "Epoch 5:\n",
      "Training loss: 1.2010, Training accuracy: 0.7094\n",
      "Validation loss: 0.8758, Validation accuracy: 0.6994\n",
      "Saving ...\n",
      "\n",
      "Epoch 6:\n",
      "Training loss: 1.1415, Training accuracy: 0.7236\n",
      "Validation loss: 0.8436, Validation accuracy: 0.7207\n",
      "Saving ...\n",
      "\n",
      "Epoch 7:\n",
      "Training loss: 1.0881, Training accuracy: 0.7383\n",
      "Validation loss: 0.7945, Validation accuracy: 0.7347\n",
      "Saving ...\n",
      "\n",
      "Epoch 8:\n",
      "Training loss: 1.0327, Training accuracy: 0.7487\n",
      "Validation loss: 0.8002, Validation accuracy: 0.7330\n",
      "\n",
      "Epoch 9:\n",
      "Training loss: 0.9915, Training accuracy: 0.7635\n",
      "Validation loss: 0.7439, Validation accuracy: 0.7503\n",
      "Saving ...\n",
      "\n",
      "Epoch 10:\n",
      "Training loss: 0.9556, Training accuracy: 0.7722\n",
      "Validation loss: 0.7419, Validation accuracy: 0.7578\n",
      "Saving ...\n",
      "\n",
      "Epoch 11:\n",
      "Training loss: 0.9207, Training accuracy: 0.7797\n",
      "Validation loss: 0.6995, Validation accuracy: 0.7652\n",
      "Saving ...\n",
      "\n",
      "Epoch 12:\n",
      "Training loss: 0.8892, Training accuracy: 0.7883\n",
      "Validation loss: 0.6442, Validation accuracy: 0.7858\n",
      "Saving ...\n",
      "\n",
      "Epoch 13:\n",
      "Training loss: 0.8607, Training accuracy: 0.7953\n",
      "Validation loss: 0.6590, Validation accuracy: 0.7845\n",
      "\n",
      "Epoch 14:\n",
      "Training loss: 0.8339, Training accuracy: 0.8023\n",
      "Validation loss: 0.6313, Validation accuracy: 0.7911\n",
      "Saving ...\n",
      "\n",
      "Epoch 15:\n",
      "Training loss: 0.8147, Training accuracy: 0.8083\n",
      "Validation loss: 0.5885, Validation accuracy: 0.8046\n",
      "Saving ...\n",
      "\n",
      "Epoch 16:\n",
      "Training loss: 0.7918, Training accuracy: 0.8144\n",
      "Validation loss: 0.5891, Validation accuracy: 0.8048\n",
      "Saving ...\n",
      "\n",
      "Epoch 17:\n",
      "Training loss: 0.7748, Training accuracy: 0.8177\n",
      "Validation loss: 0.5885, Validation accuracy: 0.8055\n",
      "Saving ...\n",
      "\n",
      "Epoch 18:\n",
      "Training loss: 0.7570, Training accuracy: 0.8236\n",
      "Validation loss: 0.5641, Validation accuracy: 0.8155\n",
      "Saving ...\n",
      "\n",
      "Epoch 19:\n",
      "Training loss: 0.7423, Training accuracy: 0.8260\n",
      "Validation loss: 0.5809, Validation accuracy: 0.8117\n",
      "\n",
      "Epoch 20:\n",
      "Training loss: 0.7314, Training accuracy: 0.8294\n",
      "Validation loss: 0.5493, Validation accuracy: 0.8209\n",
      "Saving ...\n",
      "\n",
      "Epoch 21:\n",
      "Training loss: 0.7149, Training accuracy: 0.8316\n",
      "Validation loss: 0.5334, Validation accuracy: 0.8265\n",
      "Saving ...\n",
      "\n",
      "Epoch 22:\n",
      "Training loss: 0.7035, Training accuracy: 0.8353\n",
      "Validation loss: 0.5384, Validation accuracy: 0.8248\n",
      "\n",
      "Epoch 23:\n",
      "Training loss: 0.6907, Training accuracy: 0.8378\n",
      "Validation loss: 0.5387, Validation accuracy: 0.8212\n",
      "\n",
      "Epoch 24:\n",
      "Training loss: 0.6800, Training accuracy: 0.8420\n",
      "Validation loss: 0.5430, Validation accuracy: 0.8240\n",
      "\n",
      "Epoch 25:\n",
      "Training loss: 0.6694, Training accuracy: 0.8446\n",
      "Validation loss: 0.5520, Validation accuracy: 0.8200\n",
      "\n",
      "Epoch 26:\n",
      "Training loss: 0.6573, Training accuracy: 0.8458\n",
      "Validation loss: 0.5270, Validation accuracy: 0.8251\n",
      "\n",
      "Epoch 27:\n",
      "Training loss: 0.6485, Training accuracy: 0.8472\n",
      "Validation loss: 0.5212, Validation accuracy: 0.8278\n",
      "Saving ...\n",
      "\n",
      "Epoch 28:\n",
      "Training loss: 0.6450, Training accuracy: 0.8486\n",
      "Validation loss: 0.5214, Validation accuracy: 0.8322\n",
      "Saving ...\n",
      "\n",
      "Epoch 29:\n",
      "Training loss: 0.6379, Training accuracy: 0.8536\n",
      "Validation loss: 0.5128, Validation accuracy: 0.8312\n",
      "\n",
      "Epoch 30:\n",
      "Training loss: 0.6222, Training accuracy: 0.8541\n",
      "Validation loss: 0.4789, Validation accuracy: 0.8409\n",
      "Saving ...\n",
      "\n",
      "Epoch 31:\n",
      "Training loss: 0.6198, Training accuracy: 0.8545\n",
      "Validation loss: 0.5082, Validation accuracy: 0.8349\n",
      "\n",
      "Epoch 32:\n",
      "Training loss: 0.6147, Training accuracy: 0.8568\n",
      "Validation loss: 0.4773, Validation accuracy: 0.8452\n",
      "Saving ...\n",
      "\n",
      "Epoch 33:\n",
      "Training loss: 0.6027, Training accuracy: 0.8609\n",
      "Validation loss: 0.5020, Validation accuracy: 0.8393\n",
      "\n",
      "Epoch 34:\n",
      "Training loss: 0.5981, Training accuracy: 0.8631\n",
      "Validation loss: 0.4718, Validation accuracy: 0.8451\n",
      "\n",
      "Epoch 35:\n",
      "Training loss: 0.5935, Training accuracy: 0.8625\n",
      "Validation loss: 0.4961, Validation accuracy: 0.8409\n",
      "\n",
      "Epoch 36:\n",
      "Training loss: 0.5900, Training accuracy: 0.8654\n",
      "Validation loss: 0.4851, Validation accuracy: 0.8438\n",
      "\n",
      "Epoch 37:\n",
      "Training loss: 0.5746, Training accuracy: 0.8674\n",
      "Validation loss: 0.4698, Validation accuracy: 0.8487\n",
      "Saving ...\n",
      "\n",
      "Epoch 38:\n",
      "Training loss: 0.5767, Training accuracy: 0.8652\n",
      "Validation loss: 0.4871, Validation accuracy: 0.8432\n",
      "\n",
      "Epoch 39:\n",
      "Training loss: 0.5645, Training accuracy: 0.8699\n",
      "Validation loss: 0.4844, Validation accuracy: 0.8422\n",
      "\n",
      "Epoch 40:\n",
      "Training loss: 0.5634, Training accuracy: 0.8701\n",
      "Validation loss: 0.4785, Validation accuracy: 0.8421\n",
      "\n",
      "Epoch 41:\n",
      "Training loss: 0.5566, Training accuracy: 0.8702\n",
      "Validation loss: 0.4540, Validation accuracy: 0.8551\n",
      "Saving ...\n",
      "\n",
      "Epoch 42:\n",
      "Training loss: 0.5549, Training accuracy: 0.8724\n",
      "Validation loss: 0.4491, Validation accuracy: 0.8556\n",
      "Saving ...\n",
      "\n",
      "Epoch 43:\n",
      "Training loss: 0.5476, Training accuracy: 0.8723\n",
      "Validation loss: 0.4672, Validation accuracy: 0.8457\n",
      "\n",
      "Epoch 44:\n",
      "Training loss: 0.5435, Training accuracy: 0.8739\n",
      "Validation loss: 0.4787, Validation accuracy: 0.8438\n",
      "\n",
      "Epoch 45:\n",
      "Training loss: 0.5409, Training accuracy: 0.8747\n",
      "Validation loss: 0.4410, Validation accuracy: 0.8570\n",
      "Saving ...\n",
      "\n",
      "Epoch 46:\n",
      "Training loss: 0.5333, Training accuracy: 0.8762\n",
      "Validation loss: 0.4436, Validation accuracy: 0.8562\n",
      "\n",
      "Epoch 47:\n",
      "Training loss: 0.5276, Training accuracy: 0.8783\n",
      "Validation loss: 0.4412, Validation accuracy: 0.8533\n",
      "\n",
      "Epoch 48:\n",
      "Training loss: 0.5299, Training accuracy: 0.8787\n",
      "Validation loss: 0.4315, Validation accuracy: 0.8592\n",
      "Saving ...\n",
      "\n",
      "Epoch 49:\n",
      "Training loss: 0.5217, Training accuracy: 0.8800\n",
      "Validation loss: 0.4304, Validation accuracy: 0.8614\n",
      "Saving ...\n",
      "\n",
      "Epoch 50:\n",
      "Training loss: 0.5200, Training accuracy: 0.8798\n",
      "Validation loss: 0.4533, Validation accuracy: 0.8533\n",
      "\n",
      "Epoch 51:\n",
      "Training loss: 0.5171, Training accuracy: 0.8808\n",
      "Validation loss: 0.4221, Validation accuracy: 0.8603\n",
      "\n",
      "Epoch 52:\n",
      "Training loss: 0.5143, Training accuracy: 0.8827\n",
      "Validation loss: 0.4396, Validation accuracy: 0.8558\n",
      "\n",
      "Epoch 53:\n",
      "Training loss: 0.5077, Training accuracy: 0.8825\n",
      "Validation loss: 0.4281, Validation accuracy: 0.8650\n",
      "Saving ...\n",
      "\n",
      "Epoch 54:\n",
      "Training loss: 0.5082, Training accuracy: 0.8826\n",
      "Validation loss: 0.4317, Validation accuracy: 0.8589\n",
      "\n",
      "Epoch 55:\n",
      "Training loss: 0.5036, Training accuracy: 0.8843\n",
      "Validation loss: 0.4315, Validation accuracy: 0.8621\n",
      "\n",
      "Epoch 56:\n",
      "Training loss: 0.5012, Training accuracy: 0.8847\n",
      "Validation loss: 0.4379, Validation accuracy: 0.8584\n",
      "\n",
      "Epoch 57:\n",
      "Training loss: 0.4937, Training accuracy: 0.8865\n",
      "Validation loss: 0.4281, Validation accuracy: 0.8634\n",
      "\n",
      "Epoch 58:\n",
      "Training loss: 0.4875, Training accuracy: 0.8879\n",
      "Validation loss: 0.4107, Validation accuracy: 0.8685\n",
      "Saving ...\n",
      "\n",
      "Epoch 59:\n",
      "Training loss: 0.4865, Training accuracy: 0.8883\n",
      "Validation loss: 0.4153, Validation accuracy: 0.8665\n",
      "\n",
      "Epoch 60:\n",
      "Training loss: 0.4867, Training accuracy: 0.8874\n",
      "Validation loss: 0.4268, Validation accuracy: 0.8616\n",
      "\n",
      "Epoch 61:\n",
      "Training loss: 0.4811, Training accuracy: 0.8873\n",
      "Validation loss: 0.4257, Validation accuracy: 0.8641\n",
      "\n",
      "Epoch 62:\n",
      "Training loss: 0.4802, Training accuracy: 0.8889\n",
      "Validation loss: 0.4123, Validation accuracy: 0.8674\n",
      "\n",
      "Epoch 63:\n",
      "Training loss: 0.4768, Training accuracy: 0.8911\n",
      "Validation loss: 0.4339, Validation accuracy: 0.8581\n",
      "\n",
      "Epoch 64:\n",
      "Training loss: 0.4746, Training accuracy: 0.8912\n",
      "Validation loss: 0.4284, Validation accuracy: 0.8649\n",
      "\n",
      "Epoch 65:\n",
      "Training loss: 0.4717, Training accuracy: 0.8913\n",
      "Validation loss: 0.4172, Validation accuracy: 0.8662\n",
      "\n",
      "Epoch 66:\n",
      "Training loss: 0.4726, Training accuracy: 0.8910\n",
      "Validation loss: 0.4092, Validation accuracy: 0.8693\n",
      "Saving ...\n",
      "\n",
      "Epoch 67:\n",
      "Training loss: 0.4661, Training accuracy: 0.8930\n",
      "Validation loss: 0.4201, Validation accuracy: 0.8645\n",
      "\n",
      "Epoch 68:\n",
      "Training loss: 0.4670, Training accuracy: 0.8937\n",
      "Validation loss: 0.3947, Validation accuracy: 0.8719\n",
      "Saving ...\n",
      "\n",
      "Epoch 69:\n",
      "Training loss: 0.4637, Training accuracy: 0.8929\n",
      "Validation loss: 0.4116, Validation accuracy: 0.8686\n",
      "\n",
      "Epoch 70:\n",
      "Training loss: 0.4625, Training accuracy: 0.8941\n",
      "Validation loss: 0.4079, Validation accuracy: 0.8704\n",
      "\n",
      "Epoch 71:\n",
      "Training loss: 0.4591, Training accuracy: 0.8951\n",
      "Validation loss: 0.4147, Validation accuracy: 0.8690\n",
      "\n",
      "Epoch 72:\n",
      "Training loss: 0.4550, Training accuracy: 0.8947\n",
      "Validation loss: 0.4083, Validation accuracy: 0.8697\n",
      "\n",
      "Epoch 73:\n",
      "Training loss: 0.4526, Training accuracy: 0.8966\n",
      "Validation loss: 0.4072, Validation accuracy: 0.8688\n",
      "\n",
      "Epoch 74:\n",
      "Training loss: 0.4527, Training accuracy: 0.8967\n",
      "Validation loss: 0.4035, Validation accuracy: 0.8697\n",
      "\n",
      "Epoch 75:\n",
      "Training loss: 0.4491, Training accuracy: 0.8973\n",
      "Validation loss: 0.4129, Validation accuracy: 0.8691\n",
      "\n",
      "Epoch 76:\n",
      "Training loss: 0.4488, Training accuracy: 0.8963\n",
      "Validation loss: 0.4105, Validation accuracy: 0.8670\n",
      "\n",
      "Epoch 77:\n",
      "Training loss: 0.4449, Training accuracy: 0.8980\n",
      "Validation loss: 0.4017, Validation accuracy: 0.8738\n",
      "Saving ...\n",
      "\n",
      "Epoch 78:\n",
      "Training loss: 0.4422, Training accuracy: 0.8985\n",
      "Validation loss: 0.4112, Validation accuracy: 0.8689\n",
      "\n",
      "Epoch 79:\n",
      "Training loss: 0.4404, Training accuracy: 0.8991\n",
      "Validation loss: 0.4133, Validation accuracy: 0.8675\n",
      "\n",
      "Epoch 80:\n",
      "Training loss: 0.4337, Training accuracy: 0.9008\n",
      "Validation loss: 0.3930, Validation accuracy: 0.8743\n",
      "Saving ...\n",
      "\n",
      "Epoch 81:\n",
      "Training loss: 0.4358, Training accuracy: 0.8988\n",
      "Validation loss: 0.3825, Validation accuracy: 0.8745\n",
      "Saving ...\n",
      "\n",
      "Epoch 82:\n",
      "Training loss: 0.4360, Training accuracy: 0.8986\n",
      "Validation loss: 0.3830, Validation accuracy: 0.8757\n",
      "Saving ...\n",
      "\n",
      "Epoch 83:\n",
      "Training loss: 0.4330, Training accuracy: 0.9001\n",
      "Validation loss: 0.3943, Validation accuracy: 0.8725\n",
      "\n",
      "Epoch 84:\n",
      "Training loss: 0.4275, Training accuracy: 0.9015\n",
      "Validation loss: 0.4037, Validation accuracy: 0.8718\n",
      "\n",
      "Epoch 85:\n",
      "Training loss: 0.4325, Training accuracy: 0.9006\n",
      "Validation loss: 0.4144, Validation accuracy: 0.8669\n",
      "\n",
      "Epoch 86:\n",
      "Training loss: 0.4286, Training accuracy: 0.9022\n",
      "Validation loss: 0.4087, Validation accuracy: 0.8715\n",
      "\n",
      "Epoch 87:\n",
      "Training loss: 0.4261, Training accuracy: 0.9013\n",
      "Validation loss: 0.3889, Validation accuracy: 0.8749\n",
      "\n",
      "Epoch 88:\n",
      "Training loss: 0.4234, Training accuracy: 0.9031\n",
      "Validation loss: 0.3889, Validation accuracy: 0.8756\n",
      "\n",
      "Epoch 89:\n",
      "Training loss: 0.4234, Training accuracy: 0.9017\n",
      "Validation loss: 0.4011, Validation accuracy: 0.8711\n",
      "\n",
      "Epoch 90:\n",
      "Training loss: 0.4186, Training accuracy: 0.9026\n",
      "Validation loss: 0.4317, Validation accuracy: 0.8636\n",
      "\n",
      "Epoch 91:\n",
      "Training loss: 0.4209, Training accuracy: 0.9036\n",
      "Validation loss: 0.3914, Validation accuracy: 0.8774\n",
      "Saving ...\n",
      "\n",
      "Epoch 92:\n",
      "Training loss: 0.4151, Training accuracy: 0.9041\n",
      "Validation loss: 0.3770, Validation accuracy: 0.8796\n",
      "Saving ...\n",
      "\n",
      "Epoch 93:\n",
      "Training loss: 0.4166, Training accuracy: 0.9048\n",
      "Validation loss: 0.3951, Validation accuracy: 0.8734\n",
      "\n",
      "Epoch 94:\n",
      "Training loss: 0.4136, Training accuracy: 0.9054\n",
      "Validation loss: 0.3833, Validation accuracy: 0.8781\n",
      "\n",
      "Epoch 95:\n",
      "Training loss: 0.4134, Training accuracy: 0.9057\n",
      "Validation loss: 0.3943, Validation accuracy: 0.8742\n",
      "\n",
      "Epoch 96:\n",
      "Training loss: 0.4099, Training accuracy: 0.9054\n",
      "Validation loss: 0.3845, Validation accuracy: 0.8754\n",
      "\n",
      "Epoch 97:\n",
      "Training loss: 0.4110, Training accuracy: 0.9059\n",
      "Validation loss: 0.3939, Validation accuracy: 0.8728\n",
      "\n",
      "Epoch 98:\n",
      "Training loss: 0.4091, Training accuracy: 0.9057\n",
      "Validation loss: 0.3835, Validation accuracy: 0.8799\n",
      "Saving ...\n",
      "\n",
      "Epoch 99:\n",
      "Training loss: 0.4072, Training accuracy: 0.9067\n",
      "Validation loss: 0.4100, Validation accuracy: 0.8687\n",
      "\n",
      "Epoch 100:\n",
      "Training loss: 0.4021, Training accuracy: 0.9069\n",
      "Validation loss: 0.3895, Validation accuracy: 0.8755\n",
      "\n",
      "Epoch 101:\n",
      "Training loss: 0.4061, Training accuracy: 0.9076\n",
      "Validation loss: 0.3824, Validation accuracy: 0.8755\n",
      "\n",
      "Epoch 102:\n",
      "Training loss: 0.4054, Training accuracy: 0.9065\n",
      "Validation loss: 0.3840, Validation accuracy: 0.8778\n",
      "\n",
      "Epoch 103:\n",
      "Training loss: 0.4047, Training accuracy: 0.9071\n",
      "Validation loss: 0.3887, Validation accuracy: 0.8779\n",
      "\n",
      "Epoch 104:\n",
      "Training loss: 0.3984, Training accuracy: 0.9083\n",
      "Validation loss: 0.3842, Validation accuracy: 0.8759\n",
      "\n",
      "Epoch 105:\n",
      "Training loss: 0.3998, Training accuracy: 0.9094\n",
      "Validation loss: 0.3825, Validation accuracy: 0.8777\n",
      "\n",
      "Epoch 106:\n",
      "Training loss: 0.3983, Training accuracy: 0.9091\n",
      "Validation loss: 0.3822, Validation accuracy: 0.8796\n",
      "\n",
      "Epoch 107:\n",
      "Training loss: 0.4002, Training accuracy: 0.9085\n",
      "Validation loss: 0.3922, Validation accuracy: 0.8730\n",
      "\n",
      "Epoch 108:\n",
      "Training loss: 0.3945, Training accuracy: 0.9100\n",
      "Validation loss: 0.3735, Validation accuracy: 0.8819\n",
      "Saving ...\n",
      "\n",
      "Epoch 109:\n",
      "Training loss: 0.3970, Training accuracy: 0.9080\n",
      "Validation loss: 0.3636, Validation accuracy: 0.8860\n",
      "Saving ...\n",
      "\n",
      "Epoch 110:\n",
      "Training loss: 0.3907, Training accuracy: 0.9105\n",
      "Validation loss: 0.3781, Validation accuracy: 0.8808\n",
      "\n",
      "Epoch 111:\n",
      "Training loss: 0.3899, Training accuracy: 0.9111\n",
      "Validation loss: 0.3853, Validation accuracy: 0.8815\n",
      "\n",
      "Epoch 112:\n",
      "Training loss: 0.3890, Training accuracy: 0.9108\n",
      "Validation loss: 0.3887, Validation accuracy: 0.8787\n",
      "\n",
      "Epoch 113:\n",
      "Training loss: 0.3891, Training accuracy: 0.9114\n",
      "Validation loss: 0.3715, Validation accuracy: 0.8848\n",
      "\n",
      "Epoch 114:\n",
      "Training loss: 0.3877, Training accuracy: 0.9115\n",
      "Validation loss: 0.3739, Validation accuracy: 0.8821\n",
      "\n",
      "Epoch 115:\n",
      "Training loss: 0.3868, Training accuracy: 0.9125\n",
      "Validation loss: 0.3796, Validation accuracy: 0.8790\n",
      "\n",
      "Epoch 116:\n",
      "Training loss: 0.3859, Training accuracy: 0.9109\n",
      "Validation loss: 0.3868, Validation accuracy: 0.8796\n",
      "\n",
      "Epoch 117:\n",
      "Training loss: 0.3842, Training accuracy: 0.9133\n",
      "Validation loss: 0.3792, Validation accuracy: 0.8804\n",
      "\n",
      "Epoch 118:\n",
      "Training loss: 0.3830, Training accuracy: 0.9129\n",
      "Validation loss: 0.3940, Validation accuracy: 0.8747\n",
      "\n",
      "Epoch 119:\n",
      "Training loss: 0.3796, Training accuracy: 0.9139\n",
      "Validation loss: 0.3728, Validation accuracy: 0.8843\n",
      "\n",
      "Epoch 120:\n",
      "Training loss: 0.3841, Training accuracy: 0.9121\n",
      "Validation loss: 0.3736, Validation accuracy: 0.8806\n",
      "\n",
      "Epoch 121:\n",
      "Training loss: 0.3843, Training accuracy: 0.9110\n",
      "Validation loss: 0.3723, Validation accuracy: 0.8816\n",
      "\n",
      "Epoch 122:\n",
      "Training loss: 0.3808, Training accuracy: 0.9123\n",
      "Validation loss: 0.3880, Validation accuracy: 0.8761\n",
      "\n",
      "Epoch 123:\n",
      "Training loss: 0.3770, Training accuracy: 0.9149\n",
      "Validation loss: 0.3929, Validation accuracy: 0.8723\n",
      "\n",
      "Epoch 124:\n",
      "Training loss: 0.3781, Training accuracy: 0.9139\n",
      "Validation loss: 0.3792, Validation accuracy: 0.8779\n",
      "\n",
      "Epoch 125:\n",
      "Training loss: 0.3762, Training accuracy: 0.9128\n",
      "Validation loss: 0.3817, Validation accuracy: 0.8806\n",
      "\n",
      "Epoch 126:\n",
      "Training loss: 0.3724, Training accuracy: 0.9152\n",
      "Validation loss: 0.3733, Validation accuracy: 0.8812\n",
      "\n",
      "Epoch 127:\n",
      "Training loss: 0.3752, Training accuracy: 0.9152\n",
      "Validation loss: 0.3769, Validation accuracy: 0.8855\n",
      "\n",
      "Epoch 128:\n",
      "Training loss: 0.3713, Training accuracy: 0.9141\n",
      "Validation loss: 0.3779, Validation accuracy: 0.8791\n",
      "\n",
      "Epoch 129:\n",
      "Training loss: 0.3709, Training accuracy: 0.9156\n",
      "Validation loss: 0.3715, Validation accuracy: 0.8806\n",
      "\n",
      "Epoch 130:\n",
      "Training loss: 0.3730, Training accuracy: 0.9148\n",
      "Validation loss: 0.4056, Validation accuracy: 0.8712\n",
      "\n",
      "Epoch 131:\n",
      "Training loss: 0.3702, Training accuracy: 0.9141\n",
      "Validation loss: 0.3703, Validation accuracy: 0.8826\n",
      "\n",
      "Epoch 132:\n",
      "Training loss: 0.3673, Training accuracy: 0.9159\n",
      "Validation loss: 0.3809, Validation accuracy: 0.8788\n",
      "\n",
      "Epoch 133:\n",
      "Training loss: 0.3665, Training accuracy: 0.9168\n",
      "Validation loss: 0.3988, Validation accuracy: 0.8724\n",
      "\n",
      "Epoch 134:\n",
      "Training loss: 0.3681, Training accuracy: 0.9163\n",
      "Validation loss: 0.3905, Validation accuracy: 0.8734\n",
      "\n",
      "Epoch 135:\n",
      "Training loss: 0.3691, Training accuracy: 0.9157\n",
      "Validation loss: 0.3710, Validation accuracy: 0.8826\n",
      "\n",
      "Epoch 136:\n",
      "Training loss: 0.3661, Training accuracy: 0.9161\n",
      "Validation loss: 0.3859, Validation accuracy: 0.8796\n",
      "\n",
      "Epoch 137:\n",
      "Training loss: 0.3669, Training accuracy: 0.9155\n",
      "Validation loss: 0.3794, Validation accuracy: 0.8820\n",
      "\n",
      "Epoch 138:\n",
      "Training loss: 0.3615, Training accuracy: 0.9173\n",
      "Validation loss: 0.3784, Validation accuracy: 0.8816\n",
      "\n",
      "Epoch 139:\n",
      "Training loss: 0.3620, Training accuracy: 0.9184\n",
      "Validation loss: 0.3781, Validation accuracy: 0.8815\n",
      "\n",
      "Epoch 140:\n",
      "Training loss: 0.3606, Training accuracy: 0.9182\n",
      "Validation loss: 0.3772, Validation accuracy: 0.8822\n",
      "\n",
      "Epoch 141:\n",
      "Training loss: 0.3625, Training accuracy: 0.9170\n",
      "Validation loss: 0.3792, Validation accuracy: 0.8821\n",
      "\n",
      "Epoch 142:\n",
      "Training loss: 0.3596, Training accuracy: 0.9183\n",
      "Validation loss: 0.3869, Validation accuracy: 0.8791\n",
      "\n",
      "Epoch 143:\n",
      "Training loss: 0.3584, Training accuracy: 0.9171\n",
      "Validation loss: 0.3815, Validation accuracy: 0.8776\n",
      "\n",
      "Epoch 144:\n",
      "Training loss: 0.3569, Training accuracy: 0.9186\n",
      "Validation loss: 0.3560, Validation accuracy: 0.8867\n",
      "Saving ...\n",
      "\n",
      "Epoch 145:\n",
      "Training loss: 0.3580, Training accuracy: 0.9188\n",
      "Validation loss: 0.3644, Validation accuracy: 0.8856\n",
      "\n",
      "Epoch 146:\n",
      "Training loss: 0.3575, Training accuracy: 0.9190\n",
      "Validation loss: 0.3699, Validation accuracy: 0.8872\n",
      "Saving ...\n",
      "\n",
      "Epoch 147:\n",
      "Training loss: 0.3561, Training accuracy: 0.9186\n",
      "Validation loss: 0.3670, Validation accuracy: 0.8818\n",
      "\n",
      "Epoch 148:\n",
      "Training loss: 0.3538, Training accuracy: 0.9197\n",
      "Validation loss: 0.3724, Validation accuracy: 0.8832\n",
      "\n",
      "Epoch 149:\n",
      "Training loss: 0.3549, Training accuracy: 0.9187\n",
      "Validation loss: 0.3777, Validation accuracy: 0.8809\n",
      "\n",
      "Epoch 150:\n",
      "Training loss: 0.3542, Training accuracy: 0.9198\n",
      "Validation loss: 0.3664, Validation accuracy: 0.8830\n",
      "\n",
      "Epoch 151:\n",
      "Training loss: 0.3534, Training accuracy: 0.9204\n",
      "Validation loss: 0.3691, Validation accuracy: 0.8868\n",
      "\n",
      "Epoch 152:\n",
      "Training loss: 0.3518, Training accuracy: 0.9200\n",
      "Validation loss: 0.3705, Validation accuracy: 0.8844\n",
      "\n",
      "Epoch 153:\n",
      "Training loss: 0.3511, Training accuracy: 0.9200\n",
      "Validation loss: 0.3814, Validation accuracy: 0.8801\n",
      "\n",
      "Epoch 154:\n",
      "Training loss: 0.3504, Training accuracy: 0.9212\n",
      "Validation loss: 0.3666, Validation accuracy: 0.8841\n",
      "\n",
      "Epoch 155:\n",
      "Training loss: 0.3482, Training accuracy: 0.9203\n",
      "Validation loss: 0.3803, Validation accuracy: 0.8813\n",
      "\n",
      "Epoch 156:\n",
      "Training loss: 0.3511, Training accuracy: 0.9196\n",
      "Validation loss: 0.3682, Validation accuracy: 0.8833\n",
      "\n",
      "Epoch 157:\n",
      "Training loss: 0.3454, Training accuracy: 0.9198\n",
      "Validation loss: 0.3647, Validation accuracy: 0.8888\n",
      "Saving ...\n",
      "\n",
      "Epoch 158:\n",
      "Training loss: 0.3491, Training accuracy: 0.9204\n",
      "Validation loss: 0.3671, Validation accuracy: 0.8838\n",
      "\n",
      "Epoch 159:\n",
      "Training loss: 0.3476, Training accuracy: 0.9197\n",
      "Validation loss: 0.3685, Validation accuracy: 0.8852\n",
      "\n",
      "Epoch 160:\n",
      "Training loss: 0.3453, Training accuracy: 0.9204\n",
      "Validation loss: 0.3811, Validation accuracy: 0.8794\n",
      "\n",
      "Epoch 161:\n",
      "Training loss: 0.3473, Training accuracy: 0.9212\n",
      "Validation loss: 0.3716, Validation accuracy: 0.8813\n",
      "\n",
      "Epoch 162:\n",
      "Training loss: 0.3445, Training accuracy: 0.9205\n",
      "Validation loss: 0.3686, Validation accuracy: 0.8850\n",
      "\n",
      "Epoch 163:\n",
      "Training loss: 0.3450, Training accuracy: 0.9205\n",
      "Validation loss: 0.3667, Validation accuracy: 0.8847\n",
      "\n",
      "Epoch 164:\n",
      "Training loss: 0.3431, Training accuracy: 0.9212\n",
      "Validation loss: 0.3870, Validation accuracy: 0.8789\n",
      "\n",
      "Epoch 165:\n",
      "Training loss: 0.3448, Training accuracy: 0.9218\n",
      "Validation loss: 0.3670, Validation accuracy: 0.8871\n",
      "\n",
      "Epoch 166:\n",
      "Training loss: 0.3487, Training accuracy: 0.9201\n",
      "Validation loss: 0.3582, Validation accuracy: 0.8879\n",
      "\n",
      "Epoch 167:\n",
      "Training loss: 0.3420, Training accuracy: 0.9211\n",
      "Validation loss: 0.3578, Validation accuracy: 0.8853\n",
      "\n",
      "Epoch 168:\n",
      "Training loss: 0.3400, Training accuracy: 0.9221\n",
      "Validation loss: 0.3540, Validation accuracy: 0.8880\n",
      "\n",
      "Epoch 169:\n",
      "Training loss: 0.3413, Training accuracy: 0.9231\n",
      "Validation loss: 0.3787, Validation accuracy: 0.8800\n",
      "\n",
      "Epoch 170:\n",
      "Training loss: 0.3415, Training accuracy: 0.9226\n",
      "Validation loss: 0.3864, Validation accuracy: 0.8749\n",
      "\n",
      "Epoch 171:\n",
      "Training loss: 0.3410, Training accuracy: 0.9232\n",
      "Validation loss: 0.3693, Validation accuracy: 0.8833\n",
      "\n",
      "Epoch 172:\n",
      "Training loss: 0.3423, Training accuracy: 0.9224\n",
      "Validation loss: 0.3768, Validation accuracy: 0.8801\n",
      "\n",
      "Epoch 173:\n",
      "Training loss: 0.3375, Training accuracy: 0.9232\n",
      "Validation loss: 0.3805, Validation accuracy: 0.8805\n",
      "\n",
      "Epoch 174:\n",
      "Training loss: 0.3417, Training accuracy: 0.9229\n",
      "Validation loss: 0.3796, Validation accuracy: 0.8830\n",
      "\n",
      "Epoch 175:\n",
      "Training loss: 0.3394, Training accuracy: 0.9235\n",
      "Validation loss: 0.3604, Validation accuracy: 0.8866\n",
      "\n",
      "Epoch 176:\n",
      "Training loss: 0.3368, Training accuracy: 0.9236\n",
      "Validation loss: 0.3685, Validation accuracy: 0.8836\n",
      "\n",
      "Epoch 177:\n",
      "Training loss: 0.3359, Training accuracy: 0.9238\n",
      "Validation loss: 0.3758, Validation accuracy: 0.8824\n",
      "\n",
      "Epoch 178:\n",
      "Training loss: 0.3349, Training accuracy: 0.9221\n",
      "Validation loss: 0.3583, Validation accuracy: 0.8876\n",
      "\n",
      "Epoch 179:\n",
      "Training loss: 0.3349, Training accuracy: 0.9248\n",
      "Validation loss: 0.3743, Validation accuracy: 0.8856\n",
      "\n",
      "Epoch 180:\n",
      "Training loss: 0.3335, Training accuracy: 0.9245\n",
      "Validation loss: 0.3634, Validation accuracy: 0.8874\n",
      "\n",
      "Epoch 181:\n",
      "Training loss: 0.3344, Training accuracy: 0.9236\n",
      "Validation loss: 0.3644, Validation accuracy: 0.8878\n",
      "\n",
      "Epoch 182:\n",
      "Training loss: 0.3305, Training accuracy: 0.9235\n",
      "Validation loss: 0.3830, Validation accuracy: 0.8795\n",
      "\n",
      "Epoch 183:\n",
      "Training loss: 0.3308, Training accuracy: 0.9234\n",
      "Validation loss: 0.3643, Validation accuracy: 0.8840\n",
      "\n",
      "Epoch 184:\n",
      "Training loss: 0.3283, Training accuracy: 0.9244\n",
      "Validation loss: 0.3675, Validation accuracy: 0.8851\n",
      "\n",
      "Epoch 185:\n",
      "Training loss: 0.3326, Training accuracy: 0.9246\n",
      "Validation loss: 0.3742, Validation accuracy: 0.8830\n",
      "\n",
      "Epoch 186:\n",
      "Training loss: 0.3297, Training accuracy: 0.9256\n",
      "Validation loss: 0.3761, Validation accuracy: 0.8818\n",
      "\n",
      "Epoch 187:\n",
      "Training loss: 0.3293, Training accuracy: 0.9260\n",
      "Validation loss: 0.3759, Validation accuracy: 0.8812\n",
      "\n",
      "Epoch 188:\n",
      "Training loss: 0.3308, Training accuracy: 0.9256\n",
      "Validation loss: 0.3645, Validation accuracy: 0.8875\n",
      "\n",
      "Epoch 189:\n",
      "Training loss: 0.3284, Training accuracy: 0.9256\n",
      "Validation loss: 0.3625, Validation accuracy: 0.8885\n",
      "\n",
      "Epoch 190:\n",
      "Training loss: 0.3258, Training accuracy: 0.9249\n",
      "Validation loss: 0.3556, Validation accuracy: 0.8843\n",
      "\n",
      "Epoch 191:\n",
      "Training loss: 0.3318, Training accuracy: 0.9247\n",
      "Validation loss: 0.3729, Validation accuracy: 0.8828\n",
      "\n",
      "Epoch 192:\n",
      "Training loss: 0.3285, Training accuracy: 0.9255\n",
      "Validation loss: 0.3722, Validation accuracy: 0.8855\n",
      "\n",
      "Epoch 193:\n",
      "Training loss: 0.3273, Training accuracy: 0.9257\n",
      "Validation loss: 0.3513, Validation accuracy: 0.8893\n",
      "Saving ...\n",
      "\n",
      "Epoch 194:\n",
      "Training loss: 0.3260, Training accuracy: 0.9272\n",
      "Validation loss: 0.3822, Validation accuracy: 0.8788\n",
      "\n",
      "Epoch 195:\n",
      "Training loss: 0.3278, Training accuracy: 0.9258\n",
      "Validation loss: 0.3584, Validation accuracy: 0.8891\n",
      "\n",
      "Epoch 196:\n",
      "Training loss: 0.3271, Training accuracy: 0.9263\n",
      "Validation loss: 0.3687, Validation accuracy: 0.8842\n",
      "\n",
      "Epoch 197:\n",
      "Training loss: 0.3277, Training accuracy: 0.9266\n",
      "Validation loss: 0.3759, Validation accuracy: 0.8825\n",
      "\n",
      "Epoch 198:\n",
      "Training loss: 0.3251, Training accuracy: 0.9263\n",
      "Validation loss: 0.3759, Validation accuracy: 0.8835\n",
      "\n",
      "Epoch 199:\n",
      "Training loss: 0.3226, Training accuracy: 0.9276\n",
      "Validation loss: 0.3542, Validation accuracy: 0.8906\n",
      "Saving ...\n",
      "\n",
      "==================================================\n",
      "==> Optimization finished! Best validation accuracy: 0.8906\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8906"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train(student,teacher,optimizer,criterion,4,[1,0,0],1,train_loader,val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Training starts!\n",
      "==================================================\n",
      "Epoch 0:\n",
      "Training loss: 1.6901, Training accuracy: 0.4247\n",
      "Validation loss: 1.5441, Validation accuracy: 0.4756\n",
      "Saving ...\n",
      "\n",
      "Epoch 1:\n",
      "Training loss: 1.3540, Training accuracy: 0.5568\n",
      "Validation loss: 1.1554, Validation accuracy: 0.6042\n",
      "Saving ...\n",
      "\n",
      "Epoch 2:\n",
      "Training loss: 1.1841, Training accuracy: 0.6200\n",
      "Validation loss: 1.0486, Validation accuracy: 0.6425\n",
      "Saving ...\n",
      "\n",
      "Epoch 3:\n",
      "Training loss: 1.0758, Training accuracy: 0.6593\n",
      "Validation loss: 0.9456, Validation accuracy: 0.6724\n",
      "Saving ...\n",
      "\n",
      "Epoch 4:\n",
      "Training loss: 0.9906, Training accuracy: 0.6916\n",
      "Validation loss: 0.8990, Validation accuracy: 0.6989\n",
      "Saving ...\n",
      "\n",
      "Epoch 5:\n",
      "Training loss: 0.9288, Training accuracy: 0.7142\n",
      "Validation loss: 0.8528, Validation accuracy: 0.7130\n",
      "Saving ...\n",
      "\n",
      "Epoch 6:\n",
      "Training loss: 0.8692, Training accuracy: 0.7350\n",
      "Validation loss: 0.7906, Validation accuracy: 0.7356\n",
      "Saving ...\n",
      "\n",
      "Epoch 7:\n",
      "Training loss: 0.8199, Training accuracy: 0.7506\n",
      "Validation loss: 0.7455, Validation accuracy: 0.7523\n",
      "Saving ...\n",
      "\n",
      "Epoch 8:\n",
      "Training loss: 0.7838, Training accuracy: 0.7626\n",
      "Validation loss: 0.7228, Validation accuracy: 0.7558\n",
      "Saving ...\n",
      "\n",
      "Epoch 9:\n",
      "Training loss: 0.7527, Training accuracy: 0.7736\n",
      "Validation loss: 0.7035, Validation accuracy: 0.7658\n",
      "Saving ...\n",
      "\n",
      "Epoch 10:\n",
      "Training loss: 0.7206, Training accuracy: 0.7840\n",
      "Validation loss: 0.6669, Validation accuracy: 0.7764\n",
      "Saving ...\n",
      "\n",
      "Epoch 11:\n",
      "Training loss: 0.6989, Training accuracy: 0.7896\n",
      "Validation loss: 0.6351, Validation accuracy: 0.7895\n",
      "Saving ...\n",
      "\n",
      "Epoch 12:\n",
      "Training loss: 0.6786, Training accuracy: 0.7965\n",
      "Validation loss: 0.6198, Validation accuracy: 0.7983\n",
      "Saving ...\n",
      "\n",
      "Epoch 13:\n",
      "Training loss: 0.6560, Training accuracy: 0.8035\n",
      "Validation loss: 0.6226, Validation accuracy: 0.7934\n",
      "\n",
      "Epoch 14:\n",
      "Training loss: 0.6371, Training accuracy: 0.8106\n",
      "Validation loss: 0.6064, Validation accuracy: 0.8011\n",
      "Saving ...\n",
      "\n",
      "Epoch 15:\n",
      "Training loss: 0.6191, Training accuracy: 0.8164\n",
      "Validation loss: 0.6171, Validation accuracy: 0.7976\n",
      "\n",
      "Epoch 16:\n",
      "Training loss: 0.6094, Training accuracy: 0.8183\n",
      "Validation loss: 0.5745, Validation accuracy: 0.8128\n",
      "Saving ...\n",
      "\n",
      "Epoch 17:\n",
      "Training loss: 0.5960, Training accuracy: 0.8237\n",
      "Validation loss: 0.5669, Validation accuracy: 0.8127\n",
      "\n",
      "Epoch 18:\n",
      "Training loss: 0.5837, Training accuracy: 0.8271\n",
      "Validation loss: 0.5536, Validation accuracy: 0.8187\n",
      "Saving ...\n",
      "\n",
      "Epoch 19:\n",
      "Training loss: 0.5762, Training accuracy: 0.8312\n",
      "Validation loss: 0.5633, Validation accuracy: 0.8182\n",
      "\n",
      "Epoch 20:\n",
      "Training loss: 0.5594, Training accuracy: 0.8356\n",
      "Validation loss: 0.5423, Validation accuracy: 0.8251\n",
      "Saving ...\n",
      "\n",
      "Epoch 21:\n",
      "Training loss: 0.5515, Training accuracy: 0.8363\n",
      "Validation loss: 0.5338, Validation accuracy: 0.8284\n",
      "Saving ...\n",
      "\n",
      "Epoch 22:\n",
      "Training loss: 0.5460, Training accuracy: 0.8376\n",
      "Validation loss: 0.5444, Validation accuracy: 0.8228\n",
      "\n",
      "Epoch 23:\n",
      "Training loss: 0.5375, Training accuracy: 0.8420\n",
      "Validation loss: 0.5231, Validation accuracy: 0.8298\n",
      "Saving ...\n",
      "\n",
      "Epoch 24:\n",
      "Training loss: 0.5268, Training accuracy: 0.8426\n",
      "Validation loss: 0.5237, Validation accuracy: 0.8306\n",
      "Saving ...\n",
      "\n",
      "Epoch 25:\n",
      "Training loss: 0.5211, Training accuracy: 0.8447\n",
      "Validation loss: 0.5270, Validation accuracy: 0.8291\n",
      "\n",
      "Epoch 26:\n",
      "Training loss: 0.5112, Training accuracy: 0.8505\n",
      "Validation loss: 0.5159, Validation accuracy: 0.8337\n",
      "Saving ...\n",
      "\n",
      "Epoch 27:\n",
      "Training loss: 0.5053, Training accuracy: 0.8514\n",
      "Validation loss: 0.5349, Validation accuracy: 0.8304\n",
      "\n",
      "Epoch 28:\n",
      "Training loss: 0.5024, Training accuracy: 0.8524\n",
      "Validation loss: 0.4851, Validation accuracy: 0.8425\n",
      "Saving ...\n",
      "\n",
      "Epoch 29:\n",
      "Training loss: 0.4907, Training accuracy: 0.8563\n",
      "Validation loss: 0.5076, Validation accuracy: 0.8334\n",
      "\n",
      "Epoch 30:\n",
      "Training loss: 0.4887, Training accuracy: 0.8554\n",
      "Validation loss: 0.4828, Validation accuracy: 0.8441\n",
      "Saving ...\n",
      "\n",
      "Epoch 31:\n",
      "Training loss: 0.4871, Training accuracy: 0.8552\n",
      "Validation loss: 0.5029, Validation accuracy: 0.8371\n",
      "\n",
      "Epoch 32:\n",
      "Training loss: 0.4774, Training accuracy: 0.8606\n",
      "Validation loss: 0.5056, Validation accuracy: 0.8353\n",
      "\n",
      "Epoch 33:\n",
      "Training loss: 0.4727, Training accuracy: 0.8604\n",
      "Validation loss: 0.4754, Validation accuracy: 0.8477\n",
      "Saving ...\n",
      "\n",
      "Epoch 34:\n",
      "Training loss: 0.4697, Training accuracy: 0.8609\n",
      "Validation loss: 0.4680, Validation accuracy: 0.8537\n",
      "Saving ...\n",
      "\n",
      "Epoch 35:\n",
      "Training loss: 0.4628, Training accuracy: 0.8634\n",
      "Validation loss: 0.4803, Validation accuracy: 0.8451\n",
      "\n",
      "Epoch 36:\n",
      "Training loss: 0.4606, Training accuracy: 0.8658\n",
      "Validation loss: 0.4752, Validation accuracy: 0.8481\n",
      "\n",
      "Epoch 37:\n",
      "Training loss: 0.4564, Training accuracy: 0.8650\n",
      "Validation loss: 0.4654, Validation accuracy: 0.8483\n",
      "\n",
      "Epoch 38:\n",
      "Training loss: 0.4515, Training accuracy: 0.8671\n",
      "Validation loss: 0.4700, Validation accuracy: 0.8481\n",
      "\n",
      "Epoch 39:\n",
      "Training loss: 0.4493, Training accuracy: 0.8691\n",
      "Validation loss: 0.4566, Validation accuracy: 0.8545\n",
      "Saving ...\n",
      "\n",
      "Epoch 40:\n",
      "Training loss: 0.4447, Training accuracy: 0.8678\n",
      "Validation loss: 0.4549, Validation accuracy: 0.8544\n",
      "\n",
      "Epoch 41:\n",
      "Training loss: 0.4447, Training accuracy: 0.8701\n",
      "Validation loss: 0.4731, Validation accuracy: 0.8484\n",
      "\n",
      "Epoch 42:\n",
      "Training loss: 0.4365, Training accuracy: 0.8731\n",
      "Validation loss: 0.4544, Validation accuracy: 0.8573\n",
      "Saving ...\n",
      "\n",
      "Epoch 43:\n",
      "Training loss: 0.4359, Training accuracy: 0.8712\n",
      "Validation loss: 0.4487, Validation accuracy: 0.8582\n",
      "Saving ...\n",
      "\n",
      "Epoch 44:\n",
      "Training loss: 0.4327, Training accuracy: 0.8745\n",
      "Validation loss: 0.4518, Validation accuracy: 0.8550\n",
      "\n",
      "Epoch 45:\n",
      "Training loss: 0.4309, Training accuracy: 0.8746\n",
      "Validation loss: 0.4425, Validation accuracy: 0.8611\n",
      "Saving ...\n",
      "\n",
      "Epoch 46:\n",
      "Training loss: 0.4250, Training accuracy: 0.8764\n",
      "Validation loss: 0.4644, Validation accuracy: 0.8546\n",
      "\n",
      "Epoch 47:\n",
      "Training loss: 0.4214, Training accuracy: 0.8758\n",
      "Validation loss: 0.4371, Validation accuracy: 0.8608\n",
      "\n",
      "Epoch 48:\n",
      "Training loss: 0.4190, Training accuracy: 0.8780\n",
      "Validation loss: 0.4557, Validation accuracy: 0.8562\n",
      "\n",
      "Epoch 49:\n",
      "Training loss: 0.4190, Training accuracy: 0.8795\n",
      "Validation loss: 0.4386, Validation accuracy: 0.8595\n",
      "\n",
      "Epoch 50:\n",
      "Training loss: 0.4128, Training accuracy: 0.8788\n",
      "Validation loss: 0.4350, Validation accuracy: 0.8596\n",
      "\n",
      "Epoch 51:\n",
      "Training loss: 0.4114, Training accuracy: 0.8798\n",
      "Validation loss: 0.4395, Validation accuracy: 0.8569\n",
      "\n",
      "Epoch 52:\n",
      "Training loss: 0.4093, Training accuracy: 0.8819\n",
      "Validation loss: 0.4292, Validation accuracy: 0.8621\n",
      "Saving ...\n",
      "\n",
      "Epoch 53:\n",
      "Training loss: 0.4043, Training accuracy: 0.8820\n",
      "Validation loss: 0.4511, Validation accuracy: 0.8562\n",
      "\n",
      "Epoch 54:\n",
      "Training loss: 0.4058, Training accuracy: 0.8815\n",
      "Validation loss: 0.4483, Validation accuracy: 0.8572\n",
      "\n",
      "Epoch 55:\n",
      "Training loss: 0.4015, Training accuracy: 0.8829\n",
      "Validation loss: 0.4311, Validation accuracy: 0.8602\n",
      "\n",
      "Epoch 56:\n",
      "Training loss: 0.4001, Training accuracy: 0.8844\n",
      "Validation loss: 0.4603, Validation accuracy: 0.8528\n",
      "\n",
      "Epoch 57:\n",
      "Training loss: 0.3955, Training accuracy: 0.8859\n",
      "Validation loss: 0.4385, Validation accuracy: 0.8579\n",
      "\n",
      "Epoch 58:\n",
      "Training loss: 0.3946, Training accuracy: 0.8849\n",
      "Validation loss: 0.4302, Validation accuracy: 0.8626\n",
      "Saving ...\n",
      "\n",
      "Epoch 59:\n",
      "Training loss: 0.3937, Training accuracy: 0.8867\n",
      "Validation loss: 0.4258, Validation accuracy: 0.8644\n",
      "Saving ...\n",
      "\n",
      "Epoch 60:\n",
      "Training loss: 0.3913, Training accuracy: 0.8860\n",
      "Validation loss: 0.4131, Validation accuracy: 0.8720\n",
      "Saving ...\n",
      "\n",
      "Epoch 61:\n",
      "Training loss: 0.3873, Training accuracy: 0.8869\n",
      "Validation loss: 0.4434, Validation accuracy: 0.8596\n",
      "\n",
      "Epoch 62:\n",
      "Training loss: 0.3905, Training accuracy: 0.8875\n",
      "Validation loss: 0.4283, Validation accuracy: 0.8638\n",
      "\n",
      "Epoch 63:\n",
      "Training loss: 0.3837, Training accuracy: 0.8881\n",
      "Validation loss: 0.4336, Validation accuracy: 0.8623\n",
      "\n",
      "Epoch 64:\n",
      "Training loss: 0.3835, Training accuracy: 0.8908\n",
      "Validation loss: 0.4278, Validation accuracy: 0.8633\n",
      "\n",
      "Epoch 65:\n",
      "Training loss: 0.3781, Training accuracy: 0.8898\n",
      "Validation loss: 0.4406, Validation accuracy: 0.8627\n",
      "\n",
      "Epoch 66:\n",
      "Training loss: 0.3812, Training accuracy: 0.8890\n",
      "Validation loss: 0.4229, Validation accuracy: 0.8660\n",
      "\n",
      "Epoch 67:\n",
      "Training loss: 0.3785, Training accuracy: 0.8884\n",
      "Validation loss: 0.4143, Validation accuracy: 0.8661\n",
      "\n",
      "Epoch 68:\n",
      "Training loss: 0.3749, Training accuracy: 0.8912\n",
      "Validation loss: 0.4197, Validation accuracy: 0.8677\n",
      "\n",
      "Epoch 69:\n",
      "Training loss: 0.3783, Training accuracy: 0.8896\n",
      "Validation loss: 0.4354, Validation accuracy: 0.8650\n",
      "\n",
      "Epoch 70:\n",
      "Training loss: 0.3734, Training accuracy: 0.8921\n",
      "Validation loss: 0.4380, Validation accuracy: 0.8613\n",
      "\n",
      "Epoch 71:\n",
      "Training loss: 0.3661, Training accuracy: 0.8944\n",
      "Validation loss: 0.4290, Validation accuracy: 0.8628\n",
      "\n",
      "Epoch 72:\n",
      "Training loss: 0.3702, Training accuracy: 0.8918\n",
      "Validation loss: 0.4153, Validation accuracy: 0.8668\n",
      "\n",
      "Epoch 73:\n",
      "Training loss: 0.3682, Training accuracy: 0.8931\n",
      "Validation loss: 0.4097, Validation accuracy: 0.8719\n",
      "\n",
      "Epoch 74:\n",
      "Training loss: 0.3652, Training accuracy: 0.8932\n",
      "Validation loss: 0.4116, Validation accuracy: 0.8734\n",
      "Saving ...\n",
      "\n",
      "Epoch 75:\n",
      "Training loss: 0.3646, Training accuracy: 0.8957\n",
      "Validation loss: 0.4028, Validation accuracy: 0.8726\n",
      "\n",
      "Epoch 76:\n",
      "Training loss: 0.3631, Training accuracy: 0.8946\n",
      "Validation loss: 0.4224, Validation accuracy: 0.8668\n",
      "\n",
      "Epoch 77:\n",
      "Training loss: 0.3605, Training accuracy: 0.8965\n",
      "Validation loss: 0.4225, Validation accuracy: 0.8660\n",
      "\n",
      "Epoch 78:\n",
      "Training loss: 0.3612, Training accuracy: 0.8944\n",
      "Validation loss: 0.4072, Validation accuracy: 0.8721\n",
      "\n",
      "Epoch 79:\n",
      "Training loss: 0.3578, Training accuracy: 0.8965\n",
      "Validation loss: 0.4093, Validation accuracy: 0.8692\n",
      "\n",
      "Epoch 80:\n",
      "Training loss: 0.3596, Training accuracy: 0.8961\n",
      "Validation loss: 0.4151, Validation accuracy: 0.8670\n",
      "\n",
      "Epoch 81:\n",
      "Training loss: 0.3563, Training accuracy: 0.8976\n",
      "Validation loss: 0.4064, Validation accuracy: 0.8718\n",
      "\n",
      "Epoch 82:\n",
      "Training loss: 0.3540, Training accuracy: 0.8985\n",
      "Validation loss: 0.4367, Validation accuracy: 0.8623\n",
      "\n",
      "Epoch 83:\n",
      "Training loss: 0.3534, Training accuracy: 0.8951\n",
      "Validation loss: 0.4053, Validation accuracy: 0.8725\n",
      "\n",
      "Epoch 84:\n",
      "Training loss: 0.3519, Training accuracy: 0.8981\n",
      "Validation loss: 0.4248, Validation accuracy: 0.8627\n",
      "\n",
      "Epoch 85:\n",
      "Training loss: 0.3534, Training accuracy: 0.8974\n",
      "Validation loss: 0.4226, Validation accuracy: 0.8660\n",
      "\n",
      "Epoch 86:\n",
      "Training loss: 0.3505, Training accuracy: 0.8991\n",
      "Validation loss: 0.4115, Validation accuracy: 0.8705\n",
      "\n",
      "Epoch 87:\n",
      "Training loss: 0.3502, Training accuracy: 0.8980\n",
      "Validation loss: 0.3966, Validation accuracy: 0.8741\n",
      "Saving ...\n",
      "\n",
      "Epoch 88:\n",
      "Training loss: 0.3454, Training accuracy: 0.8996\n",
      "Validation loss: 0.4252, Validation accuracy: 0.8631\n",
      "\n",
      "Epoch 89:\n",
      "Training loss: 0.3471, Training accuracy: 0.9007\n",
      "Validation loss: 0.3958, Validation accuracy: 0.8749\n",
      "Saving ...\n",
      "\n",
      "Epoch 90:\n",
      "Training loss: 0.3432, Training accuracy: 0.9003\n",
      "Validation loss: 0.4187, Validation accuracy: 0.8670\n",
      "\n",
      "Epoch 91:\n",
      "Training loss: 0.3419, Training accuracy: 0.9012\n",
      "Validation loss: 0.4113, Validation accuracy: 0.8708\n",
      "\n",
      "Epoch 92:\n",
      "Training loss: 0.3420, Training accuracy: 0.9007\n",
      "Validation loss: 0.3976, Validation accuracy: 0.8746\n",
      "\n",
      "Epoch 93:\n",
      "Training loss: 0.3416, Training accuracy: 0.9023\n",
      "Validation loss: 0.4017, Validation accuracy: 0.8720\n",
      "\n",
      "Epoch 94:\n",
      "Training loss: 0.3403, Training accuracy: 0.9007\n",
      "Validation loss: 0.4040, Validation accuracy: 0.8727\n",
      "\n",
      "Epoch 95:\n",
      "Training loss: 0.3404, Training accuracy: 0.9017\n",
      "Validation loss: 0.4063, Validation accuracy: 0.8692\n",
      "\n",
      "Epoch 96:\n",
      "Training loss: 0.3375, Training accuracy: 0.9035\n",
      "Validation loss: 0.4057, Validation accuracy: 0.8686\n",
      "\n",
      "Epoch 97:\n",
      "Training loss: 0.3378, Training accuracy: 0.9028\n",
      "Validation loss: 0.4068, Validation accuracy: 0.8755\n",
      "Saving ...\n",
      "\n",
      "Epoch 98:\n",
      "Training loss: 0.3356, Training accuracy: 0.9031\n",
      "Validation loss: 0.4026, Validation accuracy: 0.8739\n",
      "\n",
      "Epoch 99:\n",
      "Training loss: 0.3348, Training accuracy: 0.9041\n",
      "Validation loss: 0.3919, Validation accuracy: 0.8773\n",
      "Saving ...\n",
      "\n",
      "Epoch 100:\n",
      "Training loss: 0.3349, Training accuracy: 0.9033\n",
      "Validation loss: 0.4075, Validation accuracy: 0.8724\n",
      "\n",
      "Epoch 101:\n",
      "Training loss: 0.3332, Training accuracy: 0.9031\n",
      "Validation loss: 0.4173, Validation accuracy: 0.8712\n",
      "\n",
      "Epoch 102:\n",
      "Training loss: 0.3319, Training accuracy: 0.9046\n",
      "Validation loss: 0.3993, Validation accuracy: 0.8745\n",
      "\n",
      "Epoch 103:\n",
      "Training loss: 0.3299, Training accuracy: 0.9045\n",
      "Validation loss: 0.3942, Validation accuracy: 0.8759\n",
      "\n",
      "Epoch 104:\n",
      "Training loss: 0.3318, Training accuracy: 0.9040\n",
      "Validation loss: 0.3997, Validation accuracy: 0.8715\n",
      "\n",
      "Epoch 105:\n",
      "Training loss: 0.3333, Training accuracy: 0.9047\n",
      "Validation loss: 0.4022, Validation accuracy: 0.8729\n",
      "\n",
      "Epoch 106:\n",
      "Training loss: 0.3273, Training accuracy: 0.9056\n",
      "Validation loss: 0.4012, Validation accuracy: 0.8737\n",
      "\n",
      "Epoch 107:\n",
      "Training loss: 0.3272, Training accuracy: 0.9052\n",
      "Validation loss: 0.4059, Validation accuracy: 0.8728\n",
      "\n",
      "Epoch 108:\n",
      "Training loss: 0.3281, Training accuracy: 0.9040\n",
      "Validation loss: 0.3948, Validation accuracy: 0.8745\n",
      "\n",
      "Epoch 109:\n",
      "Training loss: 0.3239, Training accuracy: 0.9055\n",
      "Validation loss: 0.3814, Validation accuracy: 0.8803\n",
      "Saving ...\n",
      "\n",
      "Epoch 110:\n",
      "Training loss: 0.3212, Training accuracy: 0.9076\n",
      "Validation loss: 0.4092, Validation accuracy: 0.8720\n",
      "\n",
      "Epoch 111:\n",
      "Training loss: 0.3234, Training accuracy: 0.9069\n",
      "Validation loss: 0.3955, Validation accuracy: 0.8779\n",
      "\n",
      "Epoch 112:\n",
      "Training loss: 0.3228, Training accuracy: 0.9072\n",
      "Validation loss: 0.3913, Validation accuracy: 0.8782\n",
      "\n",
      "Epoch 113:\n",
      "Training loss: 0.3231, Training accuracy: 0.9071\n",
      "Validation loss: 0.3949, Validation accuracy: 0.8739\n",
      "\n",
      "Epoch 114:\n",
      "Training loss: 0.3247, Training accuracy: 0.9069\n",
      "Validation loss: 0.4037, Validation accuracy: 0.8740\n",
      "\n",
      "Epoch 115:\n",
      "Training loss: 0.3215, Training accuracy: 0.9067\n",
      "Validation loss: 0.3905, Validation accuracy: 0.8802\n",
      "\n",
      "Epoch 116:\n",
      "Training loss: 0.3209, Training accuracy: 0.9073\n",
      "Validation loss: 0.3908, Validation accuracy: 0.8794\n",
      "\n",
      "Epoch 117:\n",
      "Training loss: 0.3180, Training accuracy: 0.9095\n",
      "Validation loss: 0.3967, Validation accuracy: 0.8750\n",
      "\n",
      "Epoch 118:\n",
      "Training loss: 0.3187, Training accuracy: 0.9079\n",
      "Validation loss: 0.3891, Validation accuracy: 0.8802\n",
      "\n",
      "Epoch 119:\n",
      "Training loss: 0.3143, Training accuracy: 0.9104\n",
      "Validation loss: 0.3923, Validation accuracy: 0.8788\n",
      "\n",
      "Epoch 120:\n",
      "Training loss: 0.3139, Training accuracy: 0.9103\n",
      "Validation loss: 0.4070, Validation accuracy: 0.8727\n",
      "\n",
      "Epoch 121:\n",
      "Training loss: 0.3148, Training accuracy: 0.9102\n",
      "Validation loss: 0.3974, Validation accuracy: 0.8770\n",
      "\n",
      "Epoch 122:\n",
      "Training loss: 0.3153, Training accuracy: 0.9098\n",
      "Validation loss: 0.3878, Validation accuracy: 0.8754\n",
      "\n",
      "Epoch 123:\n",
      "Training loss: 0.3138, Training accuracy: 0.9085\n",
      "Validation loss: 0.3941, Validation accuracy: 0.8769\n",
      "\n",
      "Epoch 124:\n",
      "Training loss: 0.3107, Training accuracy: 0.9113\n",
      "Validation loss: 0.3989, Validation accuracy: 0.8734\n",
      "\n",
      "Epoch 125:\n",
      "Training loss: 0.3105, Training accuracy: 0.9089\n",
      "Validation loss: 0.4370, Validation accuracy: 0.8629\n",
      "\n",
      "Epoch 126:\n",
      "Training loss: 0.3122, Training accuracy: 0.9100\n",
      "Validation loss: 0.3986, Validation accuracy: 0.8756\n",
      "\n",
      "Epoch 127:\n",
      "Training loss: 0.3114, Training accuracy: 0.9103\n",
      "Validation loss: 0.3850, Validation accuracy: 0.8778\n",
      "\n",
      "Epoch 128:\n",
      "Training loss: 0.3114, Training accuracy: 0.9114\n",
      "Validation loss: 0.4142, Validation accuracy: 0.8691\n",
      "\n",
      "Epoch 129:\n",
      "Training loss: 0.3083, Training accuracy: 0.9125\n",
      "Validation loss: 0.3928, Validation accuracy: 0.8730\n",
      "\n",
      "Epoch 130:\n",
      "Training loss: 0.3077, Training accuracy: 0.9114\n",
      "Validation loss: 0.3859, Validation accuracy: 0.8798\n",
      "\n",
      "Epoch 131:\n",
      "Training loss: 0.3071, Training accuracy: 0.9111\n",
      "Validation loss: 0.3888, Validation accuracy: 0.8794\n",
      "\n",
      "Epoch 132:\n",
      "Training loss: 0.3081, Training accuracy: 0.9119\n",
      "Validation loss: 0.4121, Validation accuracy: 0.8708\n",
      "\n",
      "Epoch 133:\n",
      "Training loss: 0.3060, Training accuracy: 0.9113\n",
      "Validation loss: 0.3852, Validation accuracy: 0.8807\n",
      "Saving ...\n",
      "\n",
      "Epoch 134:\n",
      "Training loss: 0.3034, Training accuracy: 0.9125\n",
      "Validation loss: 0.3824, Validation accuracy: 0.8819\n",
      "Saving ...\n",
      "\n",
      "Epoch 135:\n",
      "Training loss: 0.3062, Training accuracy: 0.9118\n",
      "Validation loss: 0.4114, Validation accuracy: 0.8732\n",
      "\n",
      "Epoch 136:\n",
      "Training loss: 0.3043, Training accuracy: 0.9119\n",
      "Validation loss: 0.3874, Validation accuracy: 0.8778\n",
      "\n",
      "Epoch 137:\n",
      "Training loss: 0.3041, Training accuracy: 0.9133\n",
      "Validation loss: 0.3834, Validation accuracy: 0.8787\n",
      "\n",
      "Epoch 138:\n",
      "Training loss: 0.3007, Training accuracy: 0.9123\n",
      "Validation loss: 0.3847, Validation accuracy: 0.8781\n",
      "\n",
      "Epoch 139:\n",
      "Training loss: 0.3028, Training accuracy: 0.9136\n",
      "Validation loss: 0.4006, Validation accuracy: 0.8729\n",
      "\n",
      "Epoch 140:\n",
      "Training loss: 0.3012, Training accuracy: 0.9140\n",
      "Validation loss: 0.3939, Validation accuracy: 0.8766\n",
      "\n",
      "Epoch 141:\n",
      "Training loss: 0.2992, Training accuracy: 0.9131\n",
      "Validation loss: 0.3944, Validation accuracy: 0.8775\n",
      "\n",
      "Epoch 142:\n",
      "Training loss: 0.3001, Training accuracy: 0.9147\n",
      "Validation loss: 0.3868, Validation accuracy: 0.8798\n",
      "\n",
      "Epoch 143:\n",
      "Training loss: 0.3006, Training accuracy: 0.9131\n",
      "Validation loss: 0.3998, Validation accuracy: 0.8768\n",
      "\n",
      "Epoch 144:\n",
      "Training loss: 0.2979, Training accuracy: 0.9155\n",
      "Validation loss: 0.3991, Validation accuracy: 0.8740\n",
      "\n",
      "Epoch 145:\n",
      "Training loss: 0.3001, Training accuracy: 0.9133\n",
      "Validation loss: 0.4033, Validation accuracy: 0.8750\n",
      "\n",
      "Epoch 146:\n",
      "Training loss: 0.2942, Training accuracy: 0.9160\n",
      "Validation loss: 0.3942, Validation accuracy: 0.8785\n",
      "\n",
      "Epoch 147:\n",
      "Training loss: 0.2962, Training accuracy: 0.9155\n",
      "Validation loss: 0.4017, Validation accuracy: 0.8725\n",
      "\n",
      "Epoch 148:\n",
      "Training loss: 0.2970, Training accuracy: 0.9134\n",
      "Validation loss: 0.3848, Validation accuracy: 0.8799\n",
      "\n",
      "Epoch 149:\n",
      "Training loss: 0.2971, Training accuracy: 0.9136\n",
      "Validation loss: 0.3944, Validation accuracy: 0.8779\n",
      "\n",
      "Epoch 150:\n",
      "Training loss: 0.2950, Training accuracy: 0.9162\n",
      "Validation loss: 0.3763, Validation accuracy: 0.8807\n",
      "\n",
      "Epoch 151:\n",
      "Training loss: 0.2943, Training accuracy: 0.9158\n",
      "Validation loss: 0.3964, Validation accuracy: 0.8745\n",
      "\n",
      "Epoch 152:\n",
      "Training loss: 0.2938, Training accuracy: 0.9157\n",
      "Validation loss: 0.3758, Validation accuracy: 0.8824\n",
      "Saving ...\n",
      "\n",
      "Epoch 153:\n",
      "Training loss: 0.2943, Training accuracy: 0.9147\n",
      "Validation loss: 0.3798, Validation accuracy: 0.8823\n",
      "\n",
      "Epoch 154:\n",
      "Training loss: 0.2926, Training accuracy: 0.9158\n",
      "Validation loss: 0.3770, Validation accuracy: 0.8824\n",
      "\n",
      "Epoch 155:\n",
      "Training loss: 0.2943, Training accuracy: 0.9151\n",
      "Validation loss: 0.3772, Validation accuracy: 0.8835\n",
      "Saving ...\n",
      "\n",
      "Epoch 156:\n",
      "Training loss: 0.2937, Training accuracy: 0.9152\n",
      "Validation loss: 0.3943, Validation accuracy: 0.8759\n",
      "\n",
      "Epoch 157:\n",
      "Training loss: 0.2906, Training accuracy: 0.9174\n",
      "Validation loss: 0.3752, Validation accuracy: 0.8844\n",
      "Saving ...\n",
      "\n",
      "Epoch 158:\n",
      "Training loss: 0.2896, Training accuracy: 0.9155\n",
      "Validation loss: 0.3893, Validation accuracy: 0.8776\n",
      "\n",
      "Epoch 159:\n",
      "Training loss: 0.2906, Training accuracy: 0.9156\n",
      "Validation loss: 0.3903, Validation accuracy: 0.8798\n",
      "\n",
      "Epoch 160:\n",
      "Training loss: 0.2894, Training accuracy: 0.9176\n",
      "Validation loss: 0.3869, Validation accuracy: 0.8799\n",
      "\n",
      "Epoch 161:\n",
      "Training loss: 0.2895, Training accuracy: 0.9163\n",
      "Validation loss: 0.3892, Validation accuracy: 0.8774\n",
      "\n",
      "Epoch 162:\n",
      "Training loss: 0.2882, Training accuracy: 0.9178\n",
      "Validation loss: 0.3847, Validation accuracy: 0.8791\n",
      "\n",
      "Epoch 163:\n",
      "Training loss: 0.2885, Training accuracy: 0.9177\n",
      "Validation loss: 0.3888, Validation accuracy: 0.8794\n",
      "\n",
      "Epoch 164:\n",
      "Training loss: 0.2860, Training accuracy: 0.9177\n",
      "Validation loss: 0.3954, Validation accuracy: 0.8759\n",
      "\n",
      "Epoch 165:\n",
      "Training loss: 0.2870, Training accuracy: 0.9183\n",
      "Validation loss: 0.3773, Validation accuracy: 0.8813\n",
      "\n",
      "Epoch 166:\n",
      "Training loss: 0.2860, Training accuracy: 0.9165\n",
      "Validation loss: 0.3769, Validation accuracy: 0.8821\n",
      "\n",
      "Epoch 167:\n",
      "Training loss: 0.2862, Training accuracy: 0.9172\n",
      "Validation loss: 0.3754, Validation accuracy: 0.8835\n",
      "\n",
      "Epoch 168:\n",
      "Training loss: 0.2857, Training accuracy: 0.9178\n",
      "Validation loss: 0.3954, Validation accuracy: 0.8768\n",
      "\n",
      "Epoch 169:\n",
      "Training loss: 0.2845, Training accuracy: 0.9186\n",
      "Validation loss: 0.3977, Validation accuracy: 0.8772\n",
      "\n",
      "Epoch 170:\n",
      "Training loss: 0.2816, Training accuracy: 0.9186\n",
      "Validation loss: 0.3910, Validation accuracy: 0.8787\n",
      "\n",
      "Epoch 171:\n",
      "Training loss: 0.2884, Training accuracy: 0.9168\n",
      "Validation loss: 0.3828, Validation accuracy: 0.8839\n",
      "\n",
      "Epoch 172:\n",
      "Training loss: 0.2828, Training accuracy: 0.9191\n",
      "Validation loss: 0.3805, Validation accuracy: 0.8853\n",
      "Saving ...\n",
      "\n",
      "Epoch 173:\n",
      "Training loss: 0.2850, Training accuracy: 0.9189\n",
      "Validation loss: 0.3844, Validation accuracy: 0.8804\n",
      "\n",
      "Epoch 174:\n",
      "Training loss: 0.2844, Training accuracy: 0.9196\n",
      "Validation loss: 0.3772, Validation accuracy: 0.8843\n",
      "\n",
      "Epoch 175:\n",
      "Training loss: 0.2832, Training accuracy: 0.9192\n",
      "Validation loss: 0.3719, Validation accuracy: 0.8840\n",
      "\n",
      "Epoch 176:\n",
      "Training loss: 0.2811, Training accuracy: 0.9199\n",
      "Validation loss: 0.3792, Validation accuracy: 0.8844\n",
      "\n",
      "Epoch 177:\n",
      "Training loss: 0.2804, Training accuracy: 0.9201\n",
      "Validation loss: 0.3787, Validation accuracy: 0.8837\n",
      "\n",
      "Epoch 178:\n",
      "Training loss: 0.2809, Training accuracy: 0.9194\n",
      "Validation loss: 0.4077, Validation accuracy: 0.8724\n",
      "\n",
      "Epoch 179:\n",
      "Training loss: 0.2811, Training accuracy: 0.9196\n",
      "Validation loss: 0.3791, Validation accuracy: 0.8821\n",
      "\n",
      "Epoch 180:\n",
      "Training loss: 0.2794, Training accuracy: 0.9203\n",
      "Validation loss: 0.3923, Validation accuracy: 0.8781\n",
      "\n",
      "Epoch 181:\n",
      "Training loss: 0.2773, Training accuracy: 0.9204\n",
      "Validation loss: 0.3677, Validation accuracy: 0.8855\n",
      "Saving ...\n",
      "\n",
      "Epoch 182:\n",
      "Training loss: 0.2766, Training accuracy: 0.9208\n",
      "Validation loss: 0.3800, Validation accuracy: 0.8828\n",
      "\n",
      "Epoch 183:\n",
      "Training loss: 0.2779, Training accuracy: 0.9207\n",
      "Validation loss: 0.3751, Validation accuracy: 0.8805\n",
      "\n",
      "Epoch 184:\n",
      "Training loss: 0.2781, Training accuracy: 0.9206\n",
      "Validation loss: 0.3994, Validation accuracy: 0.8765\n",
      "\n",
      "Epoch 185:\n",
      "Training loss: 0.2789, Training accuracy: 0.9210\n",
      "Validation loss: 0.3729, Validation accuracy: 0.8846\n",
      "\n",
      "Epoch 186:\n",
      "Training loss: 0.2746, Training accuracy: 0.9225\n",
      "Validation loss: 0.3724, Validation accuracy: 0.8841\n",
      "\n",
      "Epoch 187:\n",
      "Training loss: 0.2771, Training accuracy: 0.9213\n",
      "Validation loss: 0.3826, Validation accuracy: 0.8821\n",
      "\n",
      "Epoch 188:\n",
      "Training loss: 0.2762, Training accuracy: 0.9209\n",
      "Validation loss: 0.3875, Validation accuracy: 0.8802\n",
      "\n",
      "Epoch 189:\n",
      "Training loss: 0.2758, Training accuracy: 0.9202\n",
      "Validation loss: 0.3782, Validation accuracy: 0.8826\n",
      "\n",
      "Epoch 190:\n",
      "Training loss: 0.2740, Training accuracy: 0.9212\n",
      "Validation loss: 0.3746, Validation accuracy: 0.8827\n",
      "\n",
      "Epoch 191:\n",
      "Training loss: 0.2721, Training accuracy: 0.9222\n",
      "Validation loss: 0.3711, Validation accuracy: 0.8878\n",
      "Saving ...\n",
      "\n",
      "Epoch 192:\n",
      "Training loss: 0.2756, Training accuracy: 0.9198\n",
      "Validation loss: 0.3723, Validation accuracy: 0.8840\n",
      "\n",
      "Epoch 193:\n",
      "Training loss: 0.2745, Training accuracy: 0.9228\n",
      "Validation loss: 0.3971, Validation accuracy: 0.8761\n",
      "\n",
      "Epoch 194:\n",
      "Training loss: 0.2726, Training accuracy: 0.9230\n",
      "Validation loss: 0.3776, Validation accuracy: 0.8843\n",
      "\n",
      "Epoch 195:\n",
      "Training loss: 0.2730, Training accuracy: 0.9218\n",
      "Validation loss: 0.3817, Validation accuracy: 0.8814\n",
      "\n",
      "Epoch 196:\n",
      "Training loss: 0.2720, Training accuracy: 0.9224\n",
      "Validation loss: 0.3780, Validation accuracy: 0.8817\n",
      "\n",
      "Epoch 197:\n",
      "Training loss: 0.2721, Training accuracy: 0.9224\n",
      "Validation loss: 0.3808, Validation accuracy: 0.8836\n",
      "\n",
      "Epoch 198:\n",
      "Training loss: 0.2719, Training accuracy: 0.9221\n",
      "Validation loss: 0.3767, Validation accuracy: 0.8814\n",
      "\n",
      "Epoch 199:\n",
      "Training loss: 0.2715, Training accuracy: 0.9226\n",
      "Validation loss: 0.4022, Validation accuracy: 0.8785\n",
      "\n",
      "==================================================\n",
      "==> Optimization finished! Best validation accuracy: 0.8878\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8878"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train(student,teacher,optimizer,criterion,8,[1,0,0],1,train_loader,val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Training starts!\n",
      "==================================================\n",
      "Epoch 0:\n",
      "Training loss: 1.1248, Training accuracy: 0.3453\n",
      "Validation loss: 2.6631, Validation accuracy: 0.3827\n",
      "Saving ...\n",
      "\n",
      "Epoch 1:\n",
      "Training loss: 1.0688, Training accuracy: 0.4397\n",
      "Validation loss: 2.4484, Validation accuracy: 0.4463\n",
      "Saving ...\n",
      "\n",
      "Epoch 2:\n",
      "Training loss: 1.0560, Training accuracy: 0.4807\n",
      "Validation loss: 2.1280, Validation accuracy: 0.5024\n",
      "Saving ...\n",
      "\n",
      "Epoch 3:\n",
      "Training loss: 1.0474, Training accuracy: 0.5131\n",
      "Validation loss: 2.3435, Validation accuracy: 0.4942\n",
      "\n",
      "Epoch 4:\n",
      "Training loss: 1.0413, Training accuracy: 0.5384\n",
      "Validation loss: 2.1788, Validation accuracy: 0.5265\n",
      "Saving ...\n",
      "\n",
      "Epoch 5:\n",
      "Training loss: 1.0377, Training accuracy: 0.5527\n",
      "Validation loss: 2.0903, Validation accuracy: 0.5628\n",
      "Saving ...\n",
      "\n",
      "Epoch 6:\n",
      "Training loss: 1.0347, Training accuracy: 0.5683\n",
      "Validation loss: 2.0740, Validation accuracy: 0.5646\n",
      "Saving ...\n",
      "\n",
      "Epoch 7:\n",
      "Training loss: 1.0324, Training accuracy: 0.5817\n",
      "Validation loss: 2.1203, Validation accuracy: 0.5775\n",
      "Saving ...\n",
      "\n",
      "Epoch 8:\n",
      "Training loss: 1.0306, Training accuracy: 0.5966\n",
      "Validation loss: 2.1092, Validation accuracy: 0.5886\n",
      "Saving ...\n",
      "\n",
      "Epoch 9:\n",
      "Training loss: 1.0292, Training accuracy: 0.6021\n",
      "Validation loss: 2.4272, Validation accuracy: 0.5891\n",
      "Saving ...\n",
      "\n",
      "Epoch 10:\n",
      "Training loss: 1.0278, Training accuracy: 0.6073\n",
      "Validation loss: 2.2808, Validation accuracy: 0.5793\n",
      "\n",
      "Epoch 11:\n",
      "Training loss: 1.0267, Training accuracy: 0.6177\n",
      "Validation loss: 2.0401, Validation accuracy: 0.6086\n",
      "Saving ...\n",
      "\n",
      "Epoch 12:\n",
      "Training loss: 1.0255, Training accuracy: 0.6208\n",
      "Validation loss: 2.0129, Validation accuracy: 0.6123\n",
      "Saving ...\n",
      "\n",
      "Epoch 13:\n",
      "Training loss: 1.0246, Training accuracy: 0.6271\n",
      "Validation loss: 2.1422, Validation accuracy: 0.6007\n",
      "\n",
      "Epoch 14:\n",
      "Training loss: 1.0237, Training accuracy: 0.6334\n",
      "Validation loss: 1.9709, Validation accuracy: 0.5972\n",
      "\n",
      "Epoch 15:\n",
      "Training loss: 1.0232, Training accuracy: 0.6360\n",
      "Validation loss: 1.9798, Validation accuracy: 0.6058\n",
      "\n",
      "Epoch 16:\n",
      "Training loss: 1.0225, Training accuracy: 0.6456\n",
      "Validation loss: 1.8582, Validation accuracy: 0.6326\n",
      "Saving ...\n",
      "\n",
      "Epoch 17:\n",
      "Training loss: 1.0219, Training accuracy: 0.6466\n",
      "Validation loss: 1.9870, Validation accuracy: 0.6372\n",
      "Saving ...\n",
      "\n",
      "Epoch 18:\n",
      "Training loss: 1.0214, Training accuracy: 0.6481\n",
      "Validation loss: 1.9484, Validation accuracy: 0.6280\n",
      "\n",
      "Epoch 19:\n",
      "Training loss: 1.0209, Training accuracy: 0.6558\n",
      "Validation loss: 1.8671, Validation accuracy: 0.6522\n",
      "Saving ...\n",
      "\n",
      "Epoch 20:\n",
      "Training loss: 1.0203, Training accuracy: 0.6581\n",
      "Validation loss: 1.7193, Validation accuracy: 0.6518\n",
      "\n",
      "Epoch 21:\n",
      "Training loss: 1.0202, Training accuracy: 0.6590\n",
      "Validation loss: 1.7923, Validation accuracy: 0.6502\n",
      "\n",
      "Epoch 22:\n",
      "Training loss: 1.0195, Training accuracy: 0.6647\n",
      "Validation loss: 1.8693, Validation accuracy: 0.6650\n",
      "Saving ...\n",
      "\n",
      "Epoch 23:\n",
      "Training loss: 1.0193, Training accuracy: 0.6675\n",
      "Validation loss: 1.8961, Validation accuracy: 0.6576\n",
      "\n",
      "Epoch 24:\n",
      "Training loss: 1.0189, Training accuracy: 0.6730\n",
      "Validation loss: 1.8558, Validation accuracy: 0.6624\n",
      "\n",
      "Epoch 25:\n",
      "Training loss: 1.0189, Training accuracy: 0.6737\n",
      "Validation loss: 1.9625, Validation accuracy: 0.6529\n",
      "\n",
      "Epoch 26:\n",
      "Training loss: 1.0184, Training accuracy: 0.6761\n",
      "Validation loss: 1.8728, Validation accuracy: 0.6407\n",
      "\n",
      "Epoch 27:\n",
      "Training loss: 1.0180, Training accuracy: 0.6784\n",
      "Validation loss: 1.7969, Validation accuracy: 0.6672\n",
      "Saving ...\n",
      "\n",
      "Epoch 28:\n",
      "Training loss: 1.0181, Training accuracy: 0.6797\n",
      "Validation loss: 1.7764, Validation accuracy: 0.6700\n",
      "Saving ...\n",
      "\n",
      "Epoch 29:\n",
      "Training loss: 1.0175, Training accuracy: 0.6835\n",
      "Validation loss: 1.6497, Validation accuracy: 0.6785\n",
      "Saving ...\n",
      "\n",
      "Epoch 30:\n",
      "Training loss: 1.0170, Training accuracy: 0.6863\n",
      "Validation loss: 1.7781, Validation accuracy: 0.6740\n",
      "\n",
      "Epoch 31:\n",
      "Training loss: 1.0170, Training accuracy: 0.6866\n",
      "Validation loss: 1.5842, Validation accuracy: 0.6905\n",
      "Saving ...\n",
      "\n",
      "Epoch 32:\n",
      "Training loss: 1.0167, Training accuracy: 0.6915\n",
      "Validation loss: 1.6986, Validation accuracy: 0.6762\n",
      "\n",
      "Epoch 33:\n",
      "Training loss: 1.0167, Training accuracy: 0.6926\n",
      "Validation loss: 1.7483, Validation accuracy: 0.6763\n",
      "\n",
      "Epoch 34:\n",
      "Training loss: 1.0165, Training accuracy: 0.6904\n",
      "Validation loss: 1.6718, Validation accuracy: 0.6750\n",
      "\n",
      "Epoch 35:\n",
      "Training loss: 1.0161, Training accuracy: 0.6972\n",
      "Validation loss: 1.6062, Validation accuracy: 0.6884\n",
      "\n",
      "Epoch 36:\n",
      "Training loss: 1.0156, Training accuracy: 0.7000\n",
      "Validation loss: 1.5540, Validation accuracy: 0.6948\n",
      "Saving ...\n",
      "\n",
      "Epoch 37:\n",
      "Training loss: 1.0159, Training accuracy: 0.7004\n",
      "Validation loss: 1.5711, Validation accuracy: 0.6913\n",
      "\n",
      "Epoch 38:\n",
      "Training loss: 1.0155, Training accuracy: 0.7052\n",
      "Validation loss: 1.5930, Validation accuracy: 0.6937\n",
      "\n",
      "Epoch 39:\n",
      "Training loss: 1.0151, Training accuracy: 0.7039\n",
      "Validation loss: 1.5596, Validation accuracy: 0.7009\n",
      "Saving ...\n",
      "\n",
      "Epoch 40:\n",
      "Training loss: 1.0150, Training accuracy: 0.7069\n",
      "Validation loss: 1.5794, Validation accuracy: 0.6952\n",
      "\n",
      "Epoch 41:\n",
      "Training loss: 1.0151, Training accuracy: 0.7075\n",
      "Validation loss: 1.5955, Validation accuracy: 0.6872\n",
      "\n",
      "Epoch 42:\n",
      "Training loss: 1.0148, Training accuracy: 0.7100\n",
      "Validation loss: 1.6403, Validation accuracy: 0.7031\n",
      "Saving ...\n",
      "\n",
      "Epoch 43:\n",
      "Training loss: 1.0148, Training accuracy: 0.7104\n",
      "Validation loss: 1.5450, Validation accuracy: 0.6898\n",
      "\n",
      "Epoch 44:\n",
      "Training loss: 1.0143, Training accuracy: 0.7134\n",
      "Validation loss: 1.5508, Validation accuracy: 0.6997\n",
      "\n",
      "Epoch 45:\n",
      "Training loss: 1.0141, Training accuracy: 0.7130\n",
      "Validation loss: 1.5662, Validation accuracy: 0.6996\n",
      "\n",
      "Epoch 46:\n",
      "Training loss: 1.0143, Training accuracy: 0.7138\n",
      "Validation loss: 1.5430, Validation accuracy: 0.7055\n",
      "Saving ...\n",
      "\n",
      "Epoch 47:\n",
      "Training loss: 1.0141, Training accuracy: 0.7180\n",
      "Validation loss: 1.5579, Validation accuracy: 0.7049\n",
      "\n",
      "Epoch 48:\n",
      "Training loss: 1.0137, Training accuracy: 0.7173\n",
      "Validation loss: 1.5261, Validation accuracy: 0.6971\n",
      "\n",
      "Epoch 49:\n",
      "Training loss: 1.0140, Training accuracy: 0.7200\n",
      "Validation loss: 1.4828, Validation accuracy: 0.7109\n",
      "Saving ...\n",
      "\n",
      "Epoch 50:\n",
      "Training loss: 1.0137, Training accuracy: 0.7238\n",
      "Validation loss: 1.4973, Validation accuracy: 0.7114\n",
      "Saving ...\n",
      "\n",
      "Epoch 51:\n",
      "Training loss: 1.0137, Training accuracy: 0.7232\n",
      "Validation loss: 1.4091, Validation accuracy: 0.7201\n",
      "Saving ...\n",
      "\n",
      "Epoch 52:\n",
      "Training loss: 1.0131, Training accuracy: 0.7258\n",
      "Validation loss: 1.4727, Validation accuracy: 0.7145\n",
      "\n",
      "Epoch 53:\n",
      "Training loss: 1.0131, Training accuracy: 0.7276\n",
      "Validation loss: 1.4148, Validation accuracy: 0.7241\n",
      "Saving ...\n",
      "\n",
      "Epoch 54:\n",
      "Training loss: 1.0131, Training accuracy: 0.7252\n",
      "Validation loss: 1.5017, Validation accuracy: 0.7117\n",
      "\n",
      "Epoch 55:\n",
      "Training loss: 1.0131, Training accuracy: 0.7260\n",
      "Validation loss: 1.3785, Validation accuracy: 0.7240\n",
      "\n",
      "Epoch 56:\n",
      "Training loss: 1.0130, Training accuracy: 0.7249\n",
      "Validation loss: 1.4820, Validation accuracy: 0.7135\n",
      "\n",
      "Epoch 57:\n",
      "Training loss: 1.0129, Training accuracy: 0.7258\n",
      "Validation loss: 1.3266, Validation accuracy: 0.7283\n",
      "Saving ...\n",
      "\n",
      "Epoch 58:\n",
      "Training loss: 1.0127, Training accuracy: 0.7305\n",
      "Validation loss: 1.4131, Validation accuracy: 0.7259\n",
      "\n",
      "Epoch 59:\n",
      "Training loss: 1.0128, Training accuracy: 0.7295\n",
      "Validation loss: 1.3943, Validation accuracy: 0.7114\n",
      "\n",
      "Epoch 60:\n",
      "Training loss: 1.0125, Training accuracy: 0.7326\n",
      "Validation loss: 1.4440, Validation accuracy: 0.7232\n",
      "\n",
      "Epoch 61:\n",
      "Training loss: 1.0124, Training accuracy: 0.7316\n",
      "Validation loss: 1.4226, Validation accuracy: 0.7297\n",
      "Saving ...\n",
      "\n",
      "Epoch 62:\n",
      "Training loss: 1.0122, Training accuracy: 0.7378\n",
      "Validation loss: 1.3806, Validation accuracy: 0.7245\n",
      "\n",
      "Epoch 63:\n",
      "Training loss: 1.0124, Training accuracy: 0.7362\n",
      "Validation loss: 1.4135, Validation accuracy: 0.7233\n",
      "\n",
      "Epoch 64:\n",
      "Training loss: 1.0120, Training accuracy: 0.7359\n",
      "Validation loss: 1.3863, Validation accuracy: 0.7285\n",
      "\n",
      "Epoch 65:\n",
      "Training loss: 1.0122, Training accuracy: 0.7389\n",
      "Validation loss: 1.3064, Validation accuracy: 0.7291\n",
      "\n",
      "Epoch 66:\n",
      "Training loss: 1.0121, Training accuracy: 0.7365\n",
      "Validation loss: 1.3967, Validation accuracy: 0.7278\n",
      "\n",
      "Epoch 67:\n",
      "Training loss: 1.0119, Training accuracy: 0.7408\n",
      "Validation loss: 1.3773, Validation accuracy: 0.7362\n",
      "Saving ...\n",
      "\n",
      "Epoch 68:\n",
      "Training loss: 1.0119, Training accuracy: 0.7398\n",
      "Validation loss: 1.4458, Validation accuracy: 0.7285\n",
      "\n",
      "Epoch 69:\n",
      "Training loss: 1.0117, Training accuracy: 0.7413\n",
      "Validation loss: 1.3128, Validation accuracy: 0.7285\n",
      "\n",
      "Epoch 70:\n",
      "Training loss: 1.0117, Training accuracy: 0.7423\n",
      "Validation loss: 1.2511, Validation accuracy: 0.7353\n",
      "\n",
      "Epoch 71:\n",
      "Training loss: 1.0116, Training accuracy: 0.7428\n",
      "Validation loss: 1.4454, Validation accuracy: 0.7242\n",
      "\n",
      "Epoch 72:\n",
      "Training loss: 1.0116, Training accuracy: 0.7438\n",
      "Validation loss: 1.3927, Validation accuracy: 0.7313\n",
      "\n",
      "Epoch 73:\n",
      "Training loss: 1.0114, Training accuracy: 0.7468\n",
      "Validation loss: 1.2800, Validation accuracy: 0.7345\n",
      "\n",
      "Epoch 74:\n",
      "Training loss: 1.0114, Training accuracy: 0.7440\n",
      "Validation loss: 1.2920, Validation accuracy: 0.7307\n",
      "\n",
      "Epoch 75:\n",
      "Training loss: 1.0112, Training accuracy: 0.7465\n",
      "Validation loss: 1.2922, Validation accuracy: 0.7369\n",
      "Saving ...\n",
      "\n",
      "Epoch 76:\n",
      "Training loss: 1.0111, Training accuracy: 0.7509\n",
      "Validation loss: 1.2778, Validation accuracy: 0.7370\n",
      "Saving ...\n",
      "\n",
      "Epoch 77:\n",
      "Training loss: 1.0112, Training accuracy: 0.7472\n",
      "Validation loss: 1.2276, Validation accuracy: 0.7334\n",
      "\n",
      "Epoch 78:\n",
      "Training loss: 1.0109, Training accuracy: 0.7508\n",
      "Validation loss: 1.3635, Validation accuracy: 0.7340\n",
      "\n",
      "Epoch 79:\n",
      "Training loss: 1.0109, Training accuracy: 0.7502\n",
      "Validation loss: 1.2548, Validation accuracy: 0.7392\n",
      "Saving ...\n",
      "\n",
      "Epoch 80:\n",
      "Training loss: 1.0110, Training accuracy: 0.7467\n",
      "Validation loss: 1.2337, Validation accuracy: 0.7363\n",
      "\n",
      "Epoch 81:\n",
      "Training loss: 1.0108, Training accuracy: 0.7501\n",
      "Validation loss: 1.2825, Validation accuracy: 0.7339\n",
      "\n",
      "Epoch 82:\n",
      "Training loss: 1.0109, Training accuracy: 0.7495\n",
      "Validation loss: 1.3366, Validation accuracy: 0.7369\n",
      "\n",
      "Epoch 83:\n",
      "Training loss: 1.0108, Training accuracy: 0.7505\n",
      "Validation loss: 1.3552, Validation accuracy: 0.7331\n",
      "\n",
      "Epoch 84:\n",
      "Training loss: 1.0105, Training accuracy: 0.7539\n",
      "Validation loss: 1.3503, Validation accuracy: 0.7350\n",
      "\n",
      "Epoch 85:\n",
      "Training loss: 1.0107, Training accuracy: 0.7519\n",
      "Validation loss: 1.3099, Validation accuracy: 0.7429\n",
      "Saving ...\n",
      "\n",
      "Epoch 86:\n",
      "Training loss: 1.0105, Training accuracy: 0.7536\n",
      "Validation loss: 1.2436, Validation accuracy: 0.7407\n",
      "\n",
      "Epoch 87:\n",
      "Training loss: 1.0103, Training accuracy: 0.7581\n",
      "Validation loss: 1.1595, Validation accuracy: 0.7546\n",
      "Saving ...\n",
      "\n",
      "Epoch 88:\n",
      "Training loss: 1.0104, Training accuracy: 0.7549\n",
      "Validation loss: 1.3447, Validation accuracy: 0.7407\n",
      "\n",
      "Epoch 89:\n",
      "Training loss: 1.0103, Training accuracy: 0.7548\n",
      "Validation loss: 1.2526, Validation accuracy: 0.7511\n",
      "\n",
      "Epoch 90:\n",
      "Training loss: 1.0101, Training accuracy: 0.7602\n",
      "Validation loss: 1.3133, Validation accuracy: 0.7460\n",
      "\n",
      "Epoch 91:\n",
      "Training loss: 1.0102, Training accuracy: 0.7572\n",
      "Validation loss: 1.2083, Validation accuracy: 0.7472\n",
      "\n",
      "Epoch 92:\n",
      "Training loss: 1.0102, Training accuracy: 0.7592\n",
      "Validation loss: 1.2234, Validation accuracy: 0.7383\n",
      "\n",
      "Epoch 93:\n",
      "Training loss: 1.0101, Training accuracy: 0.7591\n",
      "Validation loss: 1.2322, Validation accuracy: 0.7423\n",
      "\n",
      "Epoch 94:\n",
      "Training loss: 1.0100, Training accuracy: 0.7582\n",
      "Validation loss: 1.1990, Validation accuracy: 0.7492\n",
      "\n",
      "Epoch 95:\n",
      "Training loss: 1.0097, Training accuracy: 0.7592\n",
      "Validation loss: 1.2084, Validation accuracy: 0.7476\n",
      "\n",
      "Epoch 96:\n",
      "Training loss: 1.0099, Training accuracy: 0.7613\n",
      "Validation loss: 1.2293, Validation accuracy: 0.7458\n",
      "\n",
      "Epoch 97:\n",
      "Training loss: 1.0099, Training accuracy: 0.7597\n",
      "Validation loss: 1.1945, Validation accuracy: 0.7562\n",
      "Saving ...\n",
      "\n",
      "Epoch 98:\n",
      "Training loss: 1.0098, Training accuracy: 0.7598\n",
      "Validation loss: 1.2723, Validation accuracy: 0.7479\n",
      "\n",
      "Epoch 99:\n",
      "Training loss: 1.0097, Training accuracy: 0.7618\n",
      "Validation loss: 1.3255, Validation accuracy: 0.7549\n",
      "\n",
      "Epoch 100:\n",
      "Training loss: 1.0097, Training accuracy: 0.7618\n",
      "Validation loss: 1.1576, Validation accuracy: 0.7552\n",
      "\n",
      "Epoch 101:\n",
      "Training loss: 1.0096, Training accuracy: 0.7637\n",
      "Validation loss: 1.1612, Validation accuracy: 0.7573\n",
      "Saving ...\n",
      "\n",
      "Epoch 102:\n",
      "Training loss: 1.0097, Training accuracy: 0.7590\n",
      "Validation loss: 1.2532, Validation accuracy: 0.7408\n",
      "\n",
      "Epoch 103:\n",
      "Training loss: 1.0098, Training accuracy: 0.7604\n",
      "Validation loss: 1.2129, Validation accuracy: 0.7506\n",
      "\n",
      "Epoch 104:\n",
      "Training loss: 1.0095, Training accuracy: 0.7639\n",
      "Validation loss: 1.2333, Validation accuracy: 0.7593\n",
      "Saving ...\n",
      "\n",
      "Epoch 105:\n",
      "Training loss: 1.0094, Training accuracy: 0.7644\n",
      "Validation loss: 1.1711, Validation accuracy: 0.7549\n",
      "\n",
      "Epoch 106:\n",
      "Training loss: 1.0095, Training accuracy: 0.7628\n",
      "Validation loss: 1.1542, Validation accuracy: 0.7553\n",
      "\n",
      "Epoch 107:\n",
      "Training loss: 1.0095, Training accuracy: 0.7635\n",
      "Validation loss: 1.2326, Validation accuracy: 0.7500\n",
      "\n",
      "Epoch 108:\n",
      "Training loss: 1.0094, Training accuracy: 0.7651\n",
      "Validation loss: 1.2150, Validation accuracy: 0.7534\n",
      "\n",
      "Epoch 109:\n",
      "Training loss: 1.0093, Training accuracy: 0.7672\n",
      "Validation loss: 1.0923, Validation accuracy: 0.7635\n",
      "Saving ...\n",
      "\n",
      "Epoch 110:\n",
      "Training loss: 1.0094, Training accuracy: 0.7635\n",
      "Validation loss: 1.1637, Validation accuracy: 0.7590\n",
      "\n",
      "Epoch 111:\n",
      "Training loss: 1.0092, Training accuracy: 0.7680\n",
      "Validation loss: 1.2789, Validation accuracy: 0.7502\n",
      "\n",
      "Epoch 112:\n",
      "Training loss: 1.0091, Training accuracy: 0.7671\n",
      "Validation loss: 1.1799, Validation accuracy: 0.7614\n",
      "\n",
      "Epoch 113:\n",
      "Training loss: 1.0093, Training accuracy: 0.7693\n",
      "Validation loss: 1.0684, Validation accuracy: 0.7632\n",
      "\n",
      "Epoch 114:\n",
      "Training loss: 1.0089, Training accuracy: 0.7711\n",
      "Validation loss: 1.1214, Validation accuracy: 0.7649\n",
      "Saving ...\n",
      "\n",
      "Epoch 115:\n",
      "Training loss: 1.0091, Training accuracy: 0.7688\n",
      "Validation loss: 1.1839, Validation accuracy: 0.7584\n",
      "\n",
      "Epoch 116:\n",
      "Training loss: 1.0090, Training accuracy: 0.7688\n",
      "Validation loss: 1.2024, Validation accuracy: 0.7617\n",
      "\n",
      "Epoch 117:\n",
      "Training loss: 1.0089, Training accuracy: 0.7692\n",
      "Validation loss: 1.1290, Validation accuracy: 0.7641\n",
      "\n",
      "Epoch 118:\n",
      "Training loss: 1.0089, Training accuracy: 0.7703\n",
      "Validation loss: 1.1870, Validation accuracy: 0.7594\n",
      "\n",
      "Epoch 119:\n",
      "Training loss: 1.0088, Training accuracy: 0.7711\n",
      "Validation loss: 1.3013, Validation accuracy: 0.7516\n",
      "\n",
      "Epoch 120:\n",
      "Training loss: 1.0089, Training accuracy: 0.7686\n",
      "Validation loss: 1.1457, Validation accuracy: 0.7632\n",
      "\n",
      "Epoch 121:\n",
      "Training loss: 1.0086, Training accuracy: 0.7748\n",
      "Validation loss: 1.2173, Validation accuracy: 0.7581\n",
      "\n",
      "Epoch 122:\n",
      "Training loss: 1.0089, Training accuracy: 0.7726\n",
      "Validation loss: 1.1447, Validation accuracy: 0.7592\n",
      "\n",
      "Epoch 123:\n",
      "Training loss: 1.0086, Training accuracy: 0.7710\n",
      "Validation loss: 1.1351, Validation accuracy: 0.7648\n",
      "\n",
      "Epoch 124:\n",
      "Training loss: 1.0087, Training accuracy: 0.7710\n",
      "Validation loss: 1.1285, Validation accuracy: 0.7554\n",
      "\n",
      "Epoch 125:\n",
      "Training loss: 1.0087, Training accuracy: 0.7731\n",
      "Validation loss: 1.1065, Validation accuracy: 0.7647\n",
      "\n",
      "Epoch 126:\n",
      "Training loss: 1.0085, Training accuracy: 0.7778\n",
      "Validation loss: 1.1313, Validation accuracy: 0.7649\n",
      "\n",
      "Epoch 127:\n",
      "Training loss: 1.0085, Training accuracy: 0.7739\n",
      "Validation loss: 1.1100, Validation accuracy: 0.7690\n",
      "Saving ...\n",
      "\n",
      "Epoch 128:\n",
      "Training loss: 1.0085, Training accuracy: 0.7776\n",
      "Validation loss: 1.0814, Validation accuracy: 0.7684\n",
      "\n",
      "Epoch 129:\n",
      "Training loss: 1.0085, Training accuracy: 0.7753\n",
      "Validation loss: 1.0755, Validation accuracy: 0.7714\n",
      "Saving ...\n",
      "\n",
      "Epoch 130:\n",
      "Training loss: 1.0085, Training accuracy: 0.7728\n",
      "Validation loss: 1.1854, Validation accuracy: 0.7594\n",
      "\n",
      "Epoch 131:\n",
      "Training loss: 1.0083, Training accuracy: 0.7759\n",
      "Validation loss: 1.1244, Validation accuracy: 0.7720\n",
      "Saving ...\n",
      "\n",
      "Epoch 132:\n",
      "Training loss: 1.0084, Training accuracy: 0.7741\n",
      "Validation loss: 1.1226, Validation accuracy: 0.7661\n",
      "\n",
      "Epoch 133:\n",
      "Training loss: 1.0084, Training accuracy: 0.7740\n",
      "Validation loss: 1.2274, Validation accuracy: 0.7621\n",
      "\n",
      "Epoch 134:\n",
      "Training loss: 1.0084, Training accuracy: 0.7778\n",
      "Validation loss: 1.1596, Validation accuracy: 0.7656\n",
      "\n",
      "Epoch 135:\n",
      "Training loss: 1.0084, Training accuracy: 0.7766\n",
      "Validation loss: 1.2869, Validation accuracy: 0.7621\n",
      "\n",
      "Epoch 136:\n",
      "Training loss: 1.0085, Training accuracy: 0.7757\n",
      "Validation loss: 1.2069, Validation accuracy: 0.7492\n",
      "\n",
      "Epoch 137:\n",
      "Training loss: 1.0083, Training accuracy: 0.7779\n",
      "Validation loss: 1.0855, Validation accuracy: 0.7726\n",
      "Saving ...\n",
      "\n",
      "Epoch 138:\n",
      "Training loss: 1.0082, Training accuracy: 0.7779\n",
      "Validation loss: 1.2198, Validation accuracy: 0.7719\n",
      "\n",
      "Epoch 139:\n",
      "Training loss: 1.0082, Training accuracy: 0.7768\n",
      "Validation loss: 1.2427, Validation accuracy: 0.7583\n",
      "\n",
      "Epoch 140:\n",
      "Training loss: 1.0082, Training accuracy: 0.7769\n",
      "Validation loss: 1.1659, Validation accuracy: 0.7702\n",
      "\n",
      "Epoch 141:\n",
      "Training loss: 1.0083, Training accuracy: 0.7744\n",
      "Validation loss: 1.1724, Validation accuracy: 0.7702\n",
      "\n",
      "Epoch 142:\n",
      "Training loss: 1.0082, Training accuracy: 0.7808\n",
      "Validation loss: 1.1861, Validation accuracy: 0.7646\n",
      "\n",
      "Epoch 143:\n",
      "Training loss: 1.0081, Training accuracy: 0.7789\n",
      "Validation loss: 1.1545, Validation accuracy: 0.7708\n",
      "\n",
      "Epoch 144:\n",
      "Training loss: 1.0081, Training accuracy: 0.7764\n",
      "Validation loss: 1.1211, Validation accuracy: 0.7654\n",
      "\n",
      "Epoch 145:\n",
      "Training loss: 1.0080, Training accuracy: 0.7823\n",
      "Validation loss: 1.1714, Validation accuracy: 0.7705\n",
      "\n",
      "Epoch 146:\n",
      "Training loss: 1.0081, Training accuracy: 0.7805\n",
      "Validation loss: 1.2486, Validation accuracy: 0.7532\n",
      "\n",
      "Epoch 147:\n",
      "Training loss: 1.0080, Training accuracy: 0.7781\n",
      "Validation loss: 1.3338, Validation accuracy: 0.7550\n",
      "\n",
      "Epoch 148:\n",
      "Training loss: 1.0080, Training accuracy: 0.7817\n",
      "Validation loss: 1.0734, Validation accuracy: 0.7753\n",
      "Saving ...\n",
      "\n",
      "Epoch 149:\n",
      "Training loss: 1.0079, Training accuracy: 0.7833\n",
      "Validation loss: 1.1049, Validation accuracy: 0.7664\n",
      "\n",
      "Epoch 150:\n",
      "Training loss: 1.0080, Training accuracy: 0.7785\n",
      "Validation loss: 1.1805, Validation accuracy: 0.7654\n",
      "\n",
      "Epoch 151:\n",
      "Training loss: 1.0081, Training accuracy: 0.7798\n",
      "Validation loss: 1.0918, Validation accuracy: 0.7750\n",
      "\n",
      "Epoch 152:\n",
      "Training loss: 1.0079, Training accuracy: 0.7821\n",
      "Validation loss: 1.1676, Validation accuracy: 0.7653\n",
      "\n",
      "Epoch 153:\n",
      "Training loss: 1.0078, Training accuracy: 0.7797\n",
      "Validation loss: 1.1347, Validation accuracy: 0.7702\n",
      "\n",
      "Epoch 154:\n",
      "Training loss: 1.0078, Training accuracy: 0.7822\n",
      "Validation loss: 1.0821, Validation accuracy: 0.7776\n",
      "Saving ...\n",
      "\n",
      "Epoch 155:\n",
      "Training loss: 1.0078, Training accuracy: 0.7808\n",
      "Validation loss: 1.2183, Validation accuracy: 0.7666\n",
      "\n",
      "Epoch 156:\n",
      "Training loss: 1.0078, Training accuracy: 0.7821\n",
      "Validation loss: 1.1028, Validation accuracy: 0.7724\n",
      "\n",
      "Epoch 157:\n",
      "Training loss: 1.0076, Training accuracy: 0.7825\n",
      "Validation loss: 1.0914, Validation accuracy: 0.7764\n",
      "\n",
      "Epoch 158:\n",
      "Training loss: 1.0077, Training accuracy: 0.7821\n",
      "Validation loss: 1.1227, Validation accuracy: 0.7637\n",
      "\n",
      "Epoch 159:\n",
      "Training loss: 1.0076, Training accuracy: 0.7826\n",
      "Validation loss: 1.1602, Validation accuracy: 0.7666\n",
      "\n",
      "Epoch 160:\n",
      "Training loss: 1.0079, Training accuracy: 0.7765\n",
      "Validation loss: 1.1496, Validation accuracy: 0.7672\n",
      "\n",
      "Epoch 161:\n",
      "Training loss: 1.0076, Training accuracy: 0.7821\n",
      "Validation loss: 1.2465, Validation accuracy: 0.7672\n",
      "\n",
      "Epoch 162:\n",
      "Training loss: 1.0077, Training accuracy: 0.7830\n",
      "Validation loss: 1.1992, Validation accuracy: 0.7597\n",
      "\n",
      "Epoch 163:\n",
      "Training loss: 1.0076, Training accuracy: 0.7818\n",
      "Validation loss: 1.2188, Validation accuracy: 0.7648\n",
      "\n",
      "Epoch 164:\n",
      "Training loss: 1.0076, Training accuracy: 0.7851\n",
      "Validation loss: 1.1406, Validation accuracy: 0.7790\n",
      "Saving ...\n",
      "\n",
      "Epoch 165:\n",
      "Training loss: 1.0074, Training accuracy: 0.7854\n",
      "Validation loss: 1.0872, Validation accuracy: 0.7761\n",
      "\n",
      "Epoch 166:\n",
      "Training loss: 1.0075, Training accuracy: 0.7875\n",
      "Validation loss: 1.2029, Validation accuracy: 0.7712\n",
      "\n",
      "Epoch 167:\n",
      "Training loss: 1.0076, Training accuracy: 0.7839\n",
      "Validation loss: 1.2178, Validation accuracy: 0.7685\n",
      "\n",
      "Epoch 168:\n",
      "Training loss: 1.0074, Training accuracy: 0.7853\n",
      "Validation loss: 1.0810, Validation accuracy: 0.7744\n",
      "\n",
      "Epoch 169:\n",
      "Training loss: 1.0075, Training accuracy: 0.7846\n",
      "Validation loss: 1.0981, Validation accuracy: 0.7750\n",
      "\n",
      "Epoch 170:\n",
      "Training loss: 1.0075, Training accuracy: 0.7845\n",
      "Validation loss: 1.0931, Validation accuracy: 0.7774\n",
      "\n",
      "Epoch 171:\n",
      "Training loss: 1.0074, Training accuracy: 0.7877\n",
      "Validation loss: 1.1017, Validation accuracy: 0.7781\n",
      "\n",
      "Epoch 172:\n",
      "Training loss: 1.0073, Training accuracy: 0.7881\n",
      "Validation loss: 1.1758, Validation accuracy: 0.7589\n",
      "\n",
      "Epoch 173:\n",
      "Training loss: 1.0074, Training accuracy: 0.7838\n",
      "Validation loss: 1.1207, Validation accuracy: 0.7755\n",
      "\n",
      "Epoch 174:\n",
      "Training loss: 1.0072, Training accuracy: 0.7880\n",
      "Validation loss: 1.0642, Validation accuracy: 0.7806\n",
      "Saving ...\n",
      "\n",
      "Epoch 175:\n",
      "Training loss: 1.0073, Training accuracy: 0.7878\n",
      "Validation loss: 1.0404, Validation accuracy: 0.7795\n",
      "\n",
      "Epoch 176:\n",
      "Training loss: 1.0073, Training accuracy: 0.7884\n",
      "Validation loss: 1.0976, Validation accuracy: 0.7763\n",
      "\n",
      "Epoch 177:\n",
      "Training loss: 1.0072, Training accuracy: 0.7880\n",
      "Validation loss: 1.0650, Validation accuracy: 0.7784\n",
      "\n",
      "Epoch 178:\n",
      "Training loss: 1.0072, Training accuracy: 0.7907\n",
      "Validation loss: 1.0552, Validation accuracy: 0.7789\n",
      "\n",
      "Epoch 179:\n",
      "Training loss: 1.0072, Training accuracy: 0.7866\n",
      "Validation loss: 1.0583, Validation accuracy: 0.7770\n",
      "\n",
      "Epoch 180:\n",
      "Training loss: 1.0073, Training accuracy: 0.7860\n",
      "Validation loss: 1.1892, Validation accuracy: 0.7593\n",
      "\n",
      "Epoch 181:\n",
      "Training loss: 1.0072, Training accuracy: 0.7862\n",
      "Validation loss: 1.0904, Validation accuracy: 0.7865\n",
      "Saving ...\n",
      "\n",
      "Epoch 182:\n",
      "Training loss: 1.0072, Training accuracy: 0.7865\n",
      "Validation loss: 1.0700, Validation accuracy: 0.7766\n",
      "\n",
      "Epoch 183:\n",
      "Training loss: 1.0073, Training accuracy: 0.7850\n",
      "Validation loss: 1.1096, Validation accuracy: 0.7699\n",
      "\n",
      "Epoch 184:\n",
      "Training loss: 1.0072, Training accuracy: 0.7879\n",
      "Validation loss: 1.0813, Validation accuracy: 0.7773\n",
      "\n",
      "Epoch 185:\n",
      "Training loss: 1.0072, Training accuracy: 0.7870\n",
      "Validation loss: 1.0785, Validation accuracy: 0.7841\n",
      "\n",
      "Epoch 186:\n",
      "Training loss: 1.0072, Training accuracy: 0.7870\n",
      "Validation loss: 1.0964, Validation accuracy: 0.7859\n",
      "\n",
      "Epoch 187:\n",
      "Training loss: 1.0070, Training accuracy: 0.7904\n",
      "Validation loss: 1.1467, Validation accuracy: 0.7728\n",
      "\n",
      "Epoch 188:\n",
      "Training loss: 1.0071, Training accuracy: 0.7877\n",
      "Validation loss: 1.0848, Validation accuracy: 0.7763\n",
      "\n",
      "Epoch 189:\n",
      "Training loss: 1.0069, Training accuracy: 0.7909\n",
      "Validation loss: 1.0878, Validation accuracy: 0.7721\n",
      "\n",
      "Epoch 190:\n",
      "Training loss: 1.0070, Training accuracy: 0.7880\n",
      "Validation loss: 1.0728, Validation accuracy: 0.7803\n",
      "\n",
      "Epoch 191:\n",
      "Training loss: 1.0070, Training accuracy: 0.7894\n",
      "Validation loss: 1.0895, Validation accuracy: 0.7768\n",
      "\n",
      "Epoch 192:\n",
      "Training loss: 1.0070, Training accuracy: 0.7939\n",
      "Validation loss: 1.0774, Validation accuracy: 0.7802\n",
      "\n",
      "Epoch 193:\n",
      "Training loss: 1.0070, Training accuracy: 0.7925\n",
      "Validation loss: 1.1074, Validation accuracy: 0.7821\n",
      "\n",
      "Epoch 194:\n",
      "Training loss: 1.0071, Training accuracy: 0.7895\n",
      "Validation loss: 1.0434, Validation accuracy: 0.7775\n",
      "\n",
      "Epoch 195:\n",
      "Training loss: 1.0072, Training accuracy: 0.7864\n",
      "Validation loss: 1.2826, Validation accuracy: 0.7558\n",
      "\n",
      "Epoch 196:\n",
      "Training loss: 1.0070, Training accuracy: 0.7866\n",
      "Validation loss: 1.2630, Validation accuracy: 0.7721\n",
      "\n",
      "Epoch 197:\n",
      "Training loss: 1.0070, Training accuracy: 0.7896\n",
      "Validation loss: 1.1226, Validation accuracy: 0.7730\n",
      "\n",
      "Epoch 198:\n",
      "Training loss: 1.0069, Training accuracy: 0.7898\n",
      "Validation loss: 1.0734, Validation accuracy: 0.7828\n",
      "\n",
      "Epoch 199:\n",
      "Training loss: 1.0070, Training accuracy: 0.7850\n",
      "Validation loss: 1.1473, Validation accuracy: 0.7806\n",
      "\n",
      "==================================================\n",
      "==> Optimization finished! Best validation accuracy: 0.7865\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7865"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train(student,teacher,optimizer,criterion,1,[0,1,0],1,train_loader,val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Training starts!\n",
      "==================================================\n",
      "Epoch 0:\n",
      "Training loss: 5.0655, Training accuracy: 0.3171\n",
      "Validation loss: 4.0881, Validation accuracy: 0.3150\n",
      "Saving ...\n",
      "\n",
      "Epoch 1:\n",
      "Training loss: 4.7682, Training accuracy: 0.3813\n",
      "Validation loss: 4.2499, Validation accuracy: 0.3694\n",
      "Saving ...\n",
      "\n",
      "Epoch 2:\n",
      "Training loss: 4.6991, Training accuracy: 0.4147\n",
      "Validation loss: 4.2745, Validation accuracy: 0.4280\n",
      "Saving ...\n",
      "\n",
      "Epoch 3:\n",
      "Training loss: 4.6682, Training accuracy: 0.4336\n",
      "Validation loss: 4.3875, Validation accuracy: 0.4478\n",
      "Saving ...\n",
      "\n",
      "Epoch 4:\n",
      "Training loss: 4.6359, Training accuracy: 0.4529\n",
      "Validation loss: 4.1668, Validation accuracy: 0.4612\n",
      "Saving ...\n",
      "\n",
      "Epoch 5:\n",
      "Training loss: 4.6100, Training accuracy: 0.4739\n",
      "Validation loss: 3.6246, Validation accuracy: 0.4742\n",
      "Saving ...\n",
      "\n",
      "Epoch 6:\n",
      "Training loss: 4.5862, Training accuracy: 0.4881\n",
      "Validation loss: 3.5046, Validation accuracy: 0.4818\n",
      "Saving ...\n",
      "\n",
      "Epoch 7:\n",
      "Training loss: 4.5630, Training accuracy: 0.4977\n",
      "Validation loss: 3.2782, Validation accuracy: 0.4993\n",
      "Saving ...\n",
      "\n",
      "Epoch 8:\n",
      "Training loss: 4.5468, Training accuracy: 0.5027\n",
      "Validation loss: 3.7131, Validation accuracy: 0.5144\n",
      "Saving ...\n",
      "\n",
      "Epoch 9:\n",
      "Training loss: 4.5304, Training accuracy: 0.5118\n",
      "Validation loss: 3.4569, Validation accuracy: 0.5097\n",
      "\n",
      "Epoch 10:\n",
      "Training loss: 4.5167, Training accuracy: 0.5175\n",
      "Validation loss: 3.3116, Validation accuracy: 0.5286\n",
      "Saving ...\n",
      "\n",
      "Epoch 11:\n",
      "Training loss: 4.5029, Training accuracy: 0.5225\n",
      "Validation loss: 3.5595, Validation accuracy: 0.4927\n",
      "\n",
      "Epoch 12:\n",
      "Training loss: 4.4926, Training accuracy: 0.5238\n",
      "Validation loss: 3.1306, Validation accuracy: 0.5243\n",
      "\n",
      "Epoch 13:\n",
      "Training loss: 4.4840, Training accuracy: 0.5300\n",
      "Validation loss: 3.2264, Validation accuracy: 0.5397\n",
      "Saving ...\n",
      "\n",
      "Epoch 14:\n",
      "Training loss: 4.4757, Training accuracy: 0.5359\n",
      "Validation loss: 3.1278, Validation accuracy: 0.5462\n",
      "Saving ...\n",
      "\n",
      "Epoch 15:\n",
      "Training loss: 4.4696, Training accuracy: 0.5316\n",
      "Validation loss: 3.4042, Validation accuracy: 0.5414\n",
      "\n",
      "Epoch 16:\n",
      "Training loss: 4.4583, Training accuracy: 0.5394\n",
      "Validation loss: 3.3865, Validation accuracy: 0.5349\n",
      "\n",
      "Epoch 17:\n",
      "Training loss: 4.4556, Training accuracy: 0.5425\n",
      "Validation loss: 3.6193, Validation accuracy: 0.5223\n",
      "\n",
      "Epoch 18:\n",
      "Training loss: 4.4495, Training accuracy: 0.5412\n",
      "Validation loss: 3.2482, Validation accuracy: 0.5649\n",
      "Saving ...\n",
      "\n",
      "Epoch 19:\n",
      "Training loss: 4.4439, Training accuracy: 0.5439\n",
      "Validation loss: 3.5767, Validation accuracy: 0.5434\n",
      "\n",
      "Epoch 20:\n",
      "Training loss: 4.4404, Training accuracy: 0.5464\n",
      "Validation loss: 3.6874, Validation accuracy: 0.5706\n",
      "Saving ...\n",
      "\n",
      "Epoch 21:\n",
      "Training loss: 4.4358, Training accuracy: 0.5523\n",
      "Validation loss: 3.5745, Validation accuracy: 0.5624\n",
      "\n",
      "Epoch 22:\n",
      "Training loss: 4.4296, Training accuracy: 0.5511\n",
      "Validation loss: 3.2603, Validation accuracy: 0.5586\n",
      "\n",
      "Epoch 23:\n",
      "Training loss: 4.4251, Training accuracy: 0.5522\n",
      "Validation loss: 3.1778, Validation accuracy: 0.5718\n",
      "Saving ...\n",
      "\n",
      "Epoch 24:\n",
      "Training loss: 4.4234, Training accuracy: 0.5534\n",
      "Validation loss: 3.2590, Validation accuracy: 0.5863\n",
      "Saving ...\n",
      "\n",
      "Epoch 25:\n",
      "Training loss: 4.4153, Training accuracy: 0.5607\n",
      "Validation loss: 3.5975, Validation accuracy: 0.5631\n",
      "\n",
      "Epoch 26:\n",
      "Training loss: 4.4112, Training accuracy: 0.5595\n",
      "Validation loss: 3.7664, Validation accuracy: 0.5817\n",
      "\n",
      "Epoch 27:\n",
      "Training loss: 4.4060, Training accuracy: 0.5646\n",
      "Validation loss: 4.2914, Validation accuracy: 0.5488\n",
      "\n",
      "Epoch 28:\n",
      "Training loss: 4.4039, Training accuracy: 0.5630\n",
      "Validation loss: 3.4631, Validation accuracy: 0.5673\n",
      "\n",
      "Epoch 29:\n",
      "Training loss: 4.3987, Training accuracy: 0.5661\n",
      "Validation loss: 4.0786, Validation accuracy: 0.5685\n",
      "\n",
      "Epoch 30:\n",
      "Training loss: 4.3953, Training accuracy: 0.5639\n",
      "Validation loss: 3.3358, Validation accuracy: 0.5390\n",
      "\n",
      "Epoch 31:\n",
      "Training loss: 4.3869, Training accuracy: 0.5664\n",
      "Validation loss: 3.0802, Validation accuracy: 0.5783\n",
      "\n",
      "Epoch 32:\n",
      "Training loss: 4.3812, Training accuracy: 0.5683\n",
      "Validation loss: 2.7313, Validation accuracy: 0.6003\n",
      "Saving ...\n",
      "\n",
      "Epoch 33:\n",
      "Training loss: 4.3730, Training accuracy: 0.5733\n",
      "Validation loss: 2.9086, Validation accuracy: 0.5909\n",
      "\n",
      "Epoch 34:\n",
      "Training loss: 4.3662, Training accuracy: 0.5737\n",
      "Validation loss: 2.8610, Validation accuracy: 0.5718\n",
      "\n",
      "Epoch 35:\n",
      "Training loss: 4.3588, Training accuracy: 0.5735\n",
      "Validation loss: 2.8928, Validation accuracy: 0.6044\n",
      "Saving ...\n",
      "\n",
      "Epoch 36:\n",
      "Training loss: 4.3506, Training accuracy: 0.5728\n",
      "Validation loss: 2.8276, Validation accuracy: 0.6032\n",
      "\n",
      "Epoch 37:\n",
      "Training loss: 4.3446, Training accuracy: 0.5765\n",
      "Validation loss: 2.9932, Validation accuracy: 0.6092\n",
      "Saving ...\n",
      "\n",
      "Epoch 38:\n",
      "Training loss: 4.3357, Training accuracy: 0.5877\n",
      "Validation loss: 2.7258, Validation accuracy: 0.6042\n",
      "\n",
      "Epoch 39:\n",
      "Training loss: 4.3270, Training accuracy: 0.5815\n",
      "Validation loss: 3.5272, Validation accuracy: 0.6046\n",
      "\n",
      "Epoch 40:\n",
      "Training loss: 4.3216, Training accuracy: 0.5793\n",
      "Validation loss: 2.8196, Validation accuracy: 0.6158\n",
      "Saving ...\n",
      "\n",
      "Epoch 41:\n",
      "Training loss: 4.3177, Training accuracy: 0.5813\n",
      "Validation loss: 2.6262, Validation accuracy: 0.5866\n",
      "\n",
      "Epoch 42:\n",
      "Training loss: 4.3104, Training accuracy: 0.5841\n",
      "Validation loss: 2.8283, Validation accuracy: 0.6030\n",
      "\n",
      "Epoch 43:\n",
      "Training loss: 4.3074, Training accuracy: 0.5891\n",
      "Validation loss: 2.5786, Validation accuracy: 0.6057\n",
      "\n",
      "Epoch 44:\n",
      "Training loss: 4.3071, Training accuracy: 0.5901\n",
      "Validation loss: 3.0218, Validation accuracy: 0.6032\n",
      "\n",
      "Epoch 45:\n",
      "Training loss: 4.3070, Training accuracy: 0.5871\n",
      "Validation loss: 3.1347, Validation accuracy: 0.6069\n",
      "\n",
      "Epoch 46:\n",
      "Training loss: 4.3041, Training accuracy: 0.5939\n",
      "Validation loss: 3.5739, Validation accuracy: 0.5954\n",
      "\n",
      "Epoch 47:\n",
      "Training loss: 4.3027, Training accuracy: 0.5925\n",
      "Validation loss: 3.1247, Validation accuracy: 0.6052\n",
      "\n",
      "Epoch 48:\n",
      "Training loss: 4.3017, Training accuracy: 0.5926\n",
      "Validation loss: 2.9908, Validation accuracy: 0.6129\n",
      "\n",
      "Epoch 49:\n",
      "Training loss: 4.3004, Training accuracy: 0.5928\n",
      "Validation loss: 3.6827, Validation accuracy: 0.5769\n",
      "\n",
      "Epoch 50:\n",
      "Training loss: 4.2977, Training accuracy: 0.5989\n",
      "Validation loss: 3.1786, Validation accuracy: 0.6036\n",
      "\n",
      "Epoch 51:\n",
      "Training loss: 4.2998, Training accuracy: 0.5933\n",
      "Validation loss: 3.3467, Validation accuracy: 0.6189\n",
      "Saving ...\n",
      "\n",
      "Epoch 52:\n",
      "Training loss: 4.2961, Training accuracy: 0.5925\n",
      "Validation loss: 3.0248, Validation accuracy: 0.5899\n",
      "\n",
      "Epoch 53:\n",
      "Training loss: 4.2957, Training accuracy: 0.5995\n",
      "Validation loss: 3.4656, Validation accuracy: 0.5936\n",
      "\n",
      "Epoch 54:\n",
      "Training loss: 4.2951, Training accuracy: 0.5983\n",
      "Validation loss: 3.0404, Validation accuracy: 0.6147\n",
      "\n",
      "Epoch 55:\n",
      "Training loss: 4.2931, Training accuracy: 0.5986\n",
      "Validation loss: 3.0396, Validation accuracy: 0.6188\n",
      "\n",
      "Epoch 56:\n",
      "Training loss: 4.2925, Training accuracy: 0.6000\n",
      "Validation loss: 3.0992, Validation accuracy: 0.6096\n",
      "\n",
      "Epoch 57:\n",
      "Training loss: 4.2919, Training accuracy: 0.6012\n",
      "Validation loss: 3.3918, Validation accuracy: 0.6039\n",
      "\n",
      "Epoch 58:\n",
      "Training loss: 4.2911, Training accuracy: 0.6019\n",
      "Validation loss: 2.8580, Validation accuracy: 0.6192\n",
      "Saving ...\n",
      "\n",
      "Epoch 59:\n",
      "Training loss: 4.2917, Training accuracy: 0.5926\n",
      "Validation loss: 3.0688, Validation accuracy: 0.5780\n",
      "\n",
      "Epoch 60:\n",
      "Training loss: 4.2895, Training accuracy: 0.6001\n",
      "Validation loss: 2.9584, Validation accuracy: 0.6277\n",
      "Saving ...\n",
      "\n",
      "Epoch 61:\n",
      "Training loss: 4.2875, Training accuracy: 0.6009\n",
      "Validation loss: 3.1792, Validation accuracy: 0.6313\n",
      "Saving ...\n",
      "\n",
      "Epoch 62:\n",
      "Training loss: 4.2869, Training accuracy: 0.6039\n",
      "Validation loss: 3.0786, Validation accuracy: 0.5984\n",
      "\n",
      "Epoch 63:\n",
      "Training loss: 4.2858, Training accuracy: 0.6007\n",
      "Validation loss: 2.9877, Validation accuracy: 0.6241\n",
      "\n",
      "Epoch 64:\n",
      "Training loss: 4.2857, Training accuracy: 0.5987\n",
      "Validation loss: 3.8157, Validation accuracy: 0.6233\n",
      "\n",
      "Epoch 65:\n",
      "Training loss: 4.2845, Training accuracy: 0.5957\n",
      "Validation loss: 2.9036, Validation accuracy: 0.6194\n",
      "\n",
      "Epoch 66:\n",
      "Training loss: 4.2825, Training accuracy: 0.6054\n",
      "Validation loss: 3.3517, Validation accuracy: 0.6395\n",
      "Saving ...\n",
      "\n",
      "Epoch 67:\n",
      "Training loss: 4.2821, Training accuracy: 0.6055\n",
      "Validation loss: 2.8543, Validation accuracy: 0.6344\n",
      "\n",
      "Epoch 68:\n",
      "Training loss: 4.2826, Training accuracy: 0.6045\n",
      "Validation loss: 2.9691, Validation accuracy: 0.6116\n",
      "\n",
      "Epoch 69:\n",
      "Training loss: 4.2814, Training accuracy: 0.6050\n",
      "Validation loss: 3.8410, Validation accuracy: 0.6308\n",
      "\n",
      "Epoch 70:\n",
      "Training loss: 4.2798, Training accuracy: 0.6068\n",
      "Validation loss: 2.8487, Validation accuracy: 0.6166\n",
      "\n",
      "Epoch 71:\n",
      "Training loss: 4.2792, Training accuracy: 0.6102\n",
      "Validation loss: 2.8413, Validation accuracy: 0.6324\n",
      "\n",
      "Epoch 72:\n",
      "Training loss: 4.2773, Training accuracy: 0.6102\n",
      "Validation loss: 3.2499, Validation accuracy: 0.6296\n",
      "\n",
      "Epoch 73:\n",
      "Training loss: 4.2774, Training accuracy: 0.6118\n",
      "Validation loss: 3.9626, Validation accuracy: 0.6307\n",
      "\n",
      "Epoch 74:\n",
      "Training loss: 4.2778, Training accuracy: 0.6016\n",
      "Validation loss: 2.9963, Validation accuracy: 0.6334\n",
      "\n",
      "Epoch 75:\n",
      "Training loss: 4.2748, Training accuracy: 0.6113\n",
      "Validation loss: 3.1838, Validation accuracy: 0.6240\n",
      "\n",
      "Epoch 76:\n",
      "Training loss: 4.2754, Training accuracy: 0.6067\n",
      "Validation loss: 4.3995, Validation accuracy: 0.5941\n",
      "\n",
      "Epoch 77:\n",
      "Training loss: 4.2728, Training accuracy: 0.6137\n",
      "Validation loss: 3.0389, Validation accuracy: 0.6456\n",
      "Saving ...\n",
      "\n",
      "Epoch 78:\n",
      "Training loss: 4.2721, Training accuracy: 0.6138\n",
      "Validation loss: 3.1158, Validation accuracy: 0.6265\n",
      "\n",
      "Epoch 79:\n",
      "Training loss: 4.2720, Training accuracy: 0.6101\n",
      "Validation loss: 2.9517, Validation accuracy: 0.6119\n",
      "\n",
      "Epoch 80:\n",
      "Training loss: 4.2712, Training accuracy: 0.6053\n",
      "Validation loss: 2.9029, Validation accuracy: 0.6233\n",
      "\n",
      "Epoch 81:\n",
      "Training loss: 4.2691, Training accuracy: 0.6120\n",
      "Validation loss: 2.7499, Validation accuracy: 0.6421\n",
      "\n",
      "Epoch 82:\n",
      "Training loss: 4.2665, Training accuracy: 0.6143\n",
      "Validation loss: 2.6839, Validation accuracy: 0.6346\n",
      "\n",
      "Epoch 83:\n",
      "Training loss: 4.2662, Training accuracy: 0.6108\n",
      "Validation loss: 2.5380, Validation accuracy: 0.6452\n",
      "\n",
      "Epoch 84:\n",
      "Training loss: 4.2657, Training accuracy: 0.6070\n",
      "Validation loss: 3.9745, Validation accuracy: 0.6141\n",
      "\n",
      "Epoch 85:\n",
      "Training loss: 4.2650, Training accuracy: 0.6050\n",
      "Validation loss: 2.5803, Validation accuracy: 0.6369\n",
      "\n",
      "Epoch 86:\n",
      "Training loss: 4.2623, Training accuracy: 0.6090\n",
      "Validation loss: 3.3658, Validation accuracy: 0.6422\n",
      "\n",
      "Epoch 87:\n",
      "Training loss: 4.2647, Training accuracy: 0.6051\n",
      "Validation loss: 2.4903, Validation accuracy: 0.6250\n",
      "\n",
      "Epoch 88:\n",
      "Training loss: 4.2628, Training accuracy: 0.6012\n",
      "Validation loss: 3.9124, Validation accuracy: 0.6329\n",
      "\n",
      "Epoch 89:\n",
      "Training loss: 4.2602, Training accuracy: 0.6135\n",
      "Validation loss: 3.0599, Validation accuracy: 0.6133\n",
      "\n",
      "Epoch 90:\n",
      "Training loss: 4.2598, Training accuracy: 0.6055\n",
      "Validation loss: 3.4649, Validation accuracy: 0.5801\n",
      "\n",
      "Epoch 91:\n",
      "Training loss: 4.2576, Training accuracy: 0.6144\n",
      "Validation loss: 3.5420, Validation accuracy: 0.6118\n",
      "\n",
      "Epoch 92:\n",
      "Training loss: 4.2570, Training accuracy: 0.6134\n",
      "Validation loss: 2.7361, Validation accuracy: 0.6242\n",
      "\n",
      "Epoch 93:\n",
      "Training loss: 4.2575, Training accuracy: 0.6155\n",
      "Validation loss: 2.7770, Validation accuracy: 0.6487\n",
      "Saving ...\n",
      "\n",
      "Epoch 94:\n",
      "Training loss: 4.2583, Training accuracy: 0.6143\n",
      "Validation loss: 2.8438, Validation accuracy: 0.6213\n",
      "\n",
      "Epoch 95:\n",
      "Training loss: 4.2563, Training accuracy: 0.6167\n",
      "Validation loss: 2.6710, Validation accuracy: 0.6498\n",
      "Saving ...\n",
      "\n",
      "Epoch 96:\n",
      "Training loss: 4.2560, Training accuracy: 0.6146\n",
      "Validation loss: 2.7008, Validation accuracy: 0.6493\n",
      "\n",
      "Epoch 97:\n",
      "Training loss: 4.2564, Training accuracy: 0.6141\n",
      "Validation loss: 3.1763, Validation accuracy: 0.6528\n",
      "Saving ...\n",
      "\n",
      "Epoch 98:\n",
      "Training loss: 4.2562, Training accuracy: 0.6173\n",
      "Validation loss: 2.8715, Validation accuracy: 0.6456\n",
      "\n",
      "Epoch 99:\n",
      "Training loss: 4.2542, Training accuracy: 0.6187\n",
      "Validation loss: 3.2603, Validation accuracy: 0.6468\n",
      "\n",
      "Epoch 100:\n",
      "Training loss: 4.2543, Training accuracy: 0.6165\n",
      "Validation loss: 3.9210, Validation accuracy: 0.6367\n",
      "\n",
      "Epoch 101:\n",
      "Training loss: 4.2567, Training accuracy: 0.6095\n",
      "Validation loss: 3.0389, Validation accuracy: 0.6136\n",
      "\n",
      "Epoch 102:\n",
      "Training loss: 4.2542, Training accuracy: 0.6208\n",
      "Validation loss: 2.7384, Validation accuracy: 0.6303\n",
      "\n",
      "Epoch 103:\n",
      "Training loss: 4.2544, Training accuracy: 0.6155\n",
      "Validation loss: 3.3473, Validation accuracy: 0.5931\n",
      "\n",
      "Epoch 104:\n",
      "Training loss: 4.2534, Training accuracy: 0.6216\n",
      "Validation loss: 2.6636, Validation accuracy: 0.6402\n",
      "\n",
      "Epoch 105:\n",
      "Training loss: 4.2547, Training accuracy: 0.6184\n",
      "Validation loss: 3.5249, Validation accuracy: 0.6310\n",
      "\n",
      "Epoch 106:\n",
      "Training loss: 4.2531, Training accuracy: 0.6193\n",
      "Validation loss: 3.2907, Validation accuracy: 0.6249\n",
      "\n",
      "Epoch 107:\n",
      "Training loss: 4.2532, Training accuracy: 0.6192\n",
      "Validation loss: 3.4229, Validation accuracy: 0.6417\n",
      "\n",
      "Epoch 108:\n",
      "Training loss: 4.2535, Training accuracy: 0.6210\n",
      "Validation loss: 4.4370, Validation accuracy: 0.6279\n",
      "\n",
      "Epoch 109:\n",
      "Training loss: 4.2523, Training accuracy: 0.6181\n",
      "Validation loss: 2.7646, Validation accuracy: 0.6521\n",
      "\n",
      "Epoch 110:\n",
      "Training loss: 4.2509, Training accuracy: 0.6189\n",
      "Validation loss: 3.0981, Validation accuracy: 0.6521\n",
      "\n",
      "Epoch 111:\n",
      "Training loss: 4.2521, Training accuracy: 0.6192\n",
      "Validation loss: 2.9243, Validation accuracy: 0.6426\n",
      "\n",
      "Epoch 112:\n",
      "Training loss: 4.2520, Training accuracy: 0.6216\n",
      "Validation loss: 3.5923, Validation accuracy: 0.6091\n",
      "\n",
      "Epoch 113:\n",
      "Training loss: 4.2517, Training accuracy: 0.6177\n",
      "Validation loss: 3.2304, Validation accuracy: 0.6503\n",
      "\n",
      "Epoch 114:\n",
      "Training loss: 4.2501, Training accuracy: 0.6240\n",
      "Validation loss: 3.2422, Validation accuracy: 0.6351\n",
      "\n",
      "Epoch 115:\n",
      "Training loss: 4.2514, Training accuracy: 0.6214\n",
      "Validation loss: 3.6329, Validation accuracy: 0.6415\n",
      "\n",
      "Epoch 116:\n",
      "Training loss: 4.2502, Training accuracy: 0.6233\n",
      "Validation loss: 2.8207, Validation accuracy: 0.6623\n",
      "Saving ...\n",
      "\n",
      "Epoch 117:\n",
      "Training loss: 4.2494, Training accuracy: 0.6253\n",
      "Validation loss: 2.8894, Validation accuracy: 0.6619\n",
      "\n",
      "Epoch 118:\n",
      "Training loss: 4.2494, Training accuracy: 0.6243\n",
      "Validation loss: 3.2172, Validation accuracy: 0.6415\n",
      "\n",
      "Epoch 119:\n",
      "Training loss: 4.2483, Training accuracy: 0.6267\n",
      "Validation loss: 2.7727, Validation accuracy: 0.6481\n",
      "\n",
      "Epoch 120:\n",
      "Training loss: 4.2501, Training accuracy: 0.6228\n",
      "Validation loss: 2.9787, Validation accuracy: 0.6441\n",
      "\n",
      "Epoch 121:\n",
      "Training loss: 4.2479, Training accuracy: 0.6279\n",
      "Validation loss: 3.1813, Validation accuracy: 0.6529\n",
      "\n",
      "Epoch 122:\n",
      "Training loss: 4.2490, Training accuracy: 0.6234\n",
      "Validation loss: 2.9694, Validation accuracy: 0.6275\n",
      "\n",
      "Epoch 123:\n",
      "Training loss: 4.2466, Training accuracy: 0.6261\n",
      "Validation loss: 2.8413, Validation accuracy: 0.6449\n",
      "\n",
      "Epoch 124:\n",
      "Training loss: 4.2480, Training accuracy: 0.6291\n",
      "Validation loss: 3.0158, Validation accuracy: 0.6273\n",
      "\n",
      "Epoch 125:\n",
      "Training loss: 4.2468, Training accuracy: 0.6300\n",
      "Validation loss: 3.5937, Validation accuracy: 0.5955\n",
      "\n",
      "Epoch 126:\n",
      "Training loss: 4.2470, Training accuracy: 0.6255\n",
      "Validation loss: 4.2704, Validation accuracy: 0.6003\n",
      "\n",
      "Epoch 127:\n",
      "Training loss: 4.2469, Training accuracy: 0.6249\n",
      "Validation loss: 2.6283, Validation accuracy: 0.6420\n",
      "\n",
      "Epoch 128:\n",
      "Training loss: 4.2482, Training accuracy: 0.6225\n",
      "Validation loss: 4.5053, Validation accuracy: 0.6435\n",
      "\n",
      "Epoch 129:\n",
      "Training loss: 4.2482, Training accuracy: 0.6223\n",
      "Validation loss: 3.5258, Validation accuracy: 0.6490\n",
      "\n",
      "Epoch 130:\n",
      "Training loss: 4.2470, Training accuracy: 0.6292\n",
      "Validation loss: 2.8901, Validation accuracy: 0.6562\n",
      "\n",
      "Epoch 131:\n",
      "Training loss: 4.2479, Training accuracy: 0.6266\n",
      "Validation loss: 2.7443, Validation accuracy: 0.6553\n",
      "\n",
      "Epoch 132:\n",
      "Training loss: 4.2464, Training accuracy: 0.6236\n",
      "Validation loss: 3.2250, Validation accuracy: 0.6293\n",
      "\n",
      "Epoch 133:\n",
      "Training loss: 4.2463, Training accuracy: 0.6280\n",
      "Validation loss: 3.1745, Validation accuracy: 0.5954\n",
      "\n",
      "Epoch 134:\n",
      "Training loss: 4.2449, Training accuracy: 0.6291\n",
      "Validation loss: 3.3351, Validation accuracy: 0.6599\n",
      "\n",
      "Epoch 135:\n",
      "Training loss: 4.2467, Training accuracy: 0.6291\n",
      "Validation loss: 2.9096, Validation accuracy: 0.6561\n",
      "\n",
      "Epoch 136:\n",
      "Training loss: 4.2460, Training accuracy: 0.6300\n",
      "Validation loss: 3.0823, Validation accuracy: 0.6568\n",
      "\n",
      "Epoch 137:\n",
      "Training loss: 4.2445, Training accuracy: 0.6262\n",
      "Validation loss: 2.8273, Validation accuracy: 0.6609\n",
      "\n",
      "Epoch 138:\n",
      "Training loss: 4.2453, Training accuracy: 0.6307\n",
      "Validation loss: 3.1176, Validation accuracy: 0.6127\n",
      "\n",
      "Epoch 139:\n",
      "Training loss: 4.2434, Training accuracy: 0.6321\n",
      "Validation loss: 2.6581, Validation accuracy: 0.6634\n",
      "Saving ...\n",
      "\n",
      "Epoch 140:\n",
      "Training loss: 4.2436, Training accuracy: 0.6324\n",
      "Validation loss: 2.8115, Validation accuracy: 0.6659\n",
      "Saving ...\n",
      "\n",
      "Epoch 141:\n",
      "Training loss: 4.2442, Training accuracy: 0.6363\n",
      "Validation loss: 2.5042, Validation accuracy: 0.6116\n",
      "\n",
      "Epoch 142:\n",
      "Training loss: 4.2437, Training accuracy: 0.6315\n",
      "Validation loss: 3.2655, Validation accuracy: 0.6469\n",
      "\n",
      "Epoch 143:\n",
      "Training loss: 4.2441, Training accuracy: 0.6260\n",
      "Validation loss: 3.0753, Validation accuracy: 0.6587\n",
      "\n",
      "Epoch 144:\n",
      "Training loss: 4.2437, Training accuracy: 0.6350\n",
      "Validation loss: 3.6023, Validation accuracy: 0.6555\n",
      "\n",
      "Epoch 145:\n",
      "Training loss: 4.2443, Training accuracy: 0.6313\n",
      "Validation loss: 2.9043, Validation accuracy: 0.6635\n",
      "\n",
      "Epoch 146:\n",
      "Training loss: 4.2434, Training accuracy: 0.6344\n",
      "Validation loss: 3.2058, Validation accuracy: 0.6338\n",
      "\n",
      "Epoch 147:\n",
      "Training loss: 4.2426, Training accuracy: 0.6292\n",
      "Validation loss: 3.2541, Validation accuracy: 0.6516\n",
      "\n",
      "Epoch 148:\n",
      "Training loss: 4.2429, Training accuracy: 0.6384\n",
      "Validation loss: 3.2894, Validation accuracy: 0.6649\n",
      "\n",
      "Epoch 149:\n",
      "Training loss: 4.2424, Training accuracy: 0.6344\n",
      "Validation loss: 2.7150, Validation accuracy: 0.6587\n",
      "\n",
      "Epoch 150:\n",
      "Training loss: 4.2424, Training accuracy: 0.6364\n",
      "Validation loss: 3.2111, Validation accuracy: 0.6489\n",
      "\n",
      "Epoch 151:\n",
      "Training loss: 4.2428, Training accuracy: 0.6315\n",
      "Validation loss: 2.9075, Validation accuracy: 0.6550\n",
      "\n",
      "Epoch 152:\n",
      "Training loss: 4.2418, Training accuracy: 0.6409\n",
      "Validation loss: 2.9133, Validation accuracy: 0.6700\n",
      "Saving ...\n",
      "\n",
      "Epoch 153:\n",
      "Training loss: 4.2408, Training accuracy: 0.6397\n",
      "Validation loss: 3.7765, Validation accuracy: 0.6490\n",
      "\n",
      "Epoch 154:\n",
      "Training loss: 4.2421, Training accuracy: 0.6362\n",
      "Validation loss: 3.3323, Validation accuracy: 0.6168\n",
      "\n",
      "Epoch 155:\n",
      "Training loss: 4.2415, Training accuracy: 0.6349\n",
      "Validation loss: 2.9424, Validation accuracy: 0.6454\n",
      "\n",
      "Epoch 156:\n",
      "Training loss: 4.2423, Training accuracy: 0.6309\n",
      "Validation loss: 3.4470, Validation accuracy: 0.5816\n",
      "\n",
      "Epoch 157:\n",
      "Training loss: 4.2412, Training accuracy: 0.6330\n",
      "Validation loss: 3.1886, Validation accuracy: 0.6599\n",
      "\n",
      "Epoch 158:\n",
      "Training loss: 4.2425, Training accuracy: 0.6359\n",
      "Validation loss: 3.1115, Validation accuracy: 0.6544\n",
      "\n",
      "Epoch 159:\n",
      "Training loss: 4.2412, Training accuracy: 0.6329\n",
      "Validation loss: 3.1525, Validation accuracy: 0.6656\n",
      "\n",
      "Epoch 160:\n",
      "Training loss: 4.2407, Training accuracy: 0.6340\n",
      "Validation loss: 2.9687, Validation accuracy: 0.6771\n",
      "Saving ...\n",
      "\n",
      "Epoch 161:\n",
      "Training loss: 4.2404, Training accuracy: 0.6366\n",
      "Validation loss: 2.9704, Validation accuracy: 0.6690\n",
      "\n",
      "Epoch 162:\n",
      "Training loss: 4.2398, Training accuracy: 0.6363\n",
      "Validation loss: 2.9101, Validation accuracy: 0.6730\n",
      "\n",
      "Epoch 163:\n",
      "Training loss: 4.2419, Training accuracy: 0.6361\n",
      "Validation loss: 2.6651, Validation accuracy: 0.6590\n",
      "\n",
      "Epoch 164:\n",
      "Training loss: 4.2400, Training accuracy: 0.6411\n",
      "Validation loss: 3.0165, Validation accuracy: 0.6152\n",
      "\n",
      "Epoch 165:\n",
      "Training loss: 4.2419, Training accuracy: 0.6274\n",
      "Validation loss: 3.1919, Validation accuracy: 0.6228\n",
      "\n",
      "Epoch 166:\n",
      "Training loss: 4.2400, Training accuracy: 0.6360\n",
      "Validation loss: 2.8294, Validation accuracy: 0.6496\n",
      "\n",
      "Epoch 167:\n",
      "Training loss: 4.2401, Training accuracy: 0.6368\n",
      "Validation loss: 3.1404, Validation accuracy: 0.6531\n",
      "\n",
      "Epoch 168:\n",
      "Training loss: 4.2394, Training accuracy: 0.6348\n",
      "Validation loss: 4.0034, Validation accuracy: 0.6577\n",
      "\n",
      "Epoch 169:\n",
      "Training loss: 4.2401, Training accuracy: 0.6378\n",
      "Validation loss: 3.2519, Validation accuracy: 0.6072\n",
      "\n",
      "Epoch 170:\n",
      "Training loss: 4.2395, Training accuracy: 0.6352\n",
      "Validation loss: 2.8107, Validation accuracy: 0.6549\n",
      "\n",
      "Epoch 171:\n",
      "Training loss: 4.2396, Training accuracy: 0.6374\n",
      "Validation loss: 3.1495, Validation accuracy: 0.6557\n",
      "\n",
      "Epoch 172:\n",
      "Training loss: 4.2387, Training accuracy: 0.6361\n",
      "Validation loss: 3.2890, Validation accuracy: 0.6408\n",
      "\n",
      "Epoch 173:\n",
      "Training loss: 4.2387, Training accuracy: 0.6389\n",
      "Validation loss: 3.0995, Validation accuracy: 0.6732\n",
      "\n",
      "Epoch 174:\n",
      "Training loss: 4.2403, Training accuracy: 0.6346\n",
      "Validation loss: 2.8459, Validation accuracy: 0.6282\n",
      "\n",
      "Epoch 175:\n",
      "Training loss: 4.2394, Training accuracy: 0.6400\n",
      "Validation loss: 2.9338, Validation accuracy: 0.6512\n",
      "\n",
      "Epoch 176:\n",
      "Training loss: 4.2409, Training accuracy: 0.6279\n",
      "Validation loss: 3.0194, Validation accuracy: 0.6266\n",
      "\n",
      "Epoch 177:\n",
      "Training loss: 4.2388, Training accuracy: 0.6316\n",
      "Validation loss: 3.1555, Validation accuracy: 0.6577\n",
      "\n",
      "Epoch 178:\n",
      "Training loss: 4.2384, Training accuracy: 0.6351\n",
      "Validation loss: 3.5880, Validation accuracy: 0.6153\n",
      "\n",
      "Epoch 179:\n",
      "Training loss: 4.2393, Training accuracy: 0.6365\n",
      "Validation loss: 3.3372, Validation accuracy: 0.6303\n",
      "\n",
      "Epoch 180:\n",
      "Training loss: 4.2387, Training accuracy: 0.6302\n",
      "Validation loss: 2.8170, Validation accuracy: 0.6551\n",
      "\n",
      "Epoch 181:\n",
      "Training loss: 4.2384, Training accuracy: 0.6385\n",
      "Validation loss: 2.7531, Validation accuracy: 0.6513\n",
      "\n",
      "Epoch 182:\n",
      "Training loss: 4.2380, Training accuracy: 0.6351\n",
      "Validation loss: 3.7242, Validation accuracy: 0.6217\n",
      "\n",
      "Epoch 183:\n",
      "Training loss: 4.2383, Training accuracy: 0.6280\n",
      "Validation loss: 2.7765, Validation accuracy: 0.6631\n",
      "\n",
      "Epoch 184:\n",
      "Training loss: 4.2370, Training accuracy: 0.6383\n",
      "Validation loss: 2.8379, Validation accuracy: 0.6640\n",
      "\n",
      "Epoch 185:\n",
      "Training loss: 4.2377, Training accuracy: 0.6392\n",
      "Validation loss: 2.8105, Validation accuracy: 0.6660\n",
      "\n",
      "Epoch 186:\n",
      "Training loss: 4.2364, Training accuracy: 0.6414\n",
      "Validation loss: 2.7677, Validation accuracy: 0.6738\n",
      "\n",
      "Epoch 187:\n",
      "Training loss: 4.2363, Training accuracy: 0.6410\n",
      "Validation loss: 2.6625, Validation accuracy: 0.6694\n",
      "\n",
      "Epoch 188:\n",
      "Training loss: 4.2375, Training accuracy: 0.6383\n",
      "Validation loss: 3.3453, Validation accuracy: 0.6206\n",
      "\n",
      "Epoch 189:\n",
      "Training loss: 4.2371, Training accuracy: 0.6382\n",
      "Validation loss: 2.2609, Validation accuracy: 0.6728\n",
      "\n",
      "Epoch 190:\n",
      "Training loss: 4.2366, Training accuracy: 0.6385\n",
      "Validation loss: 3.1692, Validation accuracy: 0.6170\n",
      "\n",
      "Epoch 191:\n",
      "Training loss: 4.2363, Training accuracy: 0.6420\n",
      "Validation loss: 2.9155, Validation accuracy: 0.6764\n",
      "\n",
      "Epoch 192:\n",
      "Training loss: 4.2360, Training accuracy: 0.6386\n",
      "Validation loss: 3.1442, Validation accuracy: 0.6620\n",
      "\n",
      "Epoch 193:\n",
      "Training loss: 4.2354, Training accuracy: 0.6420\n",
      "Validation loss: 3.3857, Validation accuracy: 0.6225\n",
      "\n",
      "Epoch 194:\n",
      "Training loss: 4.2369, Training accuracy: 0.6379\n",
      "Validation loss: 2.6558, Validation accuracy: 0.6587\n",
      "\n",
      "Epoch 195:\n",
      "Training loss: 4.2365, Training accuracy: 0.6392\n",
      "Validation loss: 2.7095, Validation accuracy: 0.6753\n",
      "\n",
      "Epoch 196:\n",
      "Training loss: 4.2353, Training accuracy: 0.6384\n",
      "Validation loss: 2.9661, Validation accuracy: 0.6602\n",
      "\n",
      "Epoch 197:\n",
      "Training loss: 4.2359, Training accuracy: 0.6366\n",
      "Validation loss: 2.9685, Validation accuracy: 0.6706\n",
      "\n",
      "Epoch 198:\n",
      "Training loss: 4.2357, Training accuracy: 0.6411\n",
      "Validation loss: 2.8889, Validation accuracy: 0.6714\n",
      "\n",
      "Epoch 199:\n",
      "Training loss: 4.2348, Training accuracy: 0.6455\n",
      "Validation loss: 2.9454, Validation accuracy: 0.6751\n",
      "\n",
      "==================================================\n",
      "==> Optimization finished! Best validation accuracy: 0.6771\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6771"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train(student,teacher,optimizer,criterion,2,[0,1,0],1,train_loader,val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Training starts!\n",
      "==================================================\n",
      "Epoch 0:\n",
      "Training loss: 25.6500, Training accuracy: 0.2139\n",
      "Validation loss: 5.0232, Validation accuracy: 0.1875\n",
      "Saving ...\n",
      "\n",
      "Epoch 1:\n",
      "Training loss: 23.9535, Training accuracy: 0.2259\n",
      "Validation loss: 6.6620, Validation accuracy: 0.2895\n",
      "Saving ...\n",
      "\n",
      "Epoch 2:\n",
      "Training loss: 23.5759, Training accuracy: 0.2528\n",
      "Validation loss: 11.0997, Validation accuracy: 0.2514\n",
      "\n",
      "Epoch 3:\n",
      "Training loss: 23.3857, Training accuracy: 0.2690\n",
      "Validation loss: 11.6303, Validation accuracy: 0.2634\n",
      "\n",
      "Epoch 4:\n",
      "Training loss: 23.2681, Training accuracy: 0.2833\n",
      "Validation loss: 14.3683, Validation accuracy: 0.2860\n",
      "\n",
      "Epoch 5:\n",
      "Training loss: 23.1979, Training accuracy: 0.2923\n",
      "Validation loss: 18.2550, Validation accuracy: 0.2955\n",
      "Saving ...\n",
      "\n",
      "Epoch 6:\n",
      "Training loss: 23.1366, Training accuracy: 0.2923\n",
      "Validation loss: 16.1116, Validation accuracy: 0.3010\n",
      "Saving ...\n",
      "\n",
      "Epoch 7:\n",
      "Training loss: 23.0790, Training accuracy: 0.3015\n",
      "Validation loss: 16.5622, Validation accuracy: 0.2586\n",
      "\n",
      "Epoch 8:\n",
      "Training loss: 23.0470, Training accuracy: 0.3003\n",
      "Validation loss: 18.8804, Validation accuracy: 0.3035\n",
      "Saving ...\n",
      "\n",
      "Epoch 9:\n",
      "Training loss: 23.0173, Training accuracy: 0.3067\n",
      "Validation loss: 16.0276, Validation accuracy: 0.3086\n",
      "Saving ...\n",
      "\n",
      "Epoch 10:\n",
      "Training loss: 23.0012, Training accuracy: 0.3157\n",
      "Validation loss: 22.1675, Validation accuracy: 0.3034\n",
      "\n",
      "Epoch 11:\n",
      "Training loss: 22.9700, Training accuracy: 0.3236\n",
      "Validation loss: 23.6857, Validation accuracy: 0.2983\n",
      "\n",
      "Epoch 12:\n",
      "Training loss: 22.9461, Training accuracy: 0.3246\n",
      "Validation loss: 18.2831, Validation accuracy: 0.3127\n",
      "Saving ...\n",
      "\n",
      "Epoch 13:\n",
      "Training loss: 22.9093, Training accuracy: 0.3365\n",
      "Validation loss: 19.6854, Validation accuracy: 0.3000\n",
      "\n",
      "Epoch 14:\n",
      "Training loss: 22.9059, Training accuracy: 0.3371\n",
      "Validation loss: 19.8256, Validation accuracy: 0.3365\n",
      "Saving ...\n",
      "\n",
      "Epoch 15:\n",
      "Training loss: 22.8911, Training accuracy: 0.3432\n",
      "Validation loss: 20.9421, Validation accuracy: 0.3305\n",
      "\n",
      "Epoch 16:\n",
      "Training loss: 22.8830, Training accuracy: 0.3348\n",
      "Validation loss: 22.3719, Validation accuracy: 0.3365\n",
      "\n",
      "Epoch 17:\n",
      "Training loss: 22.8691, Training accuracy: 0.3459\n",
      "Validation loss: 32.0546, Validation accuracy: 0.3118\n",
      "\n",
      "Epoch 18:\n",
      "Training loss: 22.8690, Training accuracy: 0.3429\n",
      "Validation loss: 23.8379, Validation accuracy: 0.3550\n",
      "Saving ...\n",
      "\n",
      "Epoch 19:\n",
      "Training loss: 22.8506, Training accuracy: 0.3425\n",
      "Validation loss: 23.5199, Validation accuracy: 0.3145\n",
      "\n",
      "Epoch 20:\n",
      "Training loss: 22.8391, Training accuracy: 0.3480\n",
      "Validation loss: 28.5748, Validation accuracy: 0.3101\n",
      "\n",
      "Epoch 21:\n",
      "Training loss: 22.8248, Training accuracy: 0.3506\n",
      "Validation loss: 24.3868, Validation accuracy: 0.3540\n",
      "\n",
      "Epoch 22:\n",
      "Training loss: 22.8174, Training accuracy: 0.3547\n",
      "Validation loss: 27.0164, Validation accuracy: 0.3275\n",
      "\n",
      "Epoch 23:\n",
      "Training loss: 22.8052, Training accuracy: 0.3595\n",
      "Validation loss: 25.9455, Validation accuracy: 0.3675\n",
      "Saving ...\n",
      "\n",
      "Epoch 24:\n",
      "Training loss: 22.7821, Training accuracy: 0.3586\n",
      "Validation loss: 24.4959, Validation accuracy: 0.3369\n",
      "\n",
      "Epoch 25:\n",
      "Training loss: 22.7919, Training accuracy: 0.3601\n",
      "Validation loss: 24.5248, Validation accuracy: 0.3524\n",
      "\n",
      "Epoch 26:\n",
      "Training loss: 22.7847, Training accuracy: 0.3624\n",
      "Validation loss: 23.8296, Validation accuracy: 0.3684\n",
      "Saving ...\n",
      "\n",
      "Epoch 27:\n",
      "Training loss: 22.7840, Training accuracy: 0.3545\n",
      "Validation loss: 29.1556, Validation accuracy: 0.3162\n",
      "\n",
      "Epoch 28:\n",
      "Training loss: 22.7880, Training accuracy: 0.3531\n",
      "Validation loss: 30.0878, Validation accuracy: 0.3215\n",
      "\n",
      "Epoch 29:\n",
      "Training loss: 22.7664, Training accuracy: 0.3598\n",
      "Validation loss: 29.2241, Validation accuracy: 0.3387\n",
      "\n",
      "Epoch 30:\n",
      "Training loss: 22.7648, Training accuracy: 0.3609\n",
      "Validation loss: 24.5111, Validation accuracy: 0.3688\n",
      "Saving ...\n",
      "\n",
      "Epoch 31:\n",
      "Training loss: 22.7662, Training accuracy: 0.3624\n",
      "Validation loss: 28.1669, Validation accuracy: 0.3554\n",
      "\n",
      "Epoch 32:\n",
      "Training loss: 22.7382, Training accuracy: 0.3678\n",
      "Validation loss: 29.3144, Validation accuracy: 0.3313\n",
      "\n",
      "Epoch 33:\n",
      "Training loss: 22.7496, Training accuracy: 0.3621\n",
      "Validation loss: 26.8109, Validation accuracy: 0.3590\n",
      "\n",
      "Epoch 34:\n",
      "Training loss: 22.7434, Training accuracy: 0.3641\n",
      "Validation loss: 33.1808, Validation accuracy: 0.3487\n",
      "\n",
      "Epoch 35:\n",
      "Training loss: 22.7492, Training accuracy: 0.3634\n",
      "Validation loss: 26.2101, Validation accuracy: 0.3495\n",
      "\n",
      "Epoch 36:\n",
      "Training loss: 22.7265, Training accuracy: 0.3663\n",
      "Validation loss: 29.1630, Validation accuracy: 0.3714\n",
      "Saving ...\n",
      "\n",
      "Epoch 37:\n",
      "Training loss: 22.7240, Training accuracy: 0.3645\n",
      "Validation loss: 28.7011, Validation accuracy: 0.3619\n",
      "\n",
      "Epoch 38:\n",
      "Training loss: 22.7060, Training accuracy: 0.3642\n",
      "Validation loss: 28.8832, Validation accuracy: 0.3782\n",
      "Saving ...\n",
      "\n",
      "Epoch 39:\n",
      "Training loss: 22.7015, Training accuracy: 0.3684\n",
      "Validation loss: 28.4291, Validation accuracy: 0.3679\n",
      "\n",
      "Epoch 40:\n",
      "Training loss: 22.7127, Training accuracy: 0.3656\n",
      "Validation loss: 44.9011, Validation accuracy: 0.3204\n",
      "\n",
      "Epoch 41:\n",
      "Training loss: 22.7069, Training accuracy: 0.3623\n",
      "Validation loss: 26.4684, Validation accuracy: 0.3526\n",
      "\n",
      "Epoch 42:\n",
      "Training loss: 22.6886, Training accuracy: 0.3696\n",
      "Validation loss: 30.1409, Validation accuracy: 0.3405\n",
      "\n",
      "Epoch 43:\n",
      "Training loss: 22.6748, Training accuracy: 0.3688\n",
      "Validation loss: 28.0087, Validation accuracy: 0.3613\n",
      "\n",
      "Epoch 44:\n",
      "Training loss: 22.6752, Training accuracy: 0.3659\n",
      "Validation loss: 28.2517, Validation accuracy: 0.3655\n",
      "\n",
      "Epoch 45:\n",
      "Training loss: 22.6606, Training accuracy: 0.3649\n",
      "Validation loss: 25.1741, Validation accuracy: 0.3425\n",
      "\n",
      "Epoch 46:\n",
      "Training loss: 22.6516, Training accuracy: 0.3691\n",
      "Validation loss: 21.2127, Validation accuracy: 0.3533\n",
      "\n",
      "Epoch 47:\n",
      "Training loss: 22.6325, Training accuracy: 0.3679\n",
      "Validation loss: 21.4612, Validation accuracy: 0.3512\n",
      "\n",
      "Epoch 48:\n",
      "Training loss: 22.5595, Training accuracy: 0.3542\n",
      "Validation loss: 15.8957, Validation accuracy: 0.3353\n",
      "\n",
      "Epoch 49:\n",
      "Training loss: 22.4168, Training accuracy: 0.3483\n",
      "Validation loss: 12.3103, Validation accuracy: 0.3383\n",
      "\n",
      "Epoch 50:\n",
      "Training loss: 22.2920, Training accuracy: 0.3341\n",
      "Validation loss: 12.9866, Validation accuracy: 0.3382\n",
      "\n",
      "Epoch 51:\n",
      "Training loss: 22.1437, Training accuracy: 0.3286\n",
      "Validation loss: 11.7881, Validation accuracy: 0.3478\n",
      "\n",
      "Epoch 52:\n",
      "Training loss: 22.0213, Training accuracy: 0.3182\n",
      "Validation loss: 14.4585, Validation accuracy: 0.2941\n",
      "\n",
      "Epoch 53:\n",
      "Training loss: 21.8809, Training accuracy: 0.3105\n",
      "Validation loss: 12.0758, Validation accuracy: 0.3091\n",
      "\n",
      "Epoch 54:\n",
      "Training loss: 21.7179, Training accuracy: 0.3073\n",
      "Validation loss: 13.3505, Validation accuracy: 0.3105\n",
      "\n",
      "Epoch 55:\n",
      "Training loss: 21.5180, Training accuracy: 0.2959\n",
      "Validation loss: 18.2405, Validation accuracy: 0.3138\n",
      "\n",
      "Epoch 56:\n",
      "Training loss: 21.2000, Training accuracy: 0.2895\n",
      "Validation loss: 16.0089, Validation accuracy: 0.3311\n",
      "\n",
      "Epoch 57:\n",
      "Training loss: 20.8242, Training accuracy: 0.2778\n",
      "Validation loss: 13.0262, Validation accuracy: 0.3354\n",
      "\n",
      "Epoch 58:\n",
      "Training loss: 20.6629, Training accuracy: 0.2882\n",
      "Validation loss: 21.3827, Validation accuracy: 0.3310\n",
      "\n",
      "Epoch 59:\n",
      "Training loss: 20.5802, Training accuracy: 0.2892\n",
      "Validation loss: 16.1564, Validation accuracy: 0.3198\n",
      "\n",
      "Epoch 60:\n",
      "Training loss: 20.5011, Training accuracy: 0.2932\n",
      "Validation loss: 21.0331, Validation accuracy: 0.3223\n",
      "\n",
      "Epoch 61:\n",
      "Training loss: 20.4439, Training accuracy: 0.2949\n",
      "Validation loss: 17.9452, Validation accuracy: 0.3450\n",
      "\n",
      "Epoch 62:\n",
      "Training loss: 20.3763, Training accuracy: 0.3005\n",
      "Validation loss: 22.7701, Validation accuracy: 0.3364\n",
      "\n",
      "Epoch 63:\n",
      "Training loss: 20.3175, Training accuracy: 0.3082\n",
      "Validation loss: 19.0805, Validation accuracy: 0.3720\n",
      "\n",
      "Epoch 64:\n",
      "Training loss: 20.2802, Training accuracy: 0.3148\n",
      "Validation loss: 15.7339, Validation accuracy: 0.3507\n",
      "\n",
      "Epoch 65:\n",
      "Training loss: 20.2402, Training accuracy: 0.3104\n",
      "Validation loss: 18.2077, Validation accuracy: 0.3486\n",
      "\n",
      "Epoch 66:\n",
      "Training loss: 20.1800, Training accuracy: 0.3186\n",
      "Validation loss: 20.3905, Validation accuracy: 0.3817\n",
      "Saving ...\n",
      "\n",
      "Epoch 67:\n",
      "Training loss: 20.1687, Training accuracy: 0.3214\n",
      "Validation loss: 21.1755, Validation accuracy: 0.3453\n",
      "\n",
      "Epoch 68:\n",
      "Training loss: 20.1213, Training accuracy: 0.3273\n",
      "Validation loss: 17.6695, Validation accuracy: 0.3795\n",
      "\n",
      "Epoch 69:\n",
      "Training loss: 20.0844, Training accuracy: 0.3385\n",
      "Validation loss: 17.2857, Validation accuracy: 0.3508\n",
      "\n",
      "Epoch 70:\n",
      "Training loss: 20.0556, Training accuracy: 0.3424\n",
      "Validation loss: 22.4066, Validation accuracy: 0.3805\n",
      "\n",
      "Epoch 71:\n",
      "Training loss: 20.0413, Training accuracy: 0.3446\n",
      "Validation loss: 18.4210, Validation accuracy: 0.3608\n",
      "\n",
      "Epoch 72:\n",
      "Training loss: 20.0199, Training accuracy: 0.3449\n",
      "Validation loss: 15.0193, Validation accuracy: 0.4078\n",
      "Saving ...\n",
      "\n",
      "Epoch 73:\n",
      "Training loss: 20.0036, Training accuracy: 0.3532\n",
      "Validation loss: 18.2414, Validation accuracy: 0.3164\n",
      "\n",
      "Epoch 74:\n",
      "Training loss: 19.9885, Training accuracy: 0.3455\n",
      "Validation loss: 19.8803, Validation accuracy: 0.3929\n",
      "\n",
      "Epoch 75:\n",
      "Training loss: 19.9802, Training accuracy: 0.3578\n",
      "Validation loss: 17.0981, Validation accuracy: 0.3407\n",
      "\n",
      "Epoch 76:\n",
      "Training loss: 19.9635, Training accuracy: 0.3544\n",
      "Validation loss: 27.2368, Validation accuracy: 0.4086\n",
      "Saving ...\n",
      "\n",
      "Epoch 77:\n",
      "Training loss: 19.9586, Training accuracy: 0.3638\n",
      "Validation loss: 23.9150, Validation accuracy: 0.4062\n",
      "\n",
      "Epoch 78:\n",
      "Training loss: 19.9469, Training accuracy: 0.3614\n",
      "Validation loss: 22.1652, Validation accuracy: 0.3784\n",
      "\n",
      "Epoch 79:\n",
      "Training loss: 19.9252, Training accuracy: 0.3643\n",
      "Validation loss: 20.1391, Validation accuracy: 0.3926\n",
      "\n",
      "Epoch 80:\n",
      "Training loss: 19.9131, Training accuracy: 0.3600\n",
      "Validation loss: 14.4461, Validation accuracy: 0.4047\n",
      "\n",
      "Epoch 81:\n",
      "Training loss: 19.9035, Training accuracy: 0.3733\n",
      "Validation loss: 25.3082, Validation accuracy: 0.4108\n",
      "Saving ...\n",
      "\n",
      "Epoch 82:\n",
      "Training loss: 19.9144, Training accuracy: 0.3575\n",
      "Validation loss: 18.7955, Validation accuracy: 0.4135\n",
      "Saving ...\n",
      "\n",
      "Epoch 83:\n",
      "Training loss: 19.8795, Training accuracy: 0.3640\n",
      "Validation loss: 21.8151, Validation accuracy: 0.4051\n",
      "\n",
      "Epoch 84:\n",
      "Training loss: 19.8596, Training accuracy: 0.3712\n",
      "Validation loss: 22.9672, Validation accuracy: 0.4066\n",
      "\n",
      "Epoch 85:\n",
      "Training loss: 19.8439, Training accuracy: 0.3803\n",
      "Validation loss: 23.5604, Validation accuracy: 0.4107\n",
      "\n",
      "Epoch 86:\n",
      "Training loss: 19.8487, Training accuracy: 0.3797\n",
      "Validation loss: 13.2555, Validation accuracy: 0.3614\n",
      "\n",
      "Epoch 87:\n",
      "Training loss: 19.8380, Training accuracy: 0.3818\n",
      "Validation loss: 16.0430, Validation accuracy: 0.3383\n",
      "\n",
      "Epoch 88:\n",
      "Training loss: 19.8361, Training accuracy: 0.3787\n",
      "Validation loss: 26.4287, Validation accuracy: 0.4062\n",
      "\n",
      "Epoch 89:\n",
      "Training loss: 19.8289, Training accuracy: 0.3771\n",
      "Validation loss: 34.5509, Validation accuracy: 0.4070\n",
      "\n",
      "Epoch 90:\n",
      "Training loss: 19.8205, Training accuracy: 0.3942\n",
      "Validation loss: 28.4949, Validation accuracy: 0.4087\n",
      "\n",
      "Epoch 91:\n",
      "Training loss: 19.8098, Training accuracy: 0.3851\n",
      "Validation loss: 28.2764, Validation accuracy: 0.4258\n",
      "Saving ...\n",
      "\n",
      "Epoch 92:\n",
      "Training loss: 19.8154, Training accuracy: 0.3854\n",
      "Validation loss: 22.9300, Validation accuracy: 0.3983\n",
      "\n",
      "Epoch 93:\n",
      "Training loss: 19.8040, Training accuracy: 0.3913\n",
      "Validation loss: 31.3529, Validation accuracy: 0.4239\n",
      "\n",
      "Epoch 94:\n",
      "Training loss: 19.7924, Training accuracy: 0.3988\n",
      "Validation loss: 21.2528, Validation accuracy: 0.3912\n",
      "\n",
      "Epoch 95:\n",
      "Training loss: 19.7792, Training accuracy: 0.3988\n",
      "Validation loss: 13.8981, Validation accuracy: 0.4187\n",
      "\n",
      "Epoch 96:\n",
      "Training loss: 19.7794, Training accuracy: 0.3953\n",
      "Validation loss: 26.6442, Validation accuracy: 0.4346\n",
      "Saving ...\n",
      "\n",
      "Epoch 97:\n",
      "Training loss: 19.7676, Training accuracy: 0.3986\n",
      "Validation loss: 19.1159, Validation accuracy: 0.4276\n",
      "\n",
      "Epoch 98:\n",
      "Training loss: 19.7590, Training accuracy: 0.3925\n",
      "Validation loss: 20.9998, Validation accuracy: 0.4293\n",
      "\n",
      "Epoch 99:\n",
      "Training loss: 19.7356, Training accuracy: 0.3903\n",
      "Validation loss: 17.4597, Validation accuracy: 0.4098\n",
      "\n",
      "Epoch 100:\n",
      "Training loss: 19.7135, Training accuracy: 0.3841\n",
      "Validation loss: 19.4650, Validation accuracy: 0.4125\n",
      "\n",
      "Epoch 101:\n",
      "Training loss: 19.6865, Training accuracy: 0.3816\n",
      "Validation loss: 20.0320, Validation accuracy: 0.3775\n",
      "\n",
      "Epoch 102:\n",
      "Training loss: 19.6603, Training accuracy: 0.3788\n",
      "Validation loss: 17.2650, Validation accuracy: 0.3493\n",
      "\n",
      "Epoch 103:\n",
      "Training loss: 19.6219, Training accuracy: 0.3833\n",
      "Validation loss: 14.8893, Validation accuracy: 0.3818\n",
      "\n",
      "Epoch 104:\n",
      "Training loss: 19.5904, Training accuracy: 0.3774\n",
      "Validation loss: 15.2604, Validation accuracy: 0.3577\n",
      "\n",
      "Epoch 105:\n",
      "Training loss: 19.5755, Training accuracy: 0.3758\n",
      "Validation loss: 17.7278, Validation accuracy: 0.3543\n",
      "\n",
      "Epoch 106:\n",
      "Training loss: 19.5533, Training accuracy: 0.3743\n",
      "Validation loss: 15.7125, Validation accuracy: 0.4085\n",
      "\n",
      "Epoch 107:\n",
      "Training loss: 19.5303, Training accuracy: 0.3715\n",
      "Validation loss: 12.1835, Validation accuracy: 0.3792\n",
      "\n",
      "Epoch 108:\n",
      "Training loss: 19.5041, Training accuracy: 0.3633\n",
      "Validation loss: 15.2987, Validation accuracy: 0.4065\n",
      "\n",
      "Epoch 109:\n",
      "Training loss: 19.4715, Training accuracy: 0.3615\n",
      "Validation loss: 15.2390, Validation accuracy: 0.3567\n",
      "\n",
      "Epoch 110:\n",
      "Training loss: 19.4566, Training accuracy: 0.3693\n",
      "Validation loss: 13.1663, Validation accuracy: 0.4125\n",
      "\n",
      "Epoch 111:\n",
      "Training loss: 19.4397, Training accuracy: 0.3737\n",
      "Validation loss: 12.1003, Validation accuracy: 0.3666\n",
      "\n",
      "Epoch 112:\n",
      "Training loss: 19.4295, Training accuracy: 0.3735\n",
      "Validation loss: 11.1278, Validation accuracy: 0.3527\n",
      "\n",
      "Epoch 113:\n",
      "Training loss: 19.4180, Training accuracy: 0.3672\n",
      "Validation loss: 12.2413, Validation accuracy: 0.3931\n",
      "\n",
      "Epoch 114:\n",
      "Training loss: 19.3960, Training accuracy: 0.3681\n",
      "Validation loss: 12.5918, Validation accuracy: 0.4328\n",
      "\n",
      "Epoch 115:\n",
      "Training loss: 19.3784, Training accuracy: 0.3646\n",
      "Validation loss: 14.0124, Validation accuracy: 0.3550\n",
      "\n",
      "Epoch 116:\n",
      "Training loss: 19.3554, Training accuracy: 0.3627\n",
      "Validation loss: 10.4096, Validation accuracy: 0.4269\n",
      "\n",
      "Epoch 117:\n",
      "Training loss: 19.3151, Training accuracy: 0.3635\n",
      "Validation loss: 11.0731, Validation accuracy: 0.3602\n",
      "\n",
      "Epoch 118:\n",
      "Training loss: 19.2793, Training accuracy: 0.3627\n",
      "Validation loss: 14.1638, Validation accuracy: 0.3347\n",
      "\n",
      "Epoch 119:\n",
      "Training loss: 19.2722, Training accuracy: 0.3642\n",
      "Validation loss: 9.6444, Validation accuracy: 0.3369\n",
      "\n",
      "Epoch 120:\n",
      "Training loss: 19.2719, Training accuracy: 0.3653\n",
      "Validation loss: 11.5270, Validation accuracy: 0.3984\n",
      "\n",
      "Epoch 121:\n",
      "Training loss: 19.2625, Training accuracy: 0.3672\n",
      "Validation loss: 12.4322, Validation accuracy: 0.3857\n",
      "\n",
      "Epoch 122:\n",
      "Training loss: 19.2536, Training accuracy: 0.3722\n",
      "Validation loss: 13.0423, Validation accuracy: 0.3635\n",
      "\n",
      "Epoch 123:\n",
      "Training loss: 19.2448, Training accuracy: 0.3695\n",
      "Validation loss: 12.6050, Validation accuracy: 0.3621\n",
      "\n",
      "Epoch 124:\n",
      "Training loss: 19.2431, Training accuracy: 0.3728\n",
      "Validation loss: 9.8443, Validation accuracy: 0.3997\n",
      "\n",
      "Epoch 125:\n",
      "Training loss: 19.2406, Training accuracy: 0.3712\n",
      "Validation loss: 10.3478, Validation accuracy: 0.3795\n",
      "\n",
      "Epoch 126:\n",
      "Training loss: 19.2353, Training accuracy: 0.3690\n",
      "Validation loss: 10.8721, Validation accuracy: 0.4055\n",
      "\n",
      "Epoch 127:\n",
      "Training loss: 19.2234, Training accuracy: 0.3742\n",
      "Validation loss: 12.5101, Validation accuracy: 0.3608\n",
      "\n",
      "Epoch 128:\n",
      "Training loss: 19.2193, Training accuracy: 0.3741\n",
      "Validation loss: 14.2271, Validation accuracy: 0.3608\n",
      "\n",
      "Epoch 129:\n",
      "Training loss: 19.2140, Training accuracy: 0.3781\n",
      "Validation loss: 12.5388, Validation accuracy: 0.3702\n",
      "\n",
      "Epoch 130:\n",
      "Training loss: 19.2174, Training accuracy: 0.3746\n",
      "Validation loss: 13.1166, Validation accuracy: 0.3433\n",
      "\n",
      "Epoch 131:\n",
      "Training loss: 19.2062, Training accuracy: 0.3811\n",
      "Validation loss: 9.3556, Validation accuracy: 0.3895\n",
      "\n",
      "Epoch 132:\n",
      "Training loss: 19.2054, Training accuracy: 0.3775\n",
      "Validation loss: 11.1291, Validation accuracy: 0.3891\n",
      "\n",
      "Epoch 133:\n",
      "Training loss: 19.2022, Training accuracy: 0.3746\n",
      "Validation loss: 10.5390, Validation accuracy: 0.3322\n",
      "\n",
      "Epoch 134:\n",
      "Training loss: 19.1934, Training accuracy: 0.3750\n",
      "Validation loss: 11.8843, Validation accuracy: 0.3838\n",
      "\n",
      "Epoch 135:\n",
      "Training loss: 19.1864, Training accuracy: 0.3835\n",
      "Validation loss: 10.8034, Validation accuracy: 0.3927\n",
      "\n",
      "Epoch 136:\n",
      "Training loss: 19.1836, Training accuracy: 0.3812\n",
      "Validation loss: 9.6267, Validation accuracy: 0.4323\n",
      "\n",
      "Epoch 137:\n",
      "Training loss: 19.1860, Training accuracy: 0.3782\n",
      "Validation loss: 10.0807, Validation accuracy: 0.4163\n",
      "\n",
      "Epoch 138:\n",
      "Training loss: 19.1865, Training accuracy: 0.3764\n",
      "Validation loss: 10.0371, Validation accuracy: 0.3815\n",
      "\n",
      "Epoch 139:\n",
      "Training loss: 19.1777, Training accuracy: 0.3864\n",
      "Validation loss: 9.9667, Validation accuracy: 0.3842\n",
      "\n",
      "Epoch 140:\n",
      "Training loss: 19.1788, Training accuracy: 0.3829\n",
      "Validation loss: 10.7229, Validation accuracy: 0.3263\n",
      "\n",
      "Epoch 141:\n",
      "Training loss: 19.1646, Training accuracy: 0.3823\n",
      "Validation loss: 8.7773, Validation accuracy: 0.4238\n",
      "\n",
      "Epoch 142:\n",
      "Training loss: 19.1684, Training accuracy: 0.3822\n",
      "Validation loss: 10.7703, Validation accuracy: 0.4124\n",
      "\n",
      "Epoch 143:\n",
      "Training loss: 19.1646, Training accuracy: 0.3803\n",
      "Validation loss: 9.7363, Validation accuracy: 0.3541\n",
      "\n",
      "Epoch 144:\n",
      "Training loss: 19.1605, Training accuracy: 0.3880\n",
      "Validation loss: 11.4450, Validation accuracy: 0.3524\n",
      "\n",
      "Epoch 145:\n",
      "Training loss: 19.1524, Training accuracy: 0.3942\n",
      "Validation loss: 9.9250, Validation accuracy: 0.3516\n",
      "\n",
      "Epoch 146:\n",
      "Training loss: 19.1600, Training accuracy: 0.3853\n",
      "Validation loss: 8.2867, Validation accuracy: 0.3687\n",
      "\n",
      "Epoch 147:\n",
      "Training loss: 19.1515, Training accuracy: 0.3835\n",
      "Validation loss: 10.3155, Validation accuracy: 0.4360\n",
      "Saving ...\n",
      "\n",
      "Epoch 148:\n",
      "Training loss: 19.1549, Training accuracy: 0.3815\n",
      "Validation loss: 10.5736, Validation accuracy: 0.4368\n",
      "Saving ...\n",
      "\n",
      "Epoch 149:\n",
      "Training loss: 19.1449, Training accuracy: 0.3895\n",
      "Validation loss: 12.6076, Validation accuracy: 0.4019\n",
      "\n",
      "Epoch 150:\n",
      "Training loss: 19.1418, Training accuracy: 0.3858\n",
      "Validation loss: 11.1047, Validation accuracy: 0.3985\n",
      "\n",
      "Epoch 151:\n",
      "Training loss: 19.1420, Training accuracy: 0.3865\n",
      "Validation loss: 7.9958, Validation accuracy: 0.3752\n",
      "\n",
      "Epoch 152:\n",
      "Training loss: 19.1367, Training accuracy: 0.3894\n",
      "Validation loss: 10.0301, Validation accuracy: 0.4312\n",
      "\n",
      "Epoch 153:\n",
      "Training loss: 19.1427, Training accuracy: 0.3862\n",
      "Validation loss: 8.4478, Validation accuracy: 0.4104\n",
      "\n",
      "Epoch 154:\n",
      "Training loss: 19.1329, Training accuracy: 0.3910\n",
      "Validation loss: 9.9924, Validation accuracy: 0.4629\n",
      "Saving ...\n",
      "\n",
      "Epoch 155:\n",
      "Training loss: 19.1316, Training accuracy: 0.3940\n",
      "Validation loss: 10.1500, Validation accuracy: 0.3531\n",
      "\n",
      "Epoch 156:\n",
      "Training loss: 19.1347, Training accuracy: 0.3933\n",
      "Validation loss: 10.6087, Validation accuracy: 0.4058\n",
      "\n",
      "Epoch 157:\n",
      "Training loss: 19.1257, Training accuracy: 0.3909\n",
      "Validation loss: 11.1636, Validation accuracy: 0.4341\n",
      "\n",
      "Epoch 158:\n",
      "Training loss: 19.1248, Training accuracy: 0.3931\n",
      "Validation loss: 8.5360, Validation accuracy: 0.4633\n",
      "Saving ...\n",
      "\n",
      "Epoch 159:\n",
      "Training loss: 19.1229, Training accuracy: 0.3984\n",
      "Validation loss: 11.7955, Validation accuracy: 0.3619\n",
      "\n",
      "Epoch 160:\n",
      "Training loss: 19.1252, Training accuracy: 0.3968\n",
      "Validation loss: 9.7124, Validation accuracy: 0.4087\n",
      "\n",
      "Epoch 161:\n",
      "Training loss: 19.1220, Training accuracy: 0.3960\n",
      "Validation loss: 8.8120, Validation accuracy: 0.4418\n",
      "\n",
      "Epoch 162:\n",
      "Training loss: 19.1240, Training accuracy: 0.3944\n",
      "Validation loss: 11.1702, Validation accuracy: 0.4386\n",
      "\n",
      "Epoch 163:\n",
      "Training loss: 19.1177, Training accuracy: 0.3978\n",
      "Validation loss: 11.7993, Validation accuracy: 0.2865\n",
      "\n",
      "Epoch 164:\n",
      "Training loss: 19.1177, Training accuracy: 0.3928\n",
      "Validation loss: 9.7977, Validation accuracy: 0.4268\n",
      "\n",
      "Epoch 165:\n",
      "Training loss: 19.1153, Training accuracy: 0.3931\n",
      "Validation loss: 8.6100, Validation accuracy: 0.4511\n",
      "\n",
      "Epoch 166:\n",
      "Training loss: 19.1153, Training accuracy: 0.3958\n",
      "Validation loss: 9.6631, Validation accuracy: 0.4265\n",
      "\n",
      "Epoch 167:\n",
      "Training loss: 19.1077, Training accuracy: 0.3960\n",
      "Validation loss: 9.5836, Validation accuracy: 0.4530\n",
      "\n",
      "Epoch 168:\n",
      "Training loss: 19.1112, Training accuracy: 0.3976\n",
      "Validation loss: 11.1230, Validation accuracy: 0.2495\n",
      "\n",
      "Epoch 169:\n",
      "Training loss: 19.1107, Training accuracy: 0.4019\n",
      "Validation loss: 14.2011, Validation accuracy: 0.3745\n",
      "\n",
      "Epoch 170:\n",
      "Training loss: 19.1085, Training accuracy: 0.3956\n",
      "Validation loss: 11.5062, Validation accuracy: 0.4414\n",
      "\n",
      "Epoch 171:\n",
      "Training loss: 19.1048, Training accuracy: 0.3962\n",
      "Validation loss: 10.1706, Validation accuracy: 0.3674\n",
      "\n",
      "Epoch 172:\n",
      "Training loss: 19.1045, Training accuracy: 0.3939\n",
      "Validation loss: 10.6999, Validation accuracy: 0.3361\n",
      "\n",
      "Epoch 173:\n",
      "Training loss: 19.1024, Training accuracy: 0.3954\n",
      "Validation loss: 8.8901, Validation accuracy: 0.4065\n",
      "\n",
      "Epoch 174:\n",
      "Training loss: 19.1027, Training accuracy: 0.3970\n",
      "Validation loss: 14.0257, Validation accuracy: 0.2460\n",
      "\n",
      "Epoch 175:\n",
      "Training loss: 19.0955, Training accuracy: 0.4014\n",
      "Validation loss: 9.3074, Validation accuracy: 0.4522\n",
      "\n",
      "Epoch 176:\n",
      "Training loss: 19.0946, Training accuracy: 0.3996\n",
      "Validation loss: 9.6918, Validation accuracy: 0.4157\n",
      "\n",
      "Epoch 177:\n",
      "Training loss: 19.0950, Training accuracy: 0.3971\n",
      "Validation loss: 10.0205, Validation accuracy: 0.3744\n",
      "\n",
      "Epoch 178:\n",
      "Training loss: 19.0951, Training accuracy: 0.3989\n",
      "Validation loss: 10.9534, Validation accuracy: 0.2996\n",
      "\n",
      "Epoch 179:\n",
      "Training loss: 19.0966, Training accuracy: 0.3942\n",
      "Validation loss: 9.1984, Validation accuracy: 0.4260\n",
      "\n",
      "Epoch 180:\n",
      "Training loss: 19.0929, Training accuracy: 0.3974\n",
      "Validation loss: 10.0349, Validation accuracy: 0.3442\n",
      "\n",
      "Epoch 181:\n",
      "Training loss: 19.0951, Training accuracy: 0.4020\n",
      "Validation loss: 8.7534, Validation accuracy: 0.3498\n",
      "\n",
      "Epoch 182:\n",
      "Training loss: 19.0924, Training accuracy: 0.4017\n",
      "Validation loss: 8.9550, Validation accuracy: 0.4087\n",
      "\n",
      "Epoch 183:\n",
      "Training loss: 19.0874, Training accuracy: 0.3985\n",
      "Validation loss: 7.1130, Validation accuracy: 0.4395\n",
      "\n",
      "Epoch 184:\n",
      "Training loss: 19.0869, Training accuracy: 0.4049\n",
      "Validation loss: 7.8274, Validation accuracy: 0.4303\n",
      "\n",
      "Epoch 185:\n",
      "Training loss: 19.0893, Training accuracy: 0.4003\n",
      "Validation loss: 7.8578, Validation accuracy: 0.4305\n",
      "\n",
      "Epoch 186:\n",
      "Training loss: 19.0869, Training accuracy: 0.4062\n",
      "Validation loss: 8.9091, Validation accuracy: 0.4552\n",
      "\n",
      "Epoch 187:\n",
      "Training loss: 19.0888, Training accuracy: 0.4061\n",
      "Validation loss: 10.3008, Validation accuracy: 0.3486\n",
      "\n",
      "Epoch 188:\n",
      "Training loss: 19.0811, Training accuracy: 0.4050\n",
      "Validation loss: 9.4608, Validation accuracy: 0.3802\n",
      "\n",
      "Epoch 189:\n",
      "Training loss: 19.0850, Training accuracy: 0.4035\n",
      "Validation loss: 7.6319, Validation accuracy: 0.4504\n",
      "\n",
      "Epoch 190:\n",
      "Training loss: 19.0835, Training accuracy: 0.4042\n",
      "Validation loss: 8.4792, Validation accuracy: 0.3881\n",
      "\n",
      "Epoch 191:\n",
      "Training loss: 19.0795, Training accuracy: 0.4055\n",
      "Validation loss: 8.3781, Validation accuracy: 0.3962\n",
      "\n",
      "Epoch 192:\n",
      "Training loss: 19.0762, Training accuracy: 0.4041\n",
      "Validation loss: 8.7617, Validation accuracy: 0.4493\n",
      "\n",
      "Epoch 193:\n",
      "Training loss: 19.0791, Training accuracy: 0.4077\n",
      "Validation loss: 8.8773, Validation accuracy: 0.4203\n",
      "\n",
      "Epoch 194:\n",
      "Training loss: 19.0774, Training accuracy: 0.4029\n",
      "Validation loss: 9.2522, Validation accuracy: 0.4195\n",
      "\n",
      "Epoch 195:\n",
      "Training loss: 19.0752, Training accuracy: 0.4083\n",
      "Validation loss: 9.3371, Validation accuracy: 0.4668\n",
      "Saving ...\n",
      "\n",
      "Epoch 196:\n",
      "Training loss: 19.0814, Training accuracy: 0.4009\n",
      "Validation loss: 12.0488, Validation accuracy: 0.4152\n",
      "\n",
      "Epoch 197:\n",
      "Training loss: 19.0718, Training accuracy: 0.4040\n",
      "Validation loss: 9.9761, Validation accuracy: 0.4171\n",
      "\n",
      "Epoch 198:\n",
      "Training loss: 19.0740, Training accuracy: 0.4018\n",
      "Validation loss: 8.5069, Validation accuracy: 0.4559\n",
      "\n",
      "Epoch 199:\n",
      "Training loss: 19.0672, Training accuracy: 0.4068\n",
      "Validation loss: 8.8641, Validation accuracy: 0.3844\n",
      "\n",
      "==================================================\n",
      "==> Optimization finished! Best validation accuracy: 0.4668\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4668"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train(student,teacher,optimizer,criterion,4,[0,1,0],1,train_loader,val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Training starts!\n",
      "==================================================\n",
      "Epoch 0:\n",
      "Training loss: 116.2444, Training accuracy: 0.1834\n",
      "Validation loss: 10.3513, Validation accuracy: 0.1781\n",
      "Saving ...\n",
      "\n",
      "Epoch 1:\n",
      "Training loss: 108.7878, Training accuracy: 0.1872\n",
      "Validation loss: 25.3271, Validation accuracy: 0.1691\n",
      "\n",
      "Epoch 2:\n",
      "Training loss: 106.7553, Training accuracy: 0.1820\n",
      "Validation loss: 17.2843, Validation accuracy: 0.2095\n",
      "Saving ...\n",
      "\n",
      "Epoch 3:\n",
      "Training loss: 105.5789, Training accuracy: 0.1953\n",
      "Validation loss: 43.4810, Validation accuracy: 0.1905\n",
      "\n",
      "Epoch 4:\n",
      "Training loss: 105.0658, Training accuracy: 0.1859\n",
      "Validation loss: 40.0285, Validation accuracy: 0.1738\n",
      "\n",
      "Epoch 5:\n",
      "Training loss: 104.6674, Training accuracy: 0.1865\n",
      "Validation loss: 41.3829, Validation accuracy: 0.1920\n",
      "\n",
      "Epoch 6:\n",
      "Training loss: 104.3655, Training accuracy: 0.1786\n",
      "Validation loss: 50.6629, Validation accuracy: 0.1899\n",
      "\n",
      "Epoch 7:\n",
      "Training loss: 104.2609, Training accuracy: 0.1714\n",
      "Validation loss: 57.1645, Validation accuracy: 0.1835\n",
      "\n",
      "Epoch 8:\n",
      "Training loss: 103.9941, Training accuracy: 0.1764\n",
      "Validation loss: 73.1403, Validation accuracy: 0.1903\n",
      "\n",
      "Epoch 9:\n",
      "Training loss: 103.8691, Training accuracy: 0.1778\n",
      "Validation loss: 92.9833, Validation accuracy: 0.1745\n",
      "\n",
      "Epoch 10:\n",
      "Training loss: 103.8256, Training accuracy: 0.1711\n",
      "Validation loss: 92.0350, Validation accuracy: 0.1679\n",
      "\n",
      "Epoch 11:\n",
      "Training loss: 103.6237, Training accuracy: 0.1769\n",
      "Validation loss: 77.4041, Validation accuracy: 0.1822\n",
      "\n",
      "Epoch 12:\n",
      "Training loss: 103.5474, Training accuracy: 0.1683\n",
      "Validation loss: 133.9112, Validation accuracy: 0.1546\n",
      "\n",
      "Epoch 13:\n",
      "Training loss: 103.6096, Training accuracy: 0.1585\n",
      "Validation loss: 160.3360, Validation accuracy: 0.1207\n",
      "\n",
      "Epoch 14:\n",
      "Training loss: 103.5643, Training accuracy: 0.1563\n",
      "Validation loss: 113.8500, Validation accuracy: 0.1792\n",
      "\n",
      "Epoch 15:\n",
      "Training loss: 103.3802, Training accuracy: 0.1648\n",
      "Validation loss: 107.7872, Validation accuracy: 0.1797\n",
      "\n",
      "Epoch 16:\n",
      "Training loss: 103.3394, Training accuracy: 0.1705\n",
      "Validation loss: 149.3100, Validation accuracy: 0.1545\n",
      "\n",
      "Epoch 17:\n",
      "Training loss: 103.3486, Training accuracy: 0.1626\n",
      "Validation loss: 209.2738, Validation accuracy: 0.1413\n",
      "\n",
      "Epoch 18:\n",
      "Training loss: 103.2922, Training accuracy: 0.1710\n",
      "Validation loss: 143.7492, Validation accuracy: 0.1708\n",
      "\n",
      "Epoch 19:\n",
      "Training loss: 103.2530, Training accuracy: 0.1669\n",
      "Validation loss: 157.5839, Validation accuracy: 0.1739\n",
      "\n",
      "Epoch 20:\n",
      "Training loss: 103.2102, Training accuracy: 0.1633\n",
      "Validation loss: 134.5378, Validation accuracy: 0.1756\n",
      "\n",
      "Epoch 21:\n",
      "Training loss: 103.1029, Training accuracy: 0.1688\n",
      "Validation loss: 110.8396, Validation accuracy: 0.1938\n",
      "\n",
      "Epoch 22:\n",
      "Training loss: 103.0477, Training accuracy: 0.1826\n",
      "Validation loss: 157.2155, Validation accuracy: 0.1852\n",
      "\n",
      "Epoch 23:\n",
      "Training loss: 103.0253, Training accuracy: 0.1780\n",
      "Validation loss: 141.8588, Validation accuracy: 0.1842\n",
      "\n",
      "Epoch 24:\n",
      "Training loss: 102.9352, Training accuracy: 0.1832\n",
      "Validation loss: 105.8851, Validation accuracy: 0.1877\n",
      "\n",
      "Epoch 25:\n",
      "Training loss: 103.0555, Training accuracy: 0.1738\n",
      "Validation loss: 152.8511, Validation accuracy: 0.1735\n",
      "\n",
      "Epoch 26:\n",
      "Training loss: 102.9485, Training accuracy: 0.1802\n",
      "Validation loss: 133.5065, Validation accuracy: 0.1815\n",
      "\n",
      "Epoch 27:\n",
      "Training loss: 102.9327, Training accuracy: 0.1717\n",
      "Validation loss: 134.3356, Validation accuracy: 0.1784\n",
      "\n",
      "Epoch 28:\n",
      "Training loss: 102.8814, Training accuracy: 0.1819\n",
      "Validation loss: 170.3332, Validation accuracy: 0.1804\n",
      "\n",
      "Epoch 29:\n",
      "Training loss: 102.9507, Training accuracy: 0.1707\n",
      "Validation loss: 168.3430, Validation accuracy: 0.1713\n",
      "\n",
      "Epoch 30:\n",
      "Training loss: 102.8707, Training accuracy: 0.1738\n",
      "Validation loss: 173.0361, Validation accuracy: 0.1848\n",
      "\n",
      "Epoch 31:\n",
      "Training loss: 102.7967, Training accuracy: 0.1793\n",
      "Validation loss: 173.6597, Validation accuracy: 0.1889\n",
      "\n",
      "Epoch 32:\n",
      "Training loss: 102.7755, Training accuracy: 0.1865\n",
      "Validation loss: 166.6499, Validation accuracy: 0.1929\n",
      "\n",
      "Epoch 33:\n",
      "Training loss: 102.7511, Training accuracy: 0.1848\n",
      "Validation loss: 154.2064, Validation accuracy: 0.1838\n",
      "\n",
      "Epoch 34:\n",
      "Training loss: 102.7447, Training accuracy: 0.1892\n",
      "Validation loss: 108.0688, Validation accuracy: 0.2076\n",
      "\n",
      "Epoch 35:\n",
      "Training loss: 102.7691, Training accuracy: 0.1967\n",
      "Validation loss: 126.5734, Validation accuracy: 0.2030\n",
      "\n",
      "Epoch 36:\n",
      "Training loss: 102.7442, Training accuracy: 0.1805\n",
      "Validation loss: 193.9339, Validation accuracy: 0.1905\n",
      "\n",
      "Epoch 37:\n",
      "Training loss: 102.7100, Training accuracy: 0.1892\n",
      "Validation loss: 213.3087, Validation accuracy: 0.1854\n",
      "\n",
      "Epoch 38:\n",
      "Training loss: 103.0088, Training accuracy: 0.1585\n",
      "Validation loss: 249.7053, Validation accuracy: 0.1665\n",
      "\n",
      "Epoch 39:\n",
      "Training loss: 102.7623, Training accuracy: 0.1744\n",
      "Validation loss: 163.5853, Validation accuracy: 0.1856\n",
      "\n",
      "Epoch 40:\n",
      "Training loss: 102.6811, Training accuracy: 0.1768\n",
      "Validation loss: 174.5225, Validation accuracy: 0.1747\n",
      "\n",
      "Epoch 41:\n",
      "Training loss: 102.9170, Training accuracy: 0.1637\n",
      "Validation loss: 257.7996, Validation accuracy: 0.1722\n",
      "\n",
      "Epoch 42:\n",
      "Training loss: 102.8180, Training accuracy: 0.1710\n",
      "Validation loss: 197.6271, Validation accuracy: 0.1772\n",
      "\n",
      "Epoch 43:\n",
      "Training loss: 102.7493, Training accuracy: 0.1698\n",
      "Validation loss: 220.7390, Validation accuracy: 0.1821\n",
      "\n",
      "Epoch 44:\n",
      "Training loss: 102.8218, Training accuracy: 0.1629\n",
      "Validation loss: 237.6492, Validation accuracy: 0.1664\n",
      "\n",
      "Epoch 45:\n",
      "Training loss: 102.6911, Training accuracy: 0.1701\n",
      "Validation loss: 223.2901, Validation accuracy: 0.1818\n",
      "\n",
      "Epoch 46:\n",
      "Training loss: 102.6896, Training accuracy: 0.1698\n",
      "Validation loss: 189.8458, Validation accuracy: 0.1953\n",
      "\n",
      "Epoch 47:\n",
      "Training loss: 102.6226, Training accuracy: 0.1828\n",
      "Validation loss: 219.1984, Validation accuracy: 0.1899\n",
      "\n",
      "Epoch 48:\n",
      "Training loss: 102.6432, Training accuracy: 0.1823\n",
      "Validation loss: 262.7853, Validation accuracy: 0.1862\n",
      "\n",
      "Epoch 49:\n",
      "Training loss: 102.6332, Training accuracy: 0.1689\n",
      "Validation loss: 256.5818, Validation accuracy: 0.1730\n",
      "\n",
      "Epoch 50:\n",
      "Training loss: 102.6077, Training accuracy: 0.1780\n",
      "Validation loss: 218.1289, Validation accuracy: 0.1828\n",
      "\n",
      "Epoch 51:\n",
      "Training loss: 102.6360, Training accuracy: 0.1797\n",
      "Validation loss: 186.1310, Validation accuracy: 0.1831\n",
      "\n",
      "Epoch 52:\n",
      "Training loss: 102.6568, Training accuracy: 0.1677\n",
      "Validation loss: 260.8058, Validation accuracy: 0.1691\n",
      "\n",
      "Epoch 53:\n",
      "Training loss: 102.6346, Training accuracy: 0.1733\n",
      "Validation loss: 244.3821, Validation accuracy: 0.1686\n",
      "\n",
      "Epoch 54:\n",
      "Training loss: 102.6467, Training accuracy: 0.1716\n",
      "Validation loss: 290.0186, Validation accuracy: 0.1676\n",
      "\n",
      "Epoch 55:\n",
      "Training loss: 102.6195, Training accuracy: 0.1766\n",
      "Validation loss: 312.8091, Validation accuracy: 0.1611\n",
      "\n",
      "Epoch 56:\n",
      "Training loss: 102.6028, Training accuracy: 0.1803\n",
      "Validation loss: 208.9150, Validation accuracy: 0.1847\n",
      "\n",
      "Epoch 57:\n",
      "Training loss: 102.5945, Training accuracy: 0.1703\n",
      "Validation loss: 268.0331, Validation accuracy: 0.1630\n",
      "\n",
      "Epoch 58:\n",
      "Training loss: 102.5553, Training accuracy: 0.1755\n",
      "Validation loss: 214.9152, Validation accuracy: 0.1877\n",
      "\n",
      "Epoch 59:\n",
      "Training loss: 102.5524, Training accuracy: 0.1745\n",
      "Validation loss: 291.4920, Validation accuracy: 0.1764\n",
      "\n",
      "Epoch 60:\n",
      "Training loss: 102.5548, Training accuracy: 0.1704\n",
      "Validation loss: 276.3981, Validation accuracy: 0.1729\n",
      "\n",
      "Epoch 61:\n",
      "Training loss: 102.4942, Training accuracy: 0.1801\n",
      "Validation loss: 207.5909, Validation accuracy: 0.1846\n",
      "\n",
      "Epoch 62:\n",
      "Training loss: 102.5683, Training accuracy: 0.1782\n",
      "Validation loss: 252.0843, Validation accuracy: 0.1911\n",
      "\n",
      "Epoch 63:\n",
      "Training loss: 102.4551, Training accuracy: 0.1948\n",
      "Validation loss: 219.1374, Validation accuracy: 0.1863\n",
      "\n",
      "Epoch 64:\n",
      "Training loss: 102.4280, Training accuracy: 0.1916\n",
      "Validation loss: 178.4695, Validation accuracy: 0.2066\n",
      "\n",
      "Epoch 65:\n",
      "Training loss: 102.4079, Training accuracy: 0.1865\n",
      "Validation loss: 243.2570, Validation accuracy: 0.1845\n",
      "\n",
      "Epoch 66:\n",
      "Training loss: 102.4315, Training accuracy: 0.1903\n",
      "Validation loss: 241.8913, Validation accuracy: 0.1893\n",
      "\n",
      "Epoch 67:\n",
      "Training loss: 102.4837, Training accuracy: 0.1798\n",
      "Validation loss: 300.3465, Validation accuracy: 0.1738\n",
      "\n",
      "Epoch 68:\n",
      "Training loss: 102.4859, Training accuracy: 0.1732\n",
      "Validation loss: 206.1883, Validation accuracy: 0.1835\n",
      "\n",
      "Epoch 69:\n",
      "Training loss: 102.4290, Training accuracy: 0.1796\n",
      "Validation loss: 309.1941, Validation accuracy: 0.1698\n",
      "\n",
      "Epoch 70:\n",
      "Training loss: 102.5042, Training accuracy: 0.1680\n",
      "Validation loss: 321.0310, Validation accuracy: 0.1732\n",
      "\n",
      "Epoch 71:\n",
      "Training loss: 102.4208, Training accuracy: 0.1762\n",
      "Validation loss: 271.8018, Validation accuracy: 0.1945\n",
      "\n",
      "Epoch 72:\n",
      "Training loss: 102.4460, Training accuracy: 0.1804\n",
      "Validation loss: 281.9761, Validation accuracy: 0.1806\n",
      "\n",
      "Epoch 73:\n",
      "Training loss: 102.4045, Training accuracy: 0.1936\n",
      "Validation loss: 209.0207, Validation accuracy: 0.1992\n",
      "\n",
      "Epoch 74:\n",
      "Training loss: 102.3921, Training accuracy: 0.2022\n",
      "Validation loss: 279.2967, Validation accuracy: 0.1898\n",
      "\n",
      "Epoch 75:\n",
      "Training loss: 102.4266, Training accuracy: 0.1919\n",
      "Validation loss: 292.4875, Validation accuracy: 0.1898\n",
      "\n",
      "Epoch 76:\n",
      "Training loss: 102.3991, Training accuracy: 0.1898\n",
      "Validation loss: 228.4147, Validation accuracy: 0.1951\n",
      "\n",
      "Epoch 77:\n",
      "Training loss: 102.3580, Training accuracy: 0.1970\n",
      "Validation loss: 226.0991, Validation accuracy: 0.2107\n",
      "Saving ...\n",
      "\n",
      "Epoch 78:\n",
      "Training loss: 102.3853, Training accuracy: 0.1979\n",
      "Validation loss: 277.0124, Validation accuracy: 0.1872\n",
      "\n",
      "Epoch 79:\n",
      "Training loss: 102.3674, Training accuracy: 0.1898\n",
      "Validation loss: 290.9582, Validation accuracy: 0.1848\n",
      "\n",
      "Epoch 80:\n",
      "Training loss: 102.3547, Training accuracy: 0.1871\n",
      "Validation loss: 263.7890, Validation accuracy: 0.1962\n",
      "\n",
      "Epoch 81:\n",
      "Training loss: 102.3668, Training accuracy: 0.1880\n",
      "Validation loss: 267.3461, Validation accuracy: 0.1866\n",
      "\n",
      "Epoch 82:\n",
      "Training loss: 102.3790, Training accuracy: 0.1945\n",
      "Validation loss: 279.7425, Validation accuracy: 0.1901\n",
      "\n",
      "Epoch 83:\n",
      "Training loss: 102.3107, Training accuracy: 0.2034\n",
      "Validation loss: 172.5001, Validation accuracy: 0.2224\n",
      "Saving ...\n",
      "\n",
      "Epoch 84:\n",
      "Training loss: 102.3153, Training accuracy: 0.2178\n",
      "Validation loss: 235.7924, Validation accuracy: 0.2039\n",
      "\n",
      "Epoch 85:\n",
      "Training loss: 102.4153, Training accuracy: 0.1992\n",
      "Validation loss: 320.8805, Validation accuracy: 0.1868\n",
      "\n",
      "Epoch 86:\n",
      "Training loss: 102.3838, Training accuracy: 0.1826\n",
      "Validation loss: 236.2308, Validation accuracy: 0.1938\n",
      "\n",
      "Epoch 87:\n",
      "Training loss: 102.3144, Training accuracy: 0.1856\n",
      "Validation loss: 262.6653, Validation accuracy: 0.1813\n",
      "\n",
      "Epoch 88:\n",
      "Training loss: 102.3950, Training accuracy: 0.1840\n",
      "Validation loss: 406.7626, Validation accuracy: 0.1720\n",
      "\n",
      "Epoch 89:\n",
      "Training loss: 102.4203, Training accuracy: 0.1795\n",
      "Validation loss: 300.9487, Validation accuracy: 0.1844\n",
      "\n",
      "Epoch 90:\n",
      "Training loss: 102.3277, Training accuracy: 0.1935\n",
      "Validation loss: 237.8755, Validation accuracy: 0.2027\n",
      "\n",
      "Epoch 91:\n",
      "Training loss: 102.3389, Training accuracy: 0.1891\n",
      "Validation loss: 257.0165, Validation accuracy: 0.2097\n",
      "\n",
      "Epoch 92:\n",
      "Training loss: 102.3530, Training accuracy: 0.1902\n",
      "Validation loss: 285.0445, Validation accuracy: 0.1867\n",
      "\n",
      "Epoch 93:\n",
      "Training loss: 102.2829, Training accuracy: 0.1938\n",
      "Validation loss: 334.7610, Validation accuracy: 0.1911\n",
      "\n",
      "Epoch 94:\n",
      "Training loss: 102.3412, Training accuracy: 0.1900\n",
      "Validation loss: 352.0861, Validation accuracy: 0.1802\n",
      "\n",
      "Epoch 95:\n",
      "Training loss: 102.3549, Training accuracy: 0.1840\n",
      "Validation loss: 390.4467, Validation accuracy: 0.1798\n",
      "\n",
      "Epoch 96:\n",
      "Training loss: 102.3261, Training accuracy: 0.1839\n",
      "Validation loss: 251.8892, Validation accuracy: 0.1985\n",
      "\n",
      "Epoch 97:\n",
      "Training loss: 102.2509, Training accuracy: 0.1935\n",
      "Validation loss: 201.6231, Validation accuracy: 0.2160\n",
      "\n",
      "Epoch 98:\n",
      "Training loss: 102.2774, Training accuracy: 0.1894\n",
      "Validation loss: 238.2690, Validation accuracy: 0.1999\n",
      "\n",
      "Epoch 99:\n",
      "Training loss: 102.3479, Training accuracy: 0.1916\n",
      "Validation loss: 227.7449, Validation accuracy: 0.2166\n",
      "\n",
      "Epoch 100:\n",
      "Training loss: 102.2662, Training accuracy: 0.2018\n",
      "Validation loss: 232.2648, Validation accuracy: 0.2162\n",
      "\n",
      "Epoch 101:\n",
      "Training loss: 102.2799, Training accuracy: 0.2035\n",
      "Validation loss: 221.9573, Validation accuracy: 0.2128\n",
      "\n",
      "Epoch 102:\n",
      "Training loss: 102.2669, Training accuracy: 0.2024\n",
      "Validation loss: 242.5089, Validation accuracy: 0.2099\n",
      "\n",
      "Epoch 103:\n",
      "Training loss: 102.2947, Training accuracy: 0.2096\n",
      "Validation loss: 341.2057, Validation accuracy: 0.2041\n",
      "\n",
      "Epoch 104:\n",
      "Training loss: 102.3094, Training accuracy: 0.2081\n",
      "Validation loss: 312.3565, Validation accuracy: 0.2180\n",
      "\n",
      "Epoch 105:\n",
      "Training loss: 102.2956, Training accuracy: 0.2072\n",
      "Validation loss: 277.7314, Validation accuracy: 0.2246\n",
      "Saving ...\n",
      "\n",
      "Epoch 106:\n",
      "Training loss: 102.2800, Training accuracy: 0.2020\n",
      "Validation loss: 225.5107, Validation accuracy: 0.2168\n",
      "\n",
      "Epoch 107:\n",
      "Training loss: 102.1843, Training accuracy: 0.2072\n",
      "Validation loss: 297.4624, Validation accuracy: 0.2064\n",
      "\n",
      "Epoch 108:\n",
      "Training loss: 102.1893, Training accuracy: 0.2057\n",
      "Validation loss: 220.6870, Validation accuracy: 0.2164\n",
      "\n",
      "Epoch 109:\n",
      "Training loss: 102.1813, Training accuracy: 0.2062\n",
      "Validation loss: 388.2730, Validation accuracy: 0.1795\n",
      "\n",
      "Epoch 110:\n",
      "Training loss: 102.3484, Training accuracy: 0.1949\n",
      "Validation loss: 328.8787, Validation accuracy: 0.1933\n",
      "\n",
      "Epoch 111:\n",
      "Training loss: 102.2323, Training accuracy: 0.2037\n",
      "Validation loss: 288.5891, Validation accuracy: 0.2269\n",
      "Saving ...\n",
      "\n",
      "Epoch 112:\n",
      "Training loss: 102.2844, Training accuracy: 0.2031\n",
      "Validation loss: 367.7650, Validation accuracy: 0.1844\n",
      "\n",
      "Epoch 113:\n",
      "Training loss: 102.2332, Training accuracy: 0.2056\n",
      "Validation loss: 231.0571, Validation accuracy: 0.2299\n",
      "Saving ...\n",
      "\n",
      "Epoch 114:\n",
      "Training loss: 102.2299, Training accuracy: 0.2103\n",
      "Validation loss: 234.2517, Validation accuracy: 0.2304\n",
      "Saving ...\n",
      "\n",
      "Epoch 115:\n",
      "Training loss: 102.1750, Training accuracy: 0.2121\n",
      "Validation loss: 231.8854, Validation accuracy: 0.2284\n",
      "\n",
      "Epoch 116:\n",
      "Training loss: 102.2068, Training accuracy: 0.2189\n",
      "Validation loss: 319.6063, Validation accuracy: 0.2179\n",
      "\n",
      "Epoch 117:\n",
      "Training loss: 102.2141, Training accuracy: 0.2159\n",
      "Validation loss: 239.1282, Validation accuracy: 0.2204\n",
      "\n",
      "Epoch 118:\n",
      "Training loss: 102.1633, Training accuracy: 0.2080\n",
      "Validation loss: 278.6876, Validation accuracy: 0.2333\n",
      "Saving ...\n",
      "\n",
      "Epoch 119:\n",
      "Training loss: 102.1838, Training accuracy: 0.2137\n",
      "Validation loss: 355.8664, Validation accuracy: 0.2139\n",
      "\n",
      "Epoch 120:\n",
      "Training loss: 102.2611, Training accuracy: 0.2087\n",
      "Validation loss: 275.0183, Validation accuracy: 0.2219\n",
      "\n",
      "Epoch 121:\n",
      "Training loss: 102.1990, Training accuracy: 0.2063\n",
      "Validation loss: 267.9408, Validation accuracy: 0.2141\n",
      "\n",
      "Epoch 122:\n",
      "Training loss: 102.1952, Training accuracy: 0.1887\n",
      "Validation loss: 328.9415, Validation accuracy: 0.1772\n",
      "\n",
      "Epoch 123:\n",
      "Training loss: 102.2126, Training accuracy: 0.1921\n",
      "Validation loss: 326.2043, Validation accuracy: 0.1916\n",
      "\n",
      "Epoch 124:\n",
      "Training loss: 102.1994, Training accuracy: 0.1950\n",
      "Validation loss: 301.8750, Validation accuracy: 0.2042\n",
      "\n",
      "Epoch 125:\n",
      "Training loss: 102.2301, Training accuracy: 0.2054\n",
      "Validation loss: 277.1977, Validation accuracy: 0.2148\n",
      "\n",
      "Epoch 126:\n",
      "Training loss: 102.2166, Training accuracy: 0.2021\n",
      "Validation loss: 322.8661, Validation accuracy: 0.2182\n",
      "\n",
      "Epoch 127:\n",
      "Training loss: 102.2555, Training accuracy: 0.2068\n",
      "Validation loss: 371.0480, Validation accuracy: 0.2128\n",
      "\n",
      "Epoch 128:\n",
      "Training loss: 102.2485, Training accuracy: 0.2078\n",
      "Validation loss: 233.7097, Validation accuracy: 0.2250\n",
      "\n",
      "Epoch 129:\n",
      "Training loss: 102.2110, Training accuracy: 0.2074\n",
      "Validation loss: 303.3620, Validation accuracy: 0.2200\n",
      "\n",
      "Epoch 130:\n",
      "Training loss: 102.1618, Training accuracy: 0.2068\n",
      "Validation loss: 253.2429, Validation accuracy: 0.2347\n",
      "Saving ...\n",
      "\n",
      "Epoch 131:\n",
      "Training loss: 102.2019, Training accuracy: 0.2061\n",
      "Validation loss: 292.3211, Validation accuracy: 0.2157\n",
      "\n",
      "Epoch 132:\n",
      "Training loss: 102.3235, Training accuracy: 0.1962\n",
      "Validation loss: 459.9875, Validation accuracy: 0.1697\n",
      "\n",
      "Epoch 133:\n",
      "Training loss: 102.2820, Training accuracy: 0.1938\n",
      "Validation loss: 391.5746, Validation accuracy: 0.1927\n",
      "\n",
      "Epoch 134:\n",
      "Training loss: 102.2648, Training accuracy: 0.2018\n",
      "Validation loss: 271.0817, Validation accuracy: 0.2242\n",
      "\n",
      "Epoch 135:\n",
      "Training loss: 102.1494, Training accuracy: 0.2145\n",
      "Validation loss: 249.4112, Validation accuracy: 0.2280\n",
      "\n",
      "Epoch 136:\n",
      "Training loss: 102.1589, Training accuracy: 0.2077\n",
      "Validation loss: 266.5465, Validation accuracy: 0.2213\n",
      "\n",
      "Epoch 137:\n",
      "Training loss: 102.1240, Training accuracy: 0.2105\n",
      "Validation loss: 282.5616, Validation accuracy: 0.2191\n",
      "\n",
      "Epoch 138:\n",
      "Training loss: 102.1376, Training accuracy: 0.2111\n",
      "Validation loss: 293.5020, Validation accuracy: 0.2251\n",
      "\n",
      "Epoch 139:\n",
      "Training loss: 102.2046, Training accuracy: 0.2108\n",
      "Validation loss: 323.8892, Validation accuracy: 0.2208\n",
      "\n",
      "Epoch 140:\n",
      "Training loss: 102.2540, Training accuracy: 0.2044\n",
      "Validation loss: 378.6763, Validation accuracy: 0.1947\n",
      "\n",
      "Epoch 141:\n",
      "Training loss: 102.2184, Training accuracy: 0.2047\n",
      "Validation loss: 333.7461, Validation accuracy: 0.2092\n",
      "\n",
      "Epoch 142:\n",
      "Training loss: 102.2339, Training accuracy: 0.2035\n",
      "Validation loss: 417.2548, Validation accuracy: 0.1978\n",
      "\n",
      "Epoch 143:\n",
      "Training loss: 102.2111, Training accuracy: 0.2106\n",
      "Validation loss: 288.3577, Validation accuracy: 0.2168\n",
      "\n",
      "Epoch 144:\n",
      "Training loss: 102.1401, Training accuracy: 0.2134\n",
      "Validation loss: 254.4822, Validation accuracy: 0.2224\n",
      "\n",
      "Epoch 145:\n",
      "Training loss: 102.1233, Training accuracy: 0.2220\n",
      "Validation loss: 247.5601, Validation accuracy: 0.2206\n",
      "\n",
      "Epoch 146:\n",
      "Training loss: 102.0826, Training accuracy: 0.2175\n",
      "Validation loss: 262.1640, Validation accuracy: 0.2289\n",
      "\n",
      "Epoch 147:\n",
      "Training loss: 102.1221, Training accuracy: 0.2136\n",
      "Validation loss: 336.1767, Validation accuracy: 0.2172\n",
      "\n",
      "Epoch 148:\n",
      "Training loss: 102.2031, Training accuracy: 0.2160\n",
      "Validation loss: 428.4788, Validation accuracy: 0.2029\n",
      "\n",
      "Epoch 149:\n",
      "Training loss: 102.1666, Training accuracy: 0.2145\n",
      "Validation loss: 414.1565, Validation accuracy: 0.2425\n",
      "Saving ...\n",
      "\n",
      "Epoch 150:\n",
      "Training loss: 102.2061, Training accuracy: 0.2156\n",
      "Validation loss: 357.9156, Validation accuracy: 0.2130\n",
      "\n",
      "Epoch 151:\n",
      "Training loss: 102.2124, Training accuracy: 0.2045\n",
      "Validation loss: 295.5813, Validation accuracy: 0.2130\n",
      "\n",
      "Epoch 152:\n",
      "Training loss: 102.1741, Training accuracy: 0.2093\n",
      "Validation loss: 338.2329, Validation accuracy: 0.2161\n",
      "\n",
      "Epoch 153:\n",
      "Training loss: 102.1709, Training accuracy: 0.2152\n",
      "Validation loss: 324.3268, Validation accuracy: 0.2352\n",
      "\n",
      "Epoch 154:\n",
      "Training loss: 102.0913, Training accuracy: 0.2205\n",
      "Validation loss: 270.9936, Validation accuracy: 0.2149\n",
      "\n",
      "Epoch 155:\n",
      "Training loss: 102.1282, Training accuracy: 0.2160\n",
      "Validation loss: 334.6676, Validation accuracy: 0.2277\n",
      "\n",
      "Epoch 156:\n",
      "Training loss: 102.1118, Training accuracy: 0.2206\n",
      "Validation loss: 312.2307, Validation accuracy: 0.2332\n",
      "\n",
      "Epoch 157:\n",
      "Training loss: 102.0638, Training accuracy: 0.2254\n",
      "Validation loss: 347.8305, Validation accuracy: 0.2401\n",
      "\n",
      "Epoch 158:\n",
      "Training loss: 102.1001, Training accuracy: 0.2246\n",
      "Validation loss: 225.4767, Validation accuracy: 0.2343\n",
      "\n",
      "Epoch 159:\n",
      "Training loss: 102.1071, Training accuracy: 0.2281\n",
      "Validation loss: 257.9972, Validation accuracy: 0.2369\n",
      "\n",
      "Epoch 160:\n",
      "Training loss: 102.0884, Training accuracy: 0.2246\n",
      "Validation loss: 258.9475, Validation accuracy: 0.2375\n",
      "\n",
      "Epoch 161:\n",
      "Training loss: 102.0712, Training accuracy: 0.2297\n",
      "Validation loss: 285.1588, Validation accuracy: 0.2243\n",
      "\n",
      "Epoch 162:\n",
      "Training loss: 102.0917, Training accuracy: 0.2217\n",
      "Validation loss: 385.2826, Validation accuracy: 0.2194\n",
      "\n",
      "Epoch 163:\n",
      "Training loss: 102.2002, Training accuracy: 0.2033\n",
      "Validation loss: 306.5163, Validation accuracy: 0.2225\n",
      "\n",
      "Epoch 164:\n",
      "Training loss: 102.1940, Training accuracy: 0.2134\n",
      "Validation loss: 255.1535, Validation accuracy: 0.2316\n",
      "\n",
      "Epoch 165:\n",
      "Training loss: 102.1163, Training accuracy: 0.2215\n",
      "Validation loss: 438.1613, Validation accuracy: 0.2157\n",
      "\n",
      "Epoch 166:\n",
      "Training loss: 102.0718, Training accuracy: 0.2153\n",
      "Validation loss: 259.2593, Validation accuracy: 0.2401\n",
      "\n",
      "Epoch 167:\n",
      "Training loss: 102.0669, Training accuracy: 0.2315\n",
      "Validation loss: 365.7702, Validation accuracy: 0.2544\n",
      "Saving ...\n",
      "\n",
      "Epoch 168:\n",
      "Training loss: 102.0240, Training accuracy: 0.2236\n",
      "Validation loss: 275.4752, Validation accuracy: 0.2390\n",
      "\n",
      "Epoch 169:\n",
      "Training loss: 102.0663, Training accuracy: 0.2237\n",
      "Validation loss: 374.3645, Validation accuracy: 0.2368\n",
      "\n",
      "Epoch 170:\n",
      "Training loss: 102.0830, Training accuracy: 0.2214\n",
      "Validation loss: 329.3460, Validation accuracy: 0.2229\n",
      "\n",
      "Epoch 171:\n",
      "Training loss: 102.0778, Training accuracy: 0.2185\n",
      "Validation loss: 259.7984, Validation accuracy: 0.2429\n",
      "\n",
      "Epoch 172:\n",
      "Training loss: 102.0578, Training accuracy: 0.2277\n",
      "Validation loss: 290.3203, Validation accuracy: 0.2471\n",
      "\n",
      "Epoch 173:\n",
      "Training loss: 102.0355, Training accuracy: 0.2314\n",
      "Validation loss: 290.2749, Validation accuracy: 0.2341\n",
      "\n",
      "Epoch 174:\n",
      "Training loss: 102.0479, Training accuracy: 0.2258\n",
      "Validation loss: 367.0311, Validation accuracy: 0.2254\n",
      "\n",
      "Epoch 175:\n",
      "Training loss: 102.0687, Training accuracy: 0.2262\n",
      "Validation loss: 298.6632, Validation accuracy: 0.2299\n",
      "\n",
      "Epoch 176:\n",
      "Training loss: 102.0622, Training accuracy: 0.2214\n",
      "Validation loss: 366.8551, Validation accuracy: 0.2379\n",
      "\n",
      "Epoch 177:\n",
      "Training loss: 102.1081, Training accuracy: 0.2213\n",
      "Validation loss: 363.8481, Validation accuracy: 0.2340\n",
      "\n",
      "Epoch 178:\n",
      "Training loss: 102.0685, Training accuracy: 0.2228\n",
      "Validation loss: 335.1501, Validation accuracy: 0.2330\n",
      "\n",
      "Epoch 179:\n",
      "Training loss: 102.0416, Training accuracy: 0.2209\n",
      "Validation loss: 321.9931, Validation accuracy: 0.2405\n",
      "\n",
      "Epoch 180:\n",
      "Training loss: 102.0553, Training accuracy: 0.2230\n",
      "Validation loss: 354.8144, Validation accuracy: 0.2329\n",
      "\n",
      "Epoch 181:\n",
      "Training loss: 102.0504, Training accuracy: 0.2245\n",
      "Validation loss: 264.6988, Validation accuracy: 0.2390\n",
      "\n",
      "Epoch 182:\n",
      "Training loss: 102.0966, Training accuracy: 0.2249\n",
      "Validation loss: 386.7218, Validation accuracy: 0.2264\n",
      "\n",
      "Epoch 183:\n",
      "Training loss: 102.1018, Training accuracy: 0.2320\n",
      "Validation loss: 484.6983, Validation accuracy: 0.2306\n",
      "\n",
      "Epoch 184:\n",
      "Training loss: 102.1203, Training accuracy: 0.2249\n",
      "Validation loss: 528.6640, Validation accuracy: 0.2231\n",
      "\n",
      "Epoch 185:\n",
      "Training loss: 102.1445, Training accuracy: 0.2167\n",
      "Validation loss: 488.9066, Validation accuracy: 0.2228\n",
      "\n",
      "Epoch 186:\n",
      "Training loss: 102.0666, Training accuracy: 0.2171\n",
      "Validation loss: 350.9336, Validation accuracy: 0.2320\n",
      "\n",
      "Epoch 187:\n",
      "Training loss: 102.1062, Training accuracy: 0.2244\n",
      "Validation loss: 335.5910, Validation accuracy: 0.2230\n",
      "\n",
      "Epoch 188:\n",
      "Training loss: 102.0407, Training accuracy: 0.2194\n",
      "Validation loss: 345.6280, Validation accuracy: 0.2348\n",
      "\n",
      "Epoch 189:\n",
      "Training loss: 102.0143, Training accuracy: 0.2190\n",
      "Validation loss: 267.4105, Validation accuracy: 0.2245\n",
      "\n",
      "Epoch 190:\n",
      "Training loss: 102.0242, Training accuracy: 0.2206\n",
      "Validation loss: 351.1277, Validation accuracy: 0.2176\n",
      "\n",
      "Epoch 191:\n",
      "Training loss: 102.0330, Training accuracy: 0.2230\n",
      "Validation loss: 406.8089, Validation accuracy: 0.2142\n",
      "\n",
      "Epoch 192:\n",
      "Training loss: 102.0001, Training accuracy: 0.2193\n",
      "Validation loss: 294.6877, Validation accuracy: 0.2326\n",
      "\n",
      "Epoch 193:\n",
      "Training loss: 102.0313, Training accuracy: 0.2218\n",
      "Validation loss: 335.3007, Validation accuracy: 0.2278\n",
      "\n",
      "Epoch 194:\n",
      "Training loss: 102.0569, Training accuracy: 0.2180\n",
      "Validation loss: 303.8894, Validation accuracy: 0.2379\n",
      "\n",
      "Epoch 195:\n",
      "Training loss: 102.0119, Training accuracy: 0.2231\n",
      "Validation loss: 312.3003, Validation accuracy: 0.2272\n",
      "\n",
      "Epoch 196:\n",
      "Training loss: 102.0291, Training accuracy: 0.2286\n",
      "Validation loss: 332.5152, Validation accuracy: 0.2375\n",
      "\n",
      "Epoch 197:\n",
      "Training loss: 102.0813, Training accuracy: 0.2204\n",
      "Validation loss: 483.5340, Validation accuracy: 0.2096\n",
      "\n",
      "Epoch 198:\n",
      "Training loss: 102.0294, Training accuracy: 0.2169\n",
      "Validation loss: 376.5434, Validation accuracy: 0.2331\n",
      "\n",
      "Epoch 199:\n",
      "Training loss: 102.0090, Training accuracy: 0.2262\n",
      "Validation loss: 358.7375, Validation accuracy: 0.2363\n",
      "\n",
      "==================================================\n",
      "==> Optimization finished! Best validation accuracy: 0.2544\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.2544"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train(student,teacher,optimizer,criterion,8,[0,1,0],1,train_loader,val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Training starts!\n",
      "==================================================\n",
      "Epoch 0:\n",
      "Training loss: 5.8541, Training accuracy: 0.3465\n",
      "Validation loss: 2.2467, Validation accuracy: 0.4461\n",
      "Saving ...\n",
      "\n",
      "Epoch 1:\n",
      "Training loss: 5.8493, Training accuracy: 0.4747\n",
      "Validation loss: 2.2316, Validation accuracy: 0.5216\n",
      "Saving ...\n",
      "\n",
      "Epoch 2:\n",
      "Training loss: 5.8478, Training accuracy: 0.5400\n",
      "Validation loss: 2.2165, Validation accuracy: 0.5579\n",
      "Saving ...\n",
      "\n",
      "Epoch 3:\n",
      "Training loss: 5.8465, Training accuracy: 0.5909\n",
      "Validation loss: 2.1990, Validation accuracy: 0.6020\n",
      "Saving ...\n",
      "\n",
      "Epoch 4:\n",
      "Training loss: 5.8455, Training accuracy: 0.6250\n",
      "Validation loss: 2.1881, Validation accuracy: 0.6407\n",
      "Saving ...\n",
      "\n",
      "Epoch 5:\n",
      "Training loss: 5.8447, Training accuracy: 0.6536\n",
      "Validation loss: 2.1804, Validation accuracy: 0.6625\n",
      "Saving ...\n",
      "\n",
      "Epoch 6:\n",
      "Training loss: 5.8440, Training accuracy: 0.6743\n",
      "Validation loss: 2.1719, Validation accuracy: 0.6777\n",
      "Saving ...\n",
      "\n",
      "Epoch 7:\n",
      "Training loss: 5.8434, Training accuracy: 0.6907\n",
      "Validation loss: 2.1675, Validation accuracy: 0.6869\n",
      "Saving ...\n",
      "\n",
      "Epoch 8:\n",
      "Training loss: 5.8429, Training accuracy: 0.7093\n",
      "Validation loss: 2.1654, Validation accuracy: 0.7097\n",
      "Saving ...\n",
      "\n",
      "Epoch 9:\n",
      "Training loss: 5.8424, Training accuracy: 0.7242\n",
      "Validation loss: 2.1603, Validation accuracy: 0.7174\n",
      "Saving ...\n",
      "\n",
      "Epoch 10:\n",
      "Training loss: 5.8420, Training accuracy: 0.7385\n",
      "Validation loss: 2.1582, Validation accuracy: 0.7435\n",
      "Saving ...\n",
      "\n",
      "Epoch 11:\n",
      "Training loss: 5.8417, Training accuracy: 0.7486\n",
      "Validation loss: 2.1539, Validation accuracy: 0.7517\n",
      "Saving ...\n",
      "\n",
      "Epoch 12:\n",
      "Training loss: 5.8414, Training accuracy: 0.7574\n",
      "Validation loss: 2.1529, Validation accuracy: 0.7540\n",
      "Saving ...\n",
      "\n",
      "Epoch 13:\n",
      "Training loss: 5.8411, Training accuracy: 0.7668\n",
      "Validation loss: 2.1489, Validation accuracy: 0.7665\n",
      "Saving ...\n",
      "\n",
      "Epoch 14:\n",
      "Training loss: 5.8408, Training accuracy: 0.7753\n",
      "Validation loss: 2.1467, Validation accuracy: 0.7688\n",
      "Saving ...\n",
      "\n",
      "Epoch 15:\n",
      "Training loss: 5.8406, Training accuracy: 0.7811\n",
      "Validation loss: 2.1431, Validation accuracy: 0.7733\n",
      "Saving ...\n",
      "\n",
      "Epoch 16:\n",
      "Training loss: 5.8404, Training accuracy: 0.7831\n",
      "Validation loss: 2.1409, Validation accuracy: 0.7823\n",
      "Saving ...\n",
      "\n",
      "Epoch 17:\n",
      "Training loss: 5.8402, Training accuracy: 0.7917\n",
      "Validation loss: 2.1376, Validation accuracy: 0.7872\n",
      "Saving ...\n",
      "\n",
      "Epoch 18:\n",
      "Training loss: 5.8400, Training accuracy: 0.7960\n",
      "Validation loss: 2.1392, Validation accuracy: 0.7934\n",
      "Saving ...\n",
      "\n",
      "Epoch 19:\n",
      "Training loss: 5.8399, Training accuracy: 0.7996\n",
      "Validation loss: 2.1368, Validation accuracy: 0.7920\n",
      "\n",
      "Epoch 20:\n",
      "Training loss: 5.8397, Training accuracy: 0.8039\n",
      "Validation loss: 2.1373, Validation accuracy: 0.7979\n",
      "Saving ...\n",
      "\n",
      "Epoch 21:\n",
      "Training loss: 5.8395, Training accuracy: 0.8091\n",
      "Validation loss: 2.1293, Validation accuracy: 0.8033\n",
      "Saving ...\n",
      "\n",
      "Epoch 22:\n",
      "Training loss: 5.8394, Training accuracy: 0.8111\n",
      "Validation loss: 2.1319, Validation accuracy: 0.8052\n",
      "Saving ...\n",
      "\n",
      "Epoch 23:\n",
      "Training loss: 5.8394, Training accuracy: 0.8150\n",
      "Validation loss: 2.1316, Validation accuracy: 0.8014\n",
      "\n",
      "Epoch 24:\n",
      "Training loss: 5.8392, Training accuracy: 0.8166\n",
      "Validation loss: 2.1300, Validation accuracy: 0.8107\n",
      "Saving ...\n",
      "\n",
      "Epoch 25:\n",
      "Training loss: 5.8391, Training accuracy: 0.8209\n",
      "Validation loss: 2.1299, Validation accuracy: 0.8055\n",
      "\n",
      "Epoch 26:\n",
      "Training loss: 5.8390, Training accuracy: 0.8227\n",
      "Validation loss: 2.1278, Validation accuracy: 0.8152\n",
      "Saving ...\n",
      "\n",
      "Epoch 27:\n",
      "Training loss: 5.8389, Training accuracy: 0.8248\n",
      "Validation loss: 2.1261, Validation accuracy: 0.8198\n",
      "Saving ...\n",
      "\n",
      "Epoch 28:\n",
      "Training loss: 5.8388, Training accuracy: 0.8277\n",
      "Validation loss: 2.1281, Validation accuracy: 0.8144\n",
      "\n",
      "Epoch 29:\n",
      "Training loss: 5.8386, Training accuracy: 0.8319\n",
      "Validation loss: 2.1241, Validation accuracy: 0.8232\n",
      "Saving ...\n",
      "\n",
      "Epoch 30:\n",
      "Training loss: 5.8386, Training accuracy: 0.8312\n",
      "Validation loss: 2.1216, Validation accuracy: 0.8240\n",
      "Saving ...\n",
      "\n",
      "Epoch 31:\n",
      "Training loss: 5.8386, Training accuracy: 0.8344\n",
      "Validation loss: 2.1241, Validation accuracy: 0.8277\n",
      "Saving ...\n",
      "\n",
      "Epoch 32:\n",
      "Training loss: 5.8385, Training accuracy: 0.8349\n",
      "Validation loss: 2.1257, Validation accuracy: 0.8277\n",
      "\n",
      "Epoch 33:\n",
      "Training loss: 5.8384, Training accuracy: 0.8399\n",
      "Validation loss: 2.1255, Validation accuracy: 0.8331\n",
      "Saving ...\n",
      "\n",
      "Epoch 34:\n",
      "Training loss: 5.8383, Training accuracy: 0.8397\n",
      "Validation loss: 2.1243, Validation accuracy: 0.8264\n",
      "\n",
      "Epoch 35:\n",
      "Training loss: 5.8382, Training accuracy: 0.8422\n",
      "Validation loss: 2.1226, Validation accuracy: 0.8383\n",
      "Saving ...\n",
      "\n",
      "Epoch 36:\n",
      "Training loss: 5.8382, Training accuracy: 0.8441\n",
      "Validation loss: 2.1245, Validation accuracy: 0.8333\n",
      "\n",
      "Epoch 37:\n",
      "Training loss: 5.8381, Training accuracy: 0.8457\n",
      "Validation loss: 2.1240, Validation accuracy: 0.8349\n",
      "\n",
      "Epoch 38:\n",
      "Training loss: 5.8380, Training accuracy: 0.8487\n",
      "Validation loss: 2.1221, Validation accuracy: 0.8354\n",
      "\n",
      "Epoch 39:\n",
      "Training loss: 5.8380, Training accuracy: 0.8485\n",
      "Validation loss: 2.1243, Validation accuracy: 0.8371\n",
      "\n",
      "Epoch 40:\n",
      "Training loss: 5.8379, Training accuracy: 0.8504\n",
      "Validation loss: 2.1180, Validation accuracy: 0.8414\n",
      "Saving ...\n",
      "\n",
      "Epoch 41:\n",
      "Training loss: 5.8378, Training accuracy: 0.8515\n",
      "Validation loss: 2.1205, Validation accuracy: 0.8372\n",
      "\n",
      "Epoch 42:\n",
      "Training loss: 5.8378, Training accuracy: 0.8506\n",
      "Validation loss: 2.1189, Validation accuracy: 0.8380\n",
      "\n",
      "Epoch 43:\n",
      "Training loss: 5.8377, Training accuracy: 0.8525\n",
      "Validation loss: 2.1190, Validation accuracy: 0.8403\n",
      "\n",
      "Epoch 44:\n",
      "Training loss: 5.8377, Training accuracy: 0.8546\n",
      "Validation loss: 2.1175, Validation accuracy: 0.8389\n",
      "\n",
      "Epoch 45:\n",
      "Training loss: 5.8376, Training accuracy: 0.8547\n",
      "Validation loss: 2.1162, Validation accuracy: 0.8409\n",
      "\n",
      "Epoch 46:\n",
      "Training loss: 5.8376, Training accuracy: 0.8587\n",
      "Validation loss: 2.1185, Validation accuracy: 0.8423\n",
      "Saving ...\n",
      "\n",
      "Epoch 47:\n",
      "Training loss: 5.8376, Training accuracy: 0.8567\n",
      "Validation loss: 2.1155, Validation accuracy: 0.8380\n",
      "\n",
      "Epoch 48:\n",
      "Training loss: 5.8375, Training accuracy: 0.8613\n",
      "Validation loss: 2.1169, Validation accuracy: 0.8418\n",
      "\n",
      "Epoch 49:\n",
      "Training loss: 5.8374, Training accuracy: 0.8622\n",
      "Validation loss: 2.1150, Validation accuracy: 0.8411\n",
      "\n",
      "Epoch 50:\n",
      "Training loss: 5.8374, Training accuracy: 0.8625\n",
      "Validation loss: 2.1131, Validation accuracy: 0.8460\n",
      "Saving ...\n",
      "\n",
      "Epoch 51:\n",
      "Training loss: 5.8374, Training accuracy: 0.8627\n",
      "Validation loss: 2.1133, Validation accuracy: 0.8430\n",
      "\n",
      "Epoch 52:\n",
      "Training loss: 5.8373, Training accuracy: 0.8653\n",
      "Validation loss: 2.1163, Validation accuracy: 0.8408\n",
      "\n",
      "Epoch 53:\n",
      "Training loss: 5.8373, Training accuracy: 0.8661\n",
      "Validation loss: 2.1169, Validation accuracy: 0.8424\n",
      "\n",
      "Epoch 54:\n",
      "Training loss: 5.8373, Training accuracy: 0.8656\n",
      "Validation loss: 2.1170, Validation accuracy: 0.8390\n",
      "\n",
      "Epoch 55:\n",
      "Training loss: 5.8372, Training accuracy: 0.8652\n",
      "Validation loss: 2.1155, Validation accuracy: 0.8456\n",
      "\n",
      "Epoch 56:\n",
      "Training loss: 5.8372, Training accuracy: 0.8671\n",
      "Validation loss: 2.1163, Validation accuracy: 0.8490\n",
      "Saving ...\n",
      "\n",
      "Epoch 57:\n",
      "Training loss: 5.8372, Training accuracy: 0.8662\n",
      "Validation loss: 2.1181, Validation accuracy: 0.8468\n",
      "\n",
      "Epoch 58:\n",
      "Training loss: 5.8371, Training accuracy: 0.8674\n",
      "Validation loss: 2.1118, Validation accuracy: 0.8511\n",
      "Saving ...\n",
      "\n",
      "Epoch 59:\n",
      "Training loss: 5.8371, Training accuracy: 0.8686\n",
      "Validation loss: 2.1120, Validation accuracy: 0.8507\n",
      "\n",
      "Epoch 60:\n",
      "Training loss: 5.8371, Training accuracy: 0.8714\n",
      "Validation loss: 2.1145, Validation accuracy: 0.8544\n",
      "Saving ...\n",
      "\n",
      "Epoch 61:\n",
      "Training loss: 5.8371, Training accuracy: 0.8716\n",
      "Validation loss: 2.1120, Validation accuracy: 0.8487\n",
      "\n",
      "Epoch 62:\n",
      "Training loss: 5.8370, Training accuracy: 0.8725\n",
      "Validation loss: 2.1128, Validation accuracy: 0.8541\n",
      "\n",
      "Epoch 63:\n",
      "Training loss: 5.8370, Training accuracy: 0.8729\n",
      "Validation loss: 2.1107, Validation accuracy: 0.8524\n",
      "\n",
      "Epoch 64:\n",
      "Training loss: 5.8370, Training accuracy: 0.8732\n",
      "Validation loss: 2.1125, Validation accuracy: 0.8558\n",
      "Saving ...\n",
      "\n",
      "Epoch 65:\n",
      "Training loss: 5.8369, Training accuracy: 0.8741\n",
      "Validation loss: 2.1110, Validation accuracy: 0.8558\n",
      "\n",
      "Epoch 66:\n",
      "Training loss: 5.8369, Training accuracy: 0.8746\n",
      "Validation loss: 2.1129, Validation accuracy: 0.8501\n",
      "\n",
      "Epoch 67:\n",
      "Training loss: 5.8369, Training accuracy: 0.8753\n",
      "Validation loss: 2.1136, Validation accuracy: 0.8548\n",
      "\n",
      "Epoch 68:\n",
      "Training loss: 5.8368, Training accuracy: 0.8774\n",
      "Validation loss: 2.1117, Validation accuracy: 0.8524\n",
      "\n",
      "Epoch 69:\n",
      "Training loss: 5.8367, Training accuracy: 0.8782\n",
      "Validation loss: 2.1105, Validation accuracy: 0.8554\n",
      "\n",
      "Epoch 70:\n",
      "Training loss: 5.8367, Training accuracy: 0.8770\n",
      "Validation loss: 2.1121, Validation accuracy: 0.8565\n",
      "Saving ...\n",
      "\n",
      "Epoch 71:\n",
      "Training loss: 5.8367, Training accuracy: 0.8787\n",
      "Validation loss: 2.1094, Validation accuracy: 0.8577\n",
      "Saving ...\n",
      "\n",
      "Epoch 72:\n",
      "Training loss: 5.8367, Training accuracy: 0.8777\n",
      "Validation loss: 2.1151, Validation accuracy: 0.8564\n",
      "\n",
      "Epoch 73:\n",
      "Training loss: 5.8367, Training accuracy: 0.8794\n",
      "Validation loss: 2.1092, Validation accuracy: 0.8513\n",
      "\n",
      "Epoch 74:\n",
      "Training loss: 5.8367, Training accuracy: 0.8777\n",
      "Validation loss: 2.1110, Validation accuracy: 0.8540\n",
      "\n",
      "Epoch 75:\n",
      "Training loss: 5.8366, Training accuracy: 0.8807\n",
      "Validation loss: 2.1134, Validation accuracy: 0.8606\n",
      "Saving ...\n",
      "\n",
      "Epoch 76:\n",
      "Training loss: 5.8366, Training accuracy: 0.8802\n",
      "Validation loss: 2.1130, Validation accuracy: 0.8570\n",
      "\n",
      "Epoch 77:\n",
      "Training loss: 5.8366, Training accuracy: 0.8807\n",
      "Validation loss: 2.1081, Validation accuracy: 0.8586\n",
      "\n",
      "Epoch 78:\n",
      "Training loss: 5.8365, Training accuracy: 0.8825\n",
      "Validation loss: 2.1119, Validation accuracy: 0.8578\n",
      "\n",
      "Epoch 79:\n",
      "Training loss: 5.8365, Training accuracy: 0.8830\n",
      "Validation loss: 2.1098, Validation accuracy: 0.8573\n",
      "\n",
      "Epoch 80:\n",
      "Training loss: 5.8365, Training accuracy: 0.8841\n",
      "Validation loss: 2.1107, Validation accuracy: 0.8588\n",
      "\n",
      "Epoch 81:\n",
      "Training loss: 5.8365, Training accuracy: 0.8846\n",
      "Validation loss: 2.1128, Validation accuracy: 0.8628\n",
      "Saving ...\n",
      "\n",
      "Epoch 82:\n",
      "Training loss: 5.8365, Training accuracy: 0.8828\n",
      "Validation loss: 2.1095, Validation accuracy: 0.8630\n",
      "Saving ...\n",
      "\n",
      "Epoch 83:\n",
      "Training loss: 5.8364, Training accuracy: 0.8841\n",
      "Validation loss: 2.1064, Validation accuracy: 0.8569\n",
      "\n",
      "Epoch 84:\n",
      "Training loss: 5.8364, Training accuracy: 0.8854\n",
      "Validation loss: 2.1133, Validation accuracy: 0.8519\n",
      "\n",
      "Epoch 85:\n",
      "Training loss: 5.8364, Training accuracy: 0.8871\n",
      "Validation loss: 2.1161, Validation accuracy: 0.8543\n",
      "\n",
      "Epoch 86:\n",
      "Training loss: 5.8363, Training accuracy: 0.8857\n",
      "Validation loss: 2.1129, Validation accuracy: 0.8621\n",
      "\n",
      "Epoch 87:\n",
      "Training loss: 5.8364, Training accuracy: 0.8849\n",
      "Validation loss: 2.1130, Validation accuracy: 0.8539\n",
      "\n",
      "Epoch 88:\n",
      "Training loss: 5.8363, Training accuracy: 0.8886\n",
      "Validation loss: 2.1063, Validation accuracy: 0.8607\n",
      "\n",
      "Epoch 89:\n",
      "Training loss: 5.8363, Training accuracy: 0.8872\n",
      "Validation loss: 2.1113, Validation accuracy: 0.8613\n",
      "\n",
      "Epoch 90:\n",
      "Training loss: 5.8363, Training accuracy: 0.8861\n",
      "Validation loss: 2.1133, Validation accuracy: 0.8612\n",
      "\n",
      "Epoch 91:\n",
      "Training loss: 5.8363, Training accuracy: 0.8890\n",
      "Validation loss: 2.1076, Validation accuracy: 0.8628\n",
      "\n",
      "Epoch 92:\n",
      "Training loss: 5.8363, Training accuracy: 0.8890\n",
      "Validation loss: 2.1082, Validation accuracy: 0.8586\n",
      "\n",
      "Epoch 93:\n",
      "Training loss: 5.8362, Training accuracy: 0.8901\n",
      "Validation loss: 2.1080, Validation accuracy: 0.8658\n",
      "Saving ...\n",
      "\n",
      "Epoch 94:\n",
      "Training loss: 5.8362, Training accuracy: 0.8884\n",
      "Validation loss: 2.1060, Validation accuracy: 0.8691\n",
      "Saving ...\n",
      "\n",
      "Epoch 95:\n",
      "Training loss: 5.8361, Training accuracy: 0.8895\n",
      "Validation loss: 2.1066, Validation accuracy: 0.8568\n",
      "\n",
      "Epoch 96:\n",
      "Training loss: 5.8362, Training accuracy: 0.8898\n",
      "Validation loss: 2.1049, Validation accuracy: 0.8659\n",
      "\n",
      "Epoch 97:\n",
      "Training loss: 5.8362, Training accuracy: 0.8906\n",
      "Validation loss: 2.1082, Validation accuracy: 0.8617\n",
      "\n",
      "Epoch 98:\n",
      "Training loss: 5.8361, Training accuracy: 0.8919\n",
      "Validation loss: 2.1090, Validation accuracy: 0.8629\n",
      "\n",
      "Epoch 99:\n",
      "Training loss: 5.8361, Training accuracy: 0.8920\n",
      "Validation loss: 2.1088, Validation accuracy: 0.8675\n",
      "\n",
      "Epoch 100:\n",
      "Training loss: 5.8361, Training accuracy: 0.8912\n",
      "Validation loss: 2.1123, Validation accuracy: 0.8665\n",
      "\n",
      "Epoch 101:\n",
      "Training loss: 5.8361, Training accuracy: 0.8922\n",
      "Validation loss: 2.1036, Validation accuracy: 0.8631\n",
      "\n",
      "Epoch 102:\n",
      "Training loss: 5.8361, Training accuracy: 0.8935\n",
      "Validation loss: 2.1051, Validation accuracy: 0.8600\n",
      "\n",
      "Epoch 103:\n",
      "Training loss: 5.8360, Training accuracy: 0.8936\n",
      "Validation loss: 2.1095, Validation accuracy: 0.8627\n",
      "\n",
      "Epoch 104:\n",
      "Training loss: 5.8360, Training accuracy: 0.8951\n",
      "Validation loss: 2.1072, Validation accuracy: 0.8632\n",
      "\n",
      "Epoch 105:\n",
      "Training loss: 5.8360, Training accuracy: 0.8950\n",
      "Validation loss: 2.1058, Validation accuracy: 0.8687\n",
      "\n",
      "Epoch 106:\n",
      "Training loss: 5.8360, Training accuracy: 0.8930\n",
      "Validation loss: 2.1058, Validation accuracy: 0.8707\n",
      "Saving ...\n",
      "\n",
      "Epoch 107:\n",
      "Training loss: 5.8359, Training accuracy: 0.8945\n",
      "Validation loss: 2.1053, Validation accuracy: 0.8638\n",
      "\n",
      "Epoch 108:\n",
      "Training loss: 5.8360, Training accuracy: 0.8948\n",
      "Validation loss: 2.1081, Validation accuracy: 0.8679\n",
      "\n",
      "Epoch 109:\n",
      "Training loss: 5.8360, Training accuracy: 0.8963\n",
      "Validation loss: 2.1075, Validation accuracy: 0.8658\n",
      "\n",
      "Epoch 110:\n",
      "Training loss: 5.8360, Training accuracy: 0.8960\n",
      "Validation loss: 2.1075, Validation accuracy: 0.8627\n",
      "\n",
      "Epoch 111:\n",
      "Training loss: 5.8359, Training accuracy: 0.8963\n",
      "Validation loss: 2.1084, Validation accuracy: 0.8675\n",
      "\n",
      "Epoch 112:\n",
      "Training loss: 5.8359, Training accuracy: 0.8962\n",
      "Validation loss: 2.1117, Validation accuracy: 0.8636\n",
      "\n",
      "Epoch 113:\n",
      "Training loss: 5.8359, Training accuracy: 0.8967\n",
      "Validation loss: 2.1064, Validation accuracy: 0.8684\n",
      "\n",
      "Epoch 114:\n",
      "Training loss: 5.8359, Training accuracy: 0.8972\n",
      "Validation loss: 2.1014, Validation accuracy: 0.8673\n",
      "\n",
      "Epoch 115:\n",
      "Training loss: 5.8359, Training accuracy: 0.8966\n",
      "Validation loss: 2.1089, Validation accuracy: 0.8682\n",
      "\n",
      "Epoch 116:\n",
      "Training loss: 5.8358, Training accuracy: 0.8986\n",
      "Validation loss: 2.1050, Validation accuracy: 0.8710\n",
      "Saving ...\n",
      "\n",
      "Epoch 117:\n",
      "Training loss: 5.8359, Training accuracy: 0.8993\n",
      "Validation loss: 2.1063, Validation accuracy: 0.8666\n",
      "\n",
      "Epoch 118:\n",
      "Training loss: 5.8358, Training accuracy: 0.8997\n",
      "Validation loss: 2.1037, Validation accuracy: 0.8704\n",
      "\n",
      "Epoch 119:\n",
      "Training loss: 5.8358, Training accuracy: 0.8989\n",
      "Validation loss: 2.1050, Validation accuracy: 0.8736\n",
      "Saving ...\n",
      "\n",
      "Epoch 120:\n",
      "Training loss: 5.8358, Training accuracy: 0.8986\n",
      "Validation loss: 2.1058, Validation accuracy: 0.8670\n",
      "\n",
      "Epoch 121:\n",
      "Training loss: 5.8357, Training accuracy: 0.9003\n",
      "Validation loss: 2.1045, Validation accuracy: 0.8676\n",
      "\n",
      "Epoch 122:\n",
      "Training loss: 5.8358, Training accuracy: 0.9011\n",
      "Validation loss: 2.1059, Validation accuracy: 0.8668\n",
      "\n",
      "Epoch 123:\n",
      "Training loss: 5.8358, Training accuracy: 0.8978\n",
      "Validation loss: 2.1054, Validation accuracy: 0.8728\n",
      "\n",
      "Epoch 124:\n",
      "Training loss: 5.8357, Training accuracy: 0.9013\n",
      "Validation loss: 2.1083, Validation accuracy: 0.8695\n",
      "\n",
      "Epoch 125:\n",
      "Training loss: 5.8357, Training accuracy: 0.9008\n",
      "Validation loss: 2.1072, Validation accuracy: 0.8668\n",
      "\n",
      "Epoch 126:\n",
      "Training loss: 5.8357, Training accuracy: 0.9018\n",
      "Validation loss: 2.1046, Validation accuracy: 0.8636\n",
      "\n",
      "Epoch 127:\n",
      "Training loss: 5.8357, Training accuracy: 0.9010\n",
      "Validation loss: 2.1044, Validation accuracy: 0.8711\n",
      "\n",
      "Epoch 128:\n",
      "Training loss: 5.8357, Training accuracy: 0.9025\n",
      "Validation loss: 2.1080, Validation accuracy: 0.8705\n",
      "\n",
      "Epoch 129:\n",
      "Training loss: 5.8357, Training accuracy: 0.9031\n",
      "Validation loss: 2.1042, Validation accuracy: 0.8701\n",
      "\n",
      "Epoch 130:\n",
      "Training loss: 5.8356, Training accuracy: 0.9033\n",
      "Validation loss: 2.1051, Validation accuracy: 0.8705\n",
      "\n",
      "Epoch 131:\n",
      "Training loss: 5.8357, Training accuracy: 0.9035\n",
      "Validation loss: 2.1031, Validation accuracy: 0.8712\n",
      "\n",
      "Epoch 132:\n",
      "Training loss: 5.8356, Training accuracy: 0.9036\n",
      "Validation loss: 2.1029, Validation accuracy: 0.8738\n",
      "Saving ...\n",
      "\n",
      "Epoch 133:\n",
      "Training loss: 5.8356, Training accuracy: 0.9032\n",
      "Validation loss: 2.1038, Validation accuracy: 0.8692\n",
      "\n",
      "Epoch 134:\n",
      "Training loss: 5.8356, Training accuracy: 0.9040\n",
      "Validation loss: 2.1037, Validation accuracy: 0.8729\n",
      "\n",
      "Epoch 135:\n",
      "Training loss: 5.8356, Training accuracy: 0.9050\n",
      "Validation loss: 2.1095, Validation accuracy: 0.8675\n",
      "\n",
      "Epoch 136:\n",
      "Training loss: 5.8356, Training accuracy: 0.9049\n",
      "Validation loss: 2.1061, Validation accuracy: 0.8702\n",
      "\n",
      "Epoch 137:\n",
      "Training loss: 5.8356, Training accuracy: 0.9045\n",
      "Validation loss: 2.1058, Validation accuracy: 0.8660\n",
      "\n",
      "Epoch 138:\n",
      "Training loss: 5.8355, Training accuracy: 0.9045\n",
      "Validation loss: 2.1037, Validation accuracy: 0.8698\n",
      "\n",
      "Epoch 139:\n",
      "Training loss: 5.8356, Training accuracy: 0.9062\n",
      "Validation loss: 2.1086, Validation accuracy: 0.8647\n",
      "\n",
      "Epoch 140:\n",
      "Training loss: 5.8355, Training accuracy: 0.9055\n",
      "Validation loss: 2.1053, Validation accuracy: 0.8667\n",
      "\n",
      "Epoch 141:\n",
      "Training loss: 5.8355, Training accuracy: 0.9060\n",
      "Validation loss: 2.1065, Validation accuracy: 0.8633\n",
      "\n",
      "Epoch 142:\n",
      "Training loss: 5.8356, Training accuracy: 0.9062\n",
      "Validation loss: 2.1027, Validation accuracy: 0.8746\n",
      "Saving ...\n",
      "\n",
      "Epoch 143:\n",
      "Training loss: 5.8356, Training accuracy: 0.9069\n",
      "Validation loss: 2.1101, Validation accuracy: 0.8736\n",
      "\n",
      "Epoch 144:\n",
      "Training loss: 5.8355, Training accuracy: 0.9059\n",
      "Validation loss: 2.1019, Validation accuracy: 0.8658\n",
      "\n",
      "Epoch 145:\n",
      "Training loss: 5.8355, Training accuracy: 0.9075\n",
      "Validation loss: 2.1021, Validation accuracy: 0.8729\n",
      "\n",
      "Epoch 146:\n",
      "Training loss: 5.8355, Training accuracy: 0.9064\n",
      "Validation loss: 2.1000, Validation accuracy: 0.8723\n",
      "\n",
      "Epoch 147:\n",
      "Training loss: 5.8355, Training accuracy: 0.9057\n",
      "Validation loss: 2.1035, Validation accuracy: 0.8700\n",
      "\n",
      "Epoch 148:\n",
      "Training loss: 5.8354, Training accuracy: 0.9088\n",
      "Validation loss: 2.1046, Validation accuracy: 0.8746\n",
      "\n",
      "Epoch 149:\n",
      "Training loss: 5.8355, Training accuracy: 0.9088\n",
      "Validation loss: 2.1050, Validation accuracy: 0.8743\n",
      "\n",
      "Epoch 150:\n",
      "Training loss: 5.8355, Training accuracy: 0.9089\n",
      "Validation loss: 2.1056, Validation accuracy: 0.8674\n",
      "\n",
      "Epoch 151:\n",
      "Training loss: 5.8355, Training accuracy: 0.9077\n",
      "Validation loss: 2.1048, Validation accuracy: 0.8705\n",
      "\n",
      "Epoch 152:\n",
      "Training loss: 5.8354, Training accuracy: 0.9087\n",
      "Validation loss: 2.1054, Validation accuracy: 0.8704\n",
      "\n",
      "Epoch 153:\n",
      "Training loss: 5.8354, Training accuracy: 0.9099\n",
      "Validation loss: 2.1031, Validation accuracy: 0.8739\n",
      "\n",
      "Epoch 154:\n",
      "Training loss: 5.8354, Training accuracy: 0.9093\n",
      "Validation loss: 2.1033, Validation accuracy: 0.8742\n",
      "\n",
      "Epoch 155:\n",
      "Training loss: 5.8354, Training accuracy: 0.9083\n",
      "Validation loss: 2.1058, Validation accuracy: 0.8743\n",
      "\n",
      "Epoch 156:\n",
      "Training loss: 5.8354, Training accuracy: 0.9092\n",
      "Validation loss: 2.1048, Validation accuracy: 0.8704\n",
      "\n",
      "Epoch 157:\n",
      "Training loss: 5.8354, Training accuracy: 0.9079\n",
      "Validation loss: 2.1001, Validation accuracy: 0.8739\n",
      "\n",
      "Epoch 158:\n",
      "Training loss: 5.8354, Training accuracy: 0.9090\n",
      "Validation loss: 2.1088, Validation accuracy: 0.8705\n",
      "\n",
      "Epoch 159:\n",
      "Training loss: 5.8354, Training accuracy: 0.9094\n",
      "Validation loss: 2.1043, Validation accuracy: 0.8629\n",
      "\n",
      "Epoch 160:\n",
      "Training loss: 5.8354, Training accuracy: 0.9086\n",
      "Validation loss: 2.1006, Validation accuracy: 0.8703\n",
      "\n",
      "Epoch 161:\n",
      "Training loss: 5.8354, Training accuracy: 0.9105\n",
      "Validation loss: 2.1001, Validation accuracy: 0.8752\n",
      "Saving ...\n",
      "\n",
      "Epoch 162:\n",
      "Training loss: 5.8353, Training accuracy: 0.9118\n",
      "Validation loss: 2.1016, Validation accuracy: 0.8695\n",
      "\n",
      "Epoch 163:\n",
      "Training loss: 5.8354, Training accuracy: 0.9106\n",
      "Validation loss: 2.1053, Validation accuracy: 0.8740\n",
      "\n",
      "Epoch 164:\n",
      "Training loss: 5.8353, Training accuracy: 0.9108\n",
      "Validation loss: 2.1034, Validation accuracy: 0.8742\n",
      "\n",
      "Epoch 165:\n",
      "Training loss: 5.8353, Training accuracy: 0.9110\n",
      "Validation loss: 2.1063, Validation accuracy: 0.8727\n",
      "\n",
      "Epoch 166:\n",
      "Training loss: 5.8353, Training accuracy: 0.9114\n",
      "Validation loss: 2.1026, Validation accuracy: 0.8740\n",
      "\n",
      "Epoch 167:\n",
      "Training loss: 5.8353, Training accuracy: 0.9122\n",
      "Validation loss: 2.1046, Validation accuracy: 0.8716\n",
      "\n",
      "Epoch 168:\n",
      "Training loss: 5.8353, Training accuracy: 0.9127\n",
      "Validation loss: 2.1033, Validation accuracy: 0.8779\n",
      "Saving ...\n",
      "\n",
      "Epoch 169:\n",
      "Training loss: 5.8353, Training accuracy: 0.9132\n",
      "Validation loss: 2.1055, Validation accuracy: 0.8674\n",
      "\n",
      "Epoch 170:\n",
      "Training loss: 5.8352, Training accuracy: 0.9116\n",
      "Validation loss: 2.1045, Validation accuracy: 0.8783\n",
      "Saving ...\n",
      "\n",
      "Epoch 171:\n",
      "Training loss: 5.8352, Training accuracy: 0.9124\n",
      "Validation loss: 2.1004, Validation accuracy: 0.8761\n",
      "\n",
      "Epoch 172:\n",
      "Training loss: 5.8352, Training accuracy: 0.9144\n",
      "Validation loss: 2.1042, Validation accuracy: 0.8743\n",
      "\n",
      "Epoch 173:\n",
      "Training loss: 5.8353, Training accuracy: 0.9121\n",
      "Validation loss: 2.1042, Validation accuracy: 0.8703\n",
      "\n",
      "Epoch 174:\n",
      "Training loss: 5.8352, Training accuracy: 0.9144\n",
      "Validation loss: 2.1051, Validation accuracy: 0.8697\n",
      "\n",
      "Epoch 175:\n",
      "Training loss: 5.8353, Training accuracy: 0.9138\n",
      "Validation loss: 2.1020, Validation accuracy: 0.8764\n",
      "\n",
      "Epoch 176:\n",
      "Training loss: 5.8352, Training accuracy: 0.9136\n",
      "Validation loss: 2.0991, Validation accuracy: 0.8759\n",
      "\n",
      "Epoch 177:\n",
      "Training loss: 5.8352, Training accuracy: 0.9147\n",
      "Validation loss: 2.1008, Validation accuracy: 0.8766\n",
      "\n",
      "Epoch 178:\n",
      "Training loss: 5.8351, Training accuracy: 0.9158\n",
      "Validation loss: 2.1060, Validation accuracy: 0.8693\n",
      "\n",
      "Epoch 179:\n",
      "Training loss: 5.8353, Training accuracy: 0.9160\n",
      "Validation loss: 2.1068, Validation accuracy: 0.8765\n",
      "\n",
      "Epoch 180:\n",
      "Training loss: 5.8352, Training accuracy: 0.9147\n",
      "Validation loss: 2.1026, Validation accuracy: 0.8790\n",
      "Saving ...\n",
      "\n",
      "Epoch 181:\n",
      "Training loss: 5.8352, Training accuracy: 0.9149\n",
      "Validation loss: 2.1064, Validation accuracy: 0.8726\n",
      "\n",
      "Epoch 182:\n",
      "Training loss: 5.8352, Training accuracy: 0.9164\n",
      "Validation loss: 2.0995, Validation accuracy: 0.8768\n",
      "\n",
      "Epoch 183:\n",
      "Training loss: 5.8352, Training accuracy: 0.9156\n",
      "Validation loss: 2.1022, Validation accuracy: 0.8763\n",
      "\n",
      "Epoch 184:\n",
      "Training loss: 5.8352, Training accuracy: 0.9161\n",
      "Validation loss: 2.1049, Validation accuracy: 0.8727\n",
      "\n",
      "Epoch 185:\n",
      "Training loss: 5.8352, Training accuracy: 0.9157\n",
      "Validation loss: 2.1041, Validation accuracy: 0.8701\n",
      "\n",
      "Epoch 186:\n",
      "Training loss: 5.8352, Training accuracy: 0.9157\n",
      "Validation loss: 2.1077, Validation accuracy: 0.8719\n",
      "\n",
      "Epoch 187:\n",
      "Training loss: 5.8352, Training accuracy: 0.9162\n",
      "Validation loss: 2.1038, Validation accuracy: 0.8732\n",
      "\n",
      "Epoch 188:\n",
      "Training loss: 5.8351, Training accuracy: 0.9168\n",
      "Validation loss: 2.1050, Validation accuracy: 0.8763\n",
      "\n",
      "Epoch 189:\n",
      "Training loss: 5.8351, Training accuracy: 0.9158\n",
      "Validation loss: 2.1048, Validation accuracy: 0.8751\n",
      "\n",
      "Epoch 190:\n",
      "Training loss: 5.8351, Training accuracy: 0.9162\n",
      "Validation loss: 2.1044, Validation accuracy: 0.8720\n",
      "\n",
      "Epoch 191:\n",
      "Training loss: 5.8352, Training accuracy: 0.9170\n",
      "Validation loss: 2.1038, Validation accuracy: 0.8752\n",
      "\n",
      "Epoch 192:\n",
      "Training loss: 5.8350, Training accuracy: 0.9178\n",
      "Validation loss: 2.1017, Validation accuracy: 0.8732\n",
      "\n",
      "Epoch 193:\n",
      "Training loss: 5.8351, Training accuracy: 0.9175\n",
      "Validation loss: 2.1043, Validation accuracy: 0.8745\n",
      "\n",
      "Epoch 194:\n",
      "Training loss: 5.8351, Training accuracy: 0.9172\n",
      "Validation loss: 2.1046, Validation accuracy: 0.8758\n",
      "\n",
      "Epoch 195:\n",
      "Training loss: 5.8352, Training accuracy: 0.9178\n",
      "Validation loss: 2.1027, Validation accuracy: 0.8763\n",
      "\n",
      "Epoch 196:\n",
      "Training loss: 5.8351, Training accuracy: 0.9182\n",
      "Validation loss: 2.0984, Validation accuracy: 0.8794\n",
      "Saving ...\n",
      "\n",
      "Epoch 197:\n",
      "Training loss: 5.8351, Training accuracy: 0.9171\n",
      "Validation loss: 2.1033, Validation accuracy: 0.8698\n",
      "\n",
      "Epoch 198:\n",
      "Training loss: 5.8351, Training accuracy: 0.9187\n",
      "Validation loss: 2.1016, Validation accuracy: 0.8745\n",
      "\n",
      "Epoch 199:\n",
      "Training loss: 5.8351, Training accuracy: 0.9189\n",
      "Validation loss: 2.1044, Validation accuracy: 0.8776\n",
      "\n",
      "==================================================\n",
      "==> Optimization finished! Best validation accuracy: 0.8794\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8794"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train(student,teacher,optimizer,criterion,1,[0,0,1],1,train_loader,val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Training starts!\n",
      "==================================================\n",
      "Epoch 0:\n",
      "Training loss: 23.2290, Training accuracy: 0.3860\n",
      "Validation loss: 2.2135, Validation accuracy: 0.4815\n",
      "Saving ...\n",
      "\n",
      "Epoch 1:\n",
      "Training loss: 23.2228, Training accuracy: 0.5219\n",
      "Validation loss: 2.1835, Validation accuracy: 0.5646\n",
      "Saving ...\n",
      "\n",
      "Epoch 2:\n",
      "Training loss: 23.2197, Training accuracy: 0.5834\n",
      "Validation loss: 2.1652, Validation accuracy: 0.5893\n",
      "Saving ...\n",
      "\n",
      "Epoch 3:\n",
      "Training loss: 23.2175, Training accuracy: 0.6286\n",
      "Validation loss: 2.1423, Validation accuracy: 0.6485\n",
      "Saving ...\n",
      "\n",
      "Epoch 4:\n",
      "Training loss: 23.2156, Training accuracy: 0.6680\n",
      "Validation loss: 2.1333, Validation accuracy: 0.6877\n",
      "Saving ...\n",
      "\n",
      "Epoch 5:\n",
      "Training loss: 23.2140, Training accuracy: 0.6961\n",
      "Validation loss: 2.1150, Validation accuracy: 0.7041\n",
      "Saving ...\n",
      "\n",
      "Epoch 6:\n",
      "Training loss: 23.2129, Training accuracy: 0.7185\n",
      "Validation loss: 2.1140, Validation accuracy: 0.7228\n",
      "Saving ...\n",
      "\n",
      "Epoch 7:\n",
      "Training loss: 23.2120, Training accuracy: 0.7352\n",
      "Validation loss: 2.1091, Validation accuracy: 0.7360\n",
      "Saving ...\n",
      "\n",
      "Epoch 8:\n",
      "Training loss: 23.2109, Training accuracy: 0.7503\n",
      "Validation loss: 2.0941, Validation accuracy: 0.7489\n",
      "Saving ...\n",
      "\n",
      "Epoch 9:\n",
      "Training loss: 23.2102, Training accuracy: 0.7616\n",
      "Validation loss: 2.0897, Validation accuracy: 0.7544\n",
      "Saving ...\n",
      "\n",
      "Epoch 10:\n",
      "Training loss: 23.2096, Training accuracy: 0.7713\n",
      "Validation loss: 2.0896, Validation accuracy: 0.7529\n",
      "\n",
      "Epoch 11:\n",
      "Training loss: 23.2090, Training accuracy: 0.7833\n",
      "Validation loss: 2.0879, Validation accuracy: 0.7726\n",
      "Saving ...\n",
      "\n",
      "Epoch 12:\n",
      "Training loss: 23.2086, Training accuracy: 0.7884\n",
      "Validation loss: 2.0840, Validation accuracy: 0.7869\n",
      "Saving ...\n",
      "\n",
      "Epoch 13:\n",
      "Training loss: 23.2080, Training accuracy: 0.7939\n",
      "Validation loss: 2.0786, Validation accuracy: 0.7862\n",
      "\n",
      "Epoch 14:\n",
      "Training loss: 23.2078, Training accuracy: 0.8000\n",
      "Validation loss: 2.0822, Validation accuracy: 0.7885\n",
      "Saving ...\n",
      "\n",
      "Epoch 15:\n",
      "Training loss: 23.2074, Training accuracy: 0.8040\n",
      "Validation loss: 2.0800, Validation accuracy: 0.8007\n",
      "Saving ...\n",
      "\n",
      "Epoch 16:\n",
      "Training loss: 23.2070, Training accuracy: 0.8092\n",
      "Validation loss: 2.0735, Validation accuracy: 0.7989\n",
      "\n",
      "Epoch 17:\n",
      "Training loss: 23.2068, Training accuracy: 0.8150\n",
      "Validation loss: 2.0694, Validation accuracy: 0.8077\n",
      "Saving ...\n",
      "\n",
      "Epoch 18:\n",
      "Training loss: 23.2065, Training accuracy: 0.8172\n",
      "Validation loss: 2.0599, Validation accuracy: 0.8093\n",
      "Saving ...\n",
      "\n",
      "Epoch 19:\n",
      "Training loss: 23.2061, Training accuracy: 0.8206\n",
      "Validation loss: 2.0696, Validation accuracy: 0.8051\n",
      "\n",
      "Epoch 20:\n",
      "Training loss: 23.2059, Training accuracy: 0.8261\n",
      "Validation loss: 2.0640, Validation accuracy: 0.8174\n",
      "Saving ...\n",
      "\n",
      "Epoch 21:\n",
      "Training loss: 23.2058, Training accuracy: 0.8271\n",
      "Validation loss: 2.0626, Validation accuracy: 0.8095\n",
      "\n",
      "Epoch 22:\n",
      "Training loss: 23.2054, Training accuracy: 0.8308\n",
      "Validation loss: 2.0582, Validation accuracy: 0.8285\n",
      "Saving ...\n",
      "\n",
      "Epoch 23:\n",
      "Training loss: 23.2054, Training accuracy: 0.8328\n",
      "Validation loss: 2.0642, Validation accuracy: 0.8121\n",
      "\n",
      "Epoch 24:\n",
      "Training loss: 23.2051, Training accuracy: 0.8347\n",
      "Validation loss: 2.0549, Validation accuracy: 0.8192\n",
      "\n",
      "Epoch 25:\n",
      "Training loss: 23.2052, Training accuracy: 0.8383\n",
      "Validation loss: 2.0561, Validation accuracy: 0.8302\n",
      "Saving ...\n",
      "\n",
      "Epoch 26:\n",
      "Training loss: 23.2049, Training accuracy: 0.8399\n",
      "Validation loss: 2.0516, Validation accuracy: 0.8307\n",
      "Saving ...\n",
      "\n",
      "Epoch 27:\n",
      "Training loss: 23.2047, Training accuracy: 0.8422\n",
      "Validation loss: 2.0535, Validation accuracy: 0.8308\n",
      "Saving ...\n",
      "\n",
      "Epoch 28:\n",
      "Training loss: 23.2047, Training accuracy: 0.8444\n",
      "Validation loss: 2.0547, Validation accuracy: 0.8339\n",
      "Saving ...\n",
      "\n",
      "Epoch 29:\n",
      "Training loss: 23.2043, Training accuracy: 0.8464\n",
      "Validation loss: 2.0545, Validation accuracy: 0.8323\n",
      "\n",
      "Epoch 30:\n",
      "Training loss: 23.2044, Training accuracy: 0.8487\n",
      "Validation loss: 2.0502, Validation accuracy: 0.8331\n",
      "\n",
      "Epoch 31:\n",
      "Training loss: 23.2041, Training accuracy: 0.8495\n",
      "Validation loss: 2.0529, Validation accuracy: 0.8373\n",
      "Saving ...\n",
      "\n",
      "Epoch 32:\n",
      "Training loss: 23.2041, Training accuracy: 0.8531\n",
      "Validation loss: 2.0519, Validation accuracy: 0.8334\n",
      "\n",
      "Epoch 33:\n",
      "Training loss: 23.2037, Training accuracy: 0.8526\n",
      "Validation loss: 2.0433, Validation accuracy: 0.8438\n",
      "Saving ...\n",
      "\n",
      "Epoch 34:\n",
      "Training loss: 23.2036, Training accuracy: 0.8566\n",
      "Validation loss: 2.0486, Validation accuracy: 0.8369\n",
      "\n",
      "Epoch 35:\n",
      "Training loss: 23.2037, Training accuracy: 0.8573\n",
      "Validation loss: 2.0414, Validation accuracy: 0.8435\n",
      "\n",
      "Epoch 36:\n",
      "Training loss: 23.2034, Training accuracy: 0.8589\n",
      "Validation loss: 2.0470, Validation accuracy: 0.8435\n",
      "\n",
      "Epoch 37:\n",
      "Training loss: 23.2036, Training accuracy: 0.8588\n",
      "Validation loss: 2.0446, Validation accuracy: 0.8408\n",
      "\n",
      "Epoch 38:\n",
      "Training loss: 23.2034, Training accuracy: 0.8605\n",
      "Validation loss: 2.0458, Validation accuracy: 0.8405\n",
      "\n",
      "Epoch 39:\n",
      "Training loss: 23.2031, Training accuracy: 0.8623\n",
      "Validation loss: 2.0444, Validation accuracy: 0.8373\n",
      "\n",
      "Epoch 40:\n",
      "Training loss: 23.2032, Training accuracy: 0.8617\n",
      "Validation loss: 2.0460, Validation accuracy: 0.8328\n",
      "\n",
      "Epoch 41:\n",
      "Training loss: 23.2033, Training accuracy: 0.8651\n",
      "Validation loss: 2.0401, Validation accuracy: 0.8487\n",
      "Saving ...\n",
      "\n",
      "Epoch 42:\n",
      "Training loss: 23.2030, Training accuracy: 0.8656\n",
      "Validation loss: 2.0380, Validation accuracy: 0.8434\n",
      "\n",
      "Epoch 43:\n",
      "Training loss: 23.2028, Training accuracy: 0.8684\n",
      "Validation loss: 2.0502, Validation accuracy: 0.8515\n",
      "Saving ...\n",
      "\n",
      "Epoch 44:\n",
      "Training loss: 23.2028, Training accuracy: 0.8675\n",
      "Validation loss: 2.0474, Validation accuracy: 0.8511\n",
      "\n",
      "Epoch 45:\n",
      "Training loss: 23.2027, Training accuracy: 0.8696\n",
      "Validation loss: 2.0388, Validation accuracy: 0.8464\n",
      "\n",
      "Epoch 46:\n",
      "Training loss: 23.2028, Training accuracy: 0.8688\n",
      "Validation loss: 2.0446, Validation accuracy: 0.8521\n",
      "Saving ...\n",
      "\n",
      "Epoch 47:\n",
      "Training loss: 23.2027, Training accuracy: 0.8714\n",
      "Validation loss: 2.0382, Validation accuracy: 0.8515\n",
      "\n",
      "Epoch 48:\n",
      "Training loss: 23.2027, Training accuracy: 0.8691\n",
      "Validation loss: 2.0346, Validation accuracy: 0.8516\n",
      "\n",
      "Epoch 49:\n",
      "Training loss: 23.2024, Training accuracy: 0.8714\n",
      "Validation loss: 2.0365, Validation accuracy: 0.8530\n",
      "Saving ...\n",
      "\n",
      "Epoch 50:\n",
      "Training loss: 23.2025, Training accuracy: 0.8742\n",
      "Validation loss: 2.0414, Validation accuracy: 0.8518\n",
      "\n",
      "Epoch 51:\n",
      "Training loss: 23.2022, Training accuracy: 0.8733\n",
      "Validation loss: 2.0375, Validation accuracy: 0.8557\n",
      "Saving ...\n",
      "\n",
      "Epoch 52:\n",
      "Training loss: 23.2024, Training accuracy: 0.8746\n",
      "Validation loss: 2.0397, Validation accuracy: 0.8537\n",
      "\n",
      "Epoch 53:\n",
      "Training loss: 23.2023, Training accuracy: 0.8758\n",
      "Validation loss: 2.0393, Validation accuracy: 0.8593\n",
      "Saving ...\n",
      "\n",
      "Epoch 54:\n",
      "Training loss: 23.2021, Training accuracy: 0.8797\n",
      "Validation loss: 2.0440, Validation accuracy: 0.8602\n",
      "Saving ...\n",
      "\n",
      "Epoch 55:\n",
      "Training loss: 23.2021, Training accuracy: 0.8752\n",
      "Validation loss: 2.0396, Validation accuracy: 0.8497\n",
      "\n",
      "Epoch 56:\n",
      "Training loss: 23.2021, Training accuracy: 0.8780\n",
      "Validation loss: 2.0320, Validation accuracy: 0.8579\n",
      "\n",
      "Epoch 57:\n",
      "Training loss: 23.2022, Training accuracy: 0.8774\n",
      "Validation loss: 2.0419, Validation accuracy: 0.8539\n",
      "\n",
      "Epoch 58:\n",
      "Training loss: 23.2020, Training accuracy: 0.8793\n",
      "Validation loss: 2.0393, Validation accuracy: 0.8441\n",
      "\n",
      "Epoch 59:\n",
      "Training loss: 23.2018, Training accuracy: 0.8802\n",
      "Validation loss: 2.0408, Validation accuracy: 0.8616\n",
      "Saving ...\n",
      "\n",
      "Epoch 60:\n",
      "Training loss: 23.2019, Training accuracy: 0.8820\n",
      "Validation loss: 2.0330, Validation accuracy: 0.8635\n",
      "Saving ...\n",
      "\n",
      "Epoch 61:\n",
      "Training loss: 23.2018, Training accuracy: 0.8813\n",
      "Validation loss: 2.0332, Validation accuracy: 0.8628\n",
      "\n",
      "Epoch 62:\n",
      "Training loss: 23.2017, Training accuracy: 0.8830\n",
      "Validation loss: 2.0368, Validation accuracy: 0.8609\n",
      "\n",
      "Epoch 63:\n",
      "Training loss: 23.2016, Training accuracy: 0.8843\n",
      "Validation loss: 2.0382, Validation accuracy: 0.8619\n",
      "\n",
      "Epoch 64:\n",
      "Training loss: 23.2017, Training accuracy: 0.8841\n",
      "Validation loss: 2.0360, Validation accuracy: 0.8507\n",
      "\n",
      "Epoch 65:\n",
      "Training loss: 23.2015, Training accuracy: 0.8841\n",
      "Validation loss: 2.0366, Validation accuracy: 0.8597\n",
      "\n",
      "Epoch 66:\n",
      "Training loss: 23.2014, Training accuracy: 0.8856\n",
      "Validation loss: 2.0316, Validation accuracy: 0.8596\n",
      "\n",
      "Epoch 67:\n",
      "Training loss: 23.2015, Training accuracy: 0.8852\n",
      "Validation loss: 2.0342, Validation accuracy: 0.8537\n",
      "\n",
      "Epoch 68:\n",
      "Training loss: 23.2016, Training accuracy: 0.8871\n",
      "Validation loss: 2.0312, Validation accuracy: 0.8623\n",
      "\n",
      "Epoch 69:\n",
      "Training loss: 23.2013, Training accuracy: 0.8861\n",
      "Validation loss: 2.0336, Validation accuracy: 0.8607\n",
      "\n",
      "Epoch 70:\n",
      "Training loss: 23.2015, Training accuracy: 0.8871\n",
      "Validation loss: 2.0275, Validation accuracy: 0.8648\n",
      "Saving ...\n",
      "\n",
      "Epoch 71:\n",
      "Training loss: 23.2014, Training accuracy: 0.8887\n",
      "Validation loss: 2.0308, Validation accuracy: 0.8575\n",
      "\n",
      "Epoch 72:\n",
      "Training loss: 23.2011, Training accuracy: 0.8887\n",
      "Validation loss: 2.0307, Validation accuracy: 0.8604\n",
      "\n",
      "Epoch 73:\n",
      "Training loss: 23.2012, Training accuracy: 0.8899\n",
      "Validation loss: 2.0351, Validation accuracy: 0.8627\n",
      "\n",
      "Epoch 74:\n",
      "Training loss: 23.2011, Training accuracy: 0.8907\n",
      "Validation loss: 2.0320, Validation accuracy: 0.8653\n",
      "Saving ...\n",
      "\n",
      "Epoch 75:\n",
      "Training loss: 23.2012, Training accuracy: 0.8883\n",
      "Validation loss: 2.0398, Validation accuracy: 0.8615\n",
      "\n",
      "Epoch 76:\n",
      "Training loss: 23.2012, Training accuracy: 0.8908\n",
      "Validation loss: 2.0344, Validation accuracy: 0.8628\n",
      "\n",
      "Epoch 77:\n",
      "Training loss: 23.2012, Training accuracy: 0.8909\n",
      "Validation loss: 2.0321, Validation accuracy: 0.8679\n",
      "Saving ...\n",
      "\n",
      "Epoch 78:\n",
      "Training loss: 23.2010, Training accuracy: 0.8924\n",
      "Validation loss: 2.0349, Validation accuracy: 0.8625\n",
      "\n",
      "Epoch 79:\n",
      "Training loss: 23.2009, Training accuracy: 0.8938\n",
      "Validation loss: 2.0256, Validation accuracy: 0.8651\n",
      "\n",
      "Epoch 80:\n",
      "Training loss: 23.2010, Training accuracy: 0.8934\n",
      "Validation loss: 2.0330, Validation accuracy: 0.8599\n",
      "\n",
      "Epoch 81:\n",
      "Training loss: 23.2008, Training accuracy: 0.8930\n",
      "Validation loss: 2.0341, Validation accuracy: 0.8651\n",
      "\n",
      "Epoch 82:\n",
      "Training loss: 23.2007, Training accuracy: 0.8931\n",
      "Validation loss: 2.0261, Validation accuracy: 0.8639\n",
      "\n",
      "Epoch 83:\n",
      "Training loss: 23.2008, Training accuracy: 0.8945\n",
      "Validation loss: 2.0369, Validation accuracy: 0.8649\n",
      "\n",
      "Epoch 84:\n",
      "Training loss: 23.2007, Training accuracy: 0.8961\n",
      "Validation loss: 2.0317, Validation accuracy: 0.8653\n",
      "\n",
      "Epoch 85:\n",
      "Training loss: 23.2008, Training accuracy: 0.8950\n",
      "Validation loss: 2.0365, Validation accuracy: 0.8616\n",
      "\n",
      "Epoch 86:\n",
      "Training loss: 23.2006, Training accuracy: 0.8953\n",
      "Validation loss: 2.0371, Validation accuracy: 0.8699\n",
      "Saving ...\n",
      "\n",
      "Epoch 87:\n",
      "Training loss: 23.2006, Training accuracy: 0.8966\n",
      "Validation loss: 2.0274, Validation accuracy: 0.8633\n",
      "\n",
      "Epoch 88:\n",
      "Training loss: 23.2007, Training accuracy: 0.8961\n",
      "Validation loss: 2.0352, Validation accuracy: 0.8680\n",
      "\n",
      "Epoch 89:\n",
      "Training loss: 23.2006, Training accuracy: 0.8966\n",
      "Validation loss: 2.0327, Validation accuracy: 0.8626\n",
      "\n",
      "Epoch 90:\n",
      "Training loss: 23.2004, Training accuracy: 0.8986\n",
      "Validation loss: 2.0326, Validation accuracy: 0.8704\n",
      "Saving ...\n",
      "\n",
      "Epoch 91:\n",
      "Training loss: 23.2006, Training accuracy: 0.8972\n",
      "Validation loss: 2.0284, Validation accuracy: 0.8668\n",
      "\n",
      "Epoch 92:\n",
      "Training loss: 23.2006, Training accuracy: 0.8980\n",
      "Validation loss: 2.0240, Validation accuracy: 0.8731\n",
      "Saving ...\n",
      "\n",
      "Epoch 93:\n",
      "Training loss: 23.2005, Training accuracy: 0.8985\n",
      "Validation loss: 2.0309, Validation accuracy: 0.8587\n",
      "\n",
      "Epoch 94:\n",
      "Training loss: 23.2004, Training accuracy: 0.8985\n",
      "Validation loss: 2.0296, Validation accuracy: 0.8679\n",
      "\n",
      "Epoch 95:\n",
      "Training loss: 23.2005, Training accuracy: 0.8988\n",
      "Validation loss: 2.0304, Validation accuracy: 0.8710\n",
      "\n",
      "Epoch 96:\n",
      "Training loss: 23.2005, Training accuracy: 0.8987\n",
      "Validation loss: 2.0286, Validation accuracy: 0.8672\n",
      "\n",
      "Epoch 97:\n",
      "Training loss: 23.2004, Training accuracy: 0.9005\n",
      "Validation loss: 2.0302, Validation accuracy: 0.8650\n",
      "\n",
      "Epoch 98:\n",
      "Training loss: 23.2003, Training accuracy: 0.9007\n",
      "Validation loss: 2.0315, Validation accuracy: 0.8688\n",
      "\n",
      "Epoch 99:\n",
      "Training loss: 23.2001, Training accuracy: 0.8998\n",
      "Validation loss: 2.0278, Validation accuracy: 0.8678\n",
      "\n",
      "Epoch 100:\n",
      "Training loss: 23.2003, Training accuracy: 0.8999\n",
      "Validation loss: 2.0330, Validation accuracy: 0.8646\n",
      "\n",
      "Epoch 101:\n",
      "Training loss: 23.2003, Training accuracy: 0.9002\n",
      "Validation loss: 2.0322, Validation accuracy: 0.8742\n",
      "Saving ...\n",
      "\n",
      "Epoch 102:\n",
      "Training loss: 23.2004, Training accuracy: 0.9008\n",
      "Validation loss: 2.0289, Validation accuracy: 0.8713\n",
      "\n",
      "Epoch 103:\n",
      "Training loss: 23.2001, Training accuracy: 0.9028\n",
      "Validation loss: 2.0274, Validation accuracy: 0.8668\n",
      "\n",
      "Epoch 104:\n",
      "Training loss: 23.2002, Training accuracy: 0.9018\n",
      "Validation loss: 2.0298, Validation accuracy: 0.8640\n",
      "\n",
      "Epoch 105:\n",
      "Training loss: 23.2001, Training accuracy: 0.9017\n",
      "Validation loss: 2.0332, Validation accuracy: 0.8729\n",
      "\n",
      "Epoch 106:\n",
      "Training loss: 23.2002, Training accuracy: 0.9034\n",
      "Validation loss: 2.0310, Validation accuracy: 0.8718\n",
      "\n",
      "Epoch 107:\n",
      "Training loss: 23.2001, Training accuracy: 0.9032\n",
      "Validation loss: 2.0369, Validation accuracy: 0.8714\n",
      "\n",
      "Epoch 108:\n",
      "Training loss: 23.2002, Training accuracy: 0.9030\n",
      "Validation loss: 2.0235, Validation accuracy: 0.8721\n",
      "\n",
      "Epoch 109:\n",
      "Training loss: 23.2000, Training accuracy: 0.9041\n",
      "Validation loss: 2.0286, Validation accuracy: 0.8745\n",
      "Saving ...\n",
      "\n",
      "Epoch 110:\n",
      "Training loss: 23.2000, Training accuracy: 0.9061\n",
      "Validation loss: 2.0297, Validation accuracy: 0.8726\n",
      "\n",
      "Epoch 111:\n",
      "Training loss: 23.1999, Training accuracy: 0.9041\n",
      "Validation loss: 2.0385, Validation accuracy: 0.8683\n",
      "\n",
      "Epoch 112:\n",
      "Training loss: 23.2000, Training accuracy: 0.9055\n",
      "Validation loss: 2.0261, Validation accuracy: 0.8744\n",
      "\n",
      "Epoch 113:\n",
      "Training loss: 23.2000, Training accuracy: 0.9045\n",
      "Validation loss: 2.0260, Validation accuracy: 0.8740\n",
      "\n",
      "Epoch 114:\n",
      "Training loss: 23.1999, Training accuracy: 0.9054\n",
      "Validation loss: 2.0313, Validation accuracy: 0.8658\n",
      "\n",
      "Epoch 115:\n",
      "Training loss: 23.1996, Training accuracy: 0.9080\n",
      "Validation loss: 2.0290, Validation accuracy: 0.8748\n",
      "Saving ...\n",
      "\n",
      "Epoch 116:\n",
      "Training loss: 23.1998, Training accuracy: 0.9068\n",
      "Validation loss: 2.0228, Validation accuracy: 0.8721\n",
      "\n",
      "Epoch 117:\n",
      "Training loss: 23.1997, Training accuracy: 0.9073\n",
      "Validation loss: 2.0297, Validation accuracy: 0.8765\n",
      "Saving ...\n",
      "\n",
      "Epoch 118:\n",
      "Training loss: 23.1998, Training accuracy: 0.9077\n",
      "Validation loss: 2.0329, Validation accuracy: 0.8705\n",
      "\n",
      "Epoch 119:\n",
      "Training loss: 23.1999, Training accuracy: 0.9062\n",
      "Validation loss: 2.0236, Validation accuracy: 0.8782\n",
      "Saving ...\n",
      "\n",
      "Epoch 120:\n",
      "Training loss: 23.2000, Training accuracy: 0.9071\n",
      "Validation loss: 2.0253, Validation accuracy: 0.8698\n",
      "\n",
      "Epoch 121:\n",
      "Training loss: 23.1998, Training accuracy: 0.9066\n",
      "Validation loss: 2.0233, Validation accuracy: 0.8761\n",
      "\n",
      "Epoch 122:\n",
      "Training loss: 23.1997, Training accuracy: 0.9062\n",
      "Validation loss: 2.0300, Validation accuracy: 0.8773\n",
      "\n",
      "Epoch 123:\n",
      "Training loss: 23.1997, Training accuracy: 0.9080\n",
      "Validation loss: 2.0276, Validation accuracy: 0.8740\n",
      "\n",
      "Epoch 124:\n",
      "Training loss: 23.1997, Training accuracy: 0.9087\n",
      "Validation loss: 2.0239, Validation accuracy: 0.8741\n",
      "\n",
      "Epoch 125:\n",
      "Training loss: 23.1997, Training accuracy: 0.9081\n",
      "Validation loss: 2.0231, Validation accuracy: 0.8756\n",
      "\n",
      "Epoch 126:\n",
      "Training loss: 23.1996, Training accuracy: 0.9073\n",
      "Validation loss: 2.0322, Validation accuracy: 0.8743\n",
      "\n",
      "Epoch 127:\n",
      "Training loss: 23.1995, Training accuracy: 0.9094\n",
      "Validation loss: 2.0238, Validation accuracy: 0.8756\n",
      "\n",
      "Epoch 128:\n",
      "Training loss: 23.1997, Training accuracy: 0.9085\n",
      "Validation loss: 2.0295, Validation accuracy: 0.8777\n",
      "\n",
      "Epoch 129:\n",
      "Training loss: 23.1997, Training accuracy: 0.9099\n",
      "Validation loss: 2.0277, Validation accuracy: 0.8745\n",
      "\n",
      "Epoch 130:\n",
      "Training loss: 23.1996, Training accuracy: 0.9106\n",
      "Validation loss: 2.0250, Validation accuracy: 0.8691\n",
      "\n",
      "Epoch 131:\n",
      "Training loss: 23.1996, Training accuracy: 0.9104\n",
      "Validation loss: 2.0264, Validation accuracy: 0.8817\n",
      "Saving ...\n",
      "\n",
      "Epoch 132:\n",
      "Training loss: 23.1994, Training accuracy: 0.9108\n",
      "Validation loss: 2.0234, Validation accuracy: 0.8744\n",
      "\n",
      "Epoch 133:\n",
      "Training loss: 23.1995, Training accuracy: 0.9108\n",
      "Validation loss: 2.0278, Validation accuracy: 0.8791\n",
      "\n",
      "Epoch 134:\n",
      "Training loss: 23.1996, Training accuracy: 0.9096\n",
      "Validation loss: 2.0274, Validation accuracy: 0.8768\n",
      "\n",
      "Epoch 135:\n",
      "Training loss: 23.1995, Training accuracy: 0.9110\n",
      "Validation loss: 2.0273, Validation accuracy: 0.8786\n",
      "\n",
      "Epoch 136:\n",
      "Training loss: 23.1995, Training accuracy: 0.9103\n",
      "Validation loss: 2.0225, Validation accuracy: 0.8701\n",
      "\n",
      "Epoch 137:\n",
      "Training loss: 23.1993, Training accuracy: 0.9120\n",
      "Validation loss: 2.0290, Validation accuracy: 0.8737\n",
      "\n",
      "Epoch 138:\n",
      "Training loss: 23.1994, Training accuracy: 0.9119\n",
      "Validation loss: 2.0235, Validation accuracy: 0.8791\n",
      "\n",
      "Epoch 139:\n",
      "Training loss: 23.1994, Training accuracy: 0.9132\n",
      "Validation loss: 2.0344, Validation accuracy: 0.8796\n",
      "\n",
      "Epoch 140:\n",
      "Training loss: 23.1994, Training accuracy: 0.9117\n",
      "Validation loss: 2.0251, Validation accuracy: 0.8772\n",
      "\n",
      "Epoch 141:\n",
      "Training loss: 23.1993, Training accuracy: 0.9120\n",
      "Validation loss: 2.0269, Validation accuracy: 0.8708\n",
      "\n",
      "Epoch 142:\n",
      "Training loss: 23.1994, Training accuracy: 0.9129\n",
      "Validation loss: 2.0298, Validation accuracy: 0.8792\n",
      "\n",
      "Epoch 143:\n",
      "Training loss: 23.1992, Training accuracy: 0.9132\n",
      "Validation loss: 2.0249, Validation accuracy: 0.8739\n",
      "\n",
      "Epoch 144:\n",
      "Training loss: 23.1992, Training accuracy: 0.9138\n",
      "Validation loss: 2.0328, Validation accuracy: 0.8685\n",
      "\n",
      "Epoch 145:\n",
      "Training loss: 23.1994, Training accuracy: 0.9141\n",
      "Validation loss: 2.0216, Validation accuracy: 0.8788\n",
      "\n",
      "Epoch 146:\n",
      "Training loss: 23.1992, Training accuracy: 0.9133\n",
      "Validation loss: 2.0213, Validation accuracy: 0.8780\n",
      "\n",
      "Epoch 147:\n",
      "Training loss: 23.1992, Training accuracy: 0.9145\n",
      "Validation loss: 2.0211, Validation accuracy: 0.8769\n",
      "\n",
      "Epoch 148:\n",
      "Training loss: 23.1993, Training accuracy: 0.9130\n",
      "Validation loss: 2.0314, Validation accuracy: 0.8775\n",
      "\n",
      "Epoch 149:\n",
      "Training loss: 23.1990, Training accuracy: 0.9154\n",
      "Validation loss: 2.0297, Validation accuracy: 0.8806\n",
      "\n",
      "Epoch 150:\n",
      "Training loss: 23.1991, Training accuracy: 0.9142\n",
      "Validation loss: 2.0239, Validation accuracy: 0.8765\n",
      "\n",
      "Epoch 151:\n",
      "Training loss: 23.1992, Training accuracy: 0.9140\n",
      "Validation loss: 2.0205, Validation accuracy: 0.8796\n",
      "\n",
      "Epoch 152:\n",
      "Training loss: 23.1992, Training accuracy: 0.9148\n",
      "Validation loss: 2.0305, Validation accuracy: 0.8780\n",
      "\n",
      "Epoch 153:\n",
      "Training loss: 23.1992, Training accuracy: 0.9152\n",
      "Validation loss: 2.0263, Validation accuracy: 0.8749\n",
      "\n",
      "Epoch 154:\n",
      "Training loss: 23.1992, Training accuracy: 0.9161\n",
      "Validation loss: 2.0288, Validation accuracy: 0.8812\n",
      "\n",
      "Epoch 155:\n",
      "Training loss: 23.1992, Training accuracy: 0.9166\n",
      "Validation loss: 2.0212, Validation accuracy: 0.8818\n",
      "Saving ...\n",
      "\n",
      "Epoch 156:\n",
      "Training loss: 23.1990, Training accuracy: 0.9177\n",
      "Validation loss: 2.0287, Validation accuracy: 0.8744\n",
      "\n",
      "Epoch 157:\n",
      "Training loss: 23.1992, Training accuracy: 0.9141\n",
      "Validation loss: 2.0233, Validation accuracy: 0.8694\n",
      "\n",
      "Epoch 158:\n",
      "Training loss: 23.1990, Training accuracy: 0.9168\n",
      "Validation loss: 2.0252, Validation accuracy: 0.8757\n",
      "\n",
      "Epoch 159:\n",
      "Training loss: 23.1991, Training accuracy: 0.9172\n",
      "Validation loss: 2.0294, Validation accuracy: 0.8734\n",
      "\n",
      "Epoch 160:\n",
      "Training loss: 23.1992, Training accuracy: 0.9179\n",
      "Validation loss: 2.0273, Validation accuracy: 0.8778\n",
      "\n",
      "Epoch 161:\n",
      "Training loss: 23.1991, Training accuracy: 0.9158\n",
      "Validation loss: 2.0276, Validation accuracy: 0.8783\n",
      "\n",
      "Epoch 162:\n",
      "Training loss: 23.1991, Training accuracy: 0.9156\n",
      "Validation loss: 2.0218, Validation accuracy: 0.8815\n",
      "\n",
      "Epoch 163:\n",
      "Training loss: 23.1990, Training accuracy: 0.9176\n",
      "Validation loss: 2.0281, Validation accuracy: 0.8765\n",
      "\n",
      "Epoch 164:\n",
      "Training loss: 23.1989, Training accuracy: 0.9164\n",
      "Validation loss: 2.0254, Validation accuracy: 0.8827\n",
      "Saving ...\n",
      "\n",
      "Epoch 165:\n",
      "Training loss: 23.1990, Training accuracy: 0.9162\n",
      "Validation loss: 2.0292, Validation accuracy: 0.8753\n",
      "\n",
      "Epoch 166:\n",
      "Training loss: 23.1991, Training accuracy: 0.9176\n",
      "Validation loss: 2.0226, Validation accuracy: 0.8794\n",
      "\n",
      "Epoch 167:\n",
      "Training loss: 23.1990, Training accuracy: 0.9183\n",
      "Validation loss: 2.0182, Validation accuracy: 0.8758\n",
      "\n",
      "Epoch 168:\n",
      "Training loss: 23.1988, Training accuracy: 0.9172\n",
      "Validation loss: 2.0221, Validation accuracy: 0.8799\n",
      "\n",
      "Epoch 169:\n",
      "Training loss: 23.1990, Training accuracy: 0.9187\n",
      "Validation loss: 2.0276, Validation accuracy: 0.8773\n",
      "\n",
      "Epoch 170:\n",
      "Training loss: 23.1991, Training accuracy: 0.9178\n",
      "Validation loss: 2.0278, Validation accuracy: 0.8814\n",
      "\n",
      "Epoch 171:\n",
      "Training loss: 23.1990, Training accuracy: 0.9171\n",
      "Validation loss: 2.0287, Validation accuracy: 0.8842\n",
      "Saving ...\n",
      "\n",
      "Epoch 172:\n",
      "Training loss: 23.1988, Training accuracy: 0.9198\n",
      "Validation loss: 2.0233, Validation accuracy: 0.8856\n",
      "Saving ...\n",
      "\n",
      "Epoch 173:\n",
      "Training loss: 23.1990, Training accuracy: 0.9188\n",
      "Validation loss: 2.0255, Validation accuracy: 0.8795\n",
      "\n",
      "Epoch 174:\n",
      "Training loss: 23.1990, Training accuracy: 0.9192\n",
      "Validation loss: 2.0188, Validation accuracy: 0.8832\n",
      "\n",
      "Epoch 175:\n",
      "Training loss: 23.1990, Training accuracy: 0.9180\n",
      "Validation loss: 2.0293, Validation accuracy: 0.8797\n",
      "\n",
      "Epoch 176:\n",
      "Training loss: 23.1988, Training accuracy: 0.9195\n",
      "Validation loss: 2.0308, Validation accuracy: 0.8798\n",
      "\n",
      "Epoch 177:\n",
      "Training loss: 23.1987, Training accuracy: 0.9200\n",
      "Validation loss: 2.0267, Validation accuracy: 0.8798\n",
      "\n",
      "Epoch 178:\n",
      "Training loss: 23.1990, Training accuracy: 0.9203\n",
      "Validation loss: 2.0218, Validation accuracy: 0.8785\n",
      "\n",
      "Epoch 179:\n",
      "Training loss: 23.1988, Training accuracy: 0.9195\n",
      "Validation loss: 2.0236, Validation accuracy: 0.8807\n",
      "\n",
      "Epoch 180:\n",
      "Training loss: 23.1987, Training accuracy: 0.9204\n",
      "Validation loss: 2.0266, Validation accuracy: 0.8740\n",
      "\n",
      "Epoch 181:\n",
      "Training loss: 23.1988, Training accuracy: 0.9208\n",
      "Validation loss: 2.0213, Validation accuracy: 0.8840\n",
      "\n",
      "Epoch 182:\n",
      "Training loss: 23.1989, Training accuracy: 0.9203\n",
      "Validation loss: 2.0291, Validation accuracy: 0.8734\n",
      "\n",
      "Epoch 183:\n",
      "Training loss: 23.1989, Training accuracy: 0.9210\n",
      "Validation loss: 2.0269, Validation accuracy: 0.8769\n",
      "\n",
      "Epoch 184:\n",
      "Training loss: 23.1986, Training accuracy: 0.9204\n",
      "Validation loss: 2.0215, Validation accuracy: 0.8803\n",
      "\n",
      "Epoch 185:\n",
      "Training loss: 23.1989, Training accuracy: 0.9200\n",
      "Validation loss: 2.0231, Validation accuracy: 0.8779\n",
      "\n",
      "Epoch 186:\n",
      "Training loss: 23.1988, Training accuracy: 0.9219\n",
      "Validation loss: 2.0259, Validation accuracy: 0.8783\n",
      "\n",
      "Epoch 187:\n",
      "Training loss: 23.1987, Training accuracy: 0.9214\n",
      "Validation loss: 2.0293, Validation accuracy: 0.8809\n",
      "\n",
      "Epoch 188:\n",
      "Training loss: 23.1987, Training accuracy: 0.9223\n",
      "Validation loss: 2.0212, Validation accuracy: 0.8819\n",
      "\n",
      "Epoch 189:\n",
      "Training loss: 23.1985, Training accuracy: 0.9218\n",
      "Validation loss: 2.0282, Validation accuracy: 0.8827\n",
      "\n",
      "Epoch 190:\n",
      "Training loss: 23.1986, Training accuracy: 0.9211\n",
      "Validation loss: 2.0311, Validation accuracy: 0.8802\n",
      "\n",
      "Epoch 191:\n",
      "Training loss: 23.1989, Training accuracy: 0.9218\n",
      "Validation loss: 2.0266, Validation accuracy: 0.8789\n",
      "\n",
      "Epoch 192:\n",
      "Training loss: 23.1986, Training accuracy: 0.9219\n",
      "Validation loss: 2.0292, Validation accuracy: 0.8765\n",
      "\n",
      "Epoch 193:\n",
      "Training loss: 23.1988, Training accuracy: 0.9217\n",
      "Validation loss: 2.0261, Validation accuracy: 0.8782\n",
      "\n",
      "Epoch 194:\n",
      "Training loss: 23.1988, Training accuracy: 0.9235\n",
      "Validation loss: 2.0207, Validation accuracy: 0.8792\n",
      "\n",
      "Epoch 195:\n",
      "Training loss: 23.1987, Training accuracy: 0.9230\n",
      "Validation loss: 2.0267, Validation accuracy: 0.8812\n",
      "\n",
      "Epoch 196:\n",
      "Training loss: 23.1986, Training accuracy: 0.9231\n",
      "Validation loss: 2.0311, Validation accuracy: 0.8839\n",
      "\n",
      "Epoch 197:\n",
      "Training loss: 23.1986, Training accuracy: 0.9244\n",
      "Validation loss: 2.0253, Validation accuracy: 0.8787\n",
      "\n",
      "Epoch 198:\n",
      "Training loss: 23.1987, Training accuracy: 0.9229\n",
      "Validation loss: 2.0194, Validation accuracy: 0.8826\n",
      "\n",
      "Epoch 199:\n",
      "Training loss: 23.1986, Training accuracy: 0.9237\n",
      "Validation loss: 2.0261, Validation accuracy: 0.8813\n",
      "\n",
      "==================================================\n",
      "==> Optimization finished! Best validation accuracy: 0.8856\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8856"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train(student,teacher,optimizer,criterion,2,[0,0,1],1,train_loader,val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Training starts!\n",
      "==================================================\n",
      "Epoch 0:\n",
      "Training loss: 92.4496, Training accuracy: 0.3695\n",
      "Validation loss: 2.2326, Validation accuracy: 0.4687\n",
      "Saving ...\n",
      "\n",
      "Epoch 1:\n",
      "Training loss: 92.4442, Training accuracy: 0.4989\n",
      "Validation loss: 2.2116, Validation accuracy: 0.5524\n",
      "Saving ...\n",
      "\n",
      "Epoch 2:\n",
      "Training loss: 92.4424, Training accuracy: 0.5601\n",
      "Validation loss: 2.1980, Validation accuracy: 0.5824\n",
      "Saving ...\n",
      "\n",
      "Epoch 3:\n",
      "Training loss: 92.4410, Training accuracy: 0.6017\n",
      "Validation loss: 2.1843, Validation accuracy: 0.6229\n",
      "Saving ...\n",
      "\n",
      "Epoch 4:\n",
      "Training loss: 92.4397, Training accuracy: 0.6368\n",
      "Validation loss: 2.1699, Validation accuracy: 0.6362\n",
      "Saving ...\n",
      "\n",
      "Epoch 5:\n",
      "Training loss: 92.4390, Training accuracy: 0.6609\n",
      "Validation loss: 2.1701, Validation accuracy: 0.6699\n",
      "Saving ...\n",
      "\n",
      "Epoch 6:\n",
      "Training loss: 92.4382, Training accuracy: 0.6847\n",
      "Validation loss: 2.1591, Validation accuracy: 0.6921\n",
      "Saving ...\n",
      "\n",
      "Epoch 7:\n",
      "Training loss: 92.4376, Training accuracy: 0.7026\n",
      "Validation loss: 2.1509, Validation accuracy: 0.7022\n",
      "Saving ...\n",
      "\n",
      "Epoch 8:\n",
      "Training loss: 92.4370, Training accuracy: 0.7175\n",
      "Validation loss: 2.1460, Validation accuracy: 0.7252\n",
      "Saving ...\n",
      "\n",
      "Epoch 9:\n",
      "Training loss: 92.4365, Training accuracy: 0.7341\n",
      "Validation loss: 2.1363, Validation accuracy: 0.7250\n",
      "\n",
      "Epoch 10:\n",
      "Training loss: 92.4359, Training accuracy: 0.7479\n",
      "Validation loss: 2.1385, Validation accuracy: 0.7434\n",
      "Saving ...\n",
      "\n",
      "Epoch 11:\n",
      "Training loss: 92.4355, Training accuracy: 0.7584\n",
      "Validation loss: 2.1313, Validation accuracy: 0.7564\n",
      "Saving ...\n",
      "\n",
      "Epoch 12:\n",
      "Training loss: 92.4351, Training accuracy: 0.7631\n",
      "Validation loss: 2.1328, Validation accuracy: 0.7619\n",
      "Saving ...\n",
      "\n",
      "Epoch 13:\n",
      "Training loss: 92.4350, Training accuracy: 0.7733\n",
      "Validation loss: 2.1277, Validation accuracy: 0.7697\n",
      "Saving ...\n",
      "\n",
      "Epoch 14:\n",
      "Training loss: 92.4347, Training accuracy: 0.7806\n",
      "Validation loss: 2.1238, Validation accuracy: 0.7641\n",
      "\n",
      "Epoch 15:\n",
      "Training loss: 92.4344, Training accuracy: 0.7866\n",
      "Validation loss: 2.1162, Validation accuracy: 0.7788\n",
      "Saving ...\n",
      "\n",
      "Epoch 16:\n",
      "Training loss: 92.4341, Training accuracy: 0.7901\n",
      "Validation loss: 2.1144, Validation accuracy: 0.7913\n",
      "Saving ...\n",
      "\n",
      "Epoch 17:\n",
      "Training loss: 92.4338, Training accuracy: 0.7979\n",
      "Validation loss: 2.1138, Validation accuracy: 0.7912\n",
      "\n",
      "Epoch 18:\n",
      "Training loss: 92.4336, Training accuracy: 0.8025\n",
      "Validation loss: 2.1158, Validation accuracy: 0.7943\n",
      "Saving ...\n",
      "\n",
      "Epoch 19:\n",
      "Training loss: 92.4334, Training accuracy: 0.8056\n",
      "Validation loss: 2.1064, Validation accuracy: 0.7973\n",
      "Saving ...\n",
      "\n",
      "Epoch 20:\n",
      "Training loss: 92.4332, Training accuracy: 0.8093\n",
      "Validation loss: 2.1119, Validation accuracy: 0.8002\n",
      "Saving ...\n",
      "\n",
      "Epoch 21:\n",
      "Training loss: 92.4332, Training accuracy: 0.8138\n",
      "Validation loss: 2.1120, Validation accuracy: 0.7993\n",
      "\n",
      "Epoch 22:\n",
      "Training loss: 92.4330, Training accuracy: 0.8149\n",
      "Validation loss: 2.1075, Validation accuracy: 0.8118\n",
      "Saving ...\n",
      "\n",
      "Epoch 23:\n",
      "Training loss: 92.4328, Training accuracy: 0.8184\n",
      "Validation loss: 2.1034, Validation accuracy: 0.8073\n",
      "\n",
      "Epoch 24:\n",
      "Training loss: 92.4326, Training accuracy: 0.8238\n",
      "Validation loss: 2.1048, Validation accuracy: 0.8151\n",
      "Saving ...\n",
      "\n",
      "Epoch 25:\n",
      "Training loss: 92.4326, Training accuracy: 0.8242\n",
      "Validation loss: 2.0995, Validation accuracy: 0.8170\n",
      "Saving ...\n",
      "\n",
      "Epoch 26:\n",
      "Training loss: 92.4324, Training accuracy: 0.8282\n",
      "Validation loss: 2.0994, Validation accuracy: 0.8118\n",
      "\n",
      "Epoch 27:\n",
      "Training loss: 92.4324, Training accuracy: 0.8303\n",
      "Validation loss: 2.1045, Validation accuracy: 0.8222\n",
      "Saving ...\n",
      "\n",
      "Epoch 28:\n",
      "Training loss: 92.4323, Training accuracy: 0.8325\n",
      "Validation loss: 2.0944, Validation accuracy: 0.8165\n",
      "\n",
      "Epoch 29:\n",
      "Training loss: 92.4322, Training accuracy: 0.8334\n",
      "Validation loss: 2.0996, Validation accuracy: 0.8238\n",
      "Saving ...\n",
      "\n",
      "Epoch 30:\n",
      "Training loss: 92.4320, Training accuracy: 0.8366\n",
      "Validation loss: 2.0995, Validation accuracy: 0.8233\n",
      "\n",
      "Epoch 31:\n",
      "Training loss: 92.4320, Training accuracy: 0.8386\n",
      "Validation loss: 2.0964, Validation accuracy: 0.8290\n",
      "Saving ...\n",
      "\n",
      "Epoch 32:\n",
      "Training loss: 92.4318, Training accuracy: 0.8400\n",
      "Validation loss: 2.0990, Validation accuracy: 0.8323\n",
      "Saving ...\n",
      "\n",
      "Epoch 33:\n",
      "Training loss: 92.4320, Training accuracy: 0.8432\n",
      "Validation loss: 2.0921, Validation accuracy: 0.8262\n",
      "\n",
      "Epoch 34:\n",
      "Training loss: 92.4317, Training accuracy: 0.8446\n",
      "Validation loss: 2.0858, Validation accuracy: 0.8270\n",
      "\n",
      "Epoch 35:\n",
      "Training loss: 92.4316, Training accuracy: 0.8471\n",
      "Validation loss: 2.0949, Validation accuracy: 0.8278\n",
      "\n",
      "Epoch 36:\n",
      "Training loss: 92.4315, Training accuracy: 0.8466\n",
      "Validation loss: 2.0925, Validation accuracy: 0.8327\n",
      "Saving ...\n",
      "\n",
      "Epoch 37:\n",
      "Training loss: 92.4314, Training accuracy: 0.8489\n",
      "Validation loss: 2.1027, Validation accuracy: 0.8289\n",
      "\n",
      "Epoch 38:\n",
      "Training loss: 92.4313, Training accuracy: 0.8520\n",
      "Validation loss: 2.0870, Validation accuracy: 0.8377\n",
      "Saving ...\n",
      "\n",
      "Epoch 39:\n",
      "Training loss: 92.4314, Training accuracy: 0.8510\n",
      "Validation loss: 2.0953, Validation accuracy: 0.8393\n",
      "Saving ...\n",
      "\n",
      "Epoch 40:\n",
      "Training loss: 92.4314, Training accuracy: 0.8524\n",
      "Validation loss: 2.0949, Validation accuracy: 0.8377\n",
      "\n",
      "Epoch 41:\n",
      "Training loss: 92.4313, Training accuracy: 0.8553\n",
      "Validation loss: 2.0931, Validation accuracy: 0.8378\n",
      "\n",
      "Epoch 42:\n",
      "Training loss: 92.4312, Training accuracy: 0.8568\n",
      "Validation loss: 2.0883, Validation accuracy: 0.8438\n",
      "Saving ...\n",
      "\n",
      "Epoch 43:\n",
      "Training loss: 92.4312, Training accuracy: 0.8562\n",
      "Validation loss: 2.0872, Validation accuracy: 0.8452\n",
      "Saving ...\n",
      "\n",
      "Epoch 44:\n",
      "Training loss: 92.4311, Training accuracy: 0.8590\n",
      "Validation loss: 2.0950, Validation accuracy: 0.8389\n",
      "\n",
      "Epoch 45:\n",
      "Training loss: 92.4312, Training accuracy: 0.8602\n",
      "Validation loss: 2.0847, Validation accuracy: 0.8430\n",
      "\n",
      "Epoch 46:\n",
      "Training loss: 92.4310, Training accuracy: 0.8598\n",
      "Validation loss: 2.0854, Validation accuracy: 0.8499\n",
      "Saving ...\n",
      "\n",
      "Epoch 47:\n",
      "Training loss: 92.4310, Training accuracy: 0.8614\n",
      "Validation loss: 2.0870, Validation accuracy: 0.8364\n",
      "\n",
      "Epoch 48:\n",
      "Training loss: 92.4309, Training accuracy: 0.8639\n",
      "Validation loss: 2.0852, Validation accuracy: 0.8478\n",
      "\n",
      "Epoch 49:\n",
      "Training loss: 92.4309, Training accuracy: 0.8649\n",
      "Validation loss: 2.0894, Validation accuracy: 0.8514\n",
      "Saving ...\n",
      "\n",
      "Epoch 50:\n",
      "Training loss: 92.4308, Training accuracy: 0.8656\n",
      "Validation loss: 2.0839, Validation accuracy: 0.8433\n",
      "\n",
      "Epoch 51:\n",
      "Training loss: 92.4308, Training accuracy: 0.8673\n",
      "Validation loss: 2.0839, Validation accuracy: 0.8552\n",
      "Saving ...\n",
      "\n",
      "Epoch 52:\n",
      "Training loss: 92.4308, Training accuracy: 0.8663\n",
      "Validation loss: 2.0830, Validation accuracy: 0.8551\n",
      "\n",
      "Epoch 53:\n",
      "Training loss: 92.4307, Training accuracy: 0.8690\n",
      "Validation loss: 2.0813, Validation accuracy: 0.8489\n",
      "\n",
      "Epoch 54:\n",
      "Training loss: 92.4308, Training accuracy: 0.8675\n",
      "Validation loss: 2.0907, Validation accuracy: 0.8541\n",
      "\n",
      "Epoch 55:\n",
      "Training loss: 92.4307, Training accuracy: 0.8683\n",
      "Validation loss: 2.0826, Validation accuracy: 0.8557\n",
      "Saving ...\n",
      "\n",
      "Epoch 56:\n",
      "Training loss: 92.4306, Training accuracy: 0.8719\n",
      "Validation loss: 2.0839, Validation accuracy: 0.8586\n",
      "Saving ...\n",
      "\n",
      "Epoch 57:\n",
      "Training loss: 92.4305, Training accuracy: 0.8706\n",
      "Validation loss: 2.0879, Validation accuracy: 0.8523\n",
      "\n",
      "Epoch 58:\n",
      "Training loss: 92.4305, Training accuracy: 0.8726\n",
      "Validation loss: 2.0849, Validation accuracy: 0.8516\n",
      "\n",
      "Epoch 59:\n",
      "Training loss: 92.4304, Training accuracy: 0.8726\n",
      "Validation loss: 2.0810, Validation accuracy: 0.8477\n",
      "\n",
      "Epoch 60:\n",
      "Training loss: 92.4304, Training accuracy: 0.8731\n",
      "Validation loss: 2.0845, Validation accuracy: 0.8494\n",
      "\n",
      "Epoch 61:\n",
      "Training loss: 92.4305, Training accuracy: 0.8746\n",
      "Validation loss: 2.0836, Validation accuracy: 0.8582\n",
      "\n",
      "Epoch 62:\n",
      "Training loss: 92.4303, Training accuracy: 0.8752\n",
      "Validation loss: 2.0830, Validation accuracy: 0.8603\n",
      "Saving ...\n",
      "\n",
      "Epoch 63:\n",
      "Training loss: 92.4303, Training accuracy: 0.8747\n",
      "Validation loss: 2.0782, Validation accuracy: 0.8525\n",
      "\n",
      "Epoch 64:\n",
      "Training loss: 92.4304, Training accuracy: 0.8763\n",
      "Validation loss: 2.0835, Validation accuracy: 0.8574\n",
      "\n",
      "Epoch 65:\n",
      "Training loss: 92.4303, Training accuracy: 0.8784\n",
      "Validation loss: 2.0833, Validation accuracy: 0.8544\n",
      "\n",
      "Epoch 66:\n",
      "Training loss: 92.4302, Training accuracy: 0.8782\n",
      "Validation loss: 2.0853, Validation accuracy: 0.8539\n",
      "\n",
      "Epoch 67:\n",
      "Training loss: 92.4303, Training accuracy: 0.8777\n",
      "Validation loss: 2.0816, Validation accuracy: 0.8575\n",
      "\n",
      "Epoch 68:\n",
      "Training loss: 92.4300, Training accuracy: 0.8786\n",
      "Validation loss: 2.0822, Validation accuracy: 0.8556\n",
      "\n",
      "Epoch 69:\n",
      "Training loss: 92.4302, Training accuracy: 0.8790\n",
      "Validation loss: 2.0764, Validation accuracy: 0.8604\n",
      "Saving ...\n",
      "\n",
      "Epoch 70:\n",
      "Training loss: 92.4300, Training accuracy: 0.8829\n",
      "Validation loss: 2.0872, Validation accuracy: 0.8557\n",
      "\n",
      "Epoch 71:\n",
      "Training loss: 92.4301, Training accuracy: 0.8790\n",
      "Validation loss: 2.0710, Validation accuracy: 0.8609\n",
      "Saving ...\n",
      "\n",
      "Epoch 72:\n",
      "Training loss: 92.4301, Training accuracy: 0.8809\n",
      "Validation loss: 2.0821, Validation accuracy: 0.8575\n",
      "\n",
      "Epoch 73:\n",
      "Training loss: 92.4300, Training accuracy: 0.8825\n",
      "Validation loss: 2.0830, Validation accuracy: 0.8552\n",
      "\n",
      "Epoch 74:\n",
      "Training loss: 92.4301, Training accuracy: 0.8837\n",
      "Validation loss: 2.0810, Validation accuracy: 0.8609\n",
      "\n",
      "Epoch 75:\n",
      "Training loss: 92.4300, Training accuracy: 0.8838\n",
      "Validation loss: 2.0815, Validation accuracy: 0.8601\n",
      "\n",
      "Epoch 76:\n",
      "Training loss: 92.4299, Training accuracy: 0.8831\n",
      "Validation loss: 2.0777, Validation accuracy: 0.8606\n",
      "\n",
      "Epoch 77:\n",
      "Training loss: 92.4300, Training accuracy: 0.8844\n",
      "Validation loss: 2.0783, Validation accuracy: 0.8629\n",
      "Saving ...\n",
      "\n",
      "Epoch 78:\n",
      "Training loss: 92.4300, Training accuracy: 0.8852\n",
      "Validation loss: 2.0757, Validation accuracy: 0.8629\n",
      "\n",
      "Epoch 79:\n",
      "Training loss: 92.4300, Training accuracy: 0.8832\n",
      "Validation loss: 2.0810, Validation accuracy: 0.8618\n",
      "\n",
      "Epoch 80:\n",
      "Training loss: 92.4299, Training accuracy: 0.8857\n",
      "Validation loss: 2.0792, Validation accuracy: 0.8598\n",
      "\n",
      "Epoch 81:\n",
      "Training loss: 92.4300, Training accuracy: 0.8866\n",
      "Validation loss: 2.0818, Validation accuracy: 0.8588\n",
      "\n",
      "Epoch 82:\n",
      "Training loss: 92.4298, Training accuracy: 0.8872\n",
      "Validation loss: 2.0814, Validation accuracy: 0.8625\n",
      "\n",
      "Epoch 83:\n",
      "Training loss: 92.4298, Training accuracy: 0.8863\n",
      "Validation loss: 2.0742, Validation accuracy: 0.8635\n",
      "Saving ...\n",
      "\n",
      "Epoch 84:\n",
      "Training loss: 92.4298, Training accuracy: 0.8879\n",
      "Validation loss: 2.0842, Validation accuracy: 0.8572\n",
      "\n",
      "Epoch 85:\n",
      "Training loss: 92.4297, Training accuracy: 0.8879\n",
      "Validation loss: 2.0753, Validation accuracy: 0.8604\n",
      "\n",
      "Epoch 86:\n",
      "Training loss: 92.4297, Training accuracy: 0.8891\n",
      "Validation loss: 2.0797, Validation accuracy: 0.8612\n",
      "\n",
      "Epoch 87:\n",
      "Training loss: 92.4297, Training accuracy: 0.8892\n",
      "Validation loss: 2.0810, Validation accuracy: 0.8693\n",
      "Saving ...\n",
      "\n",
      "Epoch 88:\n",
      "Training loss: 92.4298, Training accuracy: 0.8906\n",
      "Validation loss: 2.0855, Validation accuracy: 0.8651\n",
      "\n",
      "Epoch 89:\n",
      "Training loss: 92.4297, Training accuracy: 0.8888\n",
      "Validation loss: 2.0837, Validation accuracy: 0.8491\n",
      "\n",
      "Epoch 90:\n",
      "Training loss: 92.4295, Training accuracy: 0.8916\n",
      "Validation loss: 2.0794, Validation accuracy: 0.8654\n",
      "\n",
      "Epoch 91:\n",
      "Training loss: 92.4297, Training accuracy: 0.8911\n",
      "Validation loss: 2.0721, Validation accuracy: 0.8683\n",
      "\n",
      "Epoch 92:\n",
      "Training loss: 92.4296, Training accuracy: 0.8907\n",
      "Validation loss: 2.0762, Validation accuracy: 0.8707\n",
      "Saving ...\n",
      "\n",
      "Epoch 93:\n",
      "Training loss: 92.4297, Training accuracy: 0.8914\n",
      "Validation loss: 2.0729, Validation accuracy: 0.8669\n",
      "\n",
      "Epoch 94:\n",
      "Training loss: 92.4295, Training accuracy: 0.8937\n",
      "Validation loss: 2.0806, Validation accuracy: 0.8663\n",
      "\n",
      "Epoch 95:\n",
      "Training loss: 92.4297, Training accuracy: 0.8915\n",
      "Validation loss: 2.0794, Validation accuracy: 0.8685\n",
      "\n",
      "Epoch 96:\n",
      "Training loss: 92.4294, Training accuracy: 0.8932\n",
      "Validation loss: 2.0795, Validation accuracy: 0.8649\n",
      "\n",
      "Epoch 97:\n",
      "Training loss: 92.4295, Training accuracy: 0.8929\n",
      "Validation loss: 2.0793, Validation accuracy: 0.8698\n",
      "\n",
      "Epoch 98:\n",
      "Training loss: 92.4296, Training accuracy: 0.8932\n",
      "Validation loss: 2.0836, Validation accuracy: 0.8632\n",
      "\n",
      "Epoch 99:\n",
      "Training loss: 92.4294, Training accuracy: 0.8936\n",
      "Validation loss: 2.0781, Validation accuracy: 0.8674\n",
      "\n",
      "Epoch 100:\n",
      "Training loss: 92.4295, Training accuracy: 0.8945\n",
      "Validation loss: 2.0800, Validation accuracy: 0.8619\n",
      "\n",
      "Epoch 101:\n",
      "Training loss: 92.4296, Training accuracy: 0.8964\n",
      "Validation loss: 2.0733, Validation accuracy: 0.8669\n",
      "\n",
      "Epoch 102:\n",
      "Training loss: 92.4295, Training accuracy: 0.8960\n",
      "Validation loss: 2.0760, Validation accuracy: 0.8661\n",
      "\n",
      "Epoch 103:\n",
      "Training loss: 92.4295, Training accuracy: 0.8956\n",
      "Validation loss: 2.0728, Validation accuracy: 0.8661\n",
      "\n",
      "Epoch 104:\n",
      "Training loss: 92.4293, Training accuracy: 0.8949\n",
      "Validation loss: 2.0760, Validation accuracy: 0.8639\n",
      "\n",
      "Epoch 105:\n",
      "Training loss: 92.4295, Training accuracy: 0.8970\n",
      "Validation loss: 2.0751, Validation accuracy: 0.8684\n",
      "\n",
      "Epoch 106:\n",
      "Training loss: 92.4293, Training accuracy: 0.8967\n",
      "Validation loss: 2.0707, Validation accuracy: 0.8668\n",
      "\n",
      "Epoch 107:\n",
      "Training loss: 92.4293, Training accuracy: 0.8969\n",
      "Validation loss: 2.0786, Validation accuracy: 0.8654\n",
      "\n",
      "Epoch 108:\n",
      "Training loss: 92.4292, Training accuracy: 0.8971\n",
      "Validation loss: 2.0722, Validation accuracy: 0.8712\n",
      "Saving ...\n",
      "\n",
      "Epoch 109:\n",
      "Training loss: 92.4293, Training accuracy: 0.8982\n",
      "Validation loss: 2.0713, Validation accuracy: 0.8662\n",
      "\n",
      "Epoch 110:\n",
      "Training loss: 92.4293, Training accuracy: 0.8973\n",
      "Validation loss: 2.0798, Validation accuracy: 0.8686\n",
      "\n",
      "Epoch 111:\n",
      "Training loss: 92.4294, Training accuracy: 0.8982\n",
      "Validation loss: 2.0673, Validation accuracy: 0.8716\n",
      "Saving ...\n",
      "\n",
      "Epoch 112:\n",
      "Training loss: 92.4293, Training accuracy: 0.8990\n",
      "Validation loss: 2.0750, Validation accuracy: 0.8726\n",
      "Saving ...\n",
      "\n",
      "Epoch 113:\n",
      "Training loss: 92.4293, Training accuracy: 0.8987\n",
      "Validation loss: 2.0697, Validation accuracy: 0.8725\n",
      "\n",
      "Epoch 114:\n",
      "Training loss: 92.4294, Training accuracy: 0.8987\n",
      "Validation loss: 2.0779, Validation accuracy: 0.8652\n",
      "\n",
      "Epoch 115:\n",
      "Training loss: 92.4293, Training accuracy: 0.8990\n",
      "Validation loss: 2.0772, Validation accuracy: 0.8691\n",
      "\n",
      "Epoch 116:\n",
      "Training loss: 92.4292, Training accuracy: 0.8995\n",
      "Validation loss: 2.0797, Validation accuracy: 0.8700\n",
      "\n",
      "Epoch 117:\n",
      "Training loss: 92.4293, Training accuracy: 0.9004\n",
      "Validation loss: 2.0798, Validation accuracy: 0.8718\n",
      "\n",
      "Epoch 118:\n",
      "Training loss: 92.4291, Training accuracy: 0.8992\n",
      "Validation loss: 2.0757, Validation accuracy: 0.8745\n",
      "Saving ...\n",
      "\n",
      "Epoch 119:\n",
      "Training loss: 92.4291, Training accuracy: 0.8996\n",
      "Validation loss: 2.0739, Validation accuracy: 0.8702\n",
      "\n",
      "Epoch 120:\n",
      "Training loss: 92.4292, Training accuracy: 0.9002\n",
      "Validation loss: 2.0727, Validation accuracy: 0.8733\n",
      "\n",
      "Epoch 121:\n",
      "Training loss: 92.4291, Training accuracy: 0.9014\n",
      "Validation loss: 2.0763, Validation accuracy: 0.8713\n",
      "\n",
      "Epoch 122:\n",
      "Training loss: 92.4290, Training accuracy: 0.9018\n",
      "Validation loss: 2.0705, Validation accuracy: 0.8704\n",
      "\n",
      "Epoch 123:\n",
      "Training loss: 92.4291, Training accuracy: 0.9029\n",
      "Validation loss: 2.0773, Validation accuracy: 0.8719\n",
      "\n",
      "Epoch 124:\n",
      "Training loss: 92.4291, Training accuracy: 0.9019\n",
      "Validation loss: 2.0787, Validation accuracy: 0.8669\n",
      "\n",
      "Epoch 125:\n",
      "Training loss: 92.4291, Training accuracy: 0.9035\n",
      "Validation loss: 2.0710, Validation accuracy: 0.8754\n",
      "Saving ...\n",
      "\n",
      "Epoch 126:\n",
      "Training loss: 92.4291, Training accuracy: 0.9035\n",
      "Validation loss: 2.0761, Validation accuracy: 0.8734\n",
      "\n",
      "Epoch 127:\n",
      "Training loss: 92.4291, Training accuracy: 0.9037\n",
      "Validation loss: 2.0727, Validation accuracy: 0.8716\n",
      "\n",
      "Epoch 128:\n",
      "Training loss: 92.4291, Training accuracy: 0.9024\n",
      "Validation loss: 2.0712, Validation accuracy: 0.8707\n",
      "\n",
      "Epoch 129:\n",
      "Training loss: 92.4291, Training accuracy: 0.9042\n",
      "Validation loss: 2.0718, Validation accuracy: 0.8721\n",
      "\n",
      "Epoch 130:\n",
      "Training loss: 92.4290, Training accuracy: 0.9031\n",
      "Validation loss: 2.0772, Validation accuracy: 0.8765\n",
      "Saving ...\n",
      "\n",
      "Epoch 131:\n",
      "Training loss: 92.4288, Training accuracy: 0.9040\n",
      "Validation loss: 2.0784, Validation accuracy: 0.8712\n",
      "\n",
      "Epoch 132:\n",
      "Training loss: 92.4290, Training accuracy: 0.9040\n",
      "Validation loss: 2.0736, Validation accuracy: 0.8711\n",
      "\n",
      "Epoch 133:\n",
      "Training loss: 92.4289, Training accuracy: 0.9039\n",
      "Validation loss: 2.0730, Validation accuracy: 0.8702\n",
      "\n",
      "Epoch 134:\n",
      "Training loss: 92.4290, Training accuracy: 0.9037\n",
      "Validation loss: 2.0716, Validation accuracy: 0.8725\n",
      "\n",
      "Epoch 135:\n",
      "Training loss: 92.4290, Training accuracy: 0.9039\n",
      "Validation loss: 2.0780, Validation accuracy: 0.8753\n",
      "\n",
      "Epoch 136:\n",
      "Training loss: 92.4290, Training accuracy: 0.9063\n",
      "Validation loss: 2.0709, Validation accuracy: 0.8687\n",
      "\n",
      "Epoch 137:\n",
      "Training loss: 92.4289, Training accuracy: 0.9053\n",
      "Validation loss: 2.0775, Validation accuracy: 0.8687\n",
      "\n",
      "Epoch 138:\n",
      "Training loss: 92.4290, Training accuracy: 0.9061\n",
      "Validation loss: 2.0747, Validation accuracy: 0.8738\n",
      "\n",
      "Epoch 139:\n",
      "Training loss: 92.4290, Training accuracy: 0.9074\n",
      "Validation loss: 2.0713, Validation accuracy: 0.8770\n",
      "Saving ...\n",
      "\n",
      "Epoch 140:\n",
      "Training loss: 92.4288, Training accuracy: 0.9080\n",
      "Validation loss: 2.0716, Validation accuracy: 0.8686\n",
      "\n",
      "Epoch 141:\n",
      "Training loss: 92.4290, Training accuracy: 0.9059\n",
      "Validation loss: 2.0738, Validation accuracy: 0.8743\n",
      "\n",
      "Epoch 142:\n",
      "Training loss: 92.4288, Training accuracy: 0.9065\n",
      "Validation loss: 2.0708, Validation accuracy: 0.8762\n",
      "\n",
      "Epoch 143:\n",
      "Training loss: 92.4289, Training accuracy: 0.9074\n",
      "Validation loss: 2.0738, Validation accuracy: 0.8685\n",
      "\n",
      "Epoch 144:\n",
      "Training loss: 92.4289, Training accuracy: 0.9059\n",
      "Validation loss: 2.0720, Validation accuracy: 0.8735\n",
      "\n",
      "Epoch 145:\n",
      "Training loss: 92.4289, Training accuracy: 0.9052\n",
      "Validation loss: 2.0765, Validation accuracy: 0.8748\n",
      "\n",
      "Epoch 146:\n",
      "Training loss: 92.4287, Training accuracy: 0.9077\n",
      "Validation loss: 2.0761, Validation accuracy: 0.8759\n",
      "\n",
      "Epoch 147:\n",
      "Training loss: 92.4288, Training accuracy: 0.9077\n",
      "Validation loss: 2.0710, Validation accuracy: 0.8735\n",
      "\n",
      "Epoch 148:\n",
      "Training loss: 92.4288, Training accuracy: 0.9071\n",
      "Validation loss: 2.0776, Validation accuracy: 0.8764\n",
      "\n",
      "Epoch 149:\n",
      "Training loss: 92.4287, Training accuracy: 0.9070\n",
      "Validation loss: 2.0730, Validation accuracy: 0.8738\n",
      "\n",
      "Epoch 150:\n",
      "Training loss: 92.4289, Training accuracy: 0.9079\n",
      "Validation loss: 2.0766, Validation accuracy: 0.8711\n",
      "\n",
      "Epoch 151:\n",
      "Training loss: 92.4288, Training accuracy: 0.9088\n",
      "Validation loss: 2.0721, Validation accuracy: 0.8754\n",
      "\n",
      "Epoch 152:\n",
      "Training loss: 92.4288, Training accuracy: 0.9093\n",
      "Validation loss: 2.0699, Validation accuracy: 0.8764\n",
      "\n",
      "Epoch 153:\n",
      "Training loss: 92.4289, Training accuracy: 0.9086\n",
      "Validation loss: 2.0731, Validation accuracy: 0.8749\n",
      "\n",
      "Epoch 154:\n",
      "Training loss: 92.4288, Training accuracy: 0.9104\n",
      "Validation loss: 2.0734, Validation accuracy: 0.8774\n",
      "Saving ...\n",
      "\n",
      "Epoch 155:\n",
      "Training loss: 92.4287, Training accuracy: 0.9092\n",
      "Validation loss: 2.0740, Validation accuracy: 0.8741\n",
      "\n",
      "Epoch 156:\n",
      "Training loss: 92.4287, Training accuracy: 0.9091\n",
      "Validation loss: 2.0673, Validation accuracy: 0.8806\n",
      "Saving ...\n",
      "\n",
      "Epoch 157:\n",
      "Training loss: 92.4287, Training accuracy: 0.9098\n",
      "Validation loss: 2.0718, Validation accuracy: 0.8769\n",
      "\n",
      "Epoch 158:\n",
      "Training loss: 92.4289, Training accuracy: 0.9079\n",
      "Validation loss: 2.0770, Validation accuracy: 0.8733\n",
      "\n",
      "Epoch 159:\n",
      "Training loss: 92.4287, Training accuracy: 0.9085\n",
      "Validation loss: 2.0677, Validation accuracy: 0.8753\n",
      "\n",
      "Epoch 160:\n",
      "Training loss: 92.4287, Training accuracy: 0.9101\n",
      "Validation loss: 2.0712, Validation accuracy: 0.8755\n",
      "\n",
      "Epoch 161:\n",
      "Training loss: 92.4287, Training accuracy: 0.9101\n",
      "Validation loss: 2.0703, Validation accuracy: 0.8704\n",
      "\n",
      "Epoch 162:\n",
      "Training loss: 92.4287, Training accuracy: 0.9110\n",
      "Validation loss: 2.0723, Validation accuracy: 0.8681\n",
      "\n",
      "Epoch 163:\n",
      "Training loss: 92.4286, Training accuracy: 0.9112\n",
      "Validation loss: 2.0727, Validation accuracy: 0.8790\n",
      "\n",
      "Epoch 164:\n",
      "Training loss: 92.4287, Training accuracy: 0.9109\n",
      "Validation loss: 2.0724, Validation accuracy: 0.8727\n",
      "\n",
      "Epoch 165:\n",
      "Training loss: 92.4286, Training accuracy: 0.9103\n",
      "Validation loss: 2.0667, Validation accuracy: 0.8776\n",
      "\n",
      "Epoch 166:\n",
      "Training loss: 92.4288, Training accuracy: 0.9115\n",
      "Validation loss: 2.0711, Validation accuracy: 0.8737\n",
      "\n",
      "Epoch 167:\n",
      "Training loss: 92.4286, Training accuracy: 0.9106\n",
      "Validation loss: 2.0752, Validation accuracy: 0.8753\n",
      "\n",
      "Epoch 168:\n",
      "Training loss: 92.4286, Training accuracy: 0.9124\n",
      "Validation loss: 2.0690, Validation accuracy: 0.8775\n",
      "\n",
      "Epoch 169:\n",
      "Training loss: 92.4286, Training accuracy: 0.9120\n",
      "Validation loss: 2.0677, Validation accuracy: 0.8763\n",
      "\n",
      "Epoch 170:\n",
      "Training loss: 92.4285, Training accuracy: 0.9099\n",
      "Validation loss: 2.0718, Validation accuracy: 0.8754\n",
      "\n",
      "Epoch 171:\n",
      "Training loss: 92.4286, Training accuracy: 0.9117\n",
      "Validation loss: 2.0708, Validation accuracy: 0.8840\n",
      "Saving ...\n",
      "\n",
      "Epoch 172:\n",
      "Training loss: 92.4285, Training accuracy: 0.9125\n",
      "Validation loss: 2.0689, Validation accuracy: 0.8752\n",
      "\n",
      "Epoch 173:\n",
      "Training loss: 92.4285, Training accuracy: 0.9124\n",
      "Validation loss: 2.0774, Validation accuracy: 0.8752\n",
      "\n",
      "Epoch 174:\n",
      "Training loss: 92.4286, Training accuracy: 0.9108\n",
      "Validation loss: 2.0745, Validation accuracy: 0.8773\n",
      "\n",
      "Epoch 175:\n",
      "Training loss: 92.4286, Training accuracy: 0.9133\n",
      "Validation loss: 2.0768, Validation accuracy: 0.8709\n",
      "\n",
      "Epoch 176:\n",
      "Training loss: 92.4287, Training accuracy: 0.9130\n",
      "Validation loss: 2.0729, Validation accuracy: 0.8747\n",
      "\n",
      "Epoch 177:\n",
      "Training loss: 92.4285, Training accuracy: 0.9129\n",
      "Validation loss: 2.0719, Validation accuracy: 0.8759\n",
      "\n",
      "Epoch 178:\n",
      "Training loss: 92.4285, Training accuracy: 0.9140\n",
      "Validation loss: 2.0707, Validation accuracy: 0.8712\n",
      "\n",
      "Epoch 179:\n",
      "Training loss: 92.4285, Training accuracy: 0.9125\n",
      "Validation loss: 2.0692, Validation accuracy: 0.8771\n",
      "\n",
      "Epoch 180:\n",
      "Training loss: 92.4285, Training accuracy: 0.9130\n",
      "Validation loss: 2.0697, Validation accuracy: 0.8759\n",
      "\n",
      "Epoch 181:\n",
      "Training loss: 92.4285, Training accuracy: 0.9131\n",
      "Validation loss: 2.0707, Validation accuracy: 0.8701\n",
      "\n",
      "Epoch 182:\n",
      "Training loss: 92.4286, Training accuracy: 0.9144\n",
      "Validation loss: 2.0682, Validation accuracy: 0.8831\n",
      "\n",
      "Epoch 183:\n",
      "Training loss: 92.4285, Training accuracy: 0.9145\n",
      "Validation loss: 2.0713, Validation accuracy: 0.8732\n",
      "\n",
      "Epoch 184:\n",
      "Training loss: 92.4286, Training accuracy: 0.9124\n",
      "Validation loss: 2.0701, Validation accuracy: 0.8777\n",
      "\n",
      "Epoch 185:\n",
      "Training loss: 92.4284, Training accuracy: 0.9153\n",
      "Validation loss: 2.0717, Validation accuracy: 0.8753\n",
      "\n",
      "Epoch 186:\n",
      "Training loss: 92.4286, Training accuracy: 0.9130\n",
      "Validation loss: 2.0746, Validation accuracy: 0.8742\n",
      "\n",
      "Epoch 187:\n",
      "Training loss: 92.4285, Training accuracy: 0.9140\n",
      "Validation loss: 2.0725, Validation accuracy: 0.8777\n",
      "\n",
      "Epoch 188:\n",
      "Training loss: 92.4284, Training accuracy: 0.9143\n",
      "Validation loss: 2.0727, Validation accuracy: 0.8778\n",
      "\n",
      "Epoch 189:\n",
      "Training loss: 92.4285, Training accuracy: 0.9149\n",
      "Validation loss: 2.0719, Validation accuracy: 0.8780\n",
      "\n",
      "Epoch 190:\n",
      "Training loss: 92.4284, Training accuracy: 0.9158\n",
      "Validation loss: 2.0680, Validation accuracy: 0.8767\n",
      "\n",
      "Epoch 191:\n",
      "Training loss: 92.4285, Training accuracy: 0.9157\n",
      "Validation loss: 2.0715, Validation accuracy: 0.8776\n",
      "\n",
      "Epoch 192:\n",
      "Training loss: 92.4284, Training accuracy: 0.9161\n",
      "Validation loss: 2.0733, Validation accuracy: 0.8749\n",
      "\n",
      "Epoch 193:\n",
      "Training loss: 92.4284, Training accuracy: 0.9168\n",
      "Validation loss: 2.0707, Validation accuracy: 0.8754\n",
      "\n",
      "Epoch 194:\n",
      "Training loss: 92.4284, Training accuracy: 0.9153\n",
      "Validation loss: 2.0718, Validation accuracy: 0.8775\n",
      "\n",
      "Epoch 195:\n",
      "Training loss: 92.4284, Training accuracy: 0.9170\n",
      "Validation loss: 2.0754, Validation accuracy: 0.8825\n",
      "\n",
      "Epoch 196:\n",
      "Training loss: 92.4285, Training accuracy: 0.9162\n",
      "Validation loss: 2.0745, Validation accuracy: 0.8765\n",
      "\n",
      "Epoch 197:\n",
      "Training loss: 92.4284, Training accuracy: 0.9162\n",
      "Validation loss: 2.0714, Validation accuracy: 0.8789\n",
      "\n",
      "Epoch 198:\n",
      "Training loss: 92.4284, Training accuracy: 0.9171\n",
      "Validation loss: 2.0645, Validation accuracy: 0.8744\n",
      "\n",
      "Epoch 199:\n",
      "Training loss: 92.4284, Training accuracy: 0.9177\n",
      "Validation loss: 2.0727, Validation accuracy: 0.8813\n",
      "\n",
      "==================================================\n",
      "==> Optimization finished! Best validation accuracy: 0.8840\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.884"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train(student,teacher,optimizer,criterion,4,[0,0,1],1,train_loader,val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Training starts!\n",
      "==================================================\n",
      "Epoch 0:\n",
      "Training loss: 369.4914, Training accuracy: 0.3525\n",
      "Validation loss: 2.2486, Validation accuracy: 0.4358\n",
      "Saving ...\n",
      "\n",
      "Epoch 1:\n",
      "Training loss: 369.4879, Training accuracy: 0.4772\n",
      "Validation loss: 2.2339, Validation accuracy: 0.5185\n",
      "Saving ...\n",
      "\n",
      "Epoch 2:\n",
      "Training loss: 369.4867, Training accuracy: 0.5374\n",
      "Validation loss: 2.2169, Validation accuracy: 0.5455\n",
      "Saving ...\n",
      "\n",
      "Epoch 3:\n",
      "Training loss: 369.4859, Training accuracy: 0.5851\n",
      "Validation loss: 2.2086, Validation accuracy: 0.5941\n",
      "Saving ...\n",
      "\n",
      "Epoch 4:\n",
      "Training loss: 369.4853, Training accuracy: 0.6183\n",
      "Validation loss: 2.1956, Validation accuracy: 0.6325\n",
      "Saving ...\n",
      "\n",
      "Epoch 5:\n",
      "Training loss: 369.4847, Training accuracy: 0.6433\n",
      "Validation loss: 2.1948, Validation accuracy: 0.6543\n",
      "Saving ...\n",
      "\n",
      "Epoch 6:\n",
      "Training loss: 369.4843, Training accuracy: 0.6634\n",
      "Validation loss: 2.1902, Validation accuracy: 0.6625\n",
      "Saving ...\n",
      "\n",
      "Epoch 7:\n",
      "Training loss: 369.4838, Training accuracy: 0.6799\n",
      "Validation loss: 2.1838, Validation accuracy: 0.6824\n",
      "Saving ...\n",
      "\n",
      "Epoch 8:\n",
      "Training loss: 369.4835, Training accuracy: 0.6931\n",
      "Validation loss: 2.1827, Validation accuracy: 0.6851\n",
      "Saving ...\n",
      "\n",
      "Epoch 9:\n",
      "Training loss: 369.4833, Training accuracy: 0.7063\n",
      "Validation loss: 2.1755, Validation accuracy: 0.7052\n",
      "Saving ...\n",
      "\n",
      "Epoch 10:\n",
      "Training loss: 369.4831, Training accuracy: 0.7170\n",
      "Validation loss: 2.1764, Validation accuracy: 0.7130\n",
      "Saving ...\n",
      "\n",
      "Epoch 11:\n",
      "Training loss: 369.4828, Training accuracy: 0.7253\n",
      "Validation loss: 2.1722, Validation accuracy: 0.7185\n",
      "Saving ...\n",
      "\n",
      "Epoch 12:\n",
      "Training loss: 369.4827, Training accuracy: 0.7358\n",
      "Validation loss: 2.1669, Validation accuracy: 0.7257\n",
      "Saving ...\n",
      "\n",
      "Epoch 13:\n",
      "Training loss: 369.4824, Training accuracy: 0.7417\n",
      "Validation loss: 2.1694, Validation accuracy: 0.7290\n",
      "Saving ...\n",
      "\n",
      "Epoch 14:\n",
      "Training loss: 369.4822, Training accuracy: 0.7505\n",
      "Validation loss: 2.1682, Validation accuracy: 0.7392\n",
      "Saving ...\n",
      "\n",
      "Epoch 15:\n",
      "Training loss: 369.4821, Training accuracy: 0.7591\n",
      "Validation loss: 2.1626, Validation accuracy: 0.7438\n",
      "Saving ...\n",
      "\n",
      "Epoch 16:\n",
      "Training loss: 369.4819, Training accuracy: 0.7651\n",
      "Validation loss: 2.1602, Validation accuracy: 0.7407\n",
      "\n",
      "Epoch 17:\n",
      "Training loss: 369.4818, Training accuracy: 0.7724\n",
      "Validation loss: 2.1628, Validation accuracy: 0.7662\n",
      "Saving ...\n",
      "\n",
      "Epoch 18:\n",
      "Training loss: 369.4816, Training accuracy: 0.7762\n",
      "Validation loss: 2.1582, Validation accuracy: 0.7752\n",
      "Saving ...\n",
      "\n",
      "Epoch 19:\n",
      "Training loss: 369.4814, Training accuracy: 0.7815\n",
      "Validation loss: 2.1555, Validation accuracy: 0.7721\n",
      "\n",
      "Epoch 20:\n",
      "Training loss: 369.4813, Training accuracy: 0.7865\n",
      "Validation loss: 2.1511, Validation accuracy: 0.7816\n",
      "Saving ...\n",
      "\n",
      "Epoch 21:\n",
      "Training loss: 369.4813, Training accuracy: 0.7907\n",
      "Validation loss: 2.1541, Validation accuracy: 0.7822\n",
      "Saving ...\n",
      "\n",
      "Epoch 22:\n",
      "Training loss: 369.4811, Training accuracy: 0.7951\n",
      "Validation loss: 2.1504, Validation accuracy: 0.7958\n",
      "Saving ...\n",
      "\n",
      "Epoch 23:\n",
      "Training loss: 369.4811, Training accuracy: 0.7967\n",
      "Validation loss: 2.1508, Validation accuracy: 0.7899\n",
      "\n",
      "Epoch 24:\n",
      "Training loss: 369.4809, Training accuracy: 0.8009\n",
      "Validation loss: 2.1523, Validation accuracy: 0.7913\n",
      "\n",
      "Epoch 25:\n",
      "Training loss: 369.4809, Training accuracy: 0.8032\n",
      "Validation loss: 2.1458, Validation accuracy: 0.7965\n",
      "Saving ...\n",
      "\n",
      "Epoch 26:\n",
      "Training loss: 369.4807, Training accuracy: 0.8073\n",
      "Validation loss: 2.1423, Validation accuracy: 0.8001\n",
      "Saving ...\n",
      "\n",
      "Epoch 27:\n",
      "Training loss: 369.4807, Training accuracy: 0.8110\n",
      "Validation loss: 2.1431, Validation accuracy: 0.8076\n",
      "Saving ...\n",
      "\n",
      "Epoch 28:\n",
      "Training loss: 369.4805, Training accuracy: 0.8132\n",
      "Validation loss: 2.1432, Validation accuracy: 0.8054\n",
      "\n",
      "Epoch 29:\n",
      "Training loss: 369.4805, Training accuracy: 0.8160\n",
      "Validation loss: 2.1439, Validation accuracy: 0.8092\n",
      "Saving ...\n",
      "\n",
      "Epoch 30:\n",
      "Training loss: 369.4805, Training accuracy: 0.8195\n",
      "Validation loss: 2.1430, Validation accuracy: 0.8049\n",
      "\n",
      "Epoch 31:\n",
      "Training loss: 369.4804, Training accuracy: 0.8201\n",
      "Validation loss: 2.1423, Validation accuracy: 0.8074\n",
      "\n",
      "Epoch 32:\n",
      "Training loss: 369.4804, Training accuracy: 0.8235\n",
      "Validation loss: 2.1408, Validation accuracy: 0.8045\n",
      "\n",
      "Epoch 33:\n",
      "Training loss: 369.4803, Training accuracy: 0.8249\n",
      "Validation loss: 2.1383, Validation accuracy: 0.8154\n",
      "Saving ...\n",
      "\n",
      "Epoch 34:\n",
      "Training loss: 369.4802, Training accuracy: 0.8274\n",
      "Validation loss: 2.1387, Validation accuracy: 0.8219\n",
      "Saving ...\n",
      "\n",
      "Epoch 35:\n",
      "Training loss: 369.4802, Training accuracy: 0.8268\n",
      "Validation loss: 2.1359, Validation accuracy: 0.8189\n",
      "\n",
      "Epoch 36:\n",
      "Training loss: 369.4801, Training accuracy: 0.8295\n",
      "Validation loss: 2.1398, Validation accuracy: 0.8137\n",
      "\n",
      "Epoch 37:\n",
      "Training loss: 369.4801, Training accuracy: 0.8316\n",
      "Validation loss: 2.1331, Validation accuracy: 0.8184\n",
      "\n",
      "Epoch 38:\n",
      "Training loss: 369.4800, Training accuracy: 0.8335\n",
      "Validation loss: 2.1348, Validation accuracy: 0.8205\n",
      "\n",
      "Epoch 39:\n",
      "Training loss: 369.4800, Training accuracy: 0.8333\n",
      "Validation loss: 2.1356, Validation accuracy: 0.8219\n",
      "\n",
      "Epoch 40:\n",
      "Training loss: 369.4800, Training accuracy: 0.8368\n",
      "Validation loss: 2.1342, Validation accuracy: 0.8313\n",
      "Saving ...\n",
      "\n",
      "Epoch 41:\n",
      "Training loss: 369.4799, Training accuracy: 0.8386\n",
      "Validation loss: 2.1400, Validation accuracy: 0.8189\n",
      "\n",
      "Epoch 42:\n",
      "Training loss: 369.4798, Training accuracy: 0.8399\n",
      "Validation loss: 2.1353, Validation accuracy: 0.8229\n",
      "\n",
      "Epoch 43:\n",
      "Training loss: 369.4798, Training accuracy: 0.8407\n",
      "Validation loss: 2.1324, Validation accuracy: 0.8276\n",
      "\n",
      "Epoch 44:\n",
      "Training loss: 369.4797, Training accuracy: 0.8437\n",
      "Validation loss: 2.1338, Validation accuracy: 0.8338\n",
      "Saving ...\n",
      "\n",
      "Epoch 45:\n",
      "Training loss: 369.4797, Training accuracy: 0.8440\n",
      "Validation loss: 2.1345, Validation accuracy: 0.8303\n",
      "\n",
      "Epoch 46:\n",
      "Training loss: 369.4796, Training accuracy: 0.8455\n",
      "Validation loss: 2.1333, Validation accuracy: 0.8348\n",
      "Saving ...\n",
      "\n",
      "Epoch 47:\n",
      "Training loss: 369.4796, Training accuracy: 0.8460\n",
      "Validation loss: 2.1336, Validation accuracy: 0.8267\n",
      "\n",
      "Epoch 48:\n",
      "Training loss: 369.4796, Training accuracy: 0.8489\n",
      "Validation loss: 2.1322, Validation accuracy: 0.8369\n",
      "Saving ...\n",
      "\n",
      "Epoch 49:\n",
      "Training loss: 369.4795, Training accuracy: 0.8491\n",
      "Validation loss: 2.1316, Validation accuracy: 0.8379\n",
      "Saving ...\n",
      "\n",
      "Epoch 50:\n",
      "Training loss: 369.4795, Training accuracy: 0.8488\n",
      "Validation loss: 2.1320, Validation accuracy: 0.8325\n",
      "\n",
      "Epoch 51:\n",
      "Training loss: 369.4795, Training accuracy: 0.8503\n",
      "Validation loss: 2.1340, Validation accuracy: 0.8303\n",
      "\n",
      "Epoch 52:\n",
      "Training loss: 369.4796, Training accuracy: 0.8522\n",
      "Validation loss: 2.1279, Validation accuracy: 0.8411\n",
      "Saving ...\n",
      "\n",
      "Epoch 53:\n",
      "Training loss: 369.4794, Training accuracy: 0.8528\n",
      "Validation loss: 2.1332, Validation accuracy: 0.8429\n",
      "Saving ...\n",
      "\n",
      "Epoch 54:\n",
      "Training loss: 369.4794, Training accuracy: 0.8539\n",
      "Validation loss: 2.1319, Validation accuracy: 0.8377\n",
      "\n",
      "Epoch 55:\n",
      "Training loss: 369.4794, Training accuracy: 0.8559\n",
      "Validation loss: 2.1351, Validation accuracy: 0.8381\n",
      "\n",
      "Epoch 56:\n",
      "Training loss: 369.4794, Training accuracy: 0.8547\n",
      "Validation loss: 2.1267, Validation accuracy: 0.8416\n",
      "\n",
      "Epoch 57:\n",
      "Training loss: 369.4793, Training accuracy: 0.8579\n",
      "Validation loss: 2.1269, Validation accuracy: 0.8420\n",
      "\n",
      "Epoch 58:\n",
      "Training loss: 369.4793, Training accuracy: 0.8583\n",
      "Validation loss: 2.1318, Validation accuracy: 0.8301\n",
      "\n",
      "Epoch 59:\n",
      "Training loss: 369.4793, Training accuracy: 0.8600\n",
      "Validation loss: 2.1319, Validation accuracy: 0.8435\n",
      "Saving ...\n",
      "\n",
      "Epoch 60:\n",
      "Training loss: 369.4792, Training accuracy: 0.8593\n",
      "Validation loss: 2.1296, Validation accuracy: 0.8394\n",
      "\n",
      "Epoch 61:\n",
      "Training loss: 369.4792, Training accuracy: 0.8616\n",
      "Validation loss: 2.1312, Validation accuracy: 0.8416\n",
      "\n",
      "Epoch 62:\n",
      "Training loss: 369.4792, Training accuracy: 0.8611\n",
      "Validation loss: 2.1259, Validation accuracy: 0.8463\n",
      "Saving ...\n",
      "\n",
      "Epoch 63:\n",
      "Training loss: 369.4791, Training accuracy: 0.8631\n",
      "Validation loss: 2.1320, Validation accuracy: 0.8431\n",
      "\n",
      "Epoch 64:\n",
      "Training loss: 369.4791, Training accuracy: 0.8630\n",
      "Validation loss: 2.1279, Validation accuracy: 0.8430\n",
      "\n",
      "Epoch 65:\n",
      "Training loss: 369.4791, Training accuracy: 0.8655\n",
      "Validation loss: 2.1316, Validation accuracy: 0.8425\n",
      "\n",
      "Epoch 66:\n",
      "Training loss: 369.4792, Training accuracy: 0.8647\n",
      "Validation loss: 2.1291, Validation accuracy: 0.8370\n",
      "\n",
      "Epoch 67:\n",
      "Training loss: 369.4791, Training accuracy: 0.8663\n",
      "Validation loss: 2.1352, Validation accuracy: 0.8343\n",
      "\n",
      "Epoch 68:\n",
      "Training loss: 369.4790, Training accuracy: 0.8676\n",
      "Validation loss: 2.1229, Validation accuracy: 0.8504\n",
      "Saving ...\n",
      "\n",
      "Epoch 69:\n",
      "Training loss: 369.4790, Training accuracy: 0.8669\n",
      "Validation loss: 2.1260, Validation accuracy: 0.8526\n",
      "Saving ...\n",
      "\n",
      "Epoch 70:\n",
      "Training loss: 369.4790, Training accuracy: 0.8686\n",
      "Validation loss: 2.1281, Validation accuracy: 0.8428\n",
      "\n",
      "Epoch 71:\n",
      "Training loss: 369.4789, Training accuracy: 0.8688\n",
      "Validation loss: 2.1257, Validation accuracy: 0.8529\n",
      "Saving ...\n",
      "\n",
      "Epoch 72:\n",
      "Training loss: 369.4790, Training accuracy: 0.8697\n",
      "Validation loss: 2.1241, Validation accuracy: 0.8483\n",
      "\n",
      "Epoch 73:\n",
      "Training loss: 369.4790, Training accuracy: 0.8709\n",
      "Validation loss: 2.1263, Validation accuracy: 0.8530\n",
      "Saving ...\n",
      "\n",
      "Epoch 74:\n",
      "Training loss: 369.4789, Training accuracy: 0.8720\n",
      "Validation loss: 2.1282, Validation accuracy: 0.8517\n",
      "\n",
      "Epoch 75:\n",
      "Training loss: 369.4789, Training accuracy: 0.8718\n",
      "Validation loss: 2.1236, Validation accuracy: 0.8541\n",
      "Saving ...\n",
      "\n",
      "Epoch 76:\n",
      "Training loss: 369.4789, Training accuracy: 0.8737\n",
      "Validation loss: 2.1241, Validation accuracy: 0.8501\n",
      "\n",
      "Epoch 77:\n",
      "Training loss: 369.4789, Training accuracy: 0.8737\n",
      "Validation loss: 2.1235, Validation accuracy: 0.8468\n",
      "\n",
      "Epoch 78:\n",
      "Training loss: 369.4788, Training accuracy: 0.8740\n",
      "Validation loss: 2.1254, Validation accuracy: 0.8529\n",
      "\n",
      "Epoch 79:\n",
      "Training loss: 369.4789, Training accuracy: 0.8761\n",
      "Validation loss: 2.1214, Validation accuracy: 0.8574\n",
      "Saving ...\n",
      "\n",
      "Epoch 80:\n",
      "Training loss: 369.4788, Training accuracy: 0.8753\n",
      "Validation loss: 2.1221, Validation accuracy: 0.8532\n",
      "\n",
      "Epoch 81:\n",
      "Training loss: 369.4788, Training accuracy: 0.8764\n",
      "Validation loss: 2.1285, Validation accuracy: 0.8450\n",
      "\n",
      "Epoch 82:\n",
      "Training loss: 369.4788, Training accuracy: 0.8770\n",
      "Validation loss: 2.1239, Validation accuracy: 0.8531\n",
      "\n",
      "Epoch 83:\n",
      "Training loss: 369.4788, Training accuracy: 0.8768\n",
      "Validation loss: 2.1292, Validation accuracy: 0.8520\n",
      "\n",
      "Epoch 84:\n",
      "Training loss: 369.4788, Training accuracy: 0.8780\n",
      "Validation loss: 2.1237, Validation accuracy: 0.8492\n",
      "\n",
      "Epoch 85:\n",
      "Training loss: 369.4788, Training accuracy: 0.8776\n",
      "Validation loss: 2.1252, Validation accuracy: 0.8502\n",
      "\n",
      "Epoch 86:\n",
      "Training loss: 369.4788, Training accuracy: 0.8779\n",
      "Validation loss: 2.1292, Validation accuracy: 0.8496\n",
      "\n",
      "Epoch 87:\n",
      "Training loss: 369.4787, Training accuracy: 0.8795\n",
      "Validation loss: 2.1264, Validation accuracy: 0.8466\n",
      "\n",
      "Epoch 88:\n",
      "Training loss: 369.4788, Training accuracy: 0.8799\n",
      "Validation loss: 2.1228, Validation accuracy: 0.8571\n",
      "\n",
      "Epoch 89:\n",
      "Training loss: 369.4787, Training accuracy: 0.8796\n",
      "Validation loss: 2.1224, Validation accuracy: 0.8574\n",
      "\n",
      "Epoch 90:\n",
      "Training loss: 369.4787, Training accuracy: 0.8808\n",
      "Validation loss: 2.1251, Validation accuracy: 0.8590\n",
      "Saving ...\n",
      "\n",
      "Epoch 91:\n",
      "Training loss: 369.4787, Training accuracy: 0.8810\n",
      "Validation loss: 2.1209, Validation accuracy: 0.8539\n",
      "\n",
      "Epoch 92:\n",
      "Training loss: 369.4787, Training accuracy: 0.8802\n",
      "Validation loss: 2.1230, Validation accuracy: 0.8591\n",
      "Saving ...\n",
      "\n",
      "Epoch 93:\n",
      "Training loss: 369.4786, Training accuracy: 0.8806\n",
      "Validation loss: 2.1222, Validation accuracy: 0.8556\n",
      "\n",
      "Epoch 94:\n",
      "Training loss: 369.4787, Training accuracy: 0.8801\n",
      "Validation loss: 2.1249, Validation accuracy: 0.8545\n",
      "\n",
      "Epoch 95:\n",
      "Training loss: 369.4786, Training accuracy: 0.8833\n",
      "Validation loss: 2.1221, Validation accuracy: 0.8589\n",
      "\n",
      "Epoch 96:\n",
      "Training loss: 369.4786, Training accuracy: 0.8843\n",
      "Validation loss: 2.1243, Validation accuracy: 0.8535\n",
      "\n",
      "Epoch 97:\n",
      "Training loss: 369.4786, Training accuracy: 0.8836\n",
      "Validation loss: 2.1284, Validation accuracy: 0.8558\n",
      "\n",
      "Epoch 98:\n",
      "Training loss: 369.4786, Training accuracy: 0.8834\n",
      "Validation loss: 2.1245, Validation accuracy: 0.8518\n",
      "\n",
      "Epoch 99:\n",
      "Training loss: 369.4786, Training accuracy: 0.8828\n",
      "Validation loss: 2.1213, Validation accuracy: 0.8596\n",
      "Saving ...\n",
      "\n",
      "Epoch 100:\n",
      "Training loss: 369.4786, Training accuracy: 0.8847\n",
      "Validation loss: 2.1214, Validation accuracy: 0.8581\n",
      "\n",
      "Epoch 101:\n",
      "Training loss: 369.4785, Training accuracy: 0.8874\n",
      "Validation loss: 2.1235, Validation accuracy: 0.8587\n",
      "\n",
      "Epoch 102:\n",
      "Training loss: 369.4785, Training accuracy: 0.8857\n",
      "Validation loss: 2.1205, Validation accuracy: 0.8607\n",
      "Saving ...\n",
      "\n",
      "Epoch 103:\n",
      "Training loss: 369.4784, Training accuracy: 0.8862\n",
      "Validation loss: 2.1217, Validation accuracy: 0.8628\n",
      "Saving ...\n",
      "\n",
      "Epoch 104:\n",
      "Training loss: 369.4785, Training accuracy: 0.8836\n",
      "Validation loss: 2.1256, Validation accuracy: 0.8584\n",
      "\n",
      "Epoch 105:\n",
      "Training loss: 369.4785, Training accuracy: 0.8874\n",
      "Validation loss: 2.1214, Validation accuracy: 0.8641\n",
      "Saving ...\n",
      "\n",
      "Epoch 106:\n",
      "Training loss: 369.4785, Training accuracy: 0.8886\n",
      "Validation loss: 2.1223, Validation accuracy: 0.8597\n",
      "\n",
      "Epoch 107:\n",
      "Training loss: 369.4784, Training accuracy: 0.8886\n",
      "Validation loss: 2.1229, Validation accuracy: 0.8621\n",
      "\n",
      "Epoch 108:\n",
      "Training loss: 369.4785, Training accuracy: 0.8855\n",
      "Validation loss: 2.1258, Validation accuracy: 0.8600\n",
      "\n",
      "Epoch 109:\n",
      "Training loss: 369.4785, Training accuracy: 0.8895\n",
      "Validation loss: 2.1217, Validation accuracy: 0.8600\n",
      "\n",
      "Epoch 110:\n",
      "Training loss: 369.4784, Training accuracy: 0.8895\n",
      "Validation loss: 2.1213, Validation accuracy: 0.8644\n",
      "Saving ...\n",
      "\n",
      "Epoch 111:\n",
      "Training loss: 369.4784, Training accuracy: 0.8902\n",
      "Validation loss: 2.1209, Validation accuracy: 0.8617\n",
      "\n",
      "Epoch 112:\n",
      "Training loss: 369.4784, Training accuracy: 0.8914\n",
      "Validation loss: 2.1192, Validation accuracy: 0.8616\n",
      "\n",
      "Epoch 113:\n",
      "Training loss: 369.4784, Training accuracy: 0.8909\n",
      "Validation loss: 2.1225, Validation accuracy: 0.8613\n",
      "\n",
      "Epoch 114:\n",
      "Training loss: 369.4784, Training accuracy: 0.8914\n",
      "Validation loss: 2.1177, Validation accuracy: 0.8646\n",
      "Saving ...\n",
      "\n",
      "Epoch 115:\n",
      "Training loss: 369.4784, Training accuracy: 0.8901\n",
      "Validation loss: 2.1221, Validation accuracy: 0.8656\n",
      "Saving ...\n",
      "\n",
      "Epoch 116:\n",
      "Training loss: 369.4784, Training accuracy: 0.8908\n",
      "Validation loss: 2.1268, Validation accuracy: 0.8601\n",
      "\n",
      "Epoch 117:\n",
      "Training loss: 369.4784, Training accuracy: 0.8918\n",
      "Validation loss: 2.1256, Validation accuracy: 0.8644\n",
      "\n",
      "Epoch 118:\n",
      "Training loss: 369.4783, Training accuracy: 0.8930\n",
      "Validation loss: 2.1230, Validation accuracy: 0.8642\n",
      "\n",
      "Epoch 119:\n",
      "Training loss: 369.4784, Training accuracy: 0.8923\n",
      "Validation loss: 2.1222, Validation accuracy: 0.8627\n",
      "\n",
      "Epoch 120:\n",
      "Training loss: 369.4784, Training accuracy: 0.8933\n",
      "Validation loss: 2.1231, Validation accuracy: 0.8673\n",
      "Saving ...\n",
      "\n",
      "Epoch 121:\n",
      "Training loss: 369.4783, Training accuracy: 0.8918\n",
      "Validation loss: 2.1306, Validation accuracy: 0.8527\n",
      "\n",
      "Epoch 122:\n",
      "Training loss: 369.4784, Training accuracy: 0.8938\n",
      "Validation loss: 2.1199, Validation accuracy: 0.8669\n",
      "\n",
      "Epoch 123:\n",
      "Training loss: 369.4783, Training accuracy: 0.8928\n",
      "Validation loss: 2.1245, Validation accuracy: 0.8656\n",
      "\n",
      "Epoch 124:\n",
      "Training loss: 369.4783, Training accuracy: 0.8930\n",
      "Validation loss: 2.1201, Validation accuracy: 0.8614\n",
      "\n",
      "Epoch 125:\n",
      "Training loss: 369.4783, Training accuracy: 0.8951\n",
      "Validation loss: 2.1210, Validation accuracy: 0.8665\n",
      "\n",
      "Epoch 126:\n",
      "Training loss: 369.4783, Training accuracy: 0.8939\n",
      "Validation loss: 2.1184, Validation accuracy: 0.8606\n",
      "\n",
      "Epoch 127:\n",
      "Training loss: 369.4783, Training accuracy: 0.8947\n",
      "Validation loss: 2.1255, Validation accuracy: 0.8639\n",
      "\n",
      "Epoch 128:\n",
      "Training loss: 369.4783, Training accuracy: 0.8956\n",
      "Validation loss: 2.1224, Validation accuracy: 0.8587\n",
      "\n",
      "Epoch 129:\n",
      "Training loss: 369.4783, Training accuracy: 0.8964\n",
      "Validation loss: 2.1226, Validation accuracy: 0.8650\n",
      "\n",
      "Epoch 130:\n",
      "Training loss: 369.4782, Training accuracy: 0.8983\n",
      "Validation loss: 2.1240, Validation accuracy: 0.8657\n",
      "\n",
      "Epoch 131:\n",
      "Training loss: 369.4782, Training accuracy: 0.8981\n",
      "Validation loss: 2.1228, Validation accuracy: 0.8681\n",
      "Saving ...\n",
      "\n",
      "Epoch 132:\n",
      "Training loss: 369.4783, Training accuracy: 0.8956\n",
      "Validation loss: 2.1243, Validation accuracy: 0.8643\n",
      "\n",
      "Epoch 133:\n",
      "Training loss: 369.4783, Training accuracy: 0.8970\n",
      "Validation loss: 2.1203, Validation accuracy: 0.8632\n",
      "\n",
      "Epoch 134:\n",
      "Training loss: 369.4783, Training accuracy: 0.8982\n",
      "Validation loss: 2.1221, Validation accuracy: 0.8691\n",
      "Saving ...\n",
      "\n",
      "Epoch 135:\n",
      "Training loss: 369.4782, Training accuracy: 0.8977\n",
      "Validation loss: 2.1284, Validation accuracy: 0.8639\n",
      "\n",
      "Epoch 136:\n",
      "Training loss: 369.4783, Training accuracy: 0.8954\n",
      "Validation loss: 2.1245, Validation accuracy: 0.8618\n",
      "\n",
      "Epoch 137:\n",
      "Training loss: 369.4782, Training accuracy: 0.8964\n",
      "Validation loss: 2.1213, Validation accuracy: 0.8710\n",
      "Saving ...\n",
      "\n",
      "Epoch 138:\n",
      "Training loss: 369.4782, Training accuracy: 0.8989\n",
      "Validation loss: 2.1212, Validation accuracy: 0.8648\n",
      "\n",
      "Epoch 139:\n",
      "Training loss: 369.4782, Training accuracy: 0.8994\n",
      "Validation loss: 2.1219, Validation accuracy: 0.8692\n",
      "\n",
      "Epoch 140:\n",
      "Training loss: 369.4781, Training accuracy: 0.8994\n",
      "Validation loss: 2.1213, Validation accuracy: 0.8680\n",
      "\n",
      "Epoch 141:\n",
      "Training loss: 369.4782, Training accuracy: 0.8991\n",
      "Validation loss: 2.1209, Validation accuracy: 0.8662\n",
      "\n",
      "Epoch 142:\n",
      "Training loss: 369.4782, Training accuracy: 0.8980\n",
      "Validation loss: 2.1189, Validation accuracy: 0.8602\n",
      "\n",
      "Epoch 143:\n",
      "Training loss: 369.4782, Training accuracy: 0.8980\n",
      "Validation loss: 2.1229, Validation accuracy: 0.8672\n",
      "\n",
      "Epoch 144:\n",
      "Training loss: 369.4781, Training accuracy: 0.8983\n",
      "Validation loss: 2.1232, Validation accuracy: 0.8725\n",
      "Saving ...\n",
      "\n",
      "Epoch 145:\n",
      "Training loss: 369.4782, Training accuracy: 0.9006\n",
      "Validation loss: 2.1199, Validation accuracy: 0.8693\n",
      "\n",
      "Epoch 146:\n",
      "Training loss: 369.4782, Training accuracy: 0.9007\n",
      "Validation loss: 2.1219, Validation accuracy: 0.8684\n",
      "\n",
      "Epoch 147:\n",
      "Training loss: 369.4782, Training accuracy: 0.9007\n",
      "Validation loss: 2.1205, Validation accuracy: 0.8686\n",
      "\n",
      "Epoch 148:\n",
      "Training loss: 369.4782, Training accuracy: 0.8997\n",
      "Validation loss: 2.1168, Validation accuracy: 0.8698\n",
      "\n",
      "Epoch 149:\n",
      "Training loss: 369.4781, Training accuracy: 0.9008\n",
      "Validation loss: 2.1229, Validation accuracy: 0.8683\n",
      "\n",
      "Epoch 150:\n",
      "Training loss: 369.4782, Training accuracy: 0.9004\n",
      "Validation loss: 2.1200, Validation accuracy: 0.8671\n",
      "\n",
      "Epoch 151:\n",
      "Training loss: 369.4781, Training accuracy: 0.9025\n",
      "Validation loss: 2.1226, Validation accuracy: 0.8659\n",
      "\n",
      "Epoch 152:\n",
      "Training loss: 369.4781, Training accuracy: 0.9007\n",
      "Validation loss: 2.1247, Validation accuracy: 0.8594\n",
      "\n",
      "Epoch 153:\n",
      "Training loss: 369.4781, Training accuracy: 0.9005\n",
      "Validation loss: 2.1210, Validation accuracy: 0.8690\n",
      "\n",
      "Epoch 154:\n",
      "Training loss: 369.4781, Training accuracy: 0.9012\n",
      "Validation loss: 2.1196, Validation accuracy: 0.8696\n",
      "\n",
      "Epoch 155:\n",
      "Training loss: 369.4781, Training accuracy: 0.9028\n",
      "Validation loss: 2.1222, Validation accuracy: 0.8676\n",
      "\n",
      "Epoch 156:\n",
      "Training loss: 369.4781, Training accuracy: 0.9017\n",
      "Validation loss: 2.1180, Validation accuracy: 0.8606\n",
      "\n",
      "Epoch 157:\n",
      "Training loss: 369.4781, Training accuracy: 0.9038\n",
      "Validation loss: 2.1241, Validation accuracy: 0.8640\n",
      "\n",
      "Epoch 158:\n",
      "Training loss: 369.4780, Training accuracy: 0.9041\n",
      "Validation loss: 2.1154, Validation accuracy: 0.8702\n",
      "\n",
      "Epoch 159:\n",
      "Training loss: 369.4781, Training accuracy: 0.9036\n",
      "Validation loss: 2.1228, Validation accuracy: 0.8657\n",
      "\n",
      "Epoch 160:\n",
      "Training loss: 369.4781, Training accuracy: 0.9021\n",
      "Validation loss: 2.1222, Validation accuracy: 0.8691\n",
      "\n",
      "Epoch 161:\n",
      "Training loss: 369.4781, Training accuracy: 0.9020\n",
      "Validation loss: 2.1196, Validation accuracy: 0.8680\n",
      "\n",
      "Epoch 162:\n",
      "Training loss: 369.4781, Training accuracy: 0.9024\n",
      "Validation loss: 2.1251, Validation accuracy: 0.8709\n",
      "\n",
      "Epoch 163:\n",
      "Training loss: 369.4780, Training accuracy: 0.9052\n",
      "Validation loss: 2.1168, Validation accuracy: 0.8648\n",
      "\n",
      "Epoch 164:\n",
      "Training loss: 369.4780, Training accuracy: 0.9053\n",
      "Validation loss: 2.1179, Validation accuracy: 0.8703\n",
      "\n",
      "Epoch 165:\n",
      "Training loss: 369.4780, Training accuracy: 0.9034\n",
      "Validation loss: 2.1184, Validation accuracy: 0.8715\n",
      "\n",
      "Epoch 166:\n",
      "Training loss: 369.4780, Training accuracy: 0.9059\n",
      "Validation loss: 2.1205, Validation accuracy: 0.8619\n",
      "\n",
      "Epoch 167:\n",
      "Training loss: 369.4781, Training accuracy: 0.9055\n",
      "Validation loss: 2.1235, Validation accuracy: 0.8698\n",
      "\n",
      "Epoch 168:\n",
      "Training loss: 369.4780, Training accuracy: 0.9056\n",
      "Validation loss: 2.1205, Validation accuracy: 0.8696\n",
      "\n",
      "Epoch 169:\n",
      "Training loss: 369.4780, Training accuracy: 0.9071\n",
      "Validation loss: 2.1197, Validation accuracy: 0.8677\n",
      "\n",
      "Epoch 170:\n",
      "Training loss: 369.4780, Training accuracy: 0.9061\n",
      "Validation loss: 2.1202, Validation accuracy: 0.8682\n",
      "\n",
      "Epoch 171:\n",
      "Training loss: 369.4780, Training accuracy: 0.9082\n",
      "Validation loss: 2.1198, Validation accuracy: 0.8699\n",
      "\n",
      "Epoch 172:\n",
      "Training loss: 369.4780, Training accuracy: 0.9067\n",
      "Validation loss: 2.1229, Validation accuracy: 0.8676\n",
      "\n",
      "Epoch 173:\n",
      "Training loss: 369.4780, Training accuracy: 0.9070\n",
      "Validation loss: 2.1192, Validation accuracy: 0.8673\n",
      "\n",
      "Epoch 174:\n",
      "Training loss: 369.4779, Training accuracy: 0.9068\n",
      "Validation loss: 2.1204, Validation accuracy: 0.8700\n",
      "\n",
      "Epoch 175:\n",
      "Training loss: 369.4780, Training accuracy: 0.9075\n",
      "Validation loss: 2.1230, Validation accuracy: 0.8688\n",
      "\n",
      "Epoch 176:\n",
      "Training loss: 369.4779, Training accuracy: 0.9075\n",
      "Validation loss: 2.1170, Validation accuracy: 0.8685\n",
      "\n",
      "Epoch 177:\n",
      "Training loss: 369.4779, Training accuracy: 0.9087\n",
      "Validation loss: 2.1221, Validation accuracy: 0.8712\n",
      "\n",
      "Epoch 178:\n",
      "Training loss: 369.4780, Training accuracy: 0.9069\n",
      "Validation loss: 2.1207, Validation accuracy: 0.8691\n",
      "\n",
      "Epoch 179:\n",
      "Training loss: 369.4780, Training accuracy: 0.9087\n",
      "Validation loss: 2.1214, Validation accuracy: 0.8740\n",
      "Saving ...\n",
      "\n",
      "Epoch 180:\n",
      "Training loss: 369.4780, Training accuracy: 0.9088\n",
      "Validation loss: 2.1180, Validation accuracy: 0.8674\n",
      "\n",
      "Epoch 181:\n",
      "Training loss: 369.4780, Training accuracy: 0.9076\n",
      "Validation loss: 2.1194, Validation accuracy: 0.8724\n",
      "\n",
      "Epoch 182:\n",
      "Training loss: 369.4780, Training accuracy: 0.9094\n",
      "Validation loss: 2.1158, Validation accuracy: 0.8707\n",
      "\n",
      "Epoch 183:\n",
      "Training loss: 369.4779, Training accuracy: 0.9099\n",
      "Validation loss: 2.1178, Validation accuracy: 0.8676\n",
      "\n",
      "Epoch 184:\n",
      "Training loss: 369.4779, Training accuracy: 0.9094\n",
      "Validation loss: 2.1203, Validation accuracy: 0.8703\n",
      "\n",
      "Epoch 185:\n",
      "Training loss: 369.4780, Training accuracy: 0.9084\n",
      "Validation loss: 2.1196, Validation accuracy: 0.8686\n",
      "\n",
      "Epoch 186:\n",
      "Training loss: 369.4779, Training accuracy: 0.9106\n",
      "Validation loss: 2.1207, Validation accuracy: 0.8717\n",
      "\n",
      "Epoch 187:\n",
      "Training loss: 369.4780, Training accuracy: 0.9095\n",
      "Validation loss: 2.1233, Validation accuracy: 0.8659\n",
      "\n",
      "Epoch 188:\n",
      "Training loss: 369.4779, Training accuracy: 0.9101\n",
      "Validation loss: 2.1207, Validation accuracy: 0.8712\n",
      "\n",
      "Epoch 189:\n",
      "Training loss: 369.4779, Training accuracy: 0.9078\n",
      "Validation loss: 2.1217, Validation accuracy: 0.8689\n",
      "\n",
      "Epoch 190:\n",
      "Training loss: 369.4779, Training accuracy: 0.9099\n",
      "Validation loss: 2.1182, Validation accuracy: 0.8720\n",
      "\n",
      "Epoch 191:\n",
      "Training loss: 369.4779, Training accuracy: 0.9091\n",
      "Validation loss: 2.1233, Validation accuracy: 0.8738\n",
      "\n",
      "Epoch 192:\n",
      "Training loss: 369.4779, Training accuracy: 0.9100\n",
      "Validation loss: 2.1210, Validation accuracy: 0.8702\n",
      "\n",
      "Epoch 193:\n",
      "Training loss: 369.4779, Training accuracy: 0.9114\n",
      "Validation loss: 2.1196, Validation accuracy: 0.8724\n",
      "\n",
      "Epoch 194:\n",
      "Training loss: 369.4779, Training accuracy: 0.9110\n",
      "Validation loss: 2.1210, Validation accuracy: 0.8690\n",
      "\n",
      "Epoch 195:\n",
      "Training loss: 369.4779, Training accuracy: 0.9107\n",
      "Validation loss: 2.1204, Validation accuracy: 0.8713\n",
      "\n",
      "Epoch 196:\n",
      "Training loss: 369.4779, Training accuracy: 0.9112\n",
      "Validation loss: 2.1195, Validation accuracy: 0.8713\n",
      "\n",
      "Epoch 197:\n",
      "Training loss: 369.4779, Training accuracy: 0.9114\n",
      "Validation loss: 2.1217, Validation accuracy: 0.8686\n",
      "\n",
      "Epoch 198:\n",
      "Training loss: 369.4779, Training accuracy: 0.9116\n",
      "Validation loss: 2.1166, Validation accuracy: 0.8786\n",
      "Saving ...\n",
      "\n",
      "Epoch 199:\n",
      "Training loss: 369.4778, Training accuracy: 0.9126\n",
      "Validation loss: 2.1196, Validation accuracy: 0.8749\n",
      "\n",
      "==================================================\n",
      "==> Optimization finished! Best validation accuracy: 0.8786\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8786"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train(student,teacher,optimizer,criterion,8,[0,0,1],1,train_loader,val_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "55f20d8859a1a0149f7d957af872e078c8283691172f5ca78f1d0b16a2e38dc4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
